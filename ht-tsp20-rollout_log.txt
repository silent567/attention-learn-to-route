231


{'baseline': 'rollout',
 'batch_size': 512,
 'bl_alpha': 0.05,
 'bl_warmup_epochs': 1,
 'checkpoint_encoder': False,
 'checkpoint_epochs': 1,
 'data_distribution': None,
 'embedding_dim': 128,
 'epoch_size': 1280000,
 'epoch_start': 0,
 'eval_batch_size': 1024,
 'eval_only': False,
 'exp_beta': 0.8,
 'graph_size': 20,
 'hidden_dim': 128,
 'load_path': None,
 'log_dir': 'logs',
 'log_step': 50,
 'lr_critic': 0.0001,
 'lr_decay': 1.0,
 'lr_model': 0.0001,
 'max_grad_norm': 1.0,
 'model': 'attention',
 'n_encode_layers': 3,
 'n_epochs': 100,
 'no_cuda': False,
 'no_progress_bar': False,
 'no_tensorboard': False,
 'normalization': 'batch',
 'output_dir': 'outputs',
 'problem': 'tsp',
 'resume': None,
 'run_name': 'tsp20_rollout_20200202T054904',
 'save_dir': 'outputs/tsp_20/tsp20_rollout_20200202T054904',
 'seed': 1234,
 'shrink_size': None,
 'tanh_clipping': 10.0,
 'use_cuda': True,
 'val_dataset': None,
 'val_size': 10000}
Evaluating baseline model on evaluation dataset
Start train epoch 0, lr=0.0001 for run tsp20_rollout_20200202T054904
314


314


314


314


157


epoch: 0, train_batch_id: 0, avg_cost: 10.302109718322754
grad_norm: 14.661965988459876, clipped: 1.0
epoch: 0, train_batch_id: 50, avg_cost: 5.068170547485352
grad_norm: 2.637641852029331, clipped: 1.0
epoch: 0, train_batch_id: 100, avg_cost: 4.674012184143066
grad_norm: 3.1166047598672457, clipped: 1.0
epoch: 0, train_batch_id: 150, avg_cost: 4.610166549682617
grad_norm: 3.9368161467452505, clipped: 1.0
epoch: 0, train_batch_id: 200, avg_cost: 4.46515417098999
grad_norm: 2.4855782109410343, clipped: 1.0
epoch: 0, train_batch_id: 250, avg_cost: 4.3825249671936035
grad_norm: 3.562083246471151, clipped: 1.0
epoch: 0, train_batch_id: 300, avg_cost: 4.3410234451293945
grad_norm: 2.520922071266519, clipped: 1.0
epoch: 0, train_batch_id: 350, avg_cost: 4.311078071594238
grad_norm: 2.8679562804640075, clipped: 1.0
epoch: 0, train_batch_id: 400, avg_cost: 4.318769454956055
grad_norm: 3.5741121269498755, clipped: 1.0
epoch: 0, train_batch_id: 450, avg_cost: 4.263648986816406
grad_norm: 2.63241873984906, clipped: 1.0
epoch: 0, train_batch_id: 500, avg_cost: 4.197294235229492
grad_norm: 2.8787506622792756, clipped: 1.0
epoch: 0, train_batch_id: 550, avg_cost: 4.213512420654297
grad_norm: 3.3187638327190583, clipped: 1.0
epoch: 0, train_batch_id: 600, avg_cost: 4.190698623657227
grad_norm: 3.262894545062054, clipped: 1.0
epoch: 0, train_batch_id: 650, avg_cost: 4.169388771057129
grad_norm: 3.182241276844242, clipped: 1.0
epoch: 0, train_batch_id: 700, avg_cost: 4.147503852844238
grad_norm: 2.753079746949266, clipped: 1.0
epoch: 0, train_batch_id: 750, avg_cost: 4.162441253662109
grad_norm: 2.7206606960835753, clipped: 1.0
epoch: 0, train_batch_id: 800, avg_cost: 4.118983268737793
grad_norm: 3.6059027094339298, clipped: 1.0
epoch: 0, train_batch_id: 850, avg_cost: 4.167819023132324
grad_norm: 3.0442678943286494, clipped: 1.0
epoch: 0, train_batch_id: 900, avg_cost: 4.088559627532959
grad_norm: 2.9219261744062135, clipped: 1.0
epoch: 0, train_batch_id: 950, avg_cost: 4.101634979248047
grad_norm: 3.576332594621621, clipped: 1.0
epoch: 0, train_batch_id: 1000, avg_cost: 4.072154998779297
grad_norm: 2.3520084252074915, clipped: 1.0
epoch: 0, train_batch_id: 1050, avg_cost: 4.084125995635986
grad_norm: 2.383675099519111, clipped: 1.0
epoch: 0, train_batch_id: 1100, avg_cost: 4.102660179138184
grad_norm: 2.92890530291231, clipped: 1.0
epoch: 0, train_batch_id: 1150, avg_cost: 4.047767639160156
grad_norm: 2.6326626366039734, clipped: 1.0
epoch: 0, train_batch_id: 1200, avg_cost: 4.079342365264893
grad_norm: 5.181981901554272, clipped: 1.0
epoch: 0, train_batch_id: 1250, avg_cost: 4.071049690246582
grad_norm: 2.771997057932639, clipped: 1.0
epoch: 0, train_batch_id: 1300, avg_cost: 4.068023681640625
grad_norm: 2.4149043706706634, clipped: 1.0
epoch: 0, train_batch_id: 1350, avg_cost: 4.030348777770996
grad_norm: 2.4534472213663685, clipped: 1.0
epoch: 0, train_batch_id: 1400, avg_cost: 4.029243469238281
grad_norm: 2.261551917261022, clipped: 1.0
epoch: 0, train_batch_id: 1450, avg_cost: 4.076530933380127
grad_norm: 2.8777751892249377, clipped: 1.0
epoch: 0, train_batch_id: 1500, avg_cost: 4.033234119415283
grad_norm: 2.5726400047256526, clipped: 1.0
epoch: 0, train_batch_id: 1550, avg_cost: 4.045125961303711
grad_norm: 2.9822416966603607, clipped: 1.0
epoch: 0, train_batch_id: 1600, avg_cost: 4.02764368057251
grad_norm: 2.703265317971822, clipped: 1.0
epoch: 0, train_batch_id: 1650, avg_cost: 4.007829666137695
grad_norm: 2.556458912135702, clipped: 1.0
epoch: 0, train_batch_id: 1700, avg_cost: 4.057440280914307
grad_norm: 2.812927186305259, clipped: 1.0
epoch: 0, train_batch_id: 1750, avg_cost: 4.034294128417969
grad_norm: 2.543302856993778, clipped: 1.0
epoch: 0, train_batch_id: 1800, avg_cost: 4.013092517852783
grad_norm: 2.284905898506567, clipped: 1.0
epoch: 0, train_batch_id: 1850, avg_cost: 3.991424560546875
grad_norm: 2.1202858146381462, clipped: 1.0
epoch: 0, train_batch_id: 1900, avg_cost: 4.015902519226074
grad_norm: 2.1231759791983045, clipped: 1.0
epoch: 0, train_batch_id: 1950, avg_cost: 4.044251441955566
grad_norm: 2.991399504654288, clipped: 1.0
epoch: 0, train_batch_id: 2000, avg_cost: 4.022397041320801
grad_norm: 3.1322044802802567, clipped: 1.0
epoch: 0, train_batch_id: 2050, avg_cost: 4.006528854370117
grad_norm: 2.5542063798190227, clipped: 1.0
epoch: 0, train_batch_id: 2100, avg_cost: 4.010509490966797
grad_norm: 2.0610240348583035, clipped: 1.0
epoch: 0, train_batch_id: 2150, avg_cost: 4.0262041091918945
grad_norm: 2.9393597051728655, clipped: 1.0
epoch: 0, train_batch_id: 2200, avg_cost: 4.000176906585693
grad_norm: 2.512350152054672, clipped: 1.0
epoch: 0, train_batch_id: 2250, avg_cost: 3.998258590698242
grad_norm: 2.3068024958624176, clipped: 1.0
epoch: 0, train_batch_id: 2300, avg_cost: 3.9953932762145996
grad_norm: 3.967332337434803, clipped: 1.0
epoch: 0, train_batch_id: 2350, avg_cost: 4.03623104095459
grad_norm: 1.7727854967018497, clipped: 1.0
epoch: 0, train_batch_id: 2400, avg_cost: 3.981377601623535
grad_norm: 2.403710321385674, clipped: 1.0
epoch: 0, train_batch_id: 2450, avg_cost: 4.019196510314941
grad_norm: 5.103397918349736, clipped: 1.0
Finished epoch 0, took 00:04:28 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.9808645248413086 +- 0.0034883120097219944
Evaluating candidate model on evaluation dataset
Epoch 0 candidate mean 3.979048728942871, baseline epoch 0 mean 7.416231155395508, difference -3.4371824264526367
p-value: 0.0
Update baseline
Evaluating baseline model on evaluation dataset
Set warmup alpha = 1.0
Start train epoch 1, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 1, train_batch_id: 0, avg_cost: 4.0045485496521
grad_norm: 2.0215010355543592, clipped: 1.0
epoch: 1, train_batch_id: 50, avg_cost: 3.990175247192383
grad_norm: 1.0612482626933344, clipped: 1.0
epoch: 1, train_batch_id: 100, avg_cost: 3.977095365524292
grad_norm: 1.54427639413293, clipped: 1.0
epoch: 1, train_batch_id: 150, avg_cost: 4.001414775848389
grad_norm: 1.1834391718031303, clipped: 1.0
epoch: 1, train_batch_id: 200, avg_cost: 3.9908652305603027
grad_norm: 2.0408319544411015, clipped: 1.0
epoch: 1, train_batch_id: 250, avg_cost: 3.9359772205352783
grad_norm: 1.0762527565821736, clipped: 1.0
epoch: 1, train_batch_id: 300, avg_cost: 3.970418691635132
grad_norm: 1.7962174702617202, clipped: 1.0
epoch: 1, train_batch_id: 350, avg_cost: 3.960188388824463
grad_norm: 1.2305728014961186, clipped: 1.0
epoch: 1, train_batch_id: 400, avg_cost: 3.9473977088928223
grad_norm: 1.537419935438827, clipped: 1.0
epoch: 1, train_batch_id: 450, avg_cost: 3.980107069015503
grad_norm: 1.2395837700048005, clipped: 1.0
epoch: 1, train_batch_id: 500, avg_cost: 3.9868171215057373
grad_norm: 1.1143749418649183, clipped: 1.0
epoch: 1, train_batch_id: 550, avg_cost: 3.9669671058654785
grad_norm: 1.3233770261101978, clipped: 1.0
epoch: 1, train_batch_id: 600, avg_cost: 3.944222927093506
grad_norm: 1.0313097242636051, clipped: 1.0
epoch: 1, train_batch_id: 650, avg_cost: 3.9411463737487793
grad_norm: 1.3567037343766506, clipped: 1.0
epoch: 1, train_batch_id: 700, avg_cost: 3.9405789375305176
grad_norm: 1.1000490488693815, clipped: 1.0
epoch: 1, train_batch_id: 750, avg_cost: 3.9686083793640137
grad_norm: 1.1616969887311432, clipped: 1.0
epoch: 1, train_batch_id: 800, avg_cost: 3.9679782390594482
grad_norm: 2.1307565218369255, clipped: 1.0
epoch: 1, train_batch_id: 850, avg_cost: 3.9533753395080566
grad_norm: 1.0236942986749367, clipped: 1.0
epoch: 1, train_batch_id: 900, avg_cost: 3.933349132537842
grad_norm: 1.207853784208589, clipped: 1.0
epoch: 1, train_batch_id: 950, avg_cost: 3.9474058151245117
grad_norm: 1.0489331745635013, clipped: 1.0
epoch: 1, train_batch_id: 1000, avg_cost: 3.9790239334106445
grad_norm: 1.6369650842158772, clipped: 1.0
epoch: 1, train_batch_id: 1050, avg_cost: 3.9523279666900635
grad_norm: 1.042828394976482, clipped: 1.0
epoch: 1, train_batch_id: 1100, avg_cost: 3.9280600547790527
grad_norm: 1.4702246767603993, clipped: 1.0
epoch: 1, train_batch_id: 1150, avg_cost: 3.9495906829833984
grad_norm: 1.2844149523964228, clipped: 1.0
epoch: 1, train_batch_id: 1200, avg_cost: 3.92771053314209
grad_norm: 1.204563148055492, clipped: 1.0
epoch: 1, train_batch_id: 1250, avg_cost: 3.9398105144500732
grad_norm: 1.1217075847887634, clipped: 1.0
epoch: 1, train_batch_id: 1300, avg_cost: 3.954221248626709
grad_norm: 2.7300463317086003, clipped: 1.0
epoch: 1, train_batch_id: 1350, avg_cost: 3.9537439346313477
grad_norm: 1.5442800997753368, clipped: 1.0
epoch: 1, train_batch_id: 1400, avg_cost: 3.9206507205963135
grad_norm: 1.2007694341569908, clipped: 1.0
epoch: 1, train_batch_id: 1450, avg_cost: 3.9372215270996094
grad_norm: 1.3662462610071129, clipped: 1.0
epoch: 1, train_batch_id: 1500, avg_cost: 3.950744152069092
grad_norm: 1.2408731967658186, clipped: 1.0
epoch: 1, train_batch_id: 1550, avg_cost: 3.9198973178863525
grad_norm: 1.557936897691298, clipped: 1.0
epoch: 1, train_batch_id: 1600, avg_cost: 3.928149938583374
grad_norm: 1.0555047369579493, clipped: 1.0
epoch: 1, train_batch_id: 1650, avg_cost: 3.9441113471984863
grad_norm: 1.2260929418328048, clipped: 1.0
epoch: 1, train_batch_id: 1700, avg_cost: 3.937037467956543
grad_norm: 1.0698250214635494, clipped: 1.0
epoch: 1, train_batch_id: 1750, avg_cost: 3.958035945892334
grad_norm: 1.2632475690116842, clipped: 1.0
epoch: 1, train_batch_id: 1800, avg_cost: 3.932466506958008
grad_norm: 1.4291826201102158, clipped: 1.0
epoch: 1, train_batch_id: 1850, avg_cost: 3.94130277633667
grad_norm: 1.2111571649090904, clipped: 1.0
epoch: 1, train_batch_id: 1900, avg_cost: 3.9352102279663086
grad_norm: 1.3057344964293758, clipped: 1.0
epoch: 1, train_batch_id: 1950, avg_cost: 3.9343955516815186
grad_norm: 1.4531193423088757, clipped: 1.0
epoch: 1, train_batch_id: 2000, avg_cost: 3.9130399227142334
grad_norm: 1.3353043907365088, clipped: 1.0
epoch: 1, train_batch_id: 2050, avg_cost: 3.9186882972717285
grad_norm: 1.29601484530416, clipped: 1.0
epoch: 1, train_batch_id: 2100, avg_cost: 3.9148142337799072
grad_norm: 0.9744600844522495, clipped: 0.9744600844522495
epoch: 1, train_batch_id: 2150, avg_cost: 3.921597957611084
grad_norm: 1.174266761336911, clipped: 1.0
epoch: 1, train_batch_id: 2200, avg_cost: 3.950073719024658
grad_norm: 1.1101511254998055, clipped: 1.0
epoch: 1, train_batch_id: 2250, avg_cost: 3.9242465496063232
grad_norm: 1.1911485740040955, clipped: 1.0
epoch: 1, train_batch_id: 2300, avg_cost: 3.947749376296997
grad_norm: 1.6866610449919437, clipped: 1.0
epoch: 1, train_batch_id: 2350, avg_cost: 3.9351682662963867
grad_norm: 2.2340613289775577, clipped: 1.0
epoch: 1, train_batch_id: 2400, avg_cost: 3.910051107406616
grad_norm: 1.1553674783257264, clipped: 1.0
epoch: 1, train_batch_id: 2450, avg_cost: 3.9399116039276123
grad_norm: 1.3731318476137375, clipped: 1.0
Finished epoch 1, took 00:05:36 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.916588306427002 +- 0.0033180760219693184
Evaluating candidate model on evaluation dataset
Epoch 1 candidate mean 3.9155051708221436, baseline epoch 0 mean 3.9791789054870605, difference -0.06367373466491699
p-value: 0.0
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 2, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 2, train_batch_id: 0, avg_cost: 3.9315853118896484
grad_norm: 0.832884642921724, clipped: 0.832884642921724
epoch: 2, train_batch_id: 50, avg_cost: 3.9310617446899414
grad_norm: 0.7798035169400274, clipped: 0.7798035169400274
epoch: 2, train_batch_id: 100, avg_cost: 3.9420111179351807
grad_norm: 1.1696544056508584, clipped: 1.0
epoch: 2, train_batch_id: 150, avg_cost: 3.92881178855896
grad_norm: 0.9518044533040825, clipped: 0.9518044533040825
epoch: 2, train_batch_id: 200, avg_cost: 3.9266698360443115
grad_norm: 1.4008236504709621, clipped: 1.0
epoch: 2, train_batch_id: 250, avg_cost: 3.9283299446105957
grad_norm: 1.4622065654454035, clipped: 1.0
epoch: 2, train_batch_id: 300, avg_cost: 3.946446418762207
grad_norm: 0.7662311726212455, clipped: 0.7662311726212455
epoch: 2, train_batch_id: 350, avg_cost: 3.9106221199035645
grad_norm: 0.6886025094728356, clipped: 0.6886025094728356
epoch: 2, train_batch_id: 400, avg_cost: 3.91892409324646
grad_norm: 1.3894538925851614, clipped: 1.0
epoch: 2, train_batch_id: 450, avg_cost: 3.894490957260132
grad_norm: 0.9294937388978753, clipped: 0.9294937388978753
epoch: 2, train_batch_id: 500, avg_cost: 3.943352222442627
grad_norm: 1.6059799359704723, clipped: 1.0
epoch: 2, train_batch_id: 550, avg_cost: 3.9154529571533203
grad_norm: 1.230921234122339, clipped: 1.0
epoch: 2, train_batch_id: 600, avg_cost: 3.927687168121338
grad_norm: 0.6882510601008592, clipped: 0.6882510601008592
epoch: 2, train_batch_id: 650, avg_cost: 3.9032459259033203
grad_norm: 1.1216372832716441, clipped: 1.0
epoch: 2, train_batch_id: 700, avg_cost: 3.923652172088623
grad_norm: 0.6531695808741008, clipped: 0.6531695808741008
epoch: 2, train_batch_id: 750, avg_cost: 3.927056074142456
grad_norm: 0.7112413960853564, clipped: 0.7112413960853564
epoch: 2, train_batch_id: 800, avg_cost: 3.9248175621032715
grad_norm: 1.118010355346139, clipped: 1.0
epoch: 2, train_batch_id: 850, avg_cost: 3.8995089530944824
grad_norm: 0.8540055385320071, clipped: 0.8540055385320071
epoch: 2, train_batch_id: 900, avg_cost: 3.91374135017395
grad_norm: 0.7438399197101708, clipped: 0.7438399197101708
epoch: 2, train_batch_id: 950, avg_cost: 3.9169325828552246
grad_norm: 1.0591707423839798, clipped: 1.0
epoch: 2, train_batch_id: 1000, avg_cost: 3.9068198204040527
grad_norm: 1.0273937189552387, clipped: 1.0
epoch: 2, train_batch_id: 1050, avg_cost: 3.9237232208251953
grad_norm: 1.1822723778409057, clipped: 1.0
epoch: 2, train_batch_id: 1100, avg_cost: 3.905886173248291
grad_norm: 1.1847226760341527, clipped: 1.0
epoch: 2, train_batch_id: 1150, avg_cost: 3.91678524017334
grad_norm: 1.2213221892437627, clipped: 1.0
epoch: 2, train_batch_id: 1200, avg_cost: 3.8849353790283203
grad_norm: 0.9614268840416279, clipped: 0.9614268840416279
epoch: 2, train_batch_id: 1250, avg_cost: 3.9042670726776123
grad_norm: 0.6636390171446901, clipped: 0.6636390171446901
epoch: 2, train_batch_id: 1300, avg_cost: 3.9047951698303223
grad_norm: 0.7250310722857095, clipped: 0.7250310722857095
epoch: 2, train_batch_id: 1350, avg_cost: 3.9180455207824707
grad_norm: 1.0170456449221879, clipped: 1.0
epoch: 2, train_batch_id: 1400, avg_cost: 3.915055751800537
grad_norm: 0.8082089962751853, clipped: 0.8082089962751853
epoch: 2, train_batch_id: 1450, avg_cost: 3.892331600189209
grad_norm: 1.1049090625794862, clipped: 1.0
epoch: 2, train_batch_id: 1500, avg_cost: 3.8925867080688477
grad_norm: 1.0734009366704373, clipped: 1.0
epoch: 2, train_batch_id: 1550, avg_cost: 3.924992084503174
grad_norm: 1.8525680196500642, clipped: 1.0
epoch: 2, train_batch_id: 1600, avg_cost: 3.9286375045776367
grad_norm: 0.7272344678475716, clipped: 0.7272344678475716
epoch: 2, train_batch_id: 1650, avg_cost: 3.9308314323425293
grad_norm: 0.9388221510097184, clipped: 0.9388221510097184
epoch: 2, train_batch_id: 1700, avg_cost: 3.9253103733062744
grad_norm: 1.5649404990683435, clipped: 1.0
epoch: 2, train_batch_id: 1750, avg_cost: 3.888002395629883
grad_norm: 1.30490254856237, clipped: 1.0
epoch: 2, train_batch_id: 1800, avg_cost: 3.9367222785949707
grad_norm: 1.3451672195104016, clipped: 1.0
epoch: 2, train_batch_id: 1850, avg_cost: 3.918546676635742
grad_norm: 0.9022928097732664, clipped: 0.9022928097732664
epoch: 2, train_batch_id: 1900, avg_cost: 3.8967809677124023
grad_norm: 0.8104787081149125, clipped: 0.8104787081149125
epoch: 2, train_batch_id: 1950, avg_cost: 3.900604248046875
grad_norm: 1.0769364552348824, clipped: 1.0
epoch: 2, train_batch_id: 2000, avg_cost: 3.9086825847625732
grad_norm: 1.0219306555445087, clipped: 1.0
epoch: 2, train_batch_id: 2050, avg_cost: 3.912734031677246
grad_norm: 1.963266043680263, clipped: 1.0
epoch: 2, train_batch_id: 2100, avg_cost: 3.9068446159362793
grad_norm: 0.9058644932839819, clipped: 0.9058644932839819
epoch: 2, train_batch_id: 2150, avg_cost: 3.89652419090271
grad_norm: 0.962687021953355, clipped: 0.962687021953355
epoch: 2, train_batch_id: 2200, avg_cost: 3.89219331741333
grad_norm: 1.1579905517941738, clipped: 1.0
epoch: 2, train_batch_id: 2250, avg_cost: 3.914175033569336
grad_norm: 1.0608828231888634, clipped: 1.0
epoch: 2, train_batch_id: 2300, avg_cost: 3.882935047149658
grad_norm: 0.8503600025848412, clipped: 0.8503600025848412
epoch: 2, train_batch_id: 2350, avg_cost: 3.91685152053833
grad_norm: 0.8438369282359588, clipped: 0.8438369282359588
epoch: 2, train_batch_id: 2400, avg_cost: 3.903407573699951
grad_norm: 1.1196009857993874, clipped: 1.0
epoch: 2, train_batch_id: 2450, avg_cost: 3.91312313079834
grad_norm: 1.006149878820892, clipped: 1.0
Finished epoch 2, took 00:05:36 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8948633670806885 +- 0.0032416635658591986
Evaluating candidate model on evaluation dataset
Epoch 2 candidate mean 3.890911817550659, baseline epoch 1 mean 3.912935972213745, difference -0.022024154663085938
p-value: 8.901976708691202e-150
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 3, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 3, train_batch_id: 0, avg_cost: 3.9191079139709473
grad_norm: 0.8529825217082473, clipped: 0.8529825217082473
epoch: 3, train_batch_id: 50, avg_cost: 3.903531074523926
grad_norm: 0.9594827417940097, clipped: 0.9594827417940097
epoch: 3, train_batch_id: 100, avg_cost: 3.8997511863708496
grad_norm: 0.6494298636597239, clipped: 0.6494298636597239
epoch: 3, train_batch_id: 150, avg_cost: 3.891908645629883
grad_norm: 0.979581573709628, clipped: 0.979581573709628
epoch: 3, train_batch_id: 200, avg_cost: 3.912132501602173
grad_norm: 1.2187892941679048, clipped: 1.0
epoch: 3, train_batch_id: 250, avg_cost: 3.8846380710601807
grad_norm: 0.8730174401003458, clipped: 0.8730174401003458
epoch: 3, train_batch_id: 300, avg_cost: 3.8892040252685547
grad_norm: 0.9017028024727247, clipped: 0.9017028024727247
epoch: 3, train_batch_id: 350, avg_cost: 3.879148006439209
grad_norm: 0.9666963647942343, clipped: 0.9666963647942343
epoch: 3, train_batch_id: 400, avg_cost: 3.9089138507843018
grad_norm: 0.9476588296690572, clipped: 0.9476588296690572
epoch: 3, train_batch_id: 450, avg_cost: 3.8907296657562256
grad_norm: 0.6638314268717761, clipped: 0.6638314268717761
epoch: 3, train_batch_id: 500, avg_cost: 3.888023614883423
grad_norm: 0.958690330415541, clipped: 0.958690330415541
epoch: 3, train_batch_id: 550, avg_cost: 3.888155937194824
grad_norm: 0.7410534482488731, clipped: 0.7410534482488731
epoch: 3, train_batch_id: 600, avg_cost: 3.8787567615509033
grad_norm: 0.9163294100832112, clipped: 0.9163294100832112
epoch: 3, train_batch_id: 650, avg_cost: 3.892148017883301
grad_norm: 0.8516162863305612, clipped: 0.8516162863305612
epoch: 3, train_batch_id: 700, avg_cost: 3.9026498794555664
grad_norm: 0.9353337527163139, clipped: 0.9353337527163139
epoch: 3, train_batch_id: 750, avg_cost: 3.896538257598877
grad_norm: 0.8209035687007743, clipped: 0.8209035687007743
epoch: 3, train_batch_id: 800, avg_cost: 3.911893844604492
grad_norm: 0.7305591953749767, clipped: 0.7305591953749767
epoch: 3, train_batch_id: 850, avg_cost: 3.8983983993530273
grad_norm: 1.6002062057868591, clipped: 1.0
epoch: 3, train_batch_id: 900, avg_cost: 3.892848014831543
grad_norm: 0.7286713636031209, clipped: 0.7286713636031209
epoch: 3, train_batch_id: 950, avg_cost: 3.9261293411254883
grad_norm: 0.9619403557904932, clipped: 0.9619403557904932
epoch: 3, train_batch_id: 1000, avg_cost: 3.8992979526519775
grad_norm: 1.0906963691116895, clipped: 1.0
epoch: 3, train_batch_id: 1050, avg_cost: 3.894338846206665
grad_norm: 0.8566507835581701, clipped: 0.8566507835581701
epoch: 3, train_batch_id: 1100, avg_cost: 3.8573391437530518
grad_norm: 1.0270476689943662, clipped: 1.0
epoch: 3, train_batch_id: 1150, avg_cost: 3.8993968963623047
grad_norm: 0.6940756929267472, clipped: 0.6940756929267472
epoch: 3, train_batch_id: 1200, avg_cost: 3.878140449523926
grad_norm: 0.7609168424912253, clipped: 0.7609168424912253
epoch: 3, train_batch_id: 1250, avg_cost: 3.9275660514831543
grad_norm: 0.7667773914285217, clipped: 0.7667773914285217
epoch: 3, train_batch_id: 1300, avg_cost: 3.9119739532470703
grad_norm: 0.6975802988461144, clipped: 0.6975802988461144
epoch: 3, train_batch_id: 1350, avg_cost: 3.899869680404663
grad_norm: 0.6951282903296775, clipped: 0.6951282903296775
epoch: 3, train_batch_id: 1400, avg_cost: 3.870906352996826
grad_norm: 1.4485645745564113, clipped: 1.0
epoch: 3, train_batch_id: 1450, avg_cost: 3.8945164680480957
grad_norm: 0.8285312866248146, clipped: 0.8285312866248146
epoch: 3, train_batch_id: 1500, avg_cost: 3.938002824783325
grad_norm: 0.6249481907264137, clipped: 0.6249481907264137
epoch: 3, train_batch_id: 1550, avg_cost: 3.882319450378418
grad_norm: 0.9903640345595419, clipped: 0.9903640345595419
epoch: 3, train_batch_id: 1600, avg_cost: 3.9148292541503906
grad_norm: 1.257773546542797, clipped: 1.0
epoch: 3, train_batch_id: 1650, avg_cost: 3.904435634613037
grad_norm: 0.9165581314626778, clipped: 0.9165581314626778
epoch: 3, train_batch_id: 1700, avg_cost: 3.8704004287719727
grad_norm: 0.8319775374471926, clipped: 0.8319775374471926
epoch: 3, train_batch_id: 1750, avg_cost: 3.9085536003112793
grad_norm: 1.3729700189456318, clipped: 1.0
epoch: 3, train_batch_id: 1800, avg_cost: 3.8990142345428467
grad_norm: 0.7602898281662709, clipped: 0.7602898281662709
epoch: 3, train_batch_id: 1850, avg_cost: 3.9027316570281982
grad_norm: 1.0555714767927056, clipped: 1.0
epoch: 3, train_batch_id: 1900, avg_cost: 3.8742618560791016
grad_norm: 0.7108138367509048, clipped: 0.7108138367509048
epoch: 3, train_batch_id: 1950, avg_cost: 3.871919631958008
grad_norm: 0.7609119031690201, clipped: 0.7609119031690201
epoch: 3, train_batch_id: 2000, avg_cost: 3.889676332473755
grad_norm: 0.7481428784033118, clipped: 0.7481428784033118
epoch: 3, train_batch_id: 2050, avg_cost: 3.9098305702209473
grad_norm: 1.278061745003509, clipped: 1.0
epoch: 3, train_batch_id: 2100, avg_cost: 3.9316725730895996
grad_norm: 0.9266761903157192, clipped: 0.9266761903157192
epoch: 3, train_batch_id: 2150, avg_cost: 3.914630889892578
grad_norm: 1.3902751669481812, clipped: 1.0
epoch: 3, train_batch_id: 2200, avg_cost: 3.869393825531006
grad_norm: 0.8768249738286159, clipped: 0.8768249738286159
epoch: 3, train_batch_id: 2250, avg_cost: 3.89275860786438
grad_norm: 0.8902933298319571, clipped: 0.8902933298319571
epoch: 3, train_batch_id: 2300, avg_cost: 3.887687921524048
grad_norm: 1.2191901872313025, clipped: 1.0
epoch: 3, train_batch_id: 2350, avg_cost: 3.8808746337890625
grad_norm: 0.7830496893155963, clipped: 0.7830496893155963
epoch: 3, train_batch_id: 2400, avg_cost: 3.887766122817993
grad_norm: 0.7394485140794358, clipped: 0.7394485140794358
epoch: 3, train_batch_id: 2450, avg_cost: 3.882214069366455
grad_norm: 1.0749371715639668, clipped: 1.0
Finished epoch 3, took 00:05:27 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.885986328125 +- 0.003227788023650646
Evaluating candidate model on evaluation dataset
Epoch 3 candidate mean 3.8807339668273926, baseline epoch 2 mean 3.8914620876312256, difference -0.010728120803833008
p-value: 5.622739079712311e-53
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 4, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 4, train_batch_id: 0, avg_cost: 3.861759901046753
grad_norm: 0.6098947037529849, clipped: 0.6098947037529849
epoch: 4, train_batch_id: 50, avg_cost: 3.8949155807495117
grad_norm: 0.9699151007452321, clipped: 0.9699151007452321
epoch: 4, train_batch_id: 100, avg_cost: 3.8816628456115723
grad_norm: 0.844041936914373, clipped: 0.844041936914373
epoch: 4, train_batch_id: 150, avg_cost: 3.90505313873291
grad_norm: 0.8870653491920737, clipped: 0.8870653491920737
epoch: 4, train_batch_id: 200, avg_cost: 3.885768413543701
grad_norm: 1.8819584688906468, clipped: 1.0
epoch: 4, train_batch_id: 250, avg_cost: 3.9081711769104004
grad_norm: 0.953258046696159, clipped: 0.953258046696159
epoch: 4, train_batch_id: 300, avg_cost: 3.871525287628174
grad_norm: 1.3884369195991504, clipped: 1.0
epoch: 4, train_batch_id: 350, avg_cost: 3.876538038253784
grad_norm: 0.7286315433527611, clipped: 0.7286315433527611
epoch: 4, train_batch_id: 400, avg_cost: 3.880239963531494
grad_norm: 1.0530733128464378, clipped: 1.0
epoch: 4, train_batch_id: 450, avg_cost: 3.897665500640869
grad_norm: 0.635365416812727, clipped: 0.635365416812727
epoch: 4, train_batch_id: 500, avg_cost: 3.872040033340454
grad_norm: 0.744481642720036, clipped: 0.744481642720036
epoch: 4, train_batch_id: 550, avg_cost: 3.899111032485962
grad_norm: 1.331442677332508, clipped: 1.0
epoch: 4, train_batch_id: 600, avg_cost: 3.8863492012023926
grad_norm: 0.777836614685426, clipped: 0.777836614685426
epoch: 4, train_batch_id: 650, avg_cost: 3.909529685974121
grad_norm: 0.8081665305679019, clipped: 0.8081665305679019
epoch: 4, train_batch_id: 700, avg_cost: 3.879870891571045
grad_norm: 1.1271786342946204, clipped: 1.0
epoch: 4, train_batch_id: 750, avg_cost: 3.9021875858306885
grad_norm: 0.8819495559771935, clipped: 0.8819495559771935
epoch: 4, train_batch_id: 800, avg_cost: 3.902498245239258
grad_norm: 0.7387442885732218, clipped: 0.7387442885732218
epoch: 4, train_batch_id: 850, avg_cost: 3.8999366760253906
grad_norm: 1.3922709922307892, clipped: 1.0
epoch: 4, train_batch_id: 900, avg_cost: 3.879436731338501
grad_norm: 0.7516041204624665, clipped: 0.7516041204624665
epoch: 4, train_batch_id: 950, avg_cost: 3.910984992980957
grad_norm: 1.3224691458215996, clipped: 1.0
epoch: 4, train_batch_id: 1000, avg_cost: 3.8837647438049316
grad_norm: 0.6945852165505325, clipped: 0.6945852165505325
epoch: 4, train_batch_id: 1050, avg_cost: 3.8812875747680664
grad_norm: 0.7532073089650334, clipped: 0.7532073089650334
epoch: 4, train_batch_id: 1100, avg_cost: 3.881654739379883
grad_norm: 1.6366030492946075, clipped: 1.0
epoch: 4, train_batch_id: 1150, avg_cost: 3.8863701820373535
grad_norm: 1.1729558948447625, clipped: 1.0
epoch: 4, train_batch_id: 1200, avg_cost: 3.868446111679077
grad_norm: 0.735742368477301, clipped: 0.735742368477301
epoch: 4, train_batch_id: 1250, avg_cost: 3.899813413619995
grad_norm: 0.9140543673792636, clipped: 0.9140543673792636
epoch: 4, train_batch_id: 1300, avg_cost: 3.873394012451172
grad_norm: 0.6924248931452998, clipped: 0.6924248931452998
epoch: 4, train_batch_id: 1350, avg_cost: 3.893056869506836
grad_norm: 0.7160266816966284, clipped: 0.7160266816966284
epoch: 4, train_batch_id: 1400, avg_cost: 3.8881585597991943
grad_norm: 0.645070421483527, clipped: 0.645070421483527
epoch: 4, train_batch_id: 1450, avg_cost: 3.865755558013916
grad_norm: 0.554788071651214, clipped: 0.554788071651214
epoch: 4, train_batch_id: 1500, avg_cost: 3.8884387016296387
grad_norm: 0.8385900993764167, clipped: 0.8385900993764167
epoch: 4, train_batch_id: 1550, avg_cost: 3.9060864448547363
grad_norm: 1.131132413636754, clipped: 1.0
epoch: 4, train_batch_id: 1600, avg_cost: 3.8909478187561035
grad_norm: 2.200354460270104, clipped: 1.0
epoch: 4, train_batch_id: 1650, avg_cost: 3.8982725143432617
grad_norm: 0.7118698850680385, clipped: 0.7118698850680385
epoch: 4, train_batch_id: 1700, avg_cost: 3.8929970264434814
grad_norm: 0.6557786299797917, clipped: 0.6557786299797917
epoch: 4, train_batch_id: 1750, avg_cost: 3.8841490745544434
grad_norm: 0.6453701947454016, clipped: 0.6453701947454016
epoch: 4, train_batch_id: 1800, avg_cost: 3.883007049560547
grad_norm: 0.9465519390350106, clipped: 0.9465519390350106
epoch: 4, train_batch_id: 1850, avg_cost: 3.8908462524414062
grad_norm: 0.9732140308881435, clipped: 0.9732140308881435
epoch: 4, train_batch_id: 1900, avg_cost: 3.885497808456421
grad_norm: 0.6941112427015602, clipped: 0.6941112427015602
epoch: 4, train_batch_id: 1950, avg_cost: 3.8812460899353027
grad_norm: 0.7092963208534723, clipped: 0.7092963208534723
epoch: 4, train_batch_id: 2000, avg_cost: 3.8999664783477783
grad_norm: 1.1395838641245308, clipped: 1.0
epoch: 4, train_batch_id: 2050, avg_cost: 3.884866237640381
grad_norm: 1.547653968318439, clipped: 1.0
epoch: 4, train_batch_id: 2100, avg_cost: 3.8844244480133057
grad_norm: 0.7974034975392191, clipped: 0.7974034975392191
epoch: 4, train_batch_id: 2150, avg_cost: 3.871166706085205
grad_norm: 0.6887446463688296, clipped: 0.6887446463688296
epoch: 4, train_batch_id: 2200, avg_cost: 3.890941619873047
grad_norm: 0.7515883741881006, clipped: 0.7515883741881006
epoch: 4, train_batch_id: 2250, avg_cost: 3.883561611175537
grad_norm: 1.0003714105826256, clipped: 1.0
epoch: 4, train_batch_id: 2300, avg_cost: 3.899775743484497
grad_norm: 0.8724573340077723, clipped: 0.8724573340077723
epoch: 4, train_batch_id: 2350, avg_cost: 3.8589510917663574
grad_norm: 0.847451002144487, clipped: 0.847451002144487
epoch: 4, train_batch_id: 2400, avg_cost: 3.8953933715820312
grad_norm: 1.026291740835091, clipped: 1.0
epoch: 4, train_batch_id: 2450, avg_cost: 3.8803606033325195
grad_norm: 0.8659765127351555, clipped: 0.8659765127351555
Finished epoch 4, took 00:05:49 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8828766345977783 +- 0.0032133341301232576
Evaluating candidate model on evaluation dataset
Epoch 4 candidate mean 3.8721187114715576, baseline epoch 3 mean 3.8759210109710693, difference -0.0038022994995117188
p-value: 2.447895803397411e-10
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 5, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 5, train_batch_id: 0, avg_cost: 3.8996198177337646
grad_norm: 0.9204863099051142, clipped: 0.9204863099051142
epoch: 5, train_batch_id: 50, avg_cost: 3.891144275665283
grad_norm: 0.6659337416390996, clipped: 0.6659337416390996
epoch: 5, train_batch_id: 100, avg_cost: 3.898848533630371
grad_norm: 0.5983699566397997, clipped: 0.5983699566397997
epoch: 5, train_batch_id: 150, avg_cost: 3.8820271492004395
grad_norm: 0.692337261543016, clipped: 0.692337261543016
epoch: 5, train_batch_id: 200, avg_cost: 3.8847341537475586
grad_norm: 0.6200241574740635, clipped: 0.6200241574740635
epoch: 5, train_batch_id: 250, avg_cost: 3.8589882850646973
grad_norm: 0.5192411778709015, clipped: 0.5192411778709015
epoch: 5, train_batch_id: 300, avg_cost: 3.888547897338867
grad_norm: 0.6533998344740328, clipped: 0.6533998344740328
epoch: 5, train_batch_id: 350, avg_cost: 3.884357452392578
grad_norm: 0.8068507151228469, clipped: 0.8068507151228469
epoch: 5, train_batch_id: 400, avg_cost: 3.8989689350128174
grad_norm: 0.8705658895558496, clipped: 0.8705658895558496
epoch: 5, train_batch_id: 450, avg_cost: 3.8898868560791016
grad_norm: 0.9582241522880266, clipped: 0.9582241522880266
epoch: 5, train_batch_id: 500, avg_cost: 3.8945276737213135
grad_norm: 1.0530332491365417, clipped: 1.0
epoch: 5, train_batch_id: 550, avg_cost: 3.9011216163635254
grad_norm: 0.7982924156266642, clipped: 0.7982924156266642
epoch: 5, train_batch_id: 600, avg_cost: 3.868165969848633
grad_norm: 1.0111167745642402, clipped: 1.0
epoch: 5, train_batch_id: 650, avg_cost: 3.9047467708587646
grad_norm: 0.5880654600980766, clipped: 0.5880654600980766
epoch: 5, train_batch_id: 700, avg_cost: 3.903407573699951
grad_norm: 1.1372014424669699, clipped: 1.0
epoch: 5, train_batch_id: 750, avg_cost: 3.882779359817505
grad_norm: 0.7227847429875887, clipped: 0.7227847429875887
epoch: 5, train_batch_id: 800, avg_cost: 3.8845133781433105
grad_norm: 3.61211708933094, clipped: 1.0
epoch: 5, train_batch_id: 850, avg_cost: 3.901141405105591
grad_norm: 0.7124410314942137, clipped: 0.7124410314942137
epoch: 5, train_batch_id: 900, avg_cost: 3.8923096656799316
grad_norm: 1.1329965511157176, clipped: 1.0
epoch: 5, train_batch_id: 950, avg_cost: 3.8781847953796387
grad_norm: 0.5762187122488179, clipped: 0.5762187122488179
epoch: 5, train_batch_id: 1000, avg_cost: 3.8697664737701416
grad_norm: 0.8224685521556022, clipped: 0.8224685521556022
epoch: 5, train_batch_id: 1050, avg_cost: 3.8685500621795654
grad_norm: 0.8326248483142701, clipped: 0.8326248483142701
epoch: 5, train_batch_id: 1100, avg_cost: 3.8638181686401367
grad_norm: 0.6085547360124144, clipped: 0.6085547360124144
epoch: 5, train_batch_id: 1150, avg_cost: 3.8546066284179688
grad_norm: 0.7344014106493135, clipped: 0.7344014106493135
epoch: 5, train_batch_id: 1200, avg_cost: 3.871860980987549
grad_norm: 0.752189081149766, clipped: 0.752189081149766
epoch: 5, train_batch_id: 1250, avg_cost: 3.8851306438446045
grad_norm: 1.0201948220205659, clipped: 1.0
epoch: 5, train_batch_id: 1300, avg_cost: 3.8973231315612793
grad_norm: 0.992563327436448, clipped: 0.992563327436448
epoch: 5, train_batch_id: 1350, avg_cost: 3.8874123096466064
grad_norm: 0.9431749755845052, clipped: 0.9431749755845052
epoch: 5, train_batch_id: 1400, avg_cost: 3.903820753097534
grad_norm: 3.5968230684743463, clipped: 1.0
epoch: 5, train_batch_id: 1450, avg_cost: 3.868307590484619
grad_norm: 0.7509824713596716, clipped: 0.7509824713596716
epoch: 5, train_batch_id: 1500, avg_cost: 3.910494804382324
grad_norm: 0.7449570769273836, clipped: 0.7449570769273836
epoch: 5, train_batch_id: 1550, avg_cost: 3.8723831176757812
grad_norm: 0.614569021472986, clipped: 0.614569021472986
epoch: 5, train_batch_id: 1600, avg_cost: 3.862574577331543
grad_norm: 1.0879185457625302, clipped: 1.0
epoch: 5, train_batch_id: 1650, avg_cost: 3.881436586380005
grad_norm: 0.5849943310341444, clipped: 0.5849943310341444
epoch: 5, train_batch_id: 1700, avg_cost: 3.873661518096924
grad_norm: 0.5747290972021141, clipped: 0.5747290972021141
epoch: 5, train_batch_id: 1750, avg_cost: 3.8723483085632324
grad_norm: 1.0499862098142745, clipped: 1.0
epoch: 5, train_batch_id: 1800, avg_cost: 3.8829550743103027
grad_norm: 0.9216073854072726, clipped: 0.9216073854072726
epoch: 5, train_batch_id: 1850, avg_cost: 3.911250591278076
grad_norm: 0.7606074726834683, clipped: 0.7606074726834683
epoch: 5, train_batch_id: 1900, avg_cost: 3.90816330909729
grad_norm: 0.7624324951582893, clipped: 0.7624324951582893
epoch: 5, train_batch_id: 1950, avg_cost: 3.876732349395752
grad_norm: 0.6504452296641293, clipped: 0.6504452296641293
epoch: 5, train_batch_id: 2000, avg_cost: 3.8664002418518066
grad_norm: 0.6687614843774654, clipped: 0.6687614843774654
epoch: 5, train_batch_id: 2050, avg_cost: 3.905883550643921
grad_norm: 0.9123237380889472, clipped: 0.9123237380889472
epoch: 5, train_batch_id: 2100, avg_cost: 3.904585123062134
grad_norm: 0.8456949097584803, clipped: 0.8456949097584803
epoch: 5, train_batch_id: 2150, avg_cost: 3.9128713607788086
grad_norm: 0.6820425911564035, clipped: 0.6820425911564035
epoch: 5, train_batch_id: 2200, avg_cost: 3.8593411445617676
grad_norm: 0.5930387971284432, clipped: 0.5930387971284432
epoch: 5, train_batch_id: 2250, avg_cost: 3.884415626525879
grad_norm: 1.008319732937858, clipped: 1.0
epoch: 5, train_batch_id: 2300, avg_cost: 3.877858877182007
grad_norm: 1.0022656991294705, clipped: 1.0
epoch: 5, train_batch_id: 2350, avg_cost: 3.866919994354248
grad_norm: 0.9730953316400583, clipped: 0.9730953316400583
epoch: 5, train_batch_id: 2400, avg_cost: 3.8552870750427246
grad_norm: 0.7931510915088771, clipped: 0.7931510915088771
epoch: 5, train_batch_id: 2450, avg_cost: 3.859771728515625
grad_norm: 0.7080286044005304, clipped: 0.7080286044005304
Finished epoch 5, took 00:05:39 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.879626989364624 +- 0.003226044587790966
Evaluating candidate model on evaluation dataset
Epoch 5 candidate mean 3.8704891204833984, baseline epoch 4 mean 3.8731305599212646, difference -0.002641439437866211
p-value: 1.9122876814323076e-05
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 6, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 6, train_batch_id: 0, avg_cost: 3.879633903503418
grad_norm: 0.6068701115928724, clipped: 0.6068701115928724
epoch: 6, train_batch_id: 50, avg_cost: 3.9022481441497803
grad_norm: 0.8307112990921269, clipped: 0.8307112990921269
epoch: 6, train_batch_id: 100, avg_cost: 3.8697996139526367
grad_norm: 0.8466965507371043, clipped: 0.8466965507371043
epoch: 6, train_batch_id: 150, avg_cost: 3.898893356323242
grad_norm: 0.7472169216610566, clipped: 0.7472169216610566
epoch: 6, train_batch_id: 200, avg_cost: 3.873089551925659
grad_norm: 0.7183318310801197, clipped: 0.7183318310801197
epoch: 6, train_batch_id: 250, avg_cost: 3.8925247192382812
grad_norm: 0.6658226525366083, clipped: 0.6658226525366083
epoch: 6, train_batch_id: 300, avg_cost: 3.878824234008789
grad_norm: 0.9848967247602759, clipped: 0.9848967247602759
epoch: 6, train_batch_id: 350, avg_cost: 3.8723769187927246
grad_norm: 0.5624354322080358, clipped: 0.5624354322080358
epoch: 6, train_batch_id: 400, avg_cost: 3.8998358249664307
grad_norm: 0.994516357462233, clipped: 0.994516357462233
epoch: 6, train_batch_id: 450, avg_cost: 3.9162726402282715
grad_norm: 1.6140908974281496, clipped: 1.0
epoch: 6, train_batch_id: 500, avg_cost: 3.8725850582122803
grad_norm: 1.028994257428602, clipped: 1.0
epoch: 6, train_batch_id: 550, avg_cost: 3.8579623699188232
grad_norm: 0.7931706083114102, clipped: 0.7931706083114102
epoch: 6, train_batch_id: 600, avg_cost: 3.8801651000976562
grad_norm: 1.0802428672149642, clipped: 1.0
epoch: 6, train_batch_id: 650, avg_cost: 3.8722920417785645
grad_norm: 0.9290325001170762, clipped: 0.9290325001170762
epoch: 6, train_batch_id: 700, avg_cost: 3.885908603668213
grad_norm: 0.617055243216177, clipped: 0.617055243216177
epoch: 6, train_batch_id: 750, avg_cost: 3.897266149520874
grad_norm: 0.6144223515977423, clipped: 0.6144223515977423
epoch: 6, train_batch_id: 800, avg_cost: 3.8844571113586426
grad_norm: 1.2359146915504842, clipped: 1.0
epoch: 6, train_batch_id: 850, avg_cost: 3.9301161766052246
grad_norm: 1.032458371450455, clipped: 1.0
epoch: 6, train_batch_id: 900, avg_cost: 3.9037110805511475
grad_norm: 2.7873328487296174, clipped: 1.0
epoch: 6, train_batch_id: 950, avg_cost: 3.8997995853424072
grad_norm: 0.8288021489266207, clipped: 0.8288021489266207
epoch: 6, train_batch_id: 1000, avg_cost: 3.8630380630493164
grad_norm: 0.8362538959172156, clipped: 0.8362538959172156
epoch: 6, train_batch_id: 1050, avg_cost: 3.8983941078186035
grad_norm: 0.7651737715069621, clipped: 0.7651737715069621
epoch: 6, train_batch_id: 1100, avg_cost: 3.870802164077759
grad_norm: 0.8475239083813759, clipped: 0.8475239083813759
epoch: 6, train_batch_id: 1150, avg_cost: 3.8747217655181885
grad_norm: 0.9229406118307303, clipped: 0.9229406118307303
epoch: 6, train_batch_id: 1200, avg_cost: 3.890002727508545
grad_norm: 0.9686523703625639, clipped: 0.9686523703625639
epoch: 6, train_batch_id: 1250, avg_cost: 3.8809943199157715
grad_norm: 1.2387585720271366, clipped: 1.0
epoch: 6, train_batch_id: 1300, avg_cost: 3.9148495197296143
grad_norm: 1.029046167160209, clipped: 1.0
epoch: 6, train_batch_id: 1350, avg_cost: 3.9052157402038574
grad_norm: 0.8383533928145135, clipped: 0.8383533928145135
epoch: 6, train_batch_id: 1400, avg_cost: 3.900686264038086
grad_norm: 0.7394568242275265, clipped: 0.7394568242275265
epoch: 6, train_batch_id: 1450, avg_cost: 3.862060546875
grad_norm: 0.7849415495468718, clipped: 0.7849415495468718
epoch: 6, train_batch_id: 1500, avg_cost: 3.9005274772644043
grad_norm: 0.796119310001384, clipped: 0.796119310001384
epoch: 6, train_batch_id: 1550, avg_cost: 3.880732774734497
grad_norm: 1.2597266445488928, clipped: 1.0
epoch: 6, train_batch_id: 1600, avg_cost: 3.901536464691162
grad_norm: 0.6855486786233594, clipped: 0.6855486786233594
epoch: 6, train_batch_id: 1650, avg_cost: 3.8654932975769043
grad_norm: 0.8313301005683581, clipped: 0.8313301005683581
epoch: 6, train_batch_id: 1700, avg_cost: 3.8684802055358887
grad_norm: 0.6722605129274334, clipped: 0.6722605129274334
epoch: 6, train_batch_id: 1750, avg_cost: 3.901618003845215
grad_norm: 1.2417952261747303, clipped: 1.0
epoch: 6, train_batch_id: 1800, avg_cost: 3.8873214721679688
grad_norm: 0.6405016127181576, clipped: 0.6405016127181576
epoch: 6, train_batch_id: 1850, avg_cost: 3.884211301803589
grad_norm: 1.3644927105735212, clipped: 1.0
epoch: 6, train_batch_id: 1900, avg_cost: 3.870224714279175
grad_norm: 0.9697036321757276, clipped: 0.9697036321757276
epoch: 6, train_batch_id: 1950, avg_cost: 3.8708560466766357
grad_norm: 0.5759511803443168, clipped: 0.5759511803443168
epoch: 6, train_batch_id: 2000, avg_cost: 3.8663086891174316
grad_norm: 0.7177277444978972, clipped: 0.7177277444978972
epoch: 6, train_batch_id: 2050, avg_cost: 3.894357919692993
grad_norm: 0.844437900678732, clipped: 0.844437900678732
epoch: 6, train_batch_id: 2100, avg_cost: 3.8912527561187744
grad_norm: 0.6648710229393494, clipped: 0.6648710229393494
epoch: 6, train_batch_id: 2150, avg_cost: 3.872384548187256
grad_norm: 0.7247490249177003, clipped: 0.7247490249177003
epoch: 6, train_batch_id: 2200, avg_cost: 3.8784000873565674
grad_norm: 0.6582810647274757, clipped: 0.6582810647274757
epoch: 6, train_batch_id: 2250, avg_cost: 3.876984119415283
grad_norm: 0.9185016613909804, clipped: 0.9185016613909804
epoch: 6, train_batch_id: 2300, avg_cost: 3.893197774887085
grad_norm: 0.6143445251268252, clipped: 0.6143445251268252
epoch: 6, train_batch_id: 2350, avg_cost: 3.8659753799438477
grad_norm: 0.6167818996316704, clipped: 0.6167818996316704
epoch: 6, train_batch_id: 2400, avg_cost: 3.8616604804992676
grad_norm: 0.6762518879809939, clipped: 0.6762518879809939
epoch: 6, train_batch_id: 2450, avg_cost: 3.898123264312744
grad_norm: 0.8859309364705372, clipped: 0.8859309364705372
Finished epoch 6, took 00:05:35 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8770174980163574 +- 0.003198390593752265
Evaluating candidate model on evaluation dataset
Epoch 6 candidate mean 3.875678062438965, baseline epoch 5 mean 3.878650665283203, difference -0.0029726028442382812
p-value: 5.261423598141018e-07
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 7, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 7, train_batch_id: 0, avg_cost: 3.875361442565918
grad_norm: 0.7226617955710705, clipped: 0.7226617955710705
epoch: 7, train_batch_id: 50, avg_cost: 3.8707029819488525
grad_norm: 0.8892855930971114, clipped: 0.8892855930971114
epoch: 7, train_batch_id: 100, avg_cost: 3.881460666656494
grad_norm: 0.7440154517553111, clipped: 0.7440154517553111
epoch: 7, train_batch_id: 150, avg_cost: 3.890625
grad_norm: 0.8089620238552094, clipped: 0.8089620238552094
epoch: 7, train_batch_id: 200, avg_cost: 3.886963129043579
grad_norm: 0.6141202242972416, clipped: 0.6141202242972416
epoch: 7, train_batch_id: 250, avg_cost: 3.8620681762695312
grad_norm: 0.7381033863479566, clipped: 0.7381033863479566
epoch: 7, train_batch_id: 300, avg_cost: 3.8831210136413574
grad_norm: 0.683409987235788, clipped: 0.683409987235788
epoch: 7, train_batch_id: 350, avg_cost: 3.8758182525634766
grad_norm: 0.7490680273693012, clipped: 0.7490680273693012
epoch: 7, train_batch_id: 400, avg_cost: 3.8817343711853027
grad_norm: 0.5448008219698187, clipped: 0.5448008219698187
epoch: 7, train_batch_id: 450, avg_cost: 3.8896682262420654
grad_norm: 0.6656006636932219, clipped: 0.6656006636932219
epoch: 7, train_batch_id: 500, avg_cost: 3.863595485687256
grad_norm: 0.8875631679991118, clipped: 0.8875631679991118
epoch: 7, train_batch_id: 550, avg_cost: 3.88838529586792
grad_norm: 0.8558284625610522, clipped: 0.8558284625610522
epoch: 7, train_batch_id: 600, avg_cost: 3.8709726333618164
grad_norm: 0.6759115994241511, clipped: 0.6759115994241511
epoch: 7, train_batch_id: 650, avg_cost: 3.884512424468994
grad_norm: 1.2640657952776007, clipped: 1.0
epoch: 7, train_batch_id: 700, avg_cost: 3.8959479331970215
grad_norm: 0.5812655506784, clipped: 0.5812655506784
epoch: 7, train_batch_id: 750, avg_cost: 3.895737886428833
grad_norm: 0.7041393677144214, clipped: 0.7041393677144214
epoch: 7, train_batch_id: 800, avg_cost: 3.842514991760254
grad_norm: 0.6066239210506368, clipped: 0.6066239210506368
epoch: 7, train_batch_id: 850, avg_cost: 3.8808703422546387
grad_norm: 0.7377189010805721, clipped: 0.7377189010805721
epoch: 7, train_batch_id: 900, avg_cost: 3.89664363861084
grad_norm: 2.478860915234944, clipped: 1.0
epoch: 7, train_batch_id: 950, avg_cost: 3.85115909576416
grad_norm: 1.2907959014376598, clipped: 1.0
epoch: 7, train_batch_id: 1000, avg_cost: 3.8843798637390137
grad_norm: 0.8680611943486455, clipped: 0.8680611943486455
epoch: 7, train_batch_id: 1050, avg_cost: 3.874514102935791
grad_norm: 0.8616388959889423, clipped: 0.8616388959889423
epoch: 7, train_batch_id: 1100, avg_cost: 3.8703393936157227
grad_norm: 0.5946047017402668, clipped: 0.5946047017402668
epoch: 7, train_batch_id: 1150, avg_cost: 3.851064682006836
grad_norm: 0.7021622302388628, clipped: 0.7021622302388628
epoch: 7, train_batch_id: 1200, avg_cost: 3.860861301422119
grad_norm: 0.7480178150097834, clipped: 0.7480178150097834
epoch: 7, train_batch_id: 1250, avg_cost: 3.870107412338257
grad_norm: 0.6634654705245958, clipped: 0.6634654705245958
epoch: 7, train_batch_id: 1300, avg_cost: 3.904853582382202
grad_norm: 0.8402359914818694, clipped: 0.8402359914818694
epoch: 7, train_batch_id: 1350, avg_cost: 3.8937835693359375
grad_norm: 0.6198583500445362, clipped: 0.6198583500445362
epoch: 7, train_batch_id: 1400, avg_cost: 3.890381097793579
grad_norm: 0.6843096136140553, clipped: 0.6843096136140553
epoch: 7, train_batch_id: 1450, avg_cost: 3.880234956741333
grad_norm: 0.45751530171073146, clipped: 0.45751530171073146
epoch: 7, train_batch_id: 1500, avg_cost: 3.875770092010498
grad_norm: 0.9386616148638023, clipped: 0.9386616148638023
epoch: 7, train_batch_id: 1550, avg_cost: 3.8688135147094727
grad_norm: 0.5749583256693184, clipped: 0.5749583256693184
epoch: 7, train_batch_id: 1600, avg_cost: 3.8825793266296387
grad_norm: 0.6470869092915359, clipped: 0.6470869092915359
epoch: 7, train_batch_id: 1650, avg_cost: 3.8655612468719482
grad_norm: 0.6557488820665588, clipped: 0.6557488820665588
epoch: 7, train_batch_id: 1700, avg_cost: 3.871229410171509
grad_norm: 0.8596193870547822, clipped: 0.8596193870547822
epoch: 7, train_batch_id: 1750, avg_cost: 3.8902010917663574
grad_norm: 0.8533279381071492, clipped: 0.8533279381071492
epoch: 7, train_batch_id: 1800, avg_cost: 3.9178826808929443
grad_norm: 0.7673677134783846, clipped: 0.7673677134783846
epoch: 7, train_batch_id: 1850, avg_cost: 3.858816623687744
grad_norm: 0.5667326018673757, clipped: 0.5667326018673757
epoch: 7, train_batch_id: 1900, avg_cost: 3.887387752532959
grad_norm: 0.7591573967541713, clipped: 0.7591573967541713
epoch: 7, train_batch_id: 1950, avg_cost: 3.8729772567749023
grad_norm: 0.5904375133720897, clipped: 0.5904375133720897
epoch: 7, train_batch_id: 2000, avg_cost: 3.872880458831787
grad_norm: 0.5258699000201494, clipped: 0.5258699000201494
epoch: 7, train_batch_id: 2050, avg_cost: 3.8739843368530273
grad_norm: 0.581299493549232, clipped: 0.581299493549232
epoch: 7, train_batch_id: 2100, avg_cost: 3.867809534072876
grad_norm: 0.71974578158532, clipped: 0.71974578158532
epoch: 7, train_batch_id: 2150, avg_cost: 3.8832664489746094
grad_norm: 1.476023307201776, clipped: 1.0
epoch: 7, train_batch_id: 2200, avg_cost: 3.8629188537597656
grad_norm: 0.6739674439341284, clipped: 0.6739674439341284
epoch: 7, train_batch_id: 2250, avg_cost: 3.8980839252471924
grad_norm: 0.8423172347328889, clipped: 0.8423172347328889
epoch: 7, train_batch_id: 2300, avg_cost: 3.873379707336426
grad_norm: 0.7190071684537147, clipped: 0.7190071684537147
epoch: 7, train_batch_id: 2350, avg_cost: 3.883420467376709
grad_norm: 1.0095889134067897, clipped: 1.0
epoch: 7, train_batch_id: 2400, avg_cost: 3.8840222358703613
grad_norm: 0.6260171448107167, clipped: 0.6260171448107167
epoch: 7, train_batch_id: 2450, avg_cost: 3.8650097846984863
grad_norm: 0.9158178833913276, clipped: 0.9158178833913276
Finished epoch 7, took 00:05:36 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8737804889678955 +- 0.003186895279213786
Evaluating candidate model on evaluation dataset
Epoch 7 candidate mean 3.8766729831695557, baseline epoch 6 mean 3.8792500495910645, difference -0.002577066421508789
p-value: 1.0296236746264372e-05
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 8, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 8, train_batch_id: 0, avg_cost: 3.869213342666626
grad_norm: 0.6774964868073597, clipped: 0.6774964868073597
epoch: 8, train_batch_id: 50, avg_cost: 3.900451183319092
grad_norm: 0.763248443625815, clipped: 0.763248443625815
epoch: 8, train_batch_id: 100, avg_cost: 3.8745622634887695
grad_norm: 1.4755158472017365, clipped: 1.0
epoch: 8, train_batch_id: 150, avg_cost: 3.8990797996520996
grad_norm: 0.5882198307838885, clipped: 0.5882198307838885
epoch: 8, train_batch_id: 200, avg_cost: 3.8905982971191406
grad_norm: 0.9607971546984697, clipped: 0.9607971546984697
epoch: 8, train_batch_id: 250, avg_cost: 3.8617477416992188
grad_norm: 0.9437783985798398, clipped: 0.9437783985798398
epoch: 8, train_batch_id: 300, avg_cost: 3.8730039596557617
grad_norm: 0.684356830690342, clipped: 0.684356830690342
epoch: 8, train_batch_id: 350, avg_cost: 3.869349479675293
grad_norm: 0.8292688192141457, clipped: 0.8292688192141457
epoch: 8, train_batch_id: 400, avg_cost: 3.8469393253326416
grad_norm: 0.8117703656417365, clipped: 0.8117703656417365
epoch: 8, train_batch_id: 450, avg_cost: 3.8600881099700928
grad_norm: 0.7837252835093, clipped: 0.7837252835093
epoch: 8, train_batch_id: 500, avg_cost: 3.8758020401000977
grad_norm: 0.6794589921947543, clipped: 0.6794589921947543
epoch: 8, train_batch_id: 550, avg_cost: 3.8752779960632324
grad_norm: 0.5248744842783934, clipped: 0.5248744842783934
epoch: 8, train_batch_id: 600, avg_cost: 3.899400234222412
grad_norm: 0.7547231300378536, clipped: 0.7547231300378536
epoch: 8, train_batch_id: 650, avg_cost: 3.863030433654785
grad_norm: 0.8408562464308301, clipped: 0.8408562464308301
epoch: 8, train_batch_id: 700, avg_cost: 3.8760733604431152
grad_norm: 0.7021663245914752, clipped: 0.7021663245914752
epoch: 8, train_batch_id: 750, avg_cost: 3.8776583671569824
grad_norm: 0.9330317029222069, clipped: 0.9330317029222069
epoch: 8, train_batch_id: 800, avg_cost: 3.8883285522460938
grad_norm: 0.8950057127899812, clipped: 0.8950057127899812
epoch: 8, train_batch_id: 850, avg_cost: 3.8859806060791016
grad_norm: 0.8773982210259864, clipped: 0.8773982210259864
epoch: 8, train_batch_id: 900, avg_cost: 3.863259792327881
grad_norm: 0.7607129990525081, clipped: 0.7607129990525081
epoch: 8, train_batch_id: 950, avg_cost: 3.8816518783569336
grad_norm: 0.7832562733486022, clipped: 0.7832562733486022
epoch: 8, train_batch_id: 1000, avg_cost: 3.896108865737915
grad_norm: 0.7736496288029028, clipped: 0.7736496288029028
epoch: 8, train_batch_id: 1050, avg_cost: 3.8893203735351562
grad_norm: 0.7044880491206789, clipped: 0.7044880491206789
epoch: 8, train_batch_id: 1100, avg_cost: 3.87017822265625
grad_norm: 0.5937108418573201, clipped: 0.5937108418573201
epoch: 8, train_batch_id: 1150, avg_cost: 3.89329195022583
grad_norm: 0.5461114027146886, clipped: 0.5461114027146886
epoch: 8, train_batch_id: 1200, avg_cost: 3.874647855758667
grad_norm: 0.986758009434488, clipped: 0.986758009434488
epoch: 8, train_batch_id: 1250, avg_cost: 3.85052490234375
grad_norm: 0.81304551399842, clipped: 0.81304551399842
epoch: 8, train_batch_id: 1300, avg_cost: 3.850196599960327
grad_norm: 0.5040038289136111, clipped: 0.5040038289136111
epoch: 8, train_batch_id: 1350, avg_cost: 3.888376474380493
grad_norm: 0.9460759568651254, clipped: 0.9460759568651254
epoch: 8, train_batch_id: 1400, avg_cost: 3.868898391723633
grad_norm: 0.7377974221026394, clipped: 0.7377974221026394
epoch: 8, train_batch_id: 1450, avg_cost: 3.8854029178619385
grad_norm: 0.9114250372948507, clipped: 0.9114250372948507
epoch: 8, train_batch_id: 1500, avg_cost: 3.8746213912963867
grad_norm: 1.0058064752202642, clipped: 1.0
epoch: 8, train_batch_id: 1550, avg_cost: 3.8687047958374023
grad_norm: 1.0767716742626525, clipped: 1.0
epoch: 8, train_batch_id: 1600, avg_cost: 3.8723573684692383
grad_norm: 0.5990785086634972, clipped: 0.5990785086634972
epoch: 8, train_batch_id: 1650, avg_cost: 3.866349458694458
grad_norm: 1.1925404188752575, clipped: 1.0
epoch: 8, train_batch_id: 1700, avg_cost: 3.8793797492980957
grad_norm: 0.97451701637161, clipped: 0.97451701637161
epoch: 8, train_batch_id: 1750, avg_cost: 3.8667449951171875
grad_norm: 2.4349627581951405, clipped: 1.0
epoch: 8, train_batch_id: 1800, avg_cost: 3.880725860595703
grad_norm: 1.2044744895585704, clipped: 1.0
epoch: 8, train_batch_id: 1850, avg_cost: 3.864135265350342
grad_norm: 0.6549597881090521, clipped: 0.6549597881090521
epoch: 8, train_batch_id: 1900, avg_cost: 3.8826770782470703
grad_norm: 4.05173287286887, clipped: 1.0
epoch: 8, train_batch_id: 1950, avg_cost: 3.8707566261291504
grad_norm: 1.3368881475472456, clipped: 1.0
epoch: 8, train_batch_id: 2000, avg_cost: 3.877040386199951
grad_norm: 0.6597102595185314, clipped: 0.6597102595185314
epoch: 8, train_batch_id: 2050, avg_cost: 3.8681111335754395
grad_norm: 0.8492684767090726, clipped: 0.8492684767090726
epoch: 8, train_batch_id: 2100, avg_cost: 3.8623337745666504
grad_norm: 0.9004594498138109, clipped: 0.9004594498138109
epoch: 8, train_batch_id: 2150, avg_cost: 3.8755290508270264
grad_norm: 0.6763120559125825, clipped: 0.6763120559125825
epoch: 8, train_batch_id: 2200, avg_cost: 3.8624625205993652
grad_norm: 1.0635199254834322, clipped: 1.0
epoch: 8, train_batch_id: 2250, avg_cost: 3.899933338165283
grad_norm: 0.5703988962021195, clipped: 0.5703988962021195
epoch: 8, train_batch_id: 2300, avg_cost: 3.8617467880249023
grad_norm: 0.6796542898549102, clipped: 0.6796542898549102
epoch: 8, train_batch_id: 2350, avg_cost: 3.86674165725708
grad_norm: 0.7110780867913609, clipped: 0.7110780867913609
epoch: 8, train_batch_id: 2400, avg_cost: 3.856165647506714
grad_norm: 0.9046997981233643, clipped: 0.9046997981233643
epoch: 8, train_batch_id: 2450, avg_cost: 3.849520683288574
grad_norm: 0.9646909740127831, clipped: 0.9646909740127831
Finished epoch 8, took 00:05:37 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.870312452316284 +- 0.003173388773575425
Evaluating candidate model on evaluation dataset
Epoch 8 candidate mean 3.8656699657440186, baseline epoch 7 mean 3.8698582649230957, difference -0.0041882991790771484
p-value: 1.2515483712307253e-15
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 9, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 9, train_batch_id: 0, avg_cost: 3.850067377090454
grad_norm: 0.6432777146825791, clipped: 0.6432777146825791
epoch: 9, train_batch_id: 50, avg_cost: 3.852027654647827
grad_norm: 0.7315718083630387, clipped: 0.7315718083630387
epoch: 9, train_batch_id: 100, avg_cost: 3.877548933029175
grad_norm: 0.7496408868101443, clipped: 0.7496408868101443
epoch: 9, train_batch_id: 150, avg_cost: 3.8706469535827637
grad_norm: 0.6279365023821586, clipped: 0.6279365023821586
epoch: 9, train_batch_id: 200, avg_cost: 3.903689384460449
grad_norm: 0.6757680510300583, clipped: 0.6757680510300583
epoch: 9, train_batch_id: 250, avg_cost: 3.86883544921875
grad_norm: 0.6518500005624298, clipped: 0.6518500005624298
epoch: 9, train_batch_id: 300, avg_cost: 3.8662376403808594
grad_norm: 0.8918918882480523, clipped: 0.8918918882480523
epoch: 9, train_batch_id: 350, avg_cost: 3.860262155532837
grad_norm: 0.811445800616696, clipped: 0.811445800616696
epoch: 9, train_batch_id: 400, avg_cost: 3.845745801925659
grad_norm: 0.8986799618055248, clipped: 0.8986799618055248
epoch: 9, train_batch_id: 450, avg_cost: 3.866649866104126
grad_norm: 0.7194062883686881, clipped: 0.7194062883686881
epoch: 9, train_batch_id: 500, avg_cost: 3.8884527683258057
grad_norm: 0.9223117208483738, clipped: 0.9223117208483738
epoch: 9, train_batch_id: 550, avg_cost: 3.867037773132324
grad_norm: 0.8492055278611751, clipped: 0.8492055278611751
epoch: 9, train_batch_id: 600, avg_cost: 3.8800997734069824
grad_norm: 1.0531452500853054, clipped: 1.0
epoch: 9, train_batch_id: 650, avg_cost: 3.8566343784332275
grad_norm: 0.5696186590369433, clipped: 0.5696186590369433
epoch: 9, train_batch_id: 700, avg_cost: 3.866147994995117
grad_norm: 0.7233875180126424, clipped: 0.7233875180126424
epoch: 9, train_batch_id: 750, avg_cost: 3.8819589614868164
grad_norm: 0.5445738586005276, clipped: 0.5445738586005276
epoch: 9, train_batch_id: 800, avg_cost: 3.861240863800049
grad_norm: 0.5820276466016233, clipped: 0.5820276466016233
epoch: 9, train_batch_id: 850, avg_cost: 3.8994956016540527
grad_norm: 0.5663312743316098, clipped: 0.5663312743316098
epoch: 9, train_batch_id: 900, avg_cost: 3.8797154426574707
grad_norm: 0.7285000567823717, clipped: 0.7285000567823717
epoch: 9, train_batch_id: 950, avg_cost: 3.8737001419067383
grad_norm: 0.7032769172986117, clipped: 0.7032769172986117
epoch: 9, train_batch_id: 1000, avg_cost: 3.86950945854187
grad_norm: 0.7023405469354939, clipped: 0.7023405469354939
epoch: 9, train_batch_id: 1050, avg_cost: 3.8639707565307617
grad_norm: 1.4529097400095823, clipped: 1.0
epoch: 9, train_batch_id: 1100, avg_cost: 3.906207799911499
grad_norm: 1.0220969115706569, clipped: 1.0
epoch: 9, train_batch_id: 1150, avg_cost: 3.861448287963867
grad_norm: 0.5978357474970275, clipped: 0.5978357474970275
epoch: 9, train_batch_id: 1200, avg_cost: 3.8948802947998047
grad_norm: 0.6864575136709848, clipped: 0.6864575136709848
epoch: 9, train_batch_id: 1250, avg_cost: 3.8866004943847656
grad_norm: 0.6610047559407772, clipped: 0.6610047559407772
epoch: 9, train_batch_id: 1300, avg_cost: 3.87770414352417
grad_norm: 0.6555655584220282, clipped: 0.6555655584220282
epoch: 9, train_batch_id: 1350, avg_cost: 3.8572463989257812
grad_norm: 0.6125498199568336, clipped: 0.6125498199568336
epoch: 9, train_batch_id: 1400, avg_cost: 3.8583247661590576
grad_norm: 0.8261736793860808, clipped: 0.8261736793860808
epoch: 9, train_batch_id: 1450, avg_cost: 3.8849892616271973
grad_norm: 0.6036605543603459, clipped: 0.6036605543603459
epoch: 9, train_batch_id: 1500, avg_cost: 3.8557417392730713
grad_norm: 0.6916067389192104, clipped: 0.6916067389192104
epoch: 9, train_batch_id: 1550, avg_cost: 3.8527028560638428
grad_norm: 0.5487777555426263, clipped: 0.5487777555426263
epoch: 9, train_batch_id: 1600, avg_cost: 3.894709825515747
grad_norm: 0.5238393414759313, clipped: 0.5238393414759313
epoch: 9, train_batch_id: 1650, avg_cost: 3.8796286582946777
grad_norm: 0.658150857727825, clipped: 0.658150857727825
epoch: 9, train_batch_id: 1700, avg_cost: 3.853546619415283
grad_norm: 0.6295810462057666, clipped: 0.6295810462057666
epoch: 9, train_batch_id: 1750, avg_cost: 3.8400421142578125
grad_norm: 1.4337911296597523, clipped: 1.0
epoch: 9, train_batch_id: 1800, avg_cost: 3.8804147243499756
grad_norm: 0.6796485502667409, clipped: 0.6796485502667409
epoch: 9, train_batch_id: 1850, avg_cost: 3.8950021266937256
grad_norm: 0.9479436062454939, clipped: 0.9479436062454939
epoch: 9, train_batch_id: 1900, avg_cost: 3.88039231300354
grad_norm: 0.6453152134441819, clipped: 0.6453152134441819
epoch: 9, train_batch_id: 1950, avg_cost: 3.8765082359313965
grad_norm: 1.9979185419628145, clipped: 1.0
epoch: 9, train_batch_id: 2000, avg_cost: 3.876282215118408
grad_norm: 0.6915547506325508, clipped: 0.6915547506325508
epoch: 9, train_batch_id: 2050, avg_cost: 3.8679039478302
grad_norm: 0.5984209978619454, clipped: 0.5984209978619454
epoch: 9, train_batch_id: 2100, avg_cost: 3.8766684532165527
grad_norm: 0.5505461859371619, clipped: 0.5505461859371619
epoch: 9, train_batch_id: 2150, avg_cost: 3.873710870742798
grad_norm: 0.43862824479620627, clipped: 0.43862824479620627
epoch: 9, train_batch_id: 2200, avg_cost: 3.8684444427490234
grad_norm: 0.6247074833514333, clipped: 0.6247074833514333
epoch: 9, train_batch_id: 2250, avg_cost: 3.878404378890991
grad_norm: 1.0324925403219063, clipped: 1.0
epoch: 9, train_batch_id: 2300, avg_cost: 3.8827641010284424
grad_norm: 0.881909033979047, clipped: 0.881909033979047
epoch: 9, train_batch_id: 2350, avg_cost: 3.8639469146728516
grad_norm: 0.7435735613785431, clipped: 0.7435735613785431
epoch: 9, train_batch_id: 2400, avg_cost: 3.864335536956787
grad_norm: 0.6954900518215387, clipped: 0.6954900518215387
epoch: 9, train_batch_id: 2450, avg_cost: 3.868704080581665
grad_norm: 0.5454364585137654, clipped: 0.5454364585137654
Finished epoch 9, took 00:05:35 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8686323165893555 +- 0.0031673761550337076
Evaluating candidate model on evaluation dataset
Epoch 9 candidate mean 3.8623948097229004, baseline epoch 8 mean 3.8637664318084717, difference -0.001371622085571289
p-value: 0.003739649126909633
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 10, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 10, train_batch_id: 0, avg_cost: 3.885504722595215
grad_norm: 0.5985300128273381, clipped: 0.5985300128273381
epoch: 10, train_batch_id: 50, avg_cost: 3.8754239082336426
grad_norm: 0.6889867891307827, clipped: 0.6889867891307827
epoch: 10, train_batch_id: 100, avg_cost: 3.8697383403778076
grad_norm: 0.5433003317611528, clipped: 0.5433003317611528
epoch: 10, train_batch_id: 150, avg_cost: 3.899228096008301
grad_norm: 0.7640181279855478, clipped: 0.7640181279855478
epoch: 10, train_batch_id: 200, avg_cost: 3.8829078674316406
grad_norm: 0.7487146895202812, clipped: 0.7487146895202812
epoch: 10, train_batch_id: 250, avg_cost: 3.8949084281921387
grad_norm: 0.9155869935395634, clipped: 0.9155869935395634
epoch: 10, train_batch_id: 300, avg_cost: 3.861755132675171
grad_norm: 0.721504591654736, clipped: 0.721504591654736
epoch: 10, train_batch_id: 350, avg_cost: 3.869072198867798
grad_norm: 0.8572527916277949, clipped: 0.8572527916277949
epoch: 10, train_batch_id: 400, avg_cost: 3.8903818130493164
grad_norm: 0.6005525054461717, clipped: 0.6005525054461717
epoch: 10, train_batch_id: 450, avg_cost: 3.9025378227233887
grad_norm: 0.6888125327113539, clipped: 0.6888125327113539
epoch: 10, train_batch_id: 500, avg_cost: 3.8658692836761475
grad_norm: 0.6397205894389254, clipped: 0.6397205894389254
epoch: 10, train_batch_id: 550, avg_cost: 3.866847515106201
grad_norm: 1.0702923470923873, clipped: 1.0
epoch: 10, train_batch_id: 600, avg_cost: 3.881558895111084
grad_norm: 1.3954238468554065, clipped: 1.0
epoch: 10, train_batch_id: 650, avg_cost: 3.867854118347168
grad_norm: 0.627557804853757, clipped: 0.627557804853757
epoch: 10, train_batch_id: 700, avg_cost: 3.8746557235717773
grad_norm: 0.5129252767588403, clipped: 0.5129252767588403
epoch: 10, train_batch_id: 750, avg_cost: 3.87042498588562
grad_norm: 0.9072233297618486, clipped: 0.9072233297618486
epoch: 10, train_batch_id: 800, avg_cost: 3.875669479370117
grad_norm: 0.482820775053492, clipped: 0.482820775053492
epoch: 10, train_batch_id: 850, avg_cost: 3.86434268951416
grad_norm: 0.6657986491023477, clipped: 0.6657986491023477
epoch: 10, train_batch_id: 900, avg_cost: 3.861809253692627
grad_norm: 0.5164813912872581, clipped: 0.5164813912872581
epoch: 10, train_batch_id: 950, avg_cost: 3.852564811706543
grad_norm: 1.0960187057662796, clipped: 1.0
epoch: 10, train_batch_id: 1000, avg_cost: 3.874021530151367
grad_norm: 1.1701697742423083, clipped: 1.0
epoch: 10, train_batch_id: 1050, avg_cost: 3.890287160873413
grad_norm: 0.7920246910637355, clipped: 0.7920246910637355
epoch: 10, train_batch_id: 1100, avg_cost: 3.8869638442993164
grad_norm: 0.6063769622020686, clipped: 0.6063769622020686
epoch: 10, train_batch_id: 1150, avg_cost: 3.8866512775421143
grad_norm: 0.8265367242156292, clipped: 0.8265367242156292
epoch: 10, train_batch_id: 1200, avg_cost: 3.8740782737731934
grad_norm: 0.9594078483443692, clipped: 0.9594078483443692
epoch: 10, train_batch_id: 1250, avg_cost: 3.86293625831604
grad_norm: 1.079313116167077, clipped: 1.0
epoch: 10, train_batch_id: 1300, avg_cost: 3.883877754211426
grad_norm: 0.6970228400477286, clipped: 0.6970228400477286
epoch: 10, train_batch_id: 1350, avg_cost: 3.8688158988952637
grad_norm: 0.8298973537406752, clipped: 0.8298973537406752
epoch: 10, train_batch_id: 1400, avg_cost: 3.896430492401123
grad_norm: 0.45091525420337647, clipped: 0.45091525420337647
epoch: 10, train_batch_id: 1450, avg_cost: 3.8854827880859375
grad_norm: 0.5566343447641452, clipped: 0.5566343447641452
epoch: 10, train_batch_id: 1500, avg_cost: 3.860373020172119
grad_norm: 0.6403321042497637, clipped: 0.6403321042497637
epoch: 10, train_batch_id: 1550, avg_cost: 3.871941089630127
grad_norm: 0.6570159463292136, clipped: 0.6570159463292136
epoch: 10, train_batch_id: 1600, avg_cost: 3.8833532333374023
grad_norm: 0.7616680323360094, clipped: 0.7616680323360094
epoch: 10, train_batch_id: 1650, avg_cost: 3.8693349361419678
grad_norm: 0.5030214579832895, clipped: 0.5030214579832895
epoch: 10, train_batch_id: 1700, avg_cost: 3.8645830154418945
grad_norm: 0.8137662325538275, clipped: 0.8137662325538275
epoch: 10, train_batch_id: 1750, avg_cost: 3.864856243133545
grad_norm: 2.0307938689041904, clipped: 1.0
epoch: 10, train_batch_id: 1800, avg_cost: 3.8758749961853027
grad_norm: 0.6307538551744486, clipped: 0.6307538551744486
epoch: 10, train_batch_id: 1850, avg_cost: 3.898575782775879
grad_norm: 0.5205777680816017, clipped: 0.5205777680816017
epoch: 10, train_batch_id: 1900, avg_cost: 3.888810396194458
grad_norm: 1.1787397239560937, clipped: 1.0
epoch: 10, train_batch_id: 1950, avg_cost: 3.8831984996795654
grad_norm: 1.1280061506803034, clipped: 1.0
epoch: 10, train_batch_id: 2000, avg_cost: 3.8655779361724854
grad_norm: 0.6431460604618274, clipped: 0.6431460604618274
epoch: 10, train_batch_id: 2050, avg_cost: 3.8487050533294678
grad_norm: 0.9287622978326447, clipped: 0.9287622978326447
epoch: 10, train_batch_id: 2100, avg_cost: 3.8706040382385254
grad_norm: 0.9025052586059589, clipped: 0.9025052586059589
epoch: 10, train_batch_id: 2150, avg_cost: 3.890620708465576
grad_norm: 0.6691693269651112, clipped: 0.6691693269651112
epoch: 10, train_batch_id: 2200, avg_cost: 3.87079119682312
grad_norm: 0.5093109371068926, clipped: 0.5093109371068926
epoch: 10, train_batch_id: 2250, avg_cost: 3.8847951889038086
grad_norm: 0.6503144030175101, clipped: 0.6503144030175101
epoch: 10, train_batch_id: 2300, avg_cost: 3.8577475547790527
grad_norm: 0.7571563189265675, clipped: 0.7571563189265675
epoch: 10, train_batch_id: 2350, avg_cost: 3.8736648559570312
grad_norm: 0.7362196929674844, clipped: 0.7362196929674844
epoch: 10, train_batch_id: 2400, avg_cost: 3.872025728225708
grad_norm: 0.5315594947017908, clipped: 0.5315594947017908
epoch: 10, train_batch_id: 2450, avg_cost: 3.868849277496338
grad_norm: 0.9078969243026072, clipped: 0.9078969243026072
Finished epoch 10, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.868297576904297 +- 0.0031710732728242874
Evaluating candidate model on evaluation dataset
Epoch 10 candidate mean 3.865992546081543, baseline epoch 9 mean 3.8672258853912354, difference -0.0012333393096923828
p-value: 0.007878826567824364
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 11, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 11, train_batch_id: 0, avg_cost: 3.8565306663513184
grad_norm: 0.6445312441504202, clipped: 0.6445312441504202
epoch: 11, train_batch_id: 50, avg_cost: 3.870065450668335
grad_norm: 0.5058085971538834, clipped: 0.5058085971538834
epoch: 11, train_batch_id: 100, avg_cost: 3.870122194290161
grad_norm: 0.6396220146665387, clipped: 0.6396220146665387
epoch: 11, train_batch_id: 150, avg_cost: 3.8496813774108887
grad_norm: 1.003377475026896, clipped: 1.0
epoch: 11, train_batch_id: 200, avg_cost: 3.8878493309020996
grad_norm: 0.6981387911792578, clipped: 0.6981387911792578
epoch: 11, train_batch_id: 250, avg_cost: 3.863969087600708
grad_norm: 0.8023097028299515, clipped: 0.8023097028299515
epoch: 11, train_batch_id: 300, avg_cost: 3.9002768993377686
grad_norm: 1.6201126856482977, clipped: 1.0
epoch: 11, train_batch_id: 350, avg_cost: 3.867089033126831
grad_norm: 0.7618793605420308, clipped: 0.7618793605420308
epoch: 11, train_batch_id: 400, avg_cost: 3.8884687423706055
grad_norm: 0.94130828206304, clipped: 0.94130828206304
epoch: 11, train_batch_id: 450, avg_cost: 3.8711376190185547
grad_norm: 0.6169820615612461, clipped: 0.6169820615612461
epoch: 11, train_batch_id: 500, avg_cost: 3.8686506748199463
grad_norm: 0.5749331878024755, clipped: 0.5749331878024755
epoch: 11, train_batch_id: 550, avg_cost: 3.8668484687805176
grad_norm: 0.7280868385251941, clipped: 0.7280868385251941
epoch: 11, train_batch_id: 600, avg_cost: 3.853651523590088
grad_norm: 0.5643768979916439, clipped: 0.5643768979916439
epoch: 11, train_batch_id: 650, avg_cost: 3.857447624206543
grad_norm: 0.6690520861743892, clipped: 0.6690520861743892
epoch: 11, train_batch_id: 700, avg_cost: 3.8935885429382324
grad_norm: 0.6651780457428337, clipped: 0.6651780457428337
epoch: 11, train_batch_id: 750, avg_cost: 3.8807590007781982
grad_norm: 0.5389599301599339, clipped: 0.5389599301599339
epoch: 11, train_batch_id: 800, avg_cost: 3.859524726867676
grad_norm: 1.0300746312899756, clipped: 1.0
epoch: 11, train_batch_id: 850, avg_cost: 3.8585872650146484
grad_norm: 0.9430066601998529, clipped: 0.9430066601998529
epoch: 11, train_batch_id: 900, avg_cost: 3.8546142578125
grad_norm: 0.47854360976945326, clipped: 0.47854360976945326
epoch: 11, train_batch_id: 950, avg_cost: 3.874560594558716
grad_norm: 0.514132683935637, clipped: 0.514132683935637
epoch: 11, train_batch_id: 1000, avg_cost: 3.8901047706604004
grad_norm: 0.7198193578486676, clipped: 0.7198193578486676
epoch: 11, train_batch_id: 1050, avg_cost: 3.8687403202056885
grad_norm: 0.8828806425223374, clipped: 0.8828806425223374
epoch: 11, train_batch_id: 1100, avg_cost: 3.8531551361083984
grad_norm: 0.5125358595476274, clipped: 0.5125358595476274
epoch: 11, train_batch_id: 1150, avg_cost: 3.8983154296875
grad_norm: 0.7131378886610781, clipped: 0.7131378886610781
epoch: 11, train_batch_id: 1200, avg_cost: 3.860565185546875
grad_norm: 0.4773207604265332, clipped: 0.4773207604265332
epoch: 11, train_batch_id: 1250, avg_cost: 3.8595588207244873
grad_norm: 1.4286067722767615, clipped: 1.0
epoch: 11, train_batch_id: 1300, avg_cost: 3.86657452583313
grad_norm: 0.5480157289842841, clipped: 0.5480157289842841
epoch: 11, train_batch_id: 1350, avg_cost: 3.866279125213623
grad_norm: 1.6111356404283335, clipped: 1.0
epoch: 11, train_batch_id: 1400, avg_cost: 3.8713669776916504
grad_norm: 0.7008635740720012, clipped: 0.7008635740720012
epoch: 11, train_batch_id: 1450, avg_cost: 3.8715667724609375
grad_norm: 0.8924686421766358, clipped: 0.8924686421766358
epoch: 11, train_batch_id: 1500, avg_cost: 3.893313407897949
grad_norm: 0.5810604516375337, clipped: 0.5810604516375337
epoch: 11, train_batch_id: 1550, avg_cost: 3.856001138687134
grad_norm: 0.7551042370666765, clipped: 0.7551042370666765
epoch: 11, train_batch_id: 1600, avg_cost: 3.8841211795806885
grad_norm: 0.6337586339374786, clipped: 0.6337586339374786
epoch: 11, train_batch_id: 1650, avg_cost: 3.865851879119873
grad_norm: 1.5174512624966223, clipped: 1.0
epoch: 11, train_batch_id: 1700, avg_cost: 3.8732714653015137
grad_norm: 0.6223799143900269, clipped: 0.6223799143900269
epoch: 11, train_batch_id: 1750, avg_cost: 3.8809328079223633
grad_norm: 0.7085818973019585, clipped: 0.7085818973019585
epoch: 11, train_batch_id: 1800, avg_cost: 3.874748706817627
grad_norm: 0.5770066827493097, clipped: 0.5770066827493097
epoch: 11, train_batch_id: 1850, avg_cost: 3.8685922622680664
grad_norm: 0.6300166663040372, clipped: 0.6300166663040372
epoch: 11, train_batch_id: 1900, avg_cost: 3.882485866546631
grad_norm: 0.645721952760038, clipped: 0.645721952760038
epoch: 11, train_batch_id: 1950, avg_cost: 3.895815372467041
grad_norm: 0.5971590591760286, clipped: 0.5971590591760286
epoch: 11, train_batch_id: 2000, avg_cost: 3.890852928161621
grad_norm: 0.7430643430099715, clipped: 0.7430643430099715
epoch: 11, train_batch_id: 2050, avg_cost: 3.8823719024658203
grad_norm: 1.31097257025468, clipped: 1.0
epoch: 11, train_batch_id: 2100, avg_cost: 3.8874685764312744
grad_norm: 0.8228077312269311, clipped: 0.8228077312269311
epoch: 11, train_batch_id: 2150, avg_cost: 3.8852429389953613
grad_norm: 0.8761959149835745, clipped: 0.8761959149835745
epoch: 11, train_batch_id: 2200, avg_cost: 3.8673582077026367
grad_norm: 0.47192180319028504, clipped: 0.47192180319028504
epoch: 11, train_batch_id: 2250, avg_cost: 3.8972795009613037
grad_norm: 0.6804136303483739, clipped: 0.6804136303483739
epoch: 11, train_batch_id: 2300, avg_cost: 3.887338638305664
grad_norm: 0.5835331785723051, clipped: 0.5835331785723051
epoch: 11, train_batch_id: 2350, avg_cost: 3.8701682090759277
grad_norm: 0.5021898884518797, clipped: 0.5021898884518797
epoch: 11, train_batch_id: 2400, avg_cost: 3.870683193206787
grad_norm: 1.220341503569381, clipped: 1.0
epoch: 11, train_batch_id: 2450, avg_cost: 3.88767147064209
grad_norm: 0.7905143177009003, clipped: 0.7905143177009003
Finished epoch 11, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8657636642456055 +- 0.0031605917029082775
Evaluating candidate model on evaluation dataset
Epoch 11 candidate mean 3.8620622158050537, baseline epoch 10 mean 3.8634679317474365, difference -0.0014057159423828125
p-value: 0.0019729863582935935
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 12, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 12, train_batch_id: 0, avg_cost: 3.864391803741455
grad_norm: 0.37616822630994096, clipped: 0.37616822630994096
epoch: 12, train_batch_id: 50, avg_cost: 3.8697168827056885
grad_norm: 0.6973695821928868, clipped: 0.6973695821928868
epoch: 12, train_batch_id: 100, avg_cost: 3.8661608695983887
grad_norm: 0.5758802669503088, clipped: 0.5758802669503088
epoch: 12, train_batch_id: 150, avg_cost: 3.8589928150177
grad_norm: 1.2211818590342585, clipped: 1.0
epoch: 12, train_batch_id: 200, avg_cost: 3.8721938133239746
grad_norm: 0.5602694942264064, clipped: 0.5602694942264064
epoch: 12, train_batch_id: 250, avg_cost: 3.8449082374572754
grad_norm: 0.6220754709913394, clipped: 0.6220754709913394
epoch: 12, train_batch_id: 300, avg_cost: 3.871558904647827
grad_norm: 0.7953547016457775, clipped: 0.7953547016457775
epoch: 12, train_batch_id: 350, avg_cost: 3.882340908050537
grad_norm: 0.6693705044600016, clipped: 0.6693705044600016
epoch: 12, train_batch_id: 400, avg_cost: 3.8600363731384277
grad_norm: 0.6815274022916323, clipped: 0.6815274022916323
epoch: 12, train_batch_id: 450, avg_cost: 3.8904776573181152
grad_norm: 1.457253750116997, clipped: 1.0
epoch: 12, train_batch_id: 500, avg_cost: 3.9059510231018066
grad_norm: 1.3112455021772709, clipped: 1.0
epoch: 12, train_batch_id: 550, avg_cost: 3.8729186058044434
grad_norm: 0.7528963219373987, clipped: 0.7528963219373987
epoch: 12, train_batch_id: 600, avg_cost: 3.868011951446533
grad_norm: 0.5661488291199829, clipped: 0.5661488291199829
epoch: 12, train_batch_id: 650, avg_cost: 3.881357192993164
grad_norm: 0.6186862259940893, clipped: 0.6186862259940893
epoch: 12, train_batch_id: 700, avg_cost: 3.8950955867767334
grad_norm: 0.4857944944031936, clipped: 0.4857944944031936
epoch: 12, train_batch_id: 750, avg_cost: 3.8698441982269287
grad_norm: 0.44992195427905546, clipped: 0.44992195427905546
epoch: 12, train_batch_id: 800, avg_cost: 3.875006914138794
grad_norm: 0.7017508378112386, clipped: 0.7017508378112386
epoch: 12, train_batch_id: 850, avg_cost: 3.8777213096618652
grad_norm: 0.4960617552912755, clipped: 0.4960617552912755
epoch: 12, train_batch_id: 900, avg_cost: 3.894711971282959
grad_norm: 0.7099379644677911, clipped: 0.7099379644677911
epoch: 12, train_batch_id: 950, avg_cost: 3.8593201637268066
grad_norm: 0.5244792956371623, clipped: 0.5244792956371623
epoch: 12, train_batch_id: 1000, avg_cost: 3.8922781944274902
grad_norm: 0.7231123183513878, clipped: 0.7231123183513878
epoch: 12, train_batch_id: 1050, avg_cost: 3.8436279296875
grad_norm: 0.5957283295033889, clipped: 0.5957283295033889
epoch: 12, train_batch_id: 1100, avg_cost: 3.87713623046875
grad_norm: 0.5827470164770252, clipped: 0.5827470164770252
epoch: 12, train_batch_id: 1150, avg_cost: 3.8755550384521484
grad_norm: 0.5346257652918228, clipped: 0.5346257652918228
epoch: 12, train_batch_id: 1200, avg_cost: 3.8799192905426025
grad_norm: 0.6659006506000302, clipped: 0.6659006506000302
epoch: 12, train_batch_id: 1250, avg_cost: 3.8724207878112793
grad_norm: 0.5873159446000357, clipped: 0.5873159446000357
epoch: 12, train_batch_id: 1300, avg_cost: 3.8788394927978516
grad_norm: 0.49402126093077176, clipped: 0.49402126093077176
epoch: 12, train_batch_id: 1350, avg_cost: 3.8816399574279785
grad_norm: 0.9682440648724269, clipped: 0.9682440648724269
epoch: 12, train_batch_id: 1400, avg_cost: 3.88938570022583
grad_norm: 0.5220941936674784, clipped: 0.5220941936674784
epoch: 12, train_batch_id: 1450, avg_cost: 3.8612117767333984
grad_norm: 0.659254214514927, clipped: 0.659254214514927
epoch: 12, train_batch_id: 1500, avg_cost: 3.871697425842285
grad_norm: 0.4977168249707168, clipped: 0.4977168249707168
epoch: 12, train_batch_id: 1550, avg_cost: 3.855682611465454
grad_norm: 0.4601528298423699, clipped: 0.4601528298423699
epoch: 12, train_batch_id: 1600, avg_cost: 3.864457130432129
grad_norm: 0.6596056536073973, clipped: 0.6596056536073973
epoch: 12, train_batch_id: 1650, avg_cost: 3.864389419555664
grad_norm: 1.0074487012888411, clipped: 1.0
epoch: 12, train_batch_id: 1700, avg_cost: 3.8586766719818115
grad_norm: 0.8989686219857135, clipped: 0.8989686219857135
epoch: 12, train_batch_id: 1750, avg_cost: 3.8613715171813965
grad_norm: 0.6297636756912423, clipped: 0.6297636756912423
epoch: 12, train_batch_id: 1800, avg_cost: 3.876884937286377
grad_norm: 0.8606325801344322, clipped: 0.8606325801344322
epoch: 12, train_batch_id: 1850, avg_cost: 3.828091859817505
grad_norm: 0.6784998396937141, clipped: 0.6784998396937141
epoch: 12, train_batch_id: 1900, avg_cost: 3.879484176635742
grad_norm: 0.7860596622357928, clipped: 0.7860596622357928
epoch: 12, train_batch_id: 1950, avg_cost: 3.861448287963867
grad_norm: 0.624578966478628, clipped: 0.624578966478628
epoch: 12, train_batch_id: 2000, avg_cost: 3.880794048309326
grad_norm: 0.7688400602469783, clipped: 0.7688400602469783
epoch: 12, train_batch_id: 2050, avg_cost: 3.8812308311462402
grad_norm: 0.6487683667385321, clipped: 0.6487683667385321
epoch: 12, train_batch_id: 2100, avg_cost: 3.8408846855163574
grad_norm: 0.6780241911923118, clipped: 0.6780241911923118
epoch: 12, train_batch_id: 2150, avg_cost: 3.871403217315674
grad_norm: 0.6982689078833252, clipped: 0.6982689078833252
epoch: 12, train_batch_id: 2200, avg_cost: 3.8559489250183105
grad_norm: 1.2037061448269237, clipped: 1.0
epoch: 12, train_batch_id: 2250, avg_cost: 3.8488452434539795
grad_norm: 0.9211177388635226, clipped: 0.9211177388635226
epoch: 12, train_batch_id: 2300, avg_cost: 3.847440481185913
grad_norm: 0.7037767449427962, clipped: 0.7037767449427962
epoch: 12, train_batch_id: 2350, avg_cost: 3.8782200813293457
grad_norm: 0.5483078524917256, clipped: 0.5483078524917256
epoch: 12, train_batch_id: 2400, avg_cost: 3.8902463912963867
grad_norm: 0.570152273651327, clipped: 0.570152273651327
epoch: 12, train_batch_id: 2450, avg_cost: 3.8629589080810547
grad_norm: 0.6694388664889459, clipped: 0.6694388664889459
Finished epoch 12, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8627960681915283 +- 0.0031523725483566523
Evaluating candidate model on evaluation dataset
Epoch 12 candidate mean 3.8578436374664307, baseline epoch 11 mean 3.8601176738739014, difference -0.002274036407470703
p-value: 5.497280940460266e-07
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 13, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 13, train_batch_id: 0, avg_cost: 3.864377975463867
grad_norm: 0.8819704659343619, clipped: 0.8819704659343619
epoch: 13, train_batch_id: 50, avg_cost: 3.856168746948242
grad_norm: 0.6381600787295704, clipped: 0.6381600787295704
epoch: 13, train_batch_id: 100, avg_cost: 3.8378379344940186
grad_norm: 0.5450791916496692, clipped: 0.5450791916496692
epoch: 13, train_batch_id: 150, avg_cost: 3.8660781383514404
grad_norm: 0.5059674045364512, clipped: 0.5059674045364512
epoch: 13, train_batch_id: 200, avg_cost: 3.882122755050659
grad_norm: 0.538783341852832, clipped: 0.538783341852832
epoch: 13, train_batch_id: 250, avg_cost: 3.8917503356933594
grad_norm: 0.6695757307736304, clipped: 0.6695757307736304
epoch: 13, train_batch_id: 300, avg_cost: 3.865013599395752
grad_norm: 0.3983729964188555, clipped: 0.3983729964188555
epoch: 13, train_batch_id: 350, avg_cost: 3.875305414199829
grad_norm: 0.5530838194876072, clipped: 0.5530838194876072
epoch: 13, train_batch_id: 400, avg_cost: 3.8646655082702637
grad_norm: 0.5403354848167483, clipped: 0.5403354848167483
epoch: 13, train_batch_id: 450, avg_cost: 3.8598010540008545
grad_norm: 0.6289703735909615, clipped: 0.6289703735909615
epoch: 13, train_batch_id: 500, avg_cost: 3.870711326599121
grad_norm: 0.6938958306480986, clipped: 0.6938958306480986
epoch: 13, train_batch_id: 550, avg_cost: 3.856659173965454
grad_norm: 0.7387228399880816, clipped: 0.7387228399880816
epoch: 13, train_batch_id: 600, avg_cost: 3.850827217102051
grad_norm: 0.7856471670610847, clipped: 0.7856471670610847
epoch: 13, train_batch_id: 650, avg_cost: 3.854391574859619
grad_norm: 0.585255197392796, clipped: 0.585255197392796
epoch: 13, train_batch_id: 700, avg_cost: 3.872985363006592
grad_norm: 0.4724100038555863, clipped: 0.4724100038555863
epoch: 13, train_batch_id: 750, avg_cost: 3.885188102722168
grad_norm: 0.42381996640291825, clipped: 0.42381996640291825
epoch: 13, train_batch_id: 800, avg_cost: 3.8822407722473145
grad_norm: 0.7334632850141065, clipped: 0.7334632850141065
epoch: 13, train_batch_id: 850, avg_cost: 3.8933305740356445
grad_norm: 0.5039205103223803, clipped: 0.5039205103223803
epoch: 13, train_batch_id: 900, avg_cost: 3.888540029525757
grad_norm: 0.5648247849309818, clipped: 0.5648247849309818
epoch: 13, train_batch_id: 950, avg_cost: 3.869433641433716
grad_norm: 0.5371118082836351, clipped: 0.5371118082836351
epoch: 13, train_batch_id: 1000, avg_cost: 3.879761219024658
grad_norm: 0.6616050269255229, clipped: 0.6616050269255229
epoch: 13, train_batch_id: 1050, avg_cost: 3.8634448051452637
grad_norm: 0.6745836117853207, clipped: 0.6745836117853207
epoch: 13, train_batch_id: 1100, avg_cost: 3.8576629161834717
grad_norm: 0.5063654576565233, clipped: 0.5063654576565233
epoch: 13, train_batch_id: 1150, avg_cost: 3.863546371459961
grad_norm: 0.41061103417233114, clipped: 0.41061103417233114
epoch: 13, train_batch_id: 1200, avg_cost: 3.862605571746826
grad_norm: 2.527501637834386, clipped: 1.0
epoch: 13, train_batch_id: 1250, avg_cost: 3.882187843322754
grad_norm: 0.5135418986688227, clipped: 0.5135418986688227
epoch: 13, train_batch_id: 1300, avg_cost: 3.8704185485839844
grad_norm: 0.5116067384886751, clipped: 0.5116067384886751
epoch: 13, train_batch_id: 1350, avg_cost: 3.8673887252807617
grad_norm: 0.8141092942750257, clipped: 0.8141092942750257
epoch: 13, train_batch_id: 1400, avg_cost: 3.8749542236328125
grad_norm: 0.685193175343639, clipped: 0.685193175343639
epoch: 13, train_batch_id: 1450, avg_cost: 3.8856356143951416
grad_norm: 0.5835200165531844, clipped: 0.5835200165531844
epoch: 13, train_batch_id: 1500, avg_cost: 3.8676538467407227
grad_norm: 0.7338731861238438, clipped: 0.7338731861238438
epoch: 13, train_batch_id: 1550, avg_cost: 3.8639016151428223
grad_norm: 0.4516092397066966, clipped: 0.4516092397066966
epoch: 13, train_batch_id: 1600, avg_cost: 3.856985092163086
grad_norm: 0.46767070606328864, clipped: 0.46767070606328864
epoch: 13, train_batch_id: 1650, avg_cost: 3.8438899517059326
grad_norm: 0.511272863363953, clipped: 0.511272863363953
epoch: 13, train_batch_id: 1700, avg_cost: 3.8805651664733887
grad_norm: 0.49130582580924964, clipped: 0.49130582580924964
epoch: 13, train_batch_id: 1750, avg_cost: 3.854943037033081
grad_norm: 0.5942763457440147, clipped: 0.5942763457440147
epoch: 13, train_batch_id: 1800, avg_cost: 3.8888912200927734
grad_norm: 0.5646205009115012, clipped: 0.5646205009115012
epoch: 13, train_batch_id: 1850, avg_cost: 3.8536272048950195
grad_norm: 0.6792943354031178, clipped: 0.6792943354031178
epoch: 13, train_batch_id: 1900, avg_cost: 3.8558080196380615
grad_norm: 0.5047500190364048, clipped: 0.5047500190364048
epoch: 13, train_batch_id: 1950, avg_cost: 3.8670082092285156
grad_norm: 0.57600066192931, clipped: 0.57600066192931
epoch: 13, train_batch_id: 2000, avg_cost: 3.8657774925231934
grad_norm: 0.8466481911040457, clipped: 0.8466481911040457
epoch: 13, train_batch_id: 2050, avg_cost: 3.8406405448913574
grad_norm: 0.6515593731500751, clipped: 0.6515593731500751
epoch: 13, train_batch_id: 2100, avg_cost: 3.863983631134033
grad_norm: 0.5734832137673829, clipped: 0.5734832137673829
epoch: 13, train_batch_id: 2150, avg_cost: 3.881988525390625
grad_norm: 0.38078342372031787, clipped: 0.38078342372031787
epoch: 13, train_batch_id: 2200, avg_cost: 3.85359787940979
grad_norm: 0.6930478910137176, clipped: 0.6930478910137176
epoch: 13, train_batch_id: 2250, avg_cost: 3.859799385070801
grad_norm: 0.6296490358596188, clipped: 0.6296490358596188
epoch: 13, train_batch_id: 2300, avg_cost: 3.8788483142852783
grad_norm: 0.7150260768589779, clipped: 0.7150260768589779
epoch: 13, train_batch_id: 2350, avg_cost: 3.861144542694092
grad_norm: 0.42868904056787915, clipped: 0.42868904056787915
epoch: 13, train_batch_id: 2400, avg_cost: 3.8544814586639404
grad_norm: 1.2844427881128564, clipped: 1.0
epoch: 13, train_batch_id: 2450, avg_cost: 3.8702733516693115
grad_norm: 1.0293508406975496, clipped: 1.0
Finished epoch 13, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.862293004989624 +- 0.0031492181587964296
Evaluating candidate model on evaluation dataset
Epoch 13 candidate mean 3.861969470977783, baseline epoch 12 mean 3.8626952171325684, difference -0.0007257461547851562
p-value: 0.047508868330979746
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 14, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 14, train_batch_id: 0, avg_cost: 3.86135196685791
grad_norm: 0.520522477286492, clipped: 0.520522477286492
epoch: 14, train_batch_id: 50, avg_cost: 3.877197742462158
grad_norm: 0.45987700750144717, clipped: 0.45987700750144717
epoch: 14, train_batch_id: 100, avg_cost: 3.85970401763916
grad_norm: 0.6784483391508415, clipped: 0.6784483391508415
epoch: 14, train_batch_id: 150, avg_cost: 3.8570070266723633
grad_norm: 0.40722961425270277, clipped: 0.40722961425270277
epoch: 14, train_batch_id: 200, avg_cost: 3.8698348999023438
grad_norm: 0.8178346439763705, clipped: 0.8178346439763705
epoch: 14, train_batch_id: 250, avg_cost: 3.877224922180176
grad_norm: 0.4438667715568932, clipped: 0.4438667715568932
epoch: 14, train_batch_id: 300, avg_cost: 3.899503231048584
grad_norm: 0.8219729192378462, clipped: 0.8219729192378462
epoch: 14, train_batch_id: 350, avg_cost: 3.8779425621032715
grad_norm: 0.6547506697990432, clipped: 0.6547506697990432
epoch: 14, train_batch_id: 400, avg_cost: 3.8738255500793457
grad_norm: 0.5531194578473381, clipped: 0.5531194578473381
epoch: 14, train_batch_id: 450, avg_cost: 3.8599562644958496
grad_norm: 0.5077041287172834, clipped: 0.5077041287172834
epoch: 14, train_batch_id: 500, avg_cost: 3.8635194301605225
grad_norm: 0.6039006548474742, clipped: 0.6039006548474742
epoch: 14, train_batch_id: 550, avg_cost: 3.8431756496429443
grad_norm: 0.7751205971318335, clipped: 0.7751205971318335
epoch: 14, train_batch_id: 600, avg_cost: 3.87105655670166
grad_norm: 0.5743104237203516, clipped: 0.5743104237203516
epoch: 14, train_batch_id: 650, avg_cost: 3.867727041244507
grad_norm: 0.5853323086893516, clipped: 0.5853323086893516
epoch: 14, train_batch_id: 700, avg_cost: 3.8582067489624023
grad_norm: 1.909400437279047, clipped: 1.0
epoch: 14, train_batch_id: 750, avg_cost: 3.861217498779297
grad_norm: 1.0574192048477333, clipped: 1.0
epoch: 14, train_batch_id: 800, avg_cost: 3.8537585735321045
grad_norm: 0.9378456167302417, clipped: 0.9378456167302417
epoch: 14, train_batch_id: 850, avg_cost: 3.8465628623962402
grad_norm: 0.4810363310498823, clipped: 0.4810363310498823
epoch: 14, train_batch_id: 900, avg_cost: 3.880239486694336
grad_norm: 0.4342072717544091, clipped: 0.4342072717544091
epoch: 14, train_batch_id: 950, avg_cost: 3.863191604614258
grad_norm: 0.968934687110097, clipped: 0.968934687110097
epoch: 14, train_batch_id: 1000, avg_cost: 3.8485679626464844
grad_norm: 0.7533476158122133, clipped: 0.7533476158122133
epoch: 14, train_batch_id: 1050, avg_cost: 3.8511929512023926
grad_norm: 0.4810693142783843, clipped: 0.4810693142783843
epoch: 14, train_batch_id: 1100, avg_cost: 3.8835935592651367
grad_norm: 0.6014458362160476, clipped: 0.6014458362160476
epoch: 14, train_batch_id: 1150, avg_cost: 3.8811073303222656
grad_norm: 0.4732064970993489, clipped: 0.4732064970993489
epoch: 14, train_batch_id: 1200, avg_cost: 3.8701725006103516
grad_norm: 0.669305837396557, clipped: 0.669305837396557
epoch: 14, train_batch_id: 1250, avg_cost: 3.839050769805908
grad_norm: 0.8483870289459122, clipped: 0.8483870289459122
epoch: 14, train_batch_id: 1300, avg_cost: 3.8687663078308105
grad_norm: 0.8872947475739466, clipped: 0.8872947475739466
epoch: 14, train_batch_id: 1350, avg_cost: 3.872227907180786
grad_norm: 0.5167425479661094, clipped: 0.5167425479661094
epoch: 14, train_batch_id: 1400, avg_cost: 3.8692739009857178
grad_norm: 1.6324606614496717, clipped: 1.0
epoch: 14, train_batch_id: 1450, avg_cost: 3.8791017532348633
grad_norm: 0.6923445189567962, clipped: 0.6923445189567962
epoch: 14, train_batch_id: 1500, avg_cost: 3.855240821838379
grad_norm: 0.8158189295998554, clipped: 0.8158189295998554
epoch: 14, train_batch_id: 1550, avg_cost: 3.8554329872131348
grad_norm: 0.5924145489401709, clipped: 0.5924145489401709
epoch: 14, train_batch_id: 1600, avg_cost: 3.8481216430664062
grad_norm: 0.43325341037887277, clipped: 0.43325341037887277
epoch: 14, train_batch_id: 1650, avg_cost: 3.880608081817627
grad_norm: 0.49326531113459543, clipped: 0.49326531113459543
epoch: 14, train_batch_id: 1700, avg_cost: 3.8734424114227295
grad_norm: 0.8643372480509436, clipped: 0.8643372480509436
epoch: 14, train_batch_id: 1750, avg_cost: 3.856865406036377
grad_norm: 0.4545095304849367, clipped: 0.4545095304849367
epoch: 14, train_batch_id: 1800, avg_cost: 3.87375807762146
grad_norm: 0.7054108052311628, clipped: 0.7054108052311628
epoch: 14, train_batch_id: 1850, avg_cost: 3.848151922225952
grad_norm: 0.4763428218363917, clipped: 0.4763428218363917
epoch: 14, train_batch_id: 1900, avg_cost: 3.8868162631988525
grad_norm: 0.6458630594122236, clipped: 0.6458630594122236
epoch: 14, train_batch_id: 1950, avg_cost: 3.8734002113342285
grad_norm: 0.47335278899191013, clipped: 0.47335278899191013
epoch: 14, train_batch_id: 2000, avg_cost: 3.8662991523742676
grad_norm: 0.7375790224426035, clipped: 0.7375790224426035
epoch: 14, train_batch_id: 2050, avg_cost: 3.858304023742676
grad_norm: 0.7236289578511992, clipped: 0.7236289578511992
epoch: 14, train_batch_id: 2100, avg_cost: 3.8631680011749268
grad_norm: 0.9203454012053841, clipped: 0.9203454012053841
epoch: 14, train_batch_id: 2150, avg_cost: 3.881700038909912
grad_norm: 0.5994702385329505, clipped: 0.5994702385329505
epoch: 14, train_batch_id: 2200, avg_cost: 3.879183769226074
grad_norm: 0.4871693682904993, clipped: 0.4871693682904993
epoch: 14, train_batch_id: 2250, avg_cost: 3.863691806793213
grad_norm: 0.42107613896245266, clipped: 0.42107613896245266
epoch: 14, train_batch_id: 2300, avg_cost: 3.8421430587768555
grad_norm: 0.6158212886909943, clipped: 0.6158212886909943
epoch: 14, train_batch_id: 2350, avg_cost: 3.8706350326538086
grad_norm: 0.5000024176514511, clipped: 0.5000024176514511
epoch: 14, train_batch_id: 2400, avg_cost: 3.8822731971740723
grad_norm: 1.1842391635010383, clipped: 1.0
epoch: 14, train_batch_id: 2450, avg_cost: 3.8450005054473877
grad_norm: 0.5660328928398018, clipped: 0.5660328928398018
Finished epoch 14, took 00:05:42 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8632590770721436 +- 0.0031558629125356674
Evaluating candidate model on evaluation dataset
Epoch 14 candidate mean 3.859220266342163, baseline epoch 13 mean 3.8585519790649414, difference 0.0006682872772216797
Start train epoch 15, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 15, train_batch_id: 0, avg_cost: 3.8578109741210938
grad_norm: 0.6420660172770587, clipped: 0.6420660172770587
epoch: 15, train_batch_id: 50, avg_cost: 3.8631608486175537
grad_norm: 0.5809724860904226, clipped: 0.5809724860904226
epoch: 15, train_batch_id: 100, avg_cost: 3.8542087078094482
grad_norm: 0.6910167107669011, clipped: 0.6910167107669011
epoch: 15, train_batch_id: 150, avg_cost: 3.876051902770996
grad_norm: 0.5305670712488837, clipped: 0.5305670712488837
epoch: 15, train_batch_id: 200, avg_cost: 3.855182647705078
grad_norm: 0.8183289728136749, clipped: 0.8183289728136749
epoch: 15, train_batch_id: 250, avg_cost: 3.8624324798583984
grad_norm: 0.5241351172108215, clipped: 0.5241351172108215
epoch: 15, train_batch_id: 300, avg_cost: 3.8463070392608643
grad_norm: 0.4077771835652878, clipped: 0.4077771835652878
epoch: 15, train_batch_id: 350, avg_cost: 3.8671088218688965
grad_norm: 0.4765069018843256, clipped: 0.4765069018843256
epoch: 15, train_batch_id: 400, avg_cost: 3.873903512954712
grad_norm: 0.5445475536384572, clipped: 0.5445475536384572
epoch: 15, train_batch_id: 450, avg_cost: 3.8526721000671387
grad_norm: 0.6000272422000864, clipped: 0.6000272422000864
epoch: 15, train_batch_id: 500, avg_cost: 3.8734869956970215
grad_norm: 0.7041542397099301, clipped: 0.7041542397099301
epoch: 15, train_batch_id: 550, avg_cost: 3.8825936317443848
grad_norm: 0.6797801683499106, clipped: 0.6797801683499106
epoch: 15, train_batch_id: 600, avg_cost: 3.8530614376068115
grad_norm: 0.5714089297886855, clipped: 0.5714089297886855
epoch: 15, train_batch_id: 650, avg_cost: 3.8606066703796387
grad_norm: 0.9655817177584888, clipped: 0.9655817177584888
epoch: 15, train_batch_id: 700, avg_cost: 3.872626781463623
grad_norm: 0.543663114063847, clipped: 0.543663114063847
epoch: 15, train_batch_id: 750, avg_cost: 3.875180721282959
grad_norm: 0.522166193291009, clipped: 0.522166193291009
epoch: 15, train_batch_id: 800, avg_cost: 3.875903606414795
grad_norm: 0.677308518986106, clipped: 0.677308518986106
epoch: 15, train_batch_id: 850, avg_cost: 3.854243278503418
grad_norm: 1.2788291268956609, clipped: 1.0
epoch: 15, train_batch_id: 900, avg_cost: 3.8709425926208496
grad_norm: 3.0884753131872986, clipped: 1.0
epoch: 15, train_batch_id: 950, avg_cost: 3.874840021133423
grad_norm: 0.5092001447919134, clipped: 0.5092001447919134
epoch: 15, train_batch_id: 1000, avg_cost: 3.8848700523376465
grad_norm: 0.6765955979601279, clipped: 0.6765955979601279
epoch: 15, train_batch_id: 1050, avg_cost: 3.8600375652313232
grad_norm: 0.7922516115545466, clipped: 0.7922516115545466
epoch: 15, train_batch_id: 1100, avg_cost: 3.8643593788146973
grad_norm: 0.45456082183780594, clipped: 0.45456082183780594
epoch: 15, train_batch_id: 1150, avg_cost: 3.8530304431915283
grad_norm: 0.6236383077207399, clipped: 0.6236383077207399
epoch: 15, train_batch_id: 1200, avg_cost: 3.8782401084899902
grad_norm: 0.4863352956521295, clipped: 0.4863352956521295
epoch: 15, train_batch_id: 1250, avg_cost: 3.860217809677124
grad_norm: 0.6792167110201566, clipped: 0.6792167110201566
epoch: 15, train_batch_id: 1300, avg_cost: 3.867971181869507
grad_norm: 1.1498298043458692, clipped: 1.0
epoch: 15, train_batch_id: 1350, avg_cost: 3.827784776687622
grad_norm: 0.46361091492871725, clipped: 0.46361091492871725
epoch: 15, train_batch_id: 1400, avg_cost: 3.8701722621917725
grad_norm: 0.6999479451589686, clipped: 0.6999479451589686
epoch: 15, train_batch_id: 1450, avg_cost: 3.858299970626831
grad_norm: 0.6285231835257473, clipped: 0.6285231835257473
epoch: 15, train_batch_id: 1500, avg_cost: 3.846010684967041
grad_norm: 0.48782329426775306, clipped: 0.48782329426775306
epoch: 15, train_batch_id: 1550, avg_cost: 3.865849018096924
grad_norm: 0.6704967775017492, clipped: 0.6704967775017492
epoch: 15, train_batch_id: 1600, avg_cost: 3.8678512573242188
grad_norm: 0.4902996757308489, clipped: 0.4902996757308489
epoch: 15, train_batch_id: 1650, avg_cost: 3.8614768981933594
grad_norm: 0.7416495851622463, clipped: 0.7416495851622463
epoch: 15, train_batch_id: 1700, avg_cost: 3.840196132659912
grad_norm: 0.6792174198954726, clipped: 0.6792174198954726
epoch: 15, train_batch_id: 1750, avg_cost: 3.8777642250061035
grad_norm: 0.5397614715449514, clipped: 0.5397614715449514
epoch: 15, train_batch_id: 1800, avg_cost: 3.823493480682373
grad_norm: 0.3935316722983589, clipped: 0.3935316722983589
epoch: 15, train_batch_id: 1850, avg_cost: 3.8539962768554688
grad_norm: 0.7655733687049827, clipped: 0.7655733687049827
epoch: 15, train_batch_id: 1900, avg_cost: 3.893299102783203
grad_norm: 0.9811014493498817, clipped: 0.9811014493498817
epoch: 15, train_batch_id: 1950, avg_cost: 3.8520636558532715
grad_norm: 0.4602189149688148, clipped: 0.4602189149688148
epoch: 15, train_batch_id: 2000, avg_cost: 3.887455940246582
grad_norm: 0.7106009380454797, clipped: 0.7106009380454797
epoch: 15, train_batch_id: 2050, avg_cost: 3.8666441440582275
grad_norm: 1.3601809267991816, clipped: 1.0
epoch: 15, train_batch_id: 2100, avg_cost: 3.8772659301757812
grad_norm: 0.5712785530352976, clipped: 0.5712785530352976
epoch: 15, train_batch_id: 2150, avg_cost: 3.893674373626709
grad_norm: 0.545139966678315, clipped: 0.545139966678315
epoch: 15, train_batch_id: 2200, avg_cost: 3.8647212982177734
grad_norm: 0.5215592094774021, clipped: 0.5215592094774021
epoch: 15, train_batch_id: 2250, avg_cost: 3.8689074516296387
grad_norm: 0.7682578687839848, clipped: 0.7682578687839848
epoch: 15, train_batch_id: 2300, avg_cost: 3.8387012481689453
grad_norm: 0.4724680968699995, clipped: 0.4724680968699995
epoch: 15, train_batch_id: 2350, avg_cost: 3.8824219703674316
grad_norm: 0.4554221864215194, clipped: 0.4554221864215194
epoch: 15, train_batch_id: 2400, avg_cost: 3.852811813354492
grad_norm: 0.8590945182325649, clipped: 0.8590945182325649
epoch: 15, train_batch_id: 2450, avg_cost: 3.874001979827881
grad_norm: 0.7624382561504625, clipped: 0.7624382561504625
Finished epoch 15, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8613812923431396 +- 0.003153557889163494
Evaluating candidate model on evaluation dataset
Epoch 15 candidate mean 3.8568055629730225, baseline epoch 13 mean 3.8585519790649414, difference -0.0017464160919189453
p-value: 3.837296565339565e-05
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 16, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 16, train_batch_id: 0, avg_cost: 3.8679144382476807
grad_norm: 0.4299521559959263, clipped: 0.4299521559959263
epoch: 16, train_batch_id: 50, avg_cost: 3.8510384559631348
grad_norm: 0.8357567742225281, clipped: 0.8357567742225281
epoch: 16, train_batch_id: 100, avg_cost: 3.8516945838928223
grad_norm: 0.38503646223182963, clipped: 0.38503646223182963
epoch: 16, train_batch_id: 150, avg_cost: 3.878366470336914
grad_norm: 0.6273667262890824, clipped: 0.6273667262890824
epoch: 16, train_batch_id: 200, avg_cost: 3.876431465148926
grad_norm: 0.5723243602261547, clipped: 0.5723243602261547
epoch: 16, train_batch_id: 250, avg_cost: 3.8648476600646973
grad_norm: 0.540664035391582, clipped: 0.540664035391582
epoch: 16, train_batch_id: 300, avg_cost: 3.8401308059692383
grad_norm: 0.5308115794658786, clipped: 0.5308115794658786
epoch: 16, train_batch_id: 350, avg_cost: 3.8661599159240723
grad_norm: 0.7531975339925789, clipped: 0.7531975339925789
epoch: 16, train_batch_id: 400, avg_cost: 3.8831405639648438
grad_norm: 0.49520703075876177, clipped: 0.49520703075876177
epoch: 16, train_batch_id: 450, avg_cost: 3.8754754066467285
grad_norm: 0.8367160411281319, clipped: 0.8367160411281319
epoch: 16, train_batch_id: 500, avg_cost: 3.873166561126709
grad_norm: 0.8501656009992543, clipped: 0.8501656009992543
epoch: 16, train_batch_id: 550, avg_cost: 3.862703323364258
grad_norm: 0.5592452011534677, clipped: 0.5592452011534677
epoch: 16, train_batch_id: 600, avg_cost: 3.8398003578186035
grad_norm: 0.43088243313829194, clipped: 0.43088243313829194
epoch: 16, train_batch_id: 650, avg_cost: 3.85030198097229
grad_norm: 0.515814013755731, clipped: 0.515814013755731
epoch: 16, train_batch_id: 700, avg_cost: 3.8267881870269775
grad_norm: 0.5620161896233588, clipped: 0.5620161896233588
epoch: 16, train_batch_id: 750, avg_cost: 3.8689522743225098
grad_norm: 0.48689151871345865, clipped: 0.48689151871345865
epoch: 16, train_batch_id: 800, avg_cost: 3.8613150119781494
grad_norm: 0.5675317169358999, clipped: 0.5675317169358999
epoch: 16, train_batch_id: 850, avg_cost: 3.8701515197753906
grad_norm: 0.5795268438274174, clipped: 0.5795268438274174
epoch: 16, train_batch_id: 900, avg_cost: 3.845475673675537
grad_norm: 0.529457480169497, clipped: 0.529457480169497
epoch: 16, train_batch_id: 950, avg_cost: 3.8588080406188965
grad_norm: 0.7103202434973931, clipped: 0.7103202434973931
epoch: 16, train_batch_id: 1000, avg_cost: 3.8877480030059814
grad_norm: 0.7695789710873349, clipped: 0.7695789710873349
epoch: 16, train_batch_id: 1050, avg_cost: 3.8469696044921875
grad_norm: 0.9566120369698825, clipped: 0.9566120369698825
epoch: 16, train_batch_id: 1100, avg_cost: 3.8435888290405273
grad_norm: 0.6257441648222337, clipped: 0.6257441648222337
epoch: 16, train_batch_id: 1150, avg_cost: 3.8568356037139893
grad_norm: 0.6193316298240816, clipped: 0.6193316298240816
epoch: 16, train_batch_id: 1200, avg_cost: 3.866856575012207
grad_norm: 0.4247629575817093, clipped: 0.4247629575817093
epoch: 16, train_batch_id: 1250, avg_cost: 3.868234634399414
grad_norm: 0.5729881822320666, clipped: 0.5729881822320666
epoch: 16, train_batch_id: 1300, avg_cost: 3.873744010925293
grad_norm: 0.8362283065668216, clipped: 0.8362283065668216
epoch: 16, train_batch_id: 1350, avg_cost: 3.862523317337036
grad_norm: 0.4616859096463093, clipped: 0.4616859096463093
epoch: 16, train_batch_id: 1400, avg_cost: 3.868311882019043
grad_norm: 0.5051070138597349, clipped: 0.5051070138597349
epoch: 16, train_batch_id: 1450, avg_cost: 3.8695015907287598
grad_norm: 0.9399300628295795, clipped: 0.9399300628295795
epoch: 16, train_batch_id: 1500, avg_cost: 3.847593069076538
grad_norm: 0.46956730760569665, clipped: 0.46956730760569665
epoch: 16, train_batch_id: 1550, avg_cost: 3.8679561614990234
grad_norm: 0.5910408346570197, clipped: 0.5910408346570197
epoch: 16, train_batch_id: 1600, avg_cost: 3.884775161743164
grad_norm: 1.672383132047043, clipped: 1.0
epoch: 16, train_batch_id: 1650, avg_cost: 3.8653130531311035
grad_norm: 0.647879575701176, clipped: 0.647879575701176
epoch: 16, train_batch_id: 1700, avg_cost: 3.886183738708496
grad_norm: 0.6940116392070433, clipped: 0.6940116392070433
epoch: 16, train_batch_id: 1750, avg_cost: 3.8358888626098633
grad_norm: 0.4792747089099946, clipped: 0.4792747089099946
epoch: 16, train_batch_id: 1800, avg_cost: 3.8766908645629883
grad_norm: 3.5353518306643306, clipped: 1.0
epoch: 16, train_batch_id: 1850, avg_cost: 3.8199360370635986
grad_norm: 0.4615371059668692, clipped: 0.4615371059668692
epoch: 16, train_batch_id: 1900, avg_cost: 3.8654065132141113
grad_norm: 0.7576068697708086, clipped: 0.7576068697708086
epoch: 16, train_batch_id: 1950, avg_cost: 3.8645381927490234
grad_norm: 0.5012750595064646, clipped: 0.5012750595064646
epoch: 16, train_batch_id: 2000, avg_cost: 3.8641514778137207
grad_norm: 0.5759347198500037, clipped: 0.5759347198500037
epoch: 16, train_batch_id: 2050, avg_cost: 3.84781813621521
grad_norm: 0.5886409584261072, clipped: 0.5886409584261072
epoch: 16, train_batch_id: 2100, avg_cost: 3.865922451019287
grad_norm: 0.4129049983715237, clipped: 0.4129049983715237
epoch: 16, train_batch_id: 2150, avg_cost: 3.866227149963379
grad_norm: 0.4556339708422038, clipped: 0.4556339708422038
epoch: 16, train_batch_id: 2200, avg_cost: 3.8715779781341553
grad_norm: 0.6708395760995081, clipped: 0.6708395760995081
epoch: 16, train_batch_id: 2250, avg_cost: 3.8348536491394043
grad_norm: 0.4395969449680409, clipped: 0.4395969449680409
epoch: 16, train_batch_id: 2300, avg_cost: 3.8730626106262207
grad_norm: 0.57864402460643, clipped: 0.57864402460643
epoch: 16, train_batch_id: 2350, avg_cost: 3.844205379486084
grad_norm: 0.8306622567348799, clipped: 0.8306622567348799
epoch: 16, train_batch_id: 2400, avg_cost: 3.8435873985290527
grad_norm: 0.6492243254572465, clipped: 0.6492243254572465
epoch: 16, train_batch_id: 2450, avg_cost: 3.8660483360290527
grad_norm: 0.513764131623049, clipped: 0.513764131623049
Finished epoch 16, took 00:05:36 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8605308532714844 +- 0.0031466661021113396
Evaluating candidate model on evaluation dataset
Epoch 16 candidate mean 3.859764814376831, baseline epoch 15 mean 3.8600406646728516, difference -0.0002758502960205078
p-value: 0.2585607297076322
Start train epoch 17, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 17, train_batch_id: 0, avg_cost: 3.8541178703308105
grad_norm: 0.5630925681233936, clipped: 0.5630925681233936
epoch: 17, train_batch_id: 50, avg_cost: 3.848217487335205
grad_norm: 0.4480376957895177, clipped: 0.4480376957895177
epoch: 17, train_batch_id: 100, avg_cost: 3.849877119064331
grad_norm: 0.5581506730950089, clipped: 0.5581506730950089
epoch: 17, train_batch_id: 150, avg_cost: 3.861487865447998
grad_norm: 0.5856370017896348, clipped: 0.5856370017896348
epoch: 17, train_batch_id: 200, avg_cost: 3.8856844902038574
grad_norm: 1.0423508966133717, clipped: 1.0
epoch: 17, train_batch_id: 250, avg_cost: 3.866901397705078
grad_norm: 0.6603723766585147, clipped: 0.6603723766585147
epoch: 17, train_batch_id: 300, avg_cost: 3.843461751937866
grad_norm: 0.42152608062354563, clipped: 0.42152608062354563
epoch: 17, train_batch_id: 350, avg_cost: 3.8696446418762207
grad_norm: 1.0921288817918713, clipped: 1.0
epoch: 17, train_batch_id: 400, avg_cost: 3.8751606941223145
grad_norm: 0.6054442519151405, clipped: 0.6054442519151405
epoch: 17, train_batch_id: 450, avg_cost: 3.868915557861328
grad_norm: 0.6676114246396888, clipped: 0.6676114246396888
epoch: 17, train_batch_id: 500, avg_cost: 3.8600122928619385
grad_norm: 1.4156188148002629, clipped: 1.0
epoch: 17, train_batch_id: 550, avg_cost: 3.8861489295959473
grad_norm: 0.6594660011386873, clipped: 0.6594660011386873
epoch: 17, train_batch_id: 600, avg_cost: 3.848550319671631
grad_norm: 0.5959053504957941, clipped: 0.5959053504957941
epoch: 17, train_batch_id: 650, avg_cost: 3.8241093158721924
grad_norm: 0.8375433818596157, clipped: 0.8375433818596157
epoch: 17, train_batch_id: 700, avg_cost: 3.8683457374572754
grad_norm: 0.4097670109100572, clipped: 0.4097670109100572
epoch: 17, train_batch_id: 750, avg_cost: 3.86401104927063
grad_norm: 0.41581568915395006, clipped: 0.41581568915395006
epoch: 17, train_batch_id: 800, avg_cost: 3.8565292358398438
grad_norm: 0.4633609809944679, clipped: 0.4633609809944679
epoch: 17, train_batch_id: 850, avg_cost: 3.8554434776306152
grad_norm: 0.6319782133311159, clipped: 0.6319782133311159
epoch: 17, train_batch_id: 900, avg_cost: 3.883086681365967
grad_norm: 0.5331228975254989, clipped: 0.5331228975254989
epoch: 17, train_batch_id: 950, avg_cost: 3.880126953125
grad_norm: 0.4428689266718052, clipped: 0.4428689266718052
epoch: 17, train_batch_id: 1000, avg_cost: 3.874248504638672
grad_norm: 0.5968844415572586, clipped: 0.5968844415572586
epoch: 17, train_batch_id: 1050, avg_cost: 3.857513666152954
grad_norm: 0.4710570023519635, clipped: 0.4710570023519635
epoch: 17, train_batch_id: 1100, avg_cost: 3.8740320205688477
grad_norm: 0.47151675269400606, clipped: 0.47151675269400606
epoch: 17, train_batch_id: 1150, avg_cost: 3.877450704574585
grad_norm: 0.45060243940256983, clipped: 0.45060243940256983
epoch: 17, train_batch_id: 1200, avg_cost: 3.856844902038574
grad_norm: 0.6603053013852617, clipped: 0.6603053013852617
epoch: 17, train_batch_id: 1250, avg_cost: 3.8807506561279297
grad_norm: 0.7238642873068645, clipped: 0.7238642873068645
epoch: 17, train_batch_id: 1300, avg_cost: 3.883035659790039
grad_norm: 0.6290235031410906, clipped: 0.6290235031410906
epoch: 17, train_batch_id: 1350, avg_cost: 3.893301486968994
grad_norm: 0.6234183445553821, clipped: 0.6234183445553821
epoch: 17, train_batch_id: 1400, avg_cost: 3.863159656524658
grad_norm: 0.38833885654048805, clipped: 0.38833885654048805
epoch: 17, train_batch_id: 1450, avg_cost: 3.8809571266174316
grad_norm: 0.38252005671399875, clipped: 0.38252005671399875
epoch: 17, train_batch_id: 1500, avg_cost: 3.855595827102661
grad_norm: 0.41912567041941223, clipped: 0.41912567041941223
epoch: 17, train_batch_id: 1550, avg_cost: 3.8779296875
grad_norm: 0.5139020866119601, clipped: 0.5139020866119601
epoch: 17, train_batch_id: 1600, avg_cost: 3.8884854316711426
grad_norm: 1.0149847260976548, clipped: 1.0
epoch: 17, train_batch_id: 1650, avg_cost: 3.86063551902771
grad_norm: 0.4296210168609701, clipped: 0.4296210168609701
epoch: 17, train_batch_id: 1700, avg_cost: 3.841503143310547
grad_norm: 0.4618951445805178, clipped: 0.4618951445805178
epoch: 17, train_batch_id: 1750, avg_cost: 3.8464627265930176
grad_norm: 0.4480134210165801, clipped: 0.4480134210165801
epoch: 17, train_batch_id: 1800, avg_cost: 3.857666015625
grad_norm: 0.6511839922905155, clipped: 0.6511839922905155
epoch: 17, train_batch_id: 1850, avg_cost: 3.8718299865722656
grad_norm: 0.51351687308363, clipped: 0.51351687308363
epoch: 17, train_batch_id: 1900, avg_cost: 3.8477258682250977
grad_norm: 0.7954279474967699, clipped: 0.7954279474967699
epoch: 17, train_batch_id: 1950, avg_cost: 3.871150016784668
grad_norm: 0.46840802247030816, clipped: 0.46840802247030816
epoch: 17, train_batch_id: 2000, avg_cost: 3.87943696975708
grad_norm: 0.5704096039404356, clipped: 0.5704096039404356
epoch: 17, train_batch_id: 2050, avg_cost: 3.8575222492218018
grad_norm: 0.5178100187011925, clipped: 0.5178100187011925
epoch: 17, train_batch_id: 2100, avg_cost: 3.860678195953369
grad_norm: 0.6294240864179772, clipped: 0.6294240864179772
epoch: 17, train_batch_id: 2150, avg_cost: 3.867018699645996
grad_norm: 0.5085027353971433, clipped: 0.5085027353971433
epoch: 17, train_batch_id: 2200, avg_cost: 3.8396430015563965
grad_norm: 0.43481696246009843, clipped: 0.43481696246009843
epoch: 17, train_batch_id: 2250, avg_cost: 3.8574814796447754
grad_norm: 0.5960080327817461, clipped: 0.5960080327817461
epoch: 17, train_batch_id: 2300, avg_cost: 3.8801283836364746
grad_norm: 0.6697955122055599, clipped: 0.6697955122055599
epoch: 17, train_batch_id: 2350, avg_cost: 3.876715660095215
grad_norm: 0.8504246055132189, clipped: 0.8504246055132189
epoch: 17, train_batch_id: 2400, avg_cost: 3.8763375282287598
grad_norm: 0.5962313536705512, clipped: 0.5962313536705512
epoch: 17, train_batch_id: 2450, avg_cost: 3.850964069366455
grad_norm: 0.4853776896314027, clipped: 0.4853776896314027
Finished epoch 17, took 00:05:37 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.860701560974121 +- 0.0031553376466035843
Evaluating candidate model on evaluation dataset
Epoch 17 candidate mean 3.859625816345215, baseline epoch 15 mean 3.8600406646728516, difference -0.00041484832763671875
p-value: 0.17111032021188088
Start train epoch 18, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 18, train_batch_id: 0, avg_cost: 3.869495153427124
grad_norm: 0.5869559854619695, clipped: 0.5869559854619695
epoch: 18, train_batch_id: 50, avg_cost: 3.865671157836914
grad_norm: 0.5310230430893009, clipped: 0.5310230430893009
epoch: 18, train_batch_id: 100, avg_cost: 3.860753297805786
grad_norm: 0.6235152601161075, clipped: 0.6235152601161075
epoch: 18, train_batch_id: 150, avg_cost: 3.8571834564208984
grad_norm: 0.5768193665456348, clipped: 0.5768193665456348
epoch: 18, train_batch_id: 200, avg_cost: 3.8665390014648438
grad_norm: 0.4133697677763579, clipped: 0.4133697677763579
epoch: 18, train_batch_id: 250, avg_cost: 3.8483152389526367
grad_norm: 0.9635364475518842, clipped: 0.9635364475518842
epoch: 18, train_batch_id: 300, avg_cost: 3.883948564529419
grad_norm: 0.6143411668574452, clipped: 0.6143411668574452
epoch: 18, train_batch_id: 350, avg_cost: 3.880013942718506
grad_norm: 0.5334502337806337, clipped: 0.5334502337806337
epoch: 18, train_batch_id: 400, avg_cost: 3.8766679763793945
grad_norm: 0.7100648275106105, clipped: 0.7100648275106105
epoch: 18, train_batch_id: 450, avg_cost: 3.8396389484405518
grad_norm: 0.38233801309538584, clipped: 0.38233801309538584
epoch: 18, train_batch_id: 500, avg_cost: 3.8440561294555664
grad_norm: 0.5966184520567289, clipped: 0.5966184520567289
epoch: 18, train_batch_id: 550, avg_cost: 3.8296515941619873
grad_norm: 0.43654019538009703, clipped: 0.43654019538009703
epoch: 18, train_batch_id: 600, avg_cost: 3.8622164726257324
grad_norm: 0.5302162934310052, clipped: 0.5302162934310052
epoch: 18, train_batch_id: 650, avg_cost: 3.8782949447631836
grad_norm: 0.5460838923411093, clipped: 0.5460838923411093
epoch: 18, train_batch_id: 700, avg_cost: 3.882418632507324
grad_norm: 1.1234349574931226, clipped: 1.0
epoch: 18, train_batch_id: 750, avg_cost: 3.8663954734802246
grad_norm: 0.4548743999931444, clipped: 0.4548743999931444
epoch: 18, train_batch_id: 800, avg_cost: 3.8789749145507812
grad_norm: 0.6413096815436907, clipped: 0.6413096815436907
epoch: 18, train_batch_id: 850, avg_cost: 3.850431442260742
grad_norm: 0.6017798085770477, clipped: 0.6017798085770477
epoch: 18, train_batch_id: 900, avg_cost: 3.868159532546997
grad_norm: 0.7131585822165365, clipped: 0.7131585822165365
epoch: 18, train_batch_id: 950, avg_cost: 3.862604856491089
grad_norm: 0.5063148277685842, clipped: 0.5063148277685842
epoch: 18, train_batch_id: 1000, avg_cost: 3.847012519836426
grad_norm: 0.5535491872610768, clipped: 0.5535491872610768
epoch: 18, train_batch_id: 1050, avg_cost: 3.8601233959198
grad_norm: 0.5804969667346056, clipped: 0.5804969667346056
epoch: 18, train_batch_id: 1100, avg_cost: 3.8849992752075195
grad_norm: 0.8207935875201661, clipped: 0.8207935875201661
epoch: 18, train_batch_id: 1150, avg_cost: 3.8505921363830566
grad_norm: 0.4745177046220159, clipped: 0.4745177046220159
epoch: 18, train_batch_id: 1200, avg_cost: 3.8805556297302246
grad_norm: 1.0992518917429508, clipped: 1.0
epoch: 18, train_batch_id: 1250, avg_cost: 3.863079071044922
grad_norm: 0.4066565891721134, clipped: 0.4066565891721134
epoch: 18, train_batch_id: 1300, avg_cost: 3.8613617420196533
grad_norm: 0.4901027267645341, clipped: 0.4901027267645341
epoch: 18, train_batch_id: 1350, avg_cost: 3.8552398681640625
grad_norm: 0.5413134952098111, clipped: 0.5413134952098111
epoch: 18, train_batch_id: 1400, avg_cost: 3.8748111724853516
grad_norm: 0.9559897148337949, clipped: 0.9559897148337949
epoch: 18, train_batch_id: 1450, avg_cost: 3.857870101928711
grad_norm: 0.5788336391762985, clipped: 0.5788336391762985
epoch: 18, train_batch_id: 1500, avg_cost: 3.8720157146453857
grad_norm: 0.4508622539282751, clipped: 0.4508622539282751
epoch: 18, train_batch_id: 1550, avg_cost: 3.8579530715942383
grad_norm: 0.5902471475493934, clipped: 0.5902471475493934
epoch: 18, train_batch_id: 1600, avg_cost: 3.848097324371338
grad_norm: 0.5202247226434629, clipped: 0.5202247226434629
epoch: 18, train_batch_id: 1650, avg_cost: 3.8318660259246826
grad_norm: 0.5258820455996738, clipped: 0.5258820455996738
epoch: 18, train_batch_id: 1700, avg_cost: 3.844679117202759
grad_norm: 0.6502980195290442, clipped: 0.6502980195290442
epoch: 18, train_batch_id: 1750, avg_cost: 3.851871967315674
grad_norm: 0.721506861106746, clipped: 0.721506861106746
epoch: 18, train_batch_id: 1800, avg_cost: 3.8399577140808105
grad_norm: 0.5916829428561577, clipped: 0.5916829428561577
epoch: 18, train_batch_id: 1850, avg_cost: 3.8636670112609863
grad_norm: 0.8520111136841816, clipped: 0.8520111136841816
epoch: 18, train_batch_id: 1900, avg_cost: 3.8712151050567627
grad_norm: 1.046568423558817, clipped: 1.0
epoch: 18, train_batch_id: 1950, avg_cost: 3.8808813095092773
grad_norm: 0.624749933270578, clipped: 0.624749933270578
epoch: 18, train_batch_id: 2000, avg_cost: 3.8566009998321533
grad_norm: 0.44602476320461965, clipped: 0.44602476320461965
epoch: 18, train_batch_id: 2050, avg_cost: 3.860917568206787
grad_norm: 0.8536764929274666, clipped: 0.8536764929274666
epoch: 18, train_batch_id: 2100, avg_cost: 3.8361806869506836
grad_norm: 0.5091044373688932, clipped: 0.5091044373688932
epoch: 18, train_batch_id: 2150, avg_cost: 3.888094425201416
grad_norm: 0.5999036924035925, clipped: 0.5999036924035925
epoch: 18, train_batch_id: 2200, avg_cost: 3.8750789165496826
grad_norm: 0.3529747506669224, clipped: 0.3529747506669224
epoch: 18, train_batch_id: 2250, avg_cost: 3.869579553604126
grad_norm: 0.7232531151400821, clipped: 0.7232531151400821
epoch: 18, train_batch_id: 2300, avg_cost: 3.8442471027374268
grad_norm: 1.4368527578530474, clipped: 1.0
epoch: 18, train_batch_id: 2350, avg_cost: 3.8572492599487305
grad_norm: 0.5913654962515095, clipped: 0.5913654962515095
epoch: 18, train_batch_id: 2400, avg_cost: 3.861090660095215
grad_norm: 0.7815461618380084, clipped: 0.7815461618380084
epoch: 18, train_batch_id: 2450, avg_cost: 3.8449559211730957
grad_norm: 0.959701371744121, clipped: 0.959701371744121
Finished epoch 18, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.859959363937378 +- 0.0031446944922208786
Evaluating candidate model on evaluation dataset
Epoch 18 candidate mean 3.8594882488250732, baseline epoch 15 mean 3.8600406646728516, difference -0.0005524158477783203
p-value: 0.10651948333053367
Start train epoch 19, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 19, train_batch_id: 0, avg_cost: 3.8535423278808594
grad_norm: 0.9003085498353285, clipped: 0.9003085498353285
epoch: 19, train_batch_id: 50, avg_cost: 3.844682216644287
grad_norm: 0.4955671294904652, clipped: 0.4955671294904652
epoch: 19, train_batch_id: 100, avg_cost: 3.856889009475708
grad_norm: 0.46941439533796, clipped: 0.46941439533796
epoch: 19, train_batch_id: 150, avg_cost: 3.8793890476226807
grad_norm: 0.3739198691486886, clipped: 0.3739198691486886
epoch: 19, train_batch_id: 200, avg_cost: 3.86295747756958
grad_norm: 0.5886074974578256, clipped: 0.5886074974578256
epoch: 19, train_batch_id: 250, avg_cost: 3.858729124069214
grad_norm: 0.3885000332301467, clipped: 0.3885000332301467
epoch: 19, train_batch_id: 300, avg_cost: 3.868715763092041
grad_norm: 0.7637842232517439, clipped: 0.7637842232517439
epoch: 19, train_batch_id: 350, avg_cost: 3.84751033782959
grad_norm: 0.556742925622044, clipped: 0.556742925622044
epoch: 19, train_batch_id: 400, avg_cost: 3.842898368835449
grad_norm: 0.5908409913135589, clipped: 0.5908409913135589
epoch: 19, train_batch_id: 450, avg_cost: 3.854799270629883
grad_norm: 1.275389214397176, clipped: 1.0
epoch: 19, train_batch_id: 500, avg_cost: 3.8568239212036133
grad_norm: 0.6710942569939171, clipped: 0.6710942569939171
epoch: 19, train_batch_id: 550, avg_cost: 3.85367751121521
grad_norm: 0.4542626716490528, clipped: 0.4542626716490528
epoch: 19, train_batch_id: 600, avg_cost: 3.869992733001709
grad_norm: 0.5799135905235898, clipped: 0.5799135905235898
epoch: 19, train_batch_id: 650, avg_cost: 3.8716132640838623
grad_norm: 0.8996268885694231, clipped: 0.8996268885694231
epoch: 19, train_batch_id: 700, avg_cost: 3.880868434906006
grad_norm: 0.4717192681721255, clipped: 0.4717192681721255
epoch: 19, train_batch_id: 750, avg_cost: 3.860013723373413
grad_norm: 0.5344463795212702, clipped: 0.5344463795212702
epoch: 19, train_batch_id: 800, avg_cost: 3.877615213394165
grad_norm: 0.4732122582506662, clipped: 0.4732122582506662
epoch: 19, train_batch_id: 850, avg_cost: 3.8703784942626953
grad_norm: 0.5872536679127348, clipped: 0.5872536679127348
epoch: 19, train_batch_id: 900, avg_cost: 3.8508095741271973
grad_norm: 0.6790576931006008, clipped: 0.6790576931006008
epoch: 19, train_batch_id: 950, avg_cost: 3.8395910263061523
grad_norm: 0.8465024460649317, clipped: 0.8465024460649317
epoch: 19, train_batch_id: 1000, avg_cost: 3.861069679260254
grad_norm: 0.5553509164409334, clipped: 0.5553509164409334
epoch: 19, train_batch_id: 1050, avg_cost: 3.8525161743164062
grad_norm: 0.4279528903736698, clipped: 0.4279528903736698
epoch: 19, train_batch_id: 1100, avg_cost: 3.859424591064453
grad_norm: 0.4824797790472978, clipped: 0.4824797790472978
epoch: 19, train_batch_id: 1150, avg_cost: 3.843899726867676
grad_norm: 0.5027213693690292, clipped: 0.5027213693690292
epoch: 19, train_batch_id: 1200, avg_cost: 3.846385955810547
grad_norm: 0.4240073629322333, clipped: 0.4240073629322333
epoch: 19, train_batch_id: 1250, avg_cost: 3.8711538314819336
grad_norm: 0.761063383913014, clipped: 0.761063383913014
epoch: 19, train_batch_id: 1300, avg_cost: 3.8737950325012207
grad_norm: 0.4160127332746079, clipped: 0.4160127332746079
epoch: 19, train_batch_id: 1350, avg_cost: 3.8790125846862793
grad_norm: 0.46699257633983227, clipped: 0.46699257633983227
epoch: 19, train_batch_id: 1400, avg_cost: 3.8436312675476074
grad_norm: 0.6527206821592145, clipped: 0.6527206821592145
epoch: 19, train_batch_id: 1450, avg_cost: 3.864525318145752
grad_norm: 0.6916741008639836, clipped: 0.6916741008639836
epoch: 19, train_batch_id: 1500, avg_cost: 3.8469059467315674
grad_norm: 0.4712565444667281, clipped: 0.4712565444667281
epoch: 19, train_batch_id: 1550, avg_cost: 3.8698067665100098
grad_norm: 0.7620747274611598, clipped: 0.7620747274611598
epoch: 19, train_batch_id: 1600, avg_cost: 3.865042209625244
grad_norm: 0.6760012001138623, clipped: 0.6760012001138623
epoch: 19, train_batch_id: 1650, avg_cost: 3.8521368503570557
grad_norm: 0.4950393850770799, clipped: 0.4950393850770799
epoch: 19, train_batch_id: 1700, avg_cost: 3.890458822250366
grad_norm: 0.878449230518371, clipped: 0.878449230518371
epoch: 19, train_batch_id: 1750, avg_cost: 3.841364860534668
grad_norm: 0.4985344771050545, clipped: 0.4985344771050545
epoch: 19, train_batch_id: 1800, avg_cost: 3.875185489654541
grad_norm: 0.678938703525986, clipped: 0.678938703525986
epoch: 19, train_batch_id: 1850, avg_cost: 3.829338312149048
grad_norm: 0.5532913813117136, clipped: 0.5532913813117136
epoch: 19, train_batch_id: 1900, avg_cost: 3.8755428791046143
grad_norm: 0.45454175167063715, clipped: 0.45454175167063715
epoch: 19, train_batch_id: 1950, avg_cost: 3.855189800262451
grad_norm: 0.3620859714885041, clipped: 0.3620859714885041
epoch: 19, train_batch_id: 2000, avg_cost: 3.877455949783325
grad_norm: 0.919881727400507, clipped: 0.919881727400507
epoch: 19, train_batch_id: 2050, avg_cost: 3.859722137451172
grad_norm: 0.4860480005129723, clipped: 0.4860480005129723
epoch: 19, train_batch_id: 2100, avg_cost: 3.8439455032348633
grad_norm: 0.48217068674602737, clipped: 0.48217068674602737
epoch: 19, train_batch_id: 2150, avg_cost: 3.8681726455688477
grad_norm: 0.9295535524622784, clipped: 0.9295535524622784
epoch: 19, train_batch_id: 2200, avg_cost: 3.8769075870513916
grad_norm: 0.6070830029465313, clipped: 0.6070830029465313
epoch: 19, train_batch_id: 2250, avg_cost: 3.856220245361328
grad_norm: 1.190461037704126, clipped: 1.0
epoch: 19, train_batch_id: 2300, avg_cost: 3.851367235183716
grad_norm: 0.5178055903875958, clipped: 0.5178055903875958
epoch: 19, train_batch_id: 2350, avg_cost: 3.876589059829712
grad_norm: 0.6474060799072717, clipped: 0.6474060799072717
epoch: 19, train_batch_id: 2400, avg_cost: 3.8683407306671143
grad_norm: 0.5023977116618921, clipped: 0.5023977116618921
epoch: 19, train_batch_id: 2450, avg_cost: 3.8538761138916016
grad_norm: 0.6077847422351672, clipped: 0.6077847422351672
Finished epoch 19, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.861180543899536 +- 0.0031571057625114918
Evaluating candidate model on evaluation dataset
Epoch 19 candidate mean 3.8603479862213135, baseline epoch 15 mean 3.8600406646728516, difference 0.00030732154846191406
Start train epoch 20, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 20, train_batch_id: 0, avg_cost: 3.862689971923828
grad_norm: 0.6768187011643393, clipped: 0.6768187011643393
epoch: 20, train_batch_id: 50, avg_cost: 3.8769657611846924
grad_norm: 0.5257014451488426, clipped: 0.5257014451488426
epoch: 20, train_batch_id: 100, avg_cost: 3.8634767532348633
grad_norm: 0.6734817224282617, clipped: 0.6734817224282617
epoch: 20, train_batch_id: 150, avg_cost: 3.8796792030334473
grad_norm: 0.6037771677325363, clipped: 0.6037771677325363
epoch: 20, train_batch_id: 200, avg_cost: 3.8512070178985596
grad_norm: 0.871712215757379, clipped: 0.871712215757379
epoch: 20, train_batch_id: 250, avg_cost: 3.8564648628234863
grad_norm: 0.7417862934892318, clipped: 0.7417862934892318
epoch: 20, train_batch_id: 300, avg_cost: 3.850536584854126
grad_norm: 0.8613967862042516, clipped: 0.8613967862042516
epoch: 20, train_batch_id: 350, avg_cost: 3.8606858253479004
grad_norm: 0.4985575421087297, clipped: 0.4985575421087297
epoch: 20, train_batch_id: 400, avg_cost: 3.8555071353912354
grad_norm: 0.499724989043415, clipped: 0.499724989043415
epoch: 20, train_batch_id: 450, avg_cost: 3.8643064498901367
grad_norm: 0.46881188265612517, clipped: 0.46881188265612517
epoch: 20, train_batch_id: 500, avg_cost: 3.854785203933716
grad_norm: 0.49557126556099823, clipped: 0.49557126556099823
epoch: 20, train_batch_id: 550, avg_cost: 3.8368515968322754
grad_norm: 0.6086170875376008, clipped: 0.6086170875376008
epoch: 20, train_batch_id: 600, avg_cost: 3.8536319732666016
grad_norm: 0.481235181578767, clipped: 0.481235181578767
epoch: 20, train_batch_id: 650, avg_cost: 3.8484740257263184
grad_norm: 0.49928634242400444, clipped: 0.49928634242400444
epoch: 20, train_batch_id: 700, avg_cost: 3.837006092071533
grad_norm: 0.4153153279482648, clipped: 0.4153153279482648
epoch: 20, train_batch_id: 750, avg_cost: 3.853984832763672
grad_norm: 0.3694208951256123, clipped: 0.3694208951256123
epoch: 20, train_batch_id: 800, avg_cost: 3.8766140937805176
grad_norm: 0.8927031427940082, clipped: 0.8927031427940082
epoch: 20, train_batch_id: 850, avg_cost: 3.8508481979370117
grad_norm: 0.46103648725250956, clipped: 0.46103648725250956
epoch: 20, train_batch_id: 900, avg_cost: 3.861846923828125
grad_norm: 0.3540846708438965, clipped: 0.3540846708438965
epoch: 20, train_batch_id: 950, avg_cost: 3.8565001487731934
grad_norm: 0.5134643711908735, clipped: 0.5134643711908735
epoch: 20, train_batch_id: 1000, avg_cost: 3.8605945110321045
grad_norm: 0.47035628292797693, clipped: 0.47035628292797693
epoch: 20, train_batch_id: 1050, avg_cost: 3.855811595916748
grad_norm: 0.7459029030887581, clipped: 0.7459029030887581
epoch: 20, train_batch_id: 1100, avg_cost: 3.8721132278442383
grad_norm: 0.4644708626070895, clipped: 0.4644708626070895
epoch: 20, train_batch_id: 1150, avg_cost: 3.8776936531066895
grad_norm: 0.43968997528240517, clipped: 0.43968997528240517
epoch: 20, train_batch_id: 1200, avg_cost: 3.857564926147461
grad_norm: 0.601750357520762, clipped: 0.601750357520762
epoch: 20, train_batch_id: 1250, avg_cost: 3.8556416034698486
grad_norm: 0.5041195157722157, clipped: 0.5041195157722157
epoch: 20, train_batch_id: 1300, avg_cost: 3.8441452980041504
grad_norm: 0.3125977496195811, clipped: 0.3125977496195811
epoch: 20, train_batch_id: 1350, avg_cost: 3.8462209701538086
grad_norm: 0.4934264137202333, clipped: 0.4934264137202333
epoch: 20, train_batch_id: 1400, avg_cost: 3.8958897590637207
grad_norm: 0.5226394665578128, clipped: 0.5226394665578128
epoch: 20, train_batch_id: 1450, avg_cost: 3.865016222000122
grad_norm: 0.5314507029219153, clipped: 0.5314507029219153
epoch: 20, train_batch_id: 1500, avg_cost: 3.8765878677368164
grad_norm: 0.4177170254897602, clipped: 0.4177170254897602
epoch: 20, train_batch_id: 1550, avg_cost: 3.8650002479553223
grad_norm: 0.46587316314836474, clipped: 0.46587316314836474
epoch: 20, train_batch_id: 1600, avg_cost: 3.8845975399017334
grad_norm: 0.43453555085083057, clipped: 0.43453555085083057
epoch: 20, train_batch_id: 1650, avg_cost: 3.8720998764038086
grad_norm: 0.6676687004182017, clipped: 0.6676687004182017
epoch: 20, train_batch_id: 1700, avg_cost: 3.836121082305908
grad_norm: 0.5166932376180032, clipped: 0.5166932376180032
epoch: 20, train_batch_id: 1750, avg_cost: 3.8760056495666504
grad_norm: 1.600668525748572, clipped: 1.0
epoch: 20, train_batch_id: 1800, avg_cost: 3.845806121826172
grad_norm: 0.35107803605366017, clipped: 0.35107803605366017
epoch: 20, train_batch_id: 1850, avg_cost: 3.874300003051758
grad_norm: 0.3575075897869579, clipped: 0.3575075897869579
epoch: 20, train_batch_id: 1900, avg_cost: 3.8646535873413086
grad_norm: 0.5693599812280539, clipped: 0.5693599812280539
epoch: 20, train_batch_id: 1950, avg_cost: 3.8423895835876465
grad_norm: 0.431019921265596, clipped: 0.431019921265596
epoch: 20, train_batch_id: 2000, avg_cost: 3.84550142288208
grad_norm: 1.0654435530191533, clipped: 1.0
epoch: 20, train_batch_id: 2050, avg_cost: 3.837491989135742
grad_norm: 0.350195186608843, clipped: 0.350195186608843
epoch: 20, train_batch_id: 2100, avg_cost: 3.8510820865631104
grad_norm: 0.6485629394657986, clipped: 0.6485629394657986
epoch: 20, train_batch_id: 2150, avg_cost: 3.852870464324951
grad_norm: 0.5326100072505747, clipped: 0.5326100072505747
epoch: 20, train_batch_id: 2200, avg_cost: 3.836494207382202
grad_norm: 0.4902837144977441, clipped: 0.4902837144977441
epoch: 20, train_batch_id: 2250, avg_cost: 3.859844207763672
grad_norm: 0.4427035032817176, clipped: 0.4427035032817176
epoch: 20, train_batch_id: 2300, avg_cost: 3.8403310775756836
grad_norm: 0.779631914568912, clipped: 0.779631914568912
epoch: 20, train_batch_id: 2350, avg_cost: 3.8259756565093994
grad_norm: 0.7250257825781243, clipped: 0.7250257825781243
epoch: 20, train_batch_id: 2400, avg_cost: 3.8906097412109375
grad_norm: 0.4873844763213259, clipped: 0.4873844763213259
epoch: 20, train_batch_id: 2450, avg_cost: 3.8541834354400635
grad_norm: 0.7273286532973489, clipped: 0.7273286532973489
Finished epoch 20, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.859556198120117 +- 0.0031445384956896305
Evaluating candidate model on evaluation dataset
Epoch 20 candidate mean 3.8580360412597656, baseline epoch 15 mean 3.8600406646728516, difference -0.0020046234130859375
p-value: 1.106917905190781e-06
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 21, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 21, train_batch_id: 0, avg_cost: 3.8548150062561035
grad_norm: 0.6214011060905691, clipped: 0.6214011060905691
epoch: 21, train_batch_id: 50, avg_cost: 3.848259210586548
grad_norm: 0.4924224252930775, clipped: 0.4924224252930775
epoch: 21, train_batch_id: 100, avg_cost: 3.863896369934082
grad_norm: 0.8698285332594908, clipped: 0.8698285332594908
epoch: 21, train_batch_id: 150, avg_cost: 3.856229782104492
grad_norm: 0.5288882841840203, clipped: 0.5288882841840203
epoch: 21, train_batch_id: 200, avg_cost: 3.846869945526123
grad_norm: 0.5592559693608042, clipped: 0.5592559693608042
epoch: 21, train_batch_id: 250, avg_cost: 3.8679282665252686
grad_norm: 0.5206775710260801, clipped: 0.5206775710260801
epoch: 21, train_batch_id: 300, avg_cost: 3.8736963272094727
grad_norm: 0.45254442695882463, clipped: 0.45254442695882463
epoch: 21, train_batch_id: 350, avg_cost: 3.86108136177063
grad_norm: 0.4033016476984143, clipped: 0.4033016476984143
epoch: 21, train_batch_id: 400, avg_cost: 3.8668088912963867
grad_norm: 0.5158169637910799, clipped: 0.5158169637910799
epoch: 21, train_batch_id: 450, avg_cost: 3.8597326278686523
grad_norm: 0.8004915900146243, clipped: 0.8004915900146243
epoch: 21, train_batch_id: 500, avg_cost: 3.863659143447876
grad_norm: 0.5028802493506278, clipped: 0.5028802493506278
epoch: 21, train_batch_id: 550, avg_cost: 3.8565423488616943
grad_norm: 0.6246039030914083, clipped: 0.6246039030914083
epoch: 21, train_batch_id: 600, avg_cost: 3.8624267578125
grad_norm: 0.6177622735356485, clipped: 0.6177622735356485
epoch: 21, train_batch_id: 650, avg_cost: 3.8573989868164062
grad_norm: 0.5350925627239964, clipped: 0.5350925627239964
epoch: 21, train_batch_id: 700, avg_cost: 3.833488941192627
grad_norm: 0.6783964430024905, clipped: 0.6783964430024905
epoch: 21, train_batch_id: 750, avg_cost: 3.8501734733581543
grad_norm: 0.4842261806416794, clipped: 0.4842261806416794
epoch: 21, train_batch_id: 800, avg_cost: 3.823383331298828
grad_norm: 0.5931700661528272, clipped: 0.5931700661528272
epoch: 21, train_batch_id: 850, avg_cost: 3.846644878387451
grad_norm: 0.6759752453728842, clipped: 0.6759752453728842
epoch: 21, train_batch_id: 900, avg_cost: 3.8489418029785156
grad_norm: 0.6129635093545884, clipped: 0.6129635093545884
epoch: 21, train_batch_id: 950, avg_cost: 3.8614959716796875
grad_norm: 0.5630892005581701, clipped: 0.5630892005581701
epoch: 21, train_batch_id: 1000, avg_cost: 3.8685076236724854
grad_norm: 0.4942002532156427, clipped: 0.4942002532156427
epoch: 21, train_batch_id: 1050, avg_cost: 3.8759403228759766
grad_norm: 0.4147831667723878, clipped: 0.4147831667723878
epoch: 21, train_batch_id: 1100, avg_cost: 3.8476130962371826
grad_norm: 0.4890113144681259, clipped: 0.4890113144681259
epoch: 21, train_batch_id: 1150, avg_cost: 3.8786027431488037
grad_norm: 0.5283759568796691, clipped: 0.5283759568796691
epoch: 21, train_batch_id: 1200, avg_cost: 3.853879928588867
grad_norm: 0.47277232526686463, clipped: 0.47277232526686463
epoch: 21, train_batch_id: 1250, avg_cost: 3.8538966178894043
grad_norm: 0.5259824981200883, clipped: 0.5259824981200883
epoch: 21, train_batch_id: 1300, avg_cost: 3.8670105934143066
grad_norm: 0.5569805342297861, clipped: 0.5569805342297861
epoch: 21, train_batch_id: 1350, avg_cost: 3.8661818504333496
grad_norm: 0.64539193185494, clipped: 0.64539193185494
epoch: 21, train_batch_id: 1400, avg_cost: 3.853764057159424
grad_norm: 1.1808029727491962, clipped: 1.0
epoch: 21, train_batch_id: 1450, avg_cost: 3.8768997192382812
grad_norm: 1.9981326400144936, clipped: 1.0
epoch: 21, train_batch_id: 1500, avg_cost: 3.8492231369018555
grad_norm: 0.7386837147898058, clipped: 0.7386837147898058
epoch: 21, train_batch_id: 1550, avg_cost: 3.857706069946289
grad_norm: 1.002422171229702, clipped: 1.0
epoch: 21, train_batch_id: 1600, avg_cost: 3.86072039604187
grad_norm: 0.43349591679106825, clipped: 0.43349591679106825
epoch: 21, train_batch_id: 1650, avg_cost: 3.8750905990600586
grad_norm: 0.7409705466311315, clipped: 0.7409705466311315
epoch: 21, train_batch_id: 1700, avg_cost: 3.8934009075164795
grad_norm: 0.45602182105700595, clipped: 0.45602182105700595
epoch: 21, train_batch_id: 1750, avg_cost: 3.891417980194092
grad_norm: 0.44446235845443394, clipped: 0.44446235845443394
epoch: 21, train_batch_id: 1800, avg_cost: 3.8478429317474365
grad_norm: 0.5129988677649719, clipped: 0.5129988677649719
epoch: 21, train_batch_id: 1850, avg_cost: 3.8361334800720215
grad_norm: 0.4116057752454017, clipped: 0.4116057752454017
epoch: 21, train_batch_id: 1900, avg_cost: 3.8753342628479004
grad_norm: 0.4750277016657812, clipped: 0.4750277016657812
epoch: 21, train_batch_id: 1950, avg_cost: 3.862332820892334
grad_norm: 0.6110167784943396, clipped: 0.6110167784943396
epoch: 21, train_batch_id: 2000, avg_cost: 3.8360512256622314
grad_norm: 1.1122894641294137, clipped: 1.0
epoch: 21, train_batch_id: 2050, avg_cost: 3.835604667663574
grad_norm: 0.4947551964111939, clipped: 0.4947551964111939
epoch: 21, train_batch_id: 2100, avg_cost: 3.8267719745635986
grad_norm: 0.4121273648470922, clipped: 0.4121273648470922
epoch: 21, train_batch_id: 2150, avg_cost: 3.8790860176086426
grad_norm: 0.46626174112541247, clipped: 0.46626174112541247
epoch: 21, train_batch_id: 2200, avg_cost: 3.8667378425598145
grad_norm: 0.41418990328898725, clipped: 0.41418990328898725
epoch: 21, train_batch_id: 2250, avg_cost: 3.8596415519714355
grad_norm: 0.49969498902476117, clipped: 0.49969498902476117
epoch: 21, train_batch_id: 2300, avg_cost: 3.864077091217041
grad_norm: 0.5461564817273769, clipped: 0.5461564817273769
epoch: 21, train_batch_id: 2350, avg_cost: 3.8489396572113037
grad_norm: 0.40914635708782626, clipped: 0.40914635708782626
epoch: 21, train_batch_id: 2400, avg_cost: 3.86358642578125
grad_norm: 0.8847023858818999, clipped: 0.8847023858818999
epoch: 21, train_batch_id: 2450, avg_cost: 3.851010322570801
grad_norm: 0.553429821803485, clipped: 0.553429821803485
Finished epoch 21, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8578202724456787 +- 0.0031478898599743843
Evaluating candidate model on evaluation dataset
Epoch 21 candidate mean 3.847914457321167, baseline epoch 20 mean 3.84954833984375, difference -0.0016338825225830078
p-value: 0.0001642449474330834
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 22, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 22, train_batch_id: 0, avg_cost: 3.8597707748413086
grad_norm: 0.604210452820724, clipped: 0.604210452820724
epoch: 22, train_batch_id: 50, avg_cost: 3.8603944778442383
grad_norm: 0.45656984883135476, clipped: 0.45656984883135476
epoch: 22, train_batch_id: 100, avg_cost: 3.8593339920043945
grad_norm: 0.44580219428071616, clipped: 0.44580219428071616
epoch: 22, train_batch_id: 150, avg_cost: 3.85782790184021
grad_norm: 0.4123424851877002, clipped: 0.4123424851877002
epoch: 22, train_batch_id: 200, avg_cost: 3.88352370262146
grad_norm: 1.0288339728604203, clipped: 1.0
epoch: 22, train_batch_id: 250, avg_cost: 3.8629374504089355
grad_norm: 0.6946382807650126, clipped: 0.6946382807650126
epoch: 22, train_batch_id: 300, avg_cost: 3.865187883377075
grad_norm: 0.4742632683334058, clipped: 0.4742632683334058
epoch: 22, train_batch_id: 350, avg_cost: 3.838111400604248
grad_norm: 0.6341260876952596, clipped: 0.6341260876952596
epoch: 22, train_batch_id: 400, avg_cost: 3.8847665786743164
grad_norm: 0.395415024204201, clipped: 0.395415024204201
epoch: 22, train_batch_id: 450, avg_cost: 3.8568732738494873
grad_norm: 0.5055000690031195, clipped: 0.5055000690031195
epoch: 22, train_batch_id: 500, avg_cost: 3.862151622772217
grad_norm: 1.3802589269263734, clipped: 1.0
epoch: 22, train_batch_id: 550, avg_cost: 3.8524627685546875
grad_norm: 0.6224094306128378, clipped: 0.6224094306128378
epoch: 22, train_batch_id: 600, avg_cost: 3.8541104793548584
grad_norm: 0.8371612523894912, clipped: 0.8371612523894912
epoch: 22, train_batch_id: 650, avg_cost: 3.8600029945373535
grad_norm: 0.6027181853359403, clipped: 0.6027181853359403
epoch: 22, train_batch_id: 700, avg_cost: 3.857408285140991
grad_norm: 0.45780962240744494, clipped: 0.45780962240744494
epoch: 22, train_batch_id: 750, avg_cost: 3.851346731185913
grad_norm: 0.4897957091312628, clipped: 0.4897957091312628
epoch: 22, train_batch_id: 800, avg_cost: 3.8743386268615723
grad_norm: 0.4503276404577932, clipped: 0.4503276404577932
epoch: 22, train_batch_id: 850, avg_cost: 3.853377342224121
grad_norm: 0.4490149676486126, clipped: 0.4490149676486126
epoch: 22, train_batch_id: 900, avg_cost: 3.8472394943237305
grad_norm: 0.38773926519431984, clipped: 0.38773926519431984
epoch: 22, train_batch_id: 950, avg_cost: 3.846315860748291
grad_norm: 0.38422245405954447, clipped: 0.38422245405954447
epoch: 22, train_batch_id: 1000, avg_cost: 3.872239112854004
grad_norm: 0.39043833276208256, clipped: 0.39043833276208256
epoch: 22, train_batch_id: 1050, avg_cost: 3.8582348823547363
grad_norm: 0.513202106625457, clipped: 0.513202106625457
epoch: 22, train_batch_id: 1100, avg_cost: 3.8719944953918457
grad_norm: 0.4890841772442796, clipped: 0.4890841772442796
epoch: 22, train_batch_id: 1150, avg_cost: 3.850721836090088
grad_norm: 0.4840730904383125, clipped: 0.4840730904383125
epoch: 22, train_batch_id: 1200, avg_cost: 3.8453409671783447
grad_norm: 0.5599089399058808, clipped: 0.5599089399058808
epoch: 22, train_batch_id: 1250, avg_cost: 3.8717989921569824
grad_norm: 0.5091726021393096, clipped: 0.5091726021393096
epoch: 22, train_batch_id: 1300, avg_cost: 3.8617939949035645
grad_norm: 0.500288373310965, clipped: 0.500288373310965
epoch: 22, train_batch_id: 1350, avg_cost: 3.8696794509887695
grad_norm: 0.5074062709940184, clipped: 0.5074062709940184
epoch: 22, train_batch_id: 1400, avg_cost: 3.8497231006622314
grad_norm: 0.36047294179351935, clipped: 0.36047294179351935
epoch: 22, train_batch_id: 1450, avg_cost: 3.8489365577697754
grad_norm: 0.8188107991545697, clipped: 0.8188107991545697
epoch: 22, train_batch_id: 1500, avg_cost: 3.8403148651123047
grad_norm: 1.2447875311359644, clipped: 1.0
epoch: 22, train_batch_id: 1550, avg_cost: 3.8670735359191895
grad_norm: 0.610570008235793, clipped: 0.610570008235793
epoch: 22, train_batch_id: 1600, avg_cost: 3.8622264862060547
grad_norm: 0.5361801124697648, clipped: 0.5361801124697648
epoch: 22, train_batch_id: 1650, avg_cost: 3.8365328311920166
grad_norm: 0.36538670461241235, clipped: 0.36538670461241235
epoch: 22, train_batch_id: 1700, avg_cost: 3.8634181022644043
grad_norm: 0.33449572157992036, clipped: 0.33449572157992036
epoch: 22, train_batch_id: 1750, avg_cost: 3.876974582672119
grad_norm: 0.34825596802870284, clipped: 0.34825596802870284
epoch: 22, train_batch_id: 1800, avg_cost: 3.8716259002685547
grad_norm: 0.7493314006011677, clipped: 0.7493314006011677
epoch: 22, train_batch_id: 1850, avg_cost: 3.8872809410095215
grad_norm: 0.5474322819137911, clipped: 0.5474322819137911
epoch: 22, train_batch_id: 1900, avg_cost: 3.8438000679016113
grad_norm: 0.7431914931512851, clipped: 0.7431914931512851
epoch: 22, train_batch_id: 1950, avg_cost: 3.8824024200439453
grad_norm: 0.6421139744645764, clipped: 0.6421139744645764
epoch: 22, train_batch_id: 2000, avg_cost: 3.855358600616455
grad_norm: 0.5416366483082627, clipped: 0.5416366483082627
epoch: 22, train_batch_id: 2050, avg_cost: 3.845768928527832
grad_norm: 0.42380632576004273, clipped: 0.42380632576004273
epoch: 22, train_batch_id: 2100, avg_cost: 3.8499579429626465
grad_norm: 0.6406052520658588, clipped: 0.6406052520658588
epoch: 22, train_batch_id: 2150, avg_cost: 3.860381841659546
grad_norm: 0.6117376256364121, clipped: 0.6117376256364121
epoch: 22, train_batch_id: 2200, avg_cost: 3.8623623847961426
grad_norm: 0.9770808369258949, clipped: 0.9770808369258949
epoch: 22, train_batch_id: 2250, avg_cost: 3.8365988731384277
grad_norm: 0.5641035360859992, clipped: 0.5641035360859992
epoch: 22, train_batch_id: 2300, avg_cost: 3.881143093109131
grad_norm: 0.564548762346181, clipped: 0.564548762346181
epoch: 22, train_batch_id: 2350, avg_cost: 3.856403112411499
grad_norm: 0.46061548876419744, clipped: 0.46061548876419744
epoch: 22, train_batch_id: 2400, avg_cost: 3.8219547271728516
grad_norm: 0.4909496254707484, clipped: 0.4909496254707484
epoch: 22, train_batch_id: 2450, avg_cost: 3.8470282554626465
grad_norm: 0.4833305944791852, clipped: 0.4833305944791852
Finished epoch 22, took 00:05:37 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.856239080429077 +- 0.0031381985172629356
Evaluating candidate model on evaluation dataset
Epoch 22 candidate mean 3.858109474182129, baseline epoch 21 mean 3.8592233657836914, difference -0.0011138916015625
p-value: 0.003569323744468317
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 23, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 23, train_batch_id: 0, avg_cost: 3.8627593517303467
grad_norm: 0.3746050355137979, clipped: 0.3746050355137979
epoch: 23, train_batch_id: 50, avg_cost: 3.8451309204101562
grad_norm: 0.4348657347716651, clipped: 0.4348657347716651
epoch: 23, train_batch_id: 100, avg_cost: 3.8494300842285156
grad_norm: 0.4780564839674296, clipped: 0.4780564839674296
epoch: 23, train_batch_id: 150, avg_cost: 3.8706717491149902
grad_norm: 0.4353416179646505, clipped: 0.4353416179646505
epoch: 23, train_batch_id: 200, avg_cost: 3.869781255722046
grad_norm: 0.7179111471654966, clipped: 0.7179111471654966
epoch: 23, train_batch_id: 250, avg_cost: 3.8398489952087402
grad_norm: 0.6905904997101007, clipped: 0.6905904997101007
epoch: 23, train_batch_id: 300, avg_cost: 3.84274959564209
grad_norm: 0.6326295725016557, clipped: 0.6326295725016557
epoch: 23, train_batch_id: 350, avg_cost: 3.8688831329345703
grad_norm: 0.45664447040477985, clipped: 0.45664447040477985
epoch: 23, train_batch_id: 400, avg_cost: 3.860414505004883
grad_norm: 0.43066765110733357, clipped: 0.43066765110733357
epoch: 23, train_batch_id: 450, avg_cost: 3.8810484409332275
grad_norm: 0.6461859655979756, clipped: 0.6461859655979756
epoch: 23, train_batch_id: 500, avg_cost: 3.8524508476257324
grad_norm: 0.4162825303558129, clipped: 0.4162825303558129
epoch: 23, train_batch_id: 550, avg_cost: 3.898507595062256
grad_norm: 0.4750667591818428, clipped: 0.4750667591818428
epoch: 23, train_batch_id: 600, avg_cost: 3.8447115421295166
grad_norm: 0.4820742617962094, clipped: 0.4820742617962094
epoch: 23, train_batch_id: 650, avg_cost: 3.892516851425171
grad_norm: 0.580593679516452, clipped: 0.580593679516452
epoch: 23, train_batch_id: 700, avg_cost: 3.873668909072876
grad_norm: 0.7543889659778028, clipped: 0.7543889659778028
epoch: 23, train_batch_id: 750, avg_cost: 3.8465464115142822
grad_norm: 0.614851704614387, clipped: 0.614851704614387
epoch: 23, train_batch_id: 800, avg_cost: 3.8686060905456543
grad_norm: 0.655481091502587, clipped: 0.655481091502587
epoch: 23, train_batch_id: 850, avg_cost: 3.863309144973755
grad_norm: 0.5731156282211987, clipped: 0.5731156282211987
epoch: 23, train_batch_id: 900, avg_cost: 3.8629581928253174
grad_norm: 0.42660901009748164, clipped: 0.42660901009748164
epoch: 23, train_batch_id: 950, avg_cost: 3.8597748279571533
grad_norm: 1.0474320530869548, clipped: 1.0
epoch: 23, train_batch_id: 1000, avg_cost: 3.8475842475891113
grad_norm: 0.5333763541756644, clipped: 0.5333763541756644
epoch: 23, train_batch_id: 1050, avg_cost: 3.8334245681762695
grad_norm: 0.752231642277039, clipped: 0.752231642277039
epoch: 23, train_batch_id: 1100, avg_cost: 3.8537285327911377
grad_norm: 0.4560381317218351, clipped: 0.4560381317218351
epoch: 23, train_batch_id: 1150, avg_cost: 3.8325982093811035
grad_norm: 0.4910044556693037, clipped: 0.4910044556693037
epoch: 23, train_batch_id: 1200, avg_cost: 3.853456497192383
grad_norm: 0.5866489516720809, clipped: 0.5866489516720809
epoch: 23, train_batch_id: 1250, avg_cost: 3.851033926010132
grad_norm: 0.7563805072622114, clipped: 0.7563805072622114
epoch: 23, train_batch_id: 1300, avg_cost: 3.8512794971466064
grad_norm: 0.36679292898884247, clipped: 0.36679292898884247
epoch: 23, train_batch_id: 1350, avg_cost: 3.8593239784240723
grad_norm: 0.3678233809291328, clipped: 0.3678233809291328
epoch: 23, train_batch_id: 1400, avg_cost: 3.8485445976257324
grad_norm: 0.4794493979607721, clipped: 0.4794493979607721
epoch: 23, train_batch_id: 1450, avg_cost: 3.848569631576538
grad_norm: 0.5462332377643919, clipped: 0.5462332377643919
epoch: 23, train_batch_id: 1500, avg_cost: 3.837918281555176
grad_norm: 0.4891222030168784, clipped: 0.4891222030168784
epoch: 23, train_batch_id: 1550, avg_cost: 3.876286506652832
grad_norm: 0.5843322146079637, clipped: 0.5843322146079637
epoch: 23, train_batch_id: 1600, avg_cost: 3.834714651107788
grad_norm: 0.35099441084117944, clipped: 0.35099441084117944
epoch: 23, train_batch_id: 1650, avg_cost: 3.855058193206787
grad_norm: 0.7885421387539385, clipped: 0.7885421387539385
epoch: 23, train_batch_id: 1700, avg_cost: 3.8666927814483643
grad_norm: 0.36217558683506, clipped: 0.36217558683506
epoch: 23, train_batch_id: 1750, avg_cost: 3.867579460144043
grad_norm: 0.5406904038876674, clipped: 0.5406904038876674
epoch: 23, train_batch_id: 1800, avg_cost: 3.876396894454956
grad_norm: 1.2863291702453423, clipped: 1.0
epoch: 23, train_batch_id: 1850, avg_cost: 3.853681802749634
grad_norm: 1.0037643949155668, clipped: 1.0
epoch: 23, train_batch_id: 1900, avg_cost: 3.863666534423828
grad_norm: 0.5788934411696597, clipped: 0.5788934411696597
epoch: 23, train_batch_id: 1950, avg_cost: 3.8498964309692383
grad_norm: 0.4854753004186078, clipped: 0.4854753004186078
epoch: 23, train_batch_id: 2000, avg_cost: 3.838118553161621
grad_norm: 0.5409578460725621, clipped: 0.5409578460725621
epoch: 23, train_batch_id: 2050, avg_cost: 3.848818063735962
grad_norm: 0.5344034408430745, clipped: 0.5344034408430745
epoch: 23, train_batch_id: 2100, avg_cost: 3.840161085128784
grad_norm: 0.4150870756779081, clipped: 0.4150870756779081
epoch: 23, train_batch_id: 2150, avg_cost: 3.879049062728882
grad_norm: 0.5253956948086694, clipped: 0.5253956948086694
epoch: 23, train_batch_id: 2200, avg_cost: 3.8551993370056152
grad_norm: 0.39027743217420735, clipped: 0.39027743217420735
epoch: 23, train_batch_id: 2250, avg_cost: 3.851241111755371
grad_norm: 0.5280011084727179, clipped: 0.5280011084727179
epoch: 23, train_batch_id: 2300, avg_cost: 3.875626564025879
grad_norm: 0.6505177914871946, clipped: 0.6505177914871946
epoch: 23, train_batch_id: 2350, avg_cost: 3.8398966789245605
grad_norm: 0.3861539517763107, clipped: 0.3861539517763107
epoch: 23, train_batch_id: 2400, avg_cost: 3.8697259426116943
grad_norm: 0.46198752673492266, clipped: 0.46198752673492266
epoch: 23, train_batch_id: 2450, avg_cost: 3.8822121620178223
grad_norm: 0.5140546121026676, clipped: 0.5140546121026676
Finished epoch 23, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8561460971832275 +- 0.003130850149318576
Evaluating candidate model on evaluation dataset
Epoch 23 candidate mean 3.8506503105163574, baseline epoch 22 mean 3.8509726524353027, difference -0.0003223419189453125
p-value: 0.20293559233456826
Start train epoch 24, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 24, train_batch_id: 0, avg_cost: 3.85402250289917
grad_norm: 0.555659019371392, clipped: 0.555659019371392
epoch: 24, train_batch_id: 50, avg_cost: 3.886948585510254
grad_norm: 0.5518004558550818, clipped: 0.5518004558550818
epoch: 24, train_batch_id: 100, avg_cost: 3.8519163131713867
grad_norm: 0.6876951026621206, clipped: 0.6876951026621206
epoch: 24, train_batch_id: 150, avg_cost: 3.8534884452819824
grad_norm: 0.32121467544737303, clipped: 0.32121467544737303
epoch: 24, train_batch_id: 200, avg_cost: 3.8486111164093018
grad_norm: 0.5787482392931236, clipped: 0.5787482392931236
epoch: 24, train_batch_id: 250, avg_cost: 3.8563451766967773
grad_norm: 0.45334294929160984, clipped: 0.45334294929160984
epoch: 24, train_batch_id: 300, avg_cost: 3.843989372253418
grad_norm: 0.41623088561737365, clipped: 0.41623088561737365
epoch: 24, train_batch_id: 350, avg_cost: 3.8453588485717773
grad_norm: 0.570912155254541, clipped: 0.570912155254541
epoch: 24, train_batch_id: 400, avg_cost: 3.8811326026916504
grad_norm: 0.3742735878855701, clipped: 0.3742735878855701
epoch: 24, train_batch_id: 450, avg_cost: 3.8666534423828125
grad_norm: 0.609301016177174, clipped: 0.609301016177174
epoch: 24, train_batch_id: 500, avg_cost: 3.8552937507629395
grad_norm: 0.5456959006430867, clipped: 0.5456959006430867
epoch: 24, train_batch_id: 550, avg_cost: 3.857011318206787
grad_norm: 0.8116922281720931, clipped: 0.8116922281720931
epoch: 24, train_batch_id: 600, avg_cost: 3.8595588207244873
grad_norm: 0.4808003705234227, clipped: 0.4808003705234227
epoch: 24, train_batch_id: 650, avg_cost: 3.865152597427368
grad_norm: 0.9620150080538318, clipped: 0.9620150080538318
epoch: 24, train_batch_id: 700, avg_cost: 3.8587565422058105
grad_norm: 1.5424300484777613, clipped: 1.0
epoch: 24, train_batch_id: 750, avg_cost: 3.8462560176849365
grad_norm: 0.5936164253264627, clipped: 0.5936164253264627
epoch: 24, train_batch_id: 800, avg_cost: 3.861859083175659
grad_norm: 0.5214668674244118, clipped: 0.5214668674244118
epoch: 24, train_batch_id: 850, avg_cost: 3.830955982208252
grad_norm: 0.6908122819278983, clipped: 0.6908122819278983
epoch: 24, train_batch_id: 900, avg_cost: 3.830443859100342
grad_norm: 0.655216845788691, clipped: 0.655216845788691
epoch: 24, train_batch_id: 950, avg_cost: 3.8672876358032227
grad_norm: 0.5315591625564485, clipped: 0.5315591625564485
epoch: 24, train_batch_id: 1000, avg_cost: 3.8766980171203613
grad_norm: 0.5212715472129639, clipped: 0.5212715472129639
epoch: 24, train_batch_id: 1050, avg_cost: 3.857390880584717
grad_norm: 1.698059609409142, clipped: 1.0
epoch: 24, train_batch_id: 1100, avg_cost: 3.8380961418151855
grad_norm: 0.36925142975722197, clipped: 0.36925142975722197
epoch: 24, train_batch_id: 1150, avg_cost: 3.8303260803222656
grad_norm: 1.131159636449012, clipped: 1.0
epoch: 24, train_batch_id: 1200, avg_cost: 3.8455910682678223
grad_norm: 0.5782496129289535, clipped: 0.5782496129289535
epoch: 24, train_batch_id: 1250, avg_cost: 3.879883050918579
grad_norm: 0.7063853531947293, clipped: 0.7063853531947293
epoch: 24, train_batch_id: 1300, avg_cost: 3.846325159072876
grad_norm: 0.5502124252887138, clipped: 0.5502124252887138
epoch: 24, train_batch_id: 1350, avg_cost: 3.869138479232788
grad_norm: 0.6925261237614735, clipped: 0.6925261237614735
epoch: 24, train_batch_id: 1400, avg_cost: 3.8674399852752686
grad_norm: 0.467510559070473, clipped: 0.467510559070473
epoch: 24, train_batch_id: 1450, avg_cost: 3.8770523071289062
grad_norm: 1.601248693171985, clipped: 1.0
epoch: 24, train_batch_id: 1500, avg_cost: 3.8516008853912354
grad_norm: 0.8153827221952888, clipped: 0.8153827221952888
epoch: 24, train_batch_id: 1550, avg_cost: 3.8534669876098633
grad_norm: 0.6854671287162016, clipped: 0.6854671287162016
epoch: 24, train_batch_id: 1600, avg_cost: 3.8606138229370117
grad_norm: 0.5190816144745147, clipped: 0.5190816144745147
epoch: 24, train_batch_id: 1650, avg_cost: 3.839909791946411
grad_norm: 0.49840102058443897, clipped: 0.49840102058443897
epoch: 24, train_batch_id: 1700, avg_cost: 3.8422107696533203
grad_norm: 0.8426248081012923, clipped: 0.8426248081012923
epoch: 24, train_batch_id: 1750, avg_cost: 3.8624773025512695
grad_norm: 0.5619387263284663, clipped: 0.5619387263284663
epoch: 24, train_batch_id: 1800, avg_cost: 3.858943462371826
grad_norm: 1.9617559932917588, clipped: 1.0
epoch: 24, train_batch_id: 1850, avg_cost: 3.8806891441345215
grad_norm: 0.6895556444060589, clipped: 0.6895556444060589
epoch: 24, train_batch_id: 1900, avg_cost: 3.8655474185943604
grad_norm: 0.5387165135561753, clipped: 0.5387165135561753
epoch: 24, train_batch_id: 1950, avg_cost: 3.857174873352051
grad_norm: 0.743340134708324, clipped: 0.743340134708324
epoch: 24, train_batch_id: 2000, avg_cost: 3.879232168197632
grad_norm: 0.425721940579669, clipped: 0.425721940579669
epoch: 24, train_batch_id: 2050, avg_cost: 3.841752290725708
grad_norm: 0.40876313495238226, clipped: 0.40876313495238226
epoch: 24, train_batch_id: 2100, avg_cost: 3.8590087890625
grad_norm: 0.4083409538255059, clipped: 0.4083409538255059
epoch: 24, train_batch_id: 2150, avg_cost: 3.8296871185302734
grad_norm: 0.46016605072046307, clipped: 0.46016605072046307
epoch: 24, train_batch_id: 2200, avg_cost: 3.8655571937561035
grad_norm: 0.2758686744830936, clipped: 0.2758686744830936
epoch: 24, train_batch_id: 2250, avg_cost: 3.8231899738311768
grad_norm: 0.40371905027316574, clipped: 0.40371905027316574
epoch: 24, train_batch_id: 2300, avg_cost: 3.854580879211426
grad_norm: 0.43517269213256193, clipped: 0.43517269213256193
epoch: 24, train_batch_id: 2350, avg_cost: 3.84322452545166
grad_norm: 0.45834369549627063, clipped: 0.45834369549627063
epoch: 24, train_batch_id: 2400, avg_cost: 3.860975742340088
grad_norm: 0.40609920410797873, clipped: 0.40609920410797873
epoch: 24, train_batch_id: 2450, avg_cost: 3.8585591316223145
grad_norm: 0.6352429527211847, clipped: 0.6352429527211847
Finished epoch 24, took 00:05:25 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8582944869995117 +- 0.0031475252471864223
Evaluating candidate model on evaluation dataset
Epoch 24 candidate mean 3.852226972579956, baseline epoch 22 mean 3.8509726524353027, difference 0.0012543201446533203
Start train epoch 25, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 25, train_batch_id: 0, avg_cost: 3.848430633544922
grad_norm: 0.5974830019808092, clipped: 0.5974830019808092
epoch: 25, train_batch_id: 50, avg_cost: 3.851802110671997
grad_norm: 0.5619919631019654, clipped: 0.5619919631019654
epoch: 25, train_batch_id: 100, avg_cost: 3.839967966079712
grad_norm: 0.40077307457943356, clipped: 0.40077307457943356
epoch: 25, train_batch_id: 150, avg_cost: 3.8825111389160156
grad_norm: 0.9212092190131764, clipped: 0.9212092190131764
epoch: 25, train_batch_id: 200, avg_cost: 3.852881908416748
grad_norm: 0.5732661293793986, clipped: 0.5732661293793986
epoch: 25, train_batch_id: 250, avg_cost: 3.8761370182037354
grad_norm: 0.4636646871446949, clipped: 0.4636646871446949
epoch: 25, train_batch_id: 300, avg_cost: 3.854095220565796
grad_norm: 0.6689649522915017, clipped: 0.6689649522915017
epoch: 25, train_batch_id: 350, avg_cost: 3.856369972229004
grad_norm: 0.498753661749526, clipped: 0.498753661749526
epoch: 25, train_batch_id: 400, avg_cost: 3.854618549346924
grad_norm: 0.42030315466538865, clipped: 0.42030315466538865
epoch: 25, train_batch_id: 450, avg_cost: 3.8510258197784424
grad_norm: 0.45204800186543526, clipped: 0.45204800186543526
epoch: 25, train_batch_id: 500, avg_cost: 3.842599391937256
grad_norm: 0.4099344432743416, clipped: 0.4099344432743416
epoch: 25, train_batch_id: 550, avg_cost: 3.851431369781494
grad_norm: 0.582122703780228, clipped: 0.582122703780228
epoch: 25, train_batch_id: 600, avg_cost: 3.8651726245880127
grad_norm: 0.3835379196335878, clipped: 0.3835379196335878
epoch: 25, train_batch_id: 650, avg_cost: 3.8647079467773438
grad_norm: 0.3862898930559078, clipped: 0.3862898930559078
epoch: 25, train_batch_id: 700, avg_cost: 3.868081569671631
grad_norm: 0.47826199126869806, clipped: 0.47826199126869806
epoch: 25, train_batch_id: 750, avg_cost: 3.827425241470337
grad_norm: 0.3352171621378325, clipped: 0.3352171621378325
epoch: 25, train_batch_id: 800, avg_cost: 3.8607330322265625
grad_norm: 0.7243352400988593, clipped: 0.7243352400988593
epoch: 25, train_batch_id: 850, avg_cost: 3.871173858642578
grad_norm: 0.44222614097898955, clipped: 0.44222614097898955
epoch: 25, train_batch_id: 900, avg_cost: 3.862243413925171
grad_norm: 0.4811576582343671, clipped: 0.4811576582343671
epoch: 25, train_batch_id: 950, avg_cost: 3.854349374771118
grad_norm: 0.45780130467656227, clipped: 0.45780130467656227
epoch: 25, train_batch_id: 1000, avg_cost: 3.8566017150878906
grad_norm: 0.45242336522493726, clipped: 0.45242336522493726
epoch: 25, train_batch_id: 1050, avg_cost: 3.875354766845703
grad_norm: 0.4076519859812622, clipped: 0.4076519859812622
epoch: 25, train_batch_id: 1100, avg_cost: 3.8537392616271973
grad_norm: 0.6498932985836088, clipped: 0.6498932985836088
epoch: 25, train_batch_id: 1150, avg_cost: 3.838818311691284
grad_norm: 0.4047908764949764, clipped: 0.4047908764949764
epoch: 25, train_batch_id: 1200, avg_cost: 3.862013816833496
grad_norm: 1.116067091307584, clipped: 1.0
epoch: 25, train_batch_id: 1250, avg_cost: 3.848595142364502
grad_norm: 0.4667783073092866, clipped: 0.4667783073092866
epoch: 25, train_batch_id: 1300, avg_cost: 3.8720922470092773
grad_norm: 0.4262036863779552, clipped: 0.4262036863779552
epoch: 25, train_batch_id: 1350, avg_cost: 3.8424863815307617
grad_norm: 0.4810677759506166, clipped: 0.4810677759506166
epoch: 25, train_batch_id: 1400, avg_cost: 3.8659026622772217
grad_norm: 0.6154658931087349, clipped: 0.6154658931087349
epoch: 25, train_batch_id: 1450, avg_cost: 3.836526870727539
grad_norm: 0.41654776199024174, clipped: 0.41654776199024174
epoch: 25, train_batch_id: 1500, avg_cost: 3.8763580322265625
grad_norm: 0.45697960415781164, clipped: 0.45697960415781164
epoch: 25, train_batch_id: 1550, avg_cost: 3.8512489795684814
grad_norm: 0.4087656819228687, clipped: 0.4087656819228687
epoch: 25, train_batch_id: 1600, avg_cost: 3.8648669719696045
grad_norm: 0.558887336866225, clipped: 0.558887336866225
epoch: 25, train_batch_id: 1650, avg_cost: 3.847682476043701
grad_norm: 0.5423348689759899, clipped: 0.5423348689759899
epoch: 25, train_batch_id: 1700, avg_cost: 3.878852605819702
grad_norm: 0.42962305235095655, clipped: 0.42962305235095655
epoch: 25, train_batch_id: 1750, avg_cost: 3.879436492919922
grad_norm: 0.5164000349812318, clipped: 0.5164000349812318
epoch: 25, train_batch_id: 1800, avg_cost: 3.832632064819336
grad_norm: 0.4166752457659583, clipped: 0.4166752457659583
epoch: 25, train_batch_id: 1850, avg_cost: 3.863837242126465
grad_norm: 0.7150831744699991, clipped: 0.7150831744699991
epoch: 25, train_batch_id: 1900, avg_cost: 3.862691879272461
grad_norm: 0.35659245005872975, clipped: 0.35659245005872975
epoch: 25, train_batch_id: 1950, avg_cost: 3.8498620986938477
grad_norm: 0.7809488835516178, clipped: 0.7809488835516178
epoch: 25, train_batch_id: 2000, avg_cost: 3.8720788955688477
grad_norm: 0.4319111223648675, clipped: 0.4319111223648675
epoch: 25, train_batch_id: 2050, avg_cost: 3.8308305740356445
grad_norm: 0.5157486302336516, clipped: 0.5157486302336516
epoch: 25, train_batch_id: 2100, avg_cost: 3.8820598125457764
grad_norm: 0.4664980715652456, clipped: 0.4664980715652456
epoch: 25, train_batch_id: 2150, avg_cost: 3.8749783039093018
grad_norm: 0.46462202703122496, clipped: 0.46462202703122496
epoch: 25, train_batch_id: 2200, avg_cost: 3.850775718688965
grad_norm: 0.3937808703569782, clipped: 0.3937808703569782
epoch: 25, train_batch_id: 2250, avg_cost: 3.8797144889831543
grad_norm: 0.4395651206658784, clipped: 0.4395651206658784
epoch: 25, train_batch_id: 2300, avg_cost: 3.870596408843994
grad_norm: 0.6771914662532903, clipped: 0.6771914662532903
epoch: 25, train_batch_id: 2350, avg_cost: 3.863980293273926
grad_norm: 0.3658262075857561, clipped: 0.3658262075857561
epoch: 25, train_batch_id: 2400, avg_cost: 3.85599422454834
grad_norm: 0.5935276308294491, clipped: 0.5935276308294491
epoch: 25, train_batch_id: 2450, avg_cost: 3.847740411758423
grad_norm: 0.4668403570701028, clipped: 0.4668403570701028
Finished epoch 25, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.854757070541382 +- 0.0031360455323010683
Evaluating candidate model on evaluation dataset
Epoch 25 candidate mean 3.849335193634033, baseline epoch 22 mean 3.8509726524353027, difference -0.0016374588012695312
p-value: 2.7514102645835582e-05
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 26, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 26, train_batch_id: 0, avg_cost: 3.8613648414611816
grad_norm: 0.38533581918008775, clipped: 0.38533581918008775
epoch: 26, train_batch_id: 50, avg_cost: 3.8413233757019043
grad_norm: 0.41800952079804055, clipped: 0.41800952079804055
epoch: 26, train_batch_id: 100, avg_cost: 3.8592875003814697
grad_norm: 0.5605158686079322, clipped: 0.5605158686079322
epoch: 26, train_batch_id: 150, avg_cost: 3.8563647270202637
grad_norm: 0.4203416774516744, clipped: 0.4203416774516744
epoch: 26, train_batch_id: 200, avg_cost: 3.8813233375549316
grad_norm: 0.5705955079396077, clipped: 0.5705955079396077
epoch: 26, train_batch_id: 250, avg_cost: 3.8792648315429688
grad_norm: 0.38573117075626995, clipped: 0.38573117075626995
epoch: 26, train_batch_id: 300, avg_cost: 3.862685203552246
grad_norm: 0.47887028604558013, clipped: 0.47887028604558013
epoch: 26, train_batch_id: 350, avg_cost: 3.8617093563079834
grad_norm: 1.1740449092151342, clipped: 1.0
epoch: 26, train_batch_id: 400, avg_cost: 3.858492374420166
grad_norm: 0.539541167897808, clipped: 0.539541167897808
epoch: 26, train_batch_id: 450, avg_cost: 3.8493189811706543
grad_norm: 0.34299029114196433, clipped: 0.34299029114196433
epoch: 26, train_batch_id: 500, avg_cost: 3.8483657836914062
grad_norm: 0.6377195439959387, clipped: 0.6377195439959387
epoch: 26, train_batch_id: 550, avg_cost: 3.8395073413848877
grad_norm: 0.5794823137858494, clipped: 0.5794823137858494
epoch: 26, train_batch_id: 600, avg_cost: 3.8663198947906494
grad_norm: 0.8607122005510283, clipped: 0.8607122005510283
epoch: 26, train_batch_id: 650, avg_cost: 3.8775393962860107
grad_norm: 0.9975539775414224, clipped: 0.9975539775414224
epoch: 26, train_batch_id: 700, avg_cost: 3.8637213706970215
grad_norm: 0.45961295348195974, clipped: 0.45961295348195974
epoch: 26, train_batch_id: 750, avg_cost: 3.8304288387298584
grad_norm: 0.3847339407747428, clipped: 0.3847339407747428
epoch: 26, train_batch_id: 800, avg_cost: 3.855621814727783
grad_norm: 0.46937552509262337, clipped: 0.46937552509262337
epoch: 26, train_batch_id: 850, avg_cost: 3.8432228565216064
grad_norm: 0.44888968635884174, clipped: 0.44888968635884174
epoch: 26, train_batch_id: 900, avg_cost: 3.86826229095459
grad_norm: 1.0497940073786454, clipped: 1.0
epoch: 26, train_batch_id: 950, avg_cost: 3.852522373199463
grad_norm: 0.3365645781228849, clipped: 0.3365645781228849
epoch: 26, train_batch_id: 1000, avg_cost: 3.867933750152588
grad_norm: 0.7157426917337782, clipped: 0.7157426917337782
epoch: 26, train_batch_id: 1050, avg_cost: 3.8531150817871094
grad_norm: 1.056116043018361, clipped: 1.0
epoch: 26, train_batch_id: 1100, avg_cost: 3.8545262813568115
grad_norm: 0.5653233123761394, clipped: 0.5653233123761394
epoch: 26, train_batch_id: 1150, avg_cost: 3.865738868713379
grad_norm: 0.8161299864541389, clipped: 0.8161299864541389
epoch: 26, train_batch_id: 1200, avg_cost: 3.8505301475524902
grad_norm: 0.4887373377633422, clipped: 0.4887373377633422
epoch: 26, train_batch_id: 1250, avg_cost: 3.8746118545532227
grad_norm: 0.6172664588439842, clipped: 0.6172664588439842
epoch: 26, train_batch_id: 1300, avg_cost: 3.849436044692993
grad_norm: 0.5680357681359296, clipped: 0.5680357681359296
epoch: 26, train_batch_id: 1350, avg_cost: 3.8476200103759766
grad_norm: 0.6086867563956683, clipped: 0.6086867563956683
epoch: 26, train_batch_id: 1400, avg_cost: 3.8484315872192383
grad_norm: 0.7757299949472407, clipped: 0.7757299949472407
epoch: 26, train_batch_id: 1450, avg_cost: 3.853877544403076
grad_norm: 0.5411496998634545, clipped: 0.5411496998634545
epoch: 26, train_batch_id: 1500, avg_cost: 3.851579427719116
grad_norm: 0.4642874404502482, clipped: 0.4642874404502482
epoch: 26, train_batch_id: 1550, avg_cost: 3.8679938316345215
grad_norm: 0.4542167701535476, clipped: 0.4542167701535476
epoch: 26, train_batch_id: 1600, avg_cost: 3.850039005279541
grad_norm: 0.48992944808237054, clipped: 0.48992944808237054
epoch: 26, train_batch_id: 1650, avg_cost: 3.808310031890869
grad_norm: 0.34806315702542145, clipped: 0.34806315702542145
epoch: 26, train_batch_id: 1700, avg_cost: 3.859363317489624
grad_norm: 0.2983930502248532, clipped: 0.2983930502248532
epoch: 26, train_batch_id: 1750, avg_cost: 3.8386311531066895
grad_norm: 0.43084309920851294, clipped: 0.43084309920851294
epoch: 26, train_batch_id: 1800, avg_cost: 3.8843982219696045
grad_norm: 0.5680903479940679, clipped: 0.5680903479940679
epoch: 26, train_batch_id: 1850, avg_cost: 3.86940336227417
grad_norm: 0.3923762398669767, clipped: 0.3923762398669767
epoch: 26, train_batch_id: 1900, avg_cost: 3.856680393218994
grad_norm: 0.4989794491546086, clipped: 0.4989794491546086
epoch: 26, train_batch_id: 1950, avg_cost: 3.8658623695373535
grad_norm: 0.4658341059728298, clipped: 0.4658341059728298
epoch: 26, train_batch_id: 2000, avg_cost: 3.8506736755371094
grad_norm: 0.32944623184274485, clipped: 0.32944623184274485
epoch: 26, train_batch_id: 2050, avg_cost: 3.8362338542938232
grad_norm: 0.4702013631555054, clipped: 0.4702013631555054
epoch: 26, train_batch_id: 2100, avg_cost: 3.8452556133270264
grad_norm: 0.4507516813706645, clipped: 0.4507516813706645
epoch: 26, train_batch_id: 2150, avg_cost: 3.881953001022339
grad_norm: 0.4674983110293371, clipped: 0.4674983110293371
epoch: 26, train_batch_id: 2200, avg_cost: 3.865476369857788
grad_norm: 0.6812461529260952, clipped: 0.6812461529260952
epoch: 26, train_batch_id: 2250, avg_cost: 3.8658556938171387
grad_norm: 0.7187121961158172, clipped: 0.7187121961158172
epoch: 26, train_batch_id: 2300, avg_cost: 3.875558376312256
grad_norm: 0.5991097583399977, clipped: 0.5991097583399977
epoch: 26, train_batch_id: 2350, avg_cost: 3.860319137573242
grad_norm: 0.5562148732718504, clipped: 0.5562148732718504
epoch: 26, train_batch_id: 2400, avg_cost: 3.8596408367156982
grad_norm: 0.39960631889761994, clipped: 0.39960631889761994
epoch: 26, train_batch_id: 2450, avg_cost: 3.8460097312927246
grad_norm: 0.338187435622853, clipped: 0.338187435622853
Finished epoch 26, took 00:05:30 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.855234384536743 +- 0.0031323349103331566
Evaluating candidate model on evaluation dataset
Epoch 26 candidate mean 3.848944902420044, baseline epoch 25 mean 3.8473398685455322, difference 0.0016050338745117188
Start train epoch 27, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 27, train_batch_id: 0, avg_cost: 3.8335471153259277
grad_norm: 1.0776430886798514, clipped: 1.0
epoch: 27, train_batch_id: 50, avg_cost: 3.8462119102478027
grad_norm: 0.5521429472353511, clipped: 0.5521429472353511
epoch: 27, train_batch_id: 100, avg_cost: 3.848482847213745
grad_norm: 0.4610901442639181, clipped: 0.4610901442639181
epoch: 27, train_batch_id: 150, avg_cost: 3.884796619415283
grad_norm: 0.9658353180779695, clipped: 0.9658353180779695
epoch: 27, train_batch_id: 200, avg_cost: 3.872328519821167
grad_norm: 0.5069899610422738, clipped: 0.5069899610422738
epoch: 27, train_batch_id: 250, avg_cost: 3.8648366928100586
grad_norm: 0.616556760458626, clipped: 0.616556760458626
epoch: 27, train_batch_id: 300, avg_cost: 3.8620247840881348
grad_norm: 0.5553588773837775, clipped: 0.5553588773837775
epoch: 27, train_batch_id: 350, avg_cost: 3.8689913749694824
grad_norm: 0.5920318718020998, clipped: 0.5920318718020998
epoch: 27, train_batch_id: 400, avg_cost: 3.8591701984405518
grad_norm: 0.49829062581454614, clipped: 0.49829062581454614
epoch: 27, train_batch_id: 450, avg_cost: 3.8766732215881348
grad_norm: 0.43471000742253263, clipped: 0.43471000742253263
epoch: 27, train_batch_id: 500, avg_cost: 3.8528895378112793
grad_norm: 0.35158581339477335, clipped: 0.35158581339477335
epoch: 27, train_batch_id: 550, avg_cost: 3.846839427947998
grad_norm: 0.46954861243028, clipped: 0.46954861243028
epoch: 27, train_batch_id: 600, avg_cost: 3.8798115253448486
grad_norm: 0.48939051079761936, clipped: 0.48939051079761936
epoch: 27, train_batch_id: 650, avg_cost: 3.8332223892211914
grad_norm: 0.39221794408984584, clipped: 0.39221794408984584
epoch: 27, train_batch_id: 700, avg_cost: 3.848940134048462
grad_norm: 0.58548636103628, clipped: 0.58548636103628
epoch: 27, train_batch_id: 750, avg_cost: 3.83648419380188
grad_norm: 0.3933177823536289, clipped: 0.3933177823536289
epoch: 27, train_batch_id: 800, avg_cost: 3.839736223220825
grad_norm: 0.5901832227350877, clipped: 0.5901832227350877
epoch: 27, train_batch_id: 850, avg_cost: 3.8414807319641113
grad_norm: 0.5501121723978242, clipped: 0.5501121723978242
epoch: 27, train_batch_id: 900, avg_cost: 3.875201940536499
grad_norm: 0.43832394431948835, clipped: 0.43832394431948835
epoch: 27, train_batch_id: 950, avg_cost: 3.8477895259857178
grad_norm: 0.4012677804455375, clipped: 0.4012677804455375
epoch: 27, train_batch_id: 1000, avg_cost: 3.871890068054199
grad_norm: 0.4020112083715666, clipped: 0.4020112083715666
epoch: 27, train_batch_id: 1050, avg_cost: 3.8374996185302734
grad_norm: 0.4566342396855254, clipped: 0.4566342396855254
epoch: 27, train_batch_id: 1100, avg_cost: 3.839362144470215
grad_norm: 0.5557395951104337, clipped: 0.5557395951104337
epoch: 27, train_batch_id: 1150, avg_cost: 3.854814052581787
grad_norm: 1.561230028786396, clipped: 1.0
epoch: 27, train_batch_id: 1200, avg_cost: 3.8563761711120605
grad_norm: 0.5035010957169418, clipped: 0.5035010957169418
epoch: 27, train_batch_id: 1250, avg_cost: 3.837808609008789
grad_norm: 0.4212454846568413, clipped: 0.4212454846568413
epoch: 27, train_batch_id: 1300, avg_cost: 3.861098289489746
grad_norm: 0.7406605533327721, clipped: 0.7406605533327721
epoch: 27, train_batch_id: 1350, avg_cost: 3.877228021621704
grad_norm: 0.44479904083149313, clipped: 0.44479904083149313
epoch: 27, train_batch_id: 1400, avg_cost: 3.829648017883301
grad_norm: 0.4635656240278847, clipped: 0.4635656240278847
epoch: 27, train_batch_id: 1450, avg_cost: 3.8551411628723145
grad_norm: 0.48003892242087315, clipped: 0.48003892242087315
epoch: 27, train_batch_id: 1500, avg_cost: 3.8726415634155273
grad_norm: 0.6806911186197171, clipped: 0.6806911186197171
epoch: 27, train_batch_id: 1550, avg_cost: 3.854396343231201
grad_norm: 0.3956355976305661, clipped: 0.3956355976305661
epoch: 27, train_batch_id: 1600, avg_cost: 3.8717808723449707
grad_norm: 0.5366129147562999, clipped: 0.5366129147562999
epoch: 27, train_batch_id: 1650, avg_cost: 3.8251090049743652
grad_norm: 0.35068553994034546, clipped: 0.35068553994034546
epoch: 27, train_batch_id: 1700, avg_cost: 3.843900680541992
grad_norm: 0.6406348662165127, clipped: 0.6406348662165127
epoch: 27, train_batch_id: 1750, avg_cost: 3.836853504180908
grad_norm: 0.625584153078537, clipped: 0.625584153078537
epoch: 27, train_batch_id: 1800, avg_cost: 3.847473621368408
grad_norm: 0.4758678125282251, clipped: 0.4758678125282251
epoch: 27, train_batch_id: 1850, avg_cost: 3.8934779167175293
grad_norm: 0.608877368381648, clipped: 0.608877368381648
epoch: 27, train_batch_id: 1900, avg_cost: 3.8712899684906006
grad_norm: 0.35355372534059726, clipped: 0.35355372534059726
epoch: 27, train_batch_id: 1950, avg_cost: 3.87153697013855
grad_norm: 0.3797527425647159, clipped: 0.3797527425647159
epoch: 27, train_batch_id: 2000, avg_cost: 3.853801965713501
grad_norm: 0.836000471155268, clipped: 0.836000471155268
epoch: 27, train_batch_id: 2050, avg_cost: 3.85150408744812
grad_norm: 0.49963620470601877, clipped: 0.49963620470601877
epoch: 27, train_batch_id: 2100, avg_cost: 3.8516738414764404
grad_norm: 0.3941439254533444, clipped: 0.3941439254533444
epoch: 27, train_batch_id: 2150, avg_cost: 3.8713431358337402
grad_norm: 0.4386539138745628, clipped: 0.4386539138745628
epoch: 27, train_batch_id: 2200, avg_cost: 3.8622121810913086
grad_norm: 0.4516466400803181, clipped: 0.4516466400803181
epoch: 27, train_batch_id: 2250, avg_cost: 3.84377121925354
grad_norm: 0.5840603639689891, clipped: 0.5840603639689891
epoch: 27, train_batch_id: 2300, avg_cost: 3.8414883613586426
grad_norm: 0.708835949539731, clipped: 0.708835949539731
epoch: 27, train_batch_id: 2350, avg_cost: 3.85446834564209
grad_norm: 0.3415247407554136, clipped: 0.3415247407554136
epoch: 27, train_batch_id: 2400, avg_cost: 3.857069492340088
grad_norm: 0.5496758850726616, clipped: 0.5496758850726616
epoch: 27, train_batch_id: 2450, avg_cost: 3.8548340797424316
grad_norm: 0.38694824314097964, clipped: 0.38694824314097964
Finished epoch 27, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8560616970062256 +- 0.0031609288416802883
Evaluating candidate model on evaluation dataset
Epoch 27 candidate mean 3.8482308387756348, baseline epoch 25 mean 3.8473398685455322, difference 0.0008909702301025391
Start train epoch 28, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 28, train_batch_id: 0, avg_cost: 3.855362892150879
grad_norm: 0.6782242140717184, clipped: 0.6782242140717184
epoch: 28, train_batch_id: 50, avg_cost: 3.8677477836608887
grad_norm: 0.45362522856637555, clipped: 0.45362522856637555
epoch: 28, train_batch_id: 100, avg_cost: 3.836676836013794
grad_norm: 0.3953641539883474, clipped: 0.3953641539883474
epoch: 28, train_batch_id: 150, avg_cost: 3.8758420944213867
grad_norm: 0.4473827569067799, clipped: 0.4473827569067799
epoch: 28, train_batch_id: 200, avg_cost: 3.841395854949951
grad_norm: 0.40927585552498363, clipped: 0.40927585552498363
epoch: 28, train_batch_id: 250, avg_cost: 3.8428537845611572
grad_norm: 0.45780875754700534, clipped: 0.45780875754700534
epoch: 28, train_batch_id: 300, avg_cost: 3.8522462844848633
grad_norm: 0.44920271723169214, clipped: 0.44920271723169214
epoch: 28, train_batch_id: 350, avg_cost: 3.876800537109375
grad_norm: 0.7203937174368111, clipped: 0.7203937174368111
epoch: 28, train_batch_id: 400, avg_cost: 3.8566782474517822
grad_norm: 0.47321277755297675, clipped: 0.47321277755297675
epoch: 28, train_batch_id: 450, avg_cost: 3.850672960281372
grad_norm: 0.4562101346144809, clipped: 0.4562101346144809
epoch: 28, train_batch_id: 500, avg_cost: 3.841914176940918
grad_norm: 1.1243618974151077, clipped: 1.0
epoch: 28, train_batch_id: 550, avg_cost: 3.874755620956421
grad_norm: 0.4866217532260257, clipped: 0.4866217532260257
epoch: 28, train_batch_id: 600, avg_cost: 3.848989486694336
grad_norm: 0.7570198196043272, clipped: 0.7570198196043272
epoch: 28, train_batch_id: 650, avg_cost: 3.8464620113372803
grad_norm: 0.6756612771497095, clipped: 0.6756612771497095
epoch: 28, train_batch_id: 700, avg_cost: 3.846806049346924
grad_norm: 0.5461123805172199, clipped: 0.5461123805172199
epoch: 28, train_batch_id: 750, avg_cost: 3.849560260772705
grad_norm: 0.3866991961477925, clipped: 0.3866991961477925
epoch: 28, train_batch_id: 800, avg_cost: 3.83180570602417
grad_norm: 0.43774197358122563, clipped: 0.43774197358122563
epoch: 28, train_batch_id: 850, avg_cost: 3.85563588142395
grad_norm: 0.48079243375667174, clipped: 0.48079243375667174
epoch: 28, train_batch_id: 900, avg_cost: 3.8669228553771973
grad_norm: 0.3627577042215642, clipped: 0.3627577042215642
epoch: 28, train_batch_id: 950, avg_cost: 3.852023124694824
grad_norm: 0.4576747870541013, clipped: 0.4576747870541013
epoch: 28, train_batch_id: 1000, avg_cost: 3.8620498180389404
grad_norm: 0.4805055760200202, clipped: 0.4805055760200202
epoch: 28, train_batch_id: 1050, avg_cost: 3.8738205432891846
grad_norm: 0.6666833624885906, clipped: 0.6666833624885906
epoch: 28, train_batch_id: 1100, avg_cost: 3.8510947227478027
grad_norm: 0.47268475999395826, clipped: 0.47268475999395826
epoch: 28, train_batch_id: 1150, avg_cost: 3.871577262878418
grad_norm: 0.5823666724532844, clipped: 0.5823666724532844
epoch: 28, train_batch_id: 1200, avg_cost: 3.8617281913757324
grad_norm: 0.6267067256574854, clipped: 0.6267067256574854
epoch: 28, train_batch_id: 1250, avg_cost: 3.852651596069336
grad_norm: 0.7777284670794187, clipped: 0.7777284670794187
epoch: 28, train_batch_id: 1300, avg_cost: 3.861084461212158
grad_norm: 0.5583605686743691, clipped: 0.5583605686743691
epoch: 28, train_batch_id: 1350, avg_cost: 3.848020553588867
grad_norm: 0.3992654749135338, clipped: 0.3992654749135338
epoch: 28, train_batch_id: 1400, avg_cost: 3.8669521808624268
grad_norm: 0.5628509740692047, clipped: 0.5628509740692047
epoch: 28, train_batch_id: 1450, avg_cost: 3.84688138961792
grad_norm: 0.5677799787435248, clipped: 0.5677799787435248
epoch: 28, train_batch_id: 1500, avg_cost: 3.850243091583252
grad_norm: 0.41882202304437854, clipped: 0.41882202304437854
epoch: 28, train_batch_id: 1550, avg_cost: 3.8404905796051025
grad_norm: 0.4689367958710928, clipped: 0.4689367958710928
epoch: 28, train_batch_id: 1600, avg_cost: 3.866394519805908
grad_norm: 0.39831338629466384, clipped: 0.39831338629466384
epoch: 28, train_batch_id: 1650, avg_cost: 3.8491921424865723
grad_norm: 0.5532541066278899, clipped: 0.5532541066278899
epoch: 28, train_batch_id: 1700, avg_cost: 3.8430917263031006
grad_norm: 0.43422177565187264, clipped: 0.43422177565187264
epoch: 28, train_batch_id: 1750, avg_cost: 3.8623039722442627
grad_norm: 0.48791408515204726, clipped: 0.48791408515204726
epoch: 28, train_batch_id: 1800, avg_cost: 3.862907886505127
grad_norm: 0.6252939595918446, clipped: 0.6252939595918446
epoch: 28, train_batch_id: 1850, avg_cost: 3.859159469604492
grad_norm: 0.42666699565852356, clipped: 0.42666699565852356
epoch: 28, train_batch_id: 1900, avg_cost: 3.845916748046875
grad_norm: 0.5919526761758527, clipped: 0.5919526761758527
epoch: 28, train_batch_id: 1950, avg_cost: 3.869428873062134
grad_norm: 0.5286099711029016, clipped: 0.5286099711029016
epoch: 28, train_batch_id: 2000, avg_cost: 3.894840717315674
grad_norm: 0.8202808970695369, clipped: 0.8202808970695369
epoch: 28, train_batch_id: 2050, avg_cost: 3.878653049468994
grad_norm: 0.4147350214010942, clipped: 0.4147350214010942
epoch: 28, train_batch_id: 2100, avg_cost: 3.86861252784729
grad_norm: 0.4424552010567154, clipped: 0.4424552010567154
epoch: 28, train_batch_id: 2150, avg_cost: 3.852543354034424
grad_norm: 0.5731210851234071, clipped: 0.5731210851234071
epoch: 28, train_batch_id: 2200, avg_cost: 3.8622446060180664
grad_norm: 0.4755992537498865, clipped: 0.4755992537498865
epoch: 28, train_batch_id: 2250, avg_cost: 3.863065004348755
grad_norm: 0.34282761712318266, clipped: 0.34282761712318266
epoch: 28, train_batch_id: 2300, avg_cost: 3.838179111480713
grad_norm: 0.7922816652431314, clipped: 0.7922816652431314
epoch: 28, train_batch_id: 2350, avg_cost: 3.859055995941162
grad_norm: 0.5014548854151174, clipped: 0.5014548854151174
epoch: 28, train_batch_id: 2400, avg_cost: 3.8528635501861572
grad_norm: 0.5766770755671042, clipped: 0.5766770755671042
epoch: 28, train_batch_id: 2450, avg_cost: 3.8739757537841797
grad_norm: 0.4751703304905404, clipped: 0.4751703304905404
Finished epoch 28, took 00:05:30 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8567616939544678 +- 0.003142070956528187
Evaluating candidate model on evaluation dataset
Epoch 28 candidate mean 3.850414752960205, baseline epoch 25 mean 3.8473398685455322, difference 0.0030748844146728516
Start train epoch 29, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 29, train_batch_id: 0, avg_cost: 3.8558924198150635
grad_norm: 0.4316016833852018, clipped: 0.4316016833852018
epoch: 29, train_batch_id: 50, avg_cost: 3.873701572418213
grad_norm: 0.4228760724198314, clipped: 0.4228760724198314
epoch: 29, train_batch_id: 100, avg_cost: 3.864759683609009
grad_norm: 0.34456452872080207, clipped: 0.34456452872080207
epoch: 29, train_batch_id: 150, avg_cost: 3.843411922454834
grad_norm: 0.5764277507453881, clipped: 0.5764277507453881
epoch: 29, train_batch_id: 200, avg_cost: 3.8527278900146484
grad_norm: 0.6083254731404727, clipped: 0.6083254731404727
epoch: 29, train_batch_id: 250, avg_cost: 3.8532843589782715
grad_norm: 0.7611222226931227, clipped: 0.7611222226931227
epoch: 29, train_batch_id: 300, avg_cost: 3.8549115657806396
grad_norm: 0.5493755608811408, clipped: 0.5493755608811408
epoch: 29, train_batch_id: 350, avg_cost: 3.840453624725342
grad_norm: 0.46199188703853244, clipped: 0.46199188703853244
epoch: 29, train_batch_id: 400, avg_cost: 3.8847451210021973
grad_norm: 0.8203146801712831, clipped: 0.8203146801712831
epoch: 29, train_batch_id: 450, avg_cost: 3.86435604095459
grad_norm: 0.4171490408137291, clipped: 0.4171490408137291
epoch: 29, train_batch_id: 500, avg_cost: 3.840348720550537
grad_norm: 0.38808439814227885, clipped: 0.38808439814227885
epoch: 29, train_batch_id: 550, avg_cost: 3.8335013389587402
grad_norm: 0.40520748387567024, clipped: 0.40520748387567024
epoch: 29, train_batch_id: 600, avg_cost: 3.8597702980041504
grad_norm: 0.4077742141017715, clipped: 0.4077742141017715
epoch: 29, train_batch_id: 650, avg_cost: 3.834261417388916
grad_norm: 0.3796539509110585, clipped: 0.3796539509110585
epoch: 29, train_batch_id: 700, avg_cost: 3.8510499000549316
grad_norm: 0.48574771227241437, clipped: 0.48574771227241437
epoch: 29, train_batch_id: 750, avg_cost: 3.867072582244873
grad_norm: 0.6623078215210291, clipped: 0.6623078215210291
epoch: 29, train_batch_id: 800, avg_cost: 3.8599040508270264
grad_norm: 0.48828272384017657, clipped: 0.48828272384017657
epoch: 29, train_batch_id: 850, avg_cost: 3.8419084548950195
grad_norm: 0.2783692555720567, clipped: 0.2783692555720567
epoch: 29, train_batch_id: 900, avg_cost: 3.8640923500061035
grad_norm: 0.31122520411831484, clipped: 0.31122520411831484
epoch: 29, train_batch_id: 950, avg_cost: 3.874270439147949
grad_norm: 0.7754894430202519, clipped: 0.7754894430202519
epoch: 29, train_batch_id: 1000, avg_cost: 3.8594348430633545
grad_norm: 0.4140685039288179, clipped: 0.4140685039288179
epoch: 29, train_batch_id: 1050, avg_cost: 3.8623595237731934
grad_norm: 0.4865008800633498, clipped: 0.4865008800633498
epoch: 29, train_batch_id: 1100, avg_cost: 3.8390188217163086
grad_norm: 0.496780410355907, clipped: 0.496780410355907
epoch: 29, train_batch_id: 1150, avg_cost: 3.8395333290100098
grad_norm: 0.3902608055399984, clipped: 0.3902608055399984
epoch: 29, train_batch_id: 1200, avg_cost: 3.876922130584717
grad_norm: 0.4191003929388765, clipped: 0.4191003929388765
epoch: 29, train_batch_id: 1250, avg_cost: 3.855679750442505
grad_norm: 2.191067600134102, clipped: 1.0
epoch: 29, train_batch_id: 1300, avg_cost: 3.8522281646728516
grad_norm: 0.5718877068802105, clipped: 0.5718877068802105
epoch: 29, train_batch_id: 1350, avg_cost: 3.867443561553955
grad_norm: 0.5546702857223004, clipped: 0.5546702857223004
epoch: 29, train_batch_id: 1400, avg_cost: 3.844733953475952
grad_norm: 0.47112547050119963, clipped: 0.47112547050119963
epoch: 29, train_batch_id: 1450, avg_cost: 3.856130361557007
grad_norm: 0.6877639230761439, clipped: 0.6877639230761439
epoch: 29, train_batch_id: 1500, avg_cost: 3.870138168334961
grad_norm: 0.617125126260659, clipped: 0.617125126260659
epoch: 29, train_batch_id: 1550, avg_cost: 3.8601458072662354
grad_norm: 0.5122565322673833, clipped: 0.5122565322673833
epoch: 29, train_batch_id: 1600, avg_cost: 3.8873255252838135
grad_norm: 0.28717197509648995, clipped: 0.28717197509648995
epoch: 29, train_batch_id: 1650, avg_cost: 3.8665595054626465
grad_norm: 0.22297167544116472, clipped: 0.22297167544116472
epoch: 29, train_batch_id: 1700, avg_cost: 3.8580498695373535
grad_norm: 0.5028641421242215, clipped: 0.5028641421242215
epoch: 29, train_batch_id: 1750, avg_cost: 3.8399200439453125
grad_norm: 0.5789199367335436, clipped: 0.5789199367335436
epoch: 29, train_batch_id: 1800, avg_cost: 3.843273162841797
grad_norm: 0.471019545787594, clipped: 0.471019545787594
epoch: 29, train_batch_id: 1850, avg_cost: 3.854785203933716
grad_norm: 0.6125111698965658, clipped: 0.6125111698965658
epoch: 29, train_batch_id: 1900, avg_cost: 3.8668053150177
grad_norm: 0.7238507767184066, clipped: 0.7238507767184066
epoch: 29, train_batch_id: 1950, avg_cost: 3.848820209503174
grad_norm: 0.44723383087102125, clipped: 0.44723383087102125
epoch: 29, train_batch_id: 2000, avg_cost: 3.8541135787963867
grad_norm: 0.2978267186868476, clipped: 0.2978267186868476
epoch: 29, train_batch_id: 2050, avg_cost: 3.842160224914551
grad_norm: 0.535261796708993, clipped: 0.535261796708993
epoch: 29, train_batch_id: 2100, avg_cost: 3.8676462173461914
grad_norm: 0.6076105786664809, clipped: 0.6076105786664809
epoch: 29, train_batch_id: 2150, avg_cost: 3.844773530960083
grad_norm: 0.5963783054249735, clipped: 0.5963783054249735
epoch: 29, train_batch_id: 2200, avg_cost: 3.8415231704711914
grad_norm: 0.49678853211737806, clipped: 0.49678853211737806
epoch: 29, train_batch_id: 2250, avg_cost: 3.864375591278076
grad_norm: 0.7973511484020706, clipped: 0.7973511484020706
epoch: 29, train_batch_id: 2300, avg_cost: 3.849292516708374
grad_norm: 0.4177824593444688, clipped: 0.4177824593444688
epoch: 29, train_batch_id: 2350, avg_cost: 3.845320701599121
grad_norm: 0.5068229051327773, clipped: 0.5068229051327773
epoch: 29, train_batch_id: 2400, avg_cost: 3.8587327003479004
grad_norm: 0.5749330999140655, clipped: 0.5749330999140655
epoch: 29, train_batch_id: 2450, avg_cost: 3.8586955070495605
grad_norm: 0.7080043500471087, clipped: 0.7080043500471087
Finished epoch 29, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8582210540771484 +- 0.003141942899674177
Evaluating candidate model on evaluation dataset
Epoch 29 candidate mean 3.851613759994507, baseline epoch 25 mean 3.8473398685455322, difference 0.004273891448974609
Start train epoch 30, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 30, train_batch_id: 0, avg_cost: 3.8327064514160156
grad_norm: 0.4762898507160172, clipped: 0.4762898507160172
epoch: 30, train_batch_id: 50, avg_cost: 3.8729989528656006
grad_norm: 0.890439711904401, clipped: 0.890439711904401
epoch: 30, train_batch_id: 100, avg_cost: 3.854727268218994
grad_norm: 0.3951165699265844, clipped: 0.3951165699265844
epoch: 30, train_batch_id: 150, avg_cost: 3.8636889457702637
grad_norm: 0.7406317190295849, clipped: 0.7406317190295849
epoch: 30, train_batch_id: 200, avg_cost: 3.8478879928588867
grad_norm: 0.41223457813968234, clipped: 0.41223457813968234
epoch: 30, train_batch_id: 250, avg_cost: 3.8428502082824707
grad_norm: 0.9006898763476064, clipped: 0.9006898763476064
epoch: 30, train_batch_id: 300, avg_cost: 3.856210708618164
grad_norm: 0.4144393371369586, clipped: 0.4144393371369586
epoch: 30, train_batch_id: 350, avg_cost: 3.871032238006592
grad_norm: 0.4763688604615636, clipped: 0.4763688604615636
epoch: 30, train_batch_id: 400, avg_cost: 3.8465189933776855
grad_norm: 1.4743898094605365, clipped: 1.0
epoch: 30, train_batch_id: 450, avg_cost: 3.8465373516082764
grad_norm: 0.4117003040148305, clipped: 0.4117003040148305
epoch: 30, train_batch_id: 500, avg_cost: 3.890866279602051
grad_norm: 0.3808121498230379, clipped: 0.3808121498230379
epoch: 30, train_batch_id: 550, avg_cost: 3.850729465484619
grad_norm: 0.5134903600078016, clipped: 0.5134903600078016
epoch: 30, train_batch_id: 600, avg_cost: 3.85624361038208
grad_norm: 0.544565261379049, clipped: 0.544565261379049
epoch: 30, train_batch_id: 650, avg_cost: 3.8595316410064697
grad_norm: 0.4374939325548485, clipped: 0.4374939325548485
epoch: 30, train_batch_id: 700, avg_cost: 3.861325740814209
grad_norm: 0.39029130503008436, clipped: 0.39029130503008436
epoch: 30, train_batch_id: 750, avg_cost: 3.860654830932617
grad_norm: 0.3968746204829443, clipped: 0.3968746204829443
epoch: 30, train_batch_id: 800, avg_cost: 3.8693594932556152
grad_norm: 0.6953583110529814, clipped: 0.6953583110529814
epoch: 30, train_batch_id: 850, avg_cost: 3.847926616668701
grad_norm: 0.4652509254066321, clipped: 0.4652509254066321
epoch: 30, train_batch_id: 900, avg_cost: 3.8656201362609863
grad_norm: 0.469502749620384, clipped: 0.469502749620384
epoch: 30, train_batch_id: 950, avg_cost: 3.853691816329956
grad_norm: 0.3874903344927951, clipped: 0.3874903344927951
epoch: 30, train_batch_id: 1000, avg_cost: 3.8374977111816406
grad_norm: 0.6009669265164658, clipped: 0.6009669265164658
epoch: 30, train_batch_id: 1050, avg_cost: 3.850032329559326
grad_norm: 0.4116003783393468, clipped: 0.4116003783393468
epoch: 30, train_batch_id: 1100, avg_cost: 3.8631699085235596
grad_norm: 0.32222508942757483, clipped: 0.32222508942757483
epoch: 30, train_batch_id: 1150, avg_cost: 3.855107307434082
grad_norm: 0.6974075102895035, clipped: 0.6974075102895035
epoch: 30, train_batch_id: 1200, avg_cost: 3.8300881385803223
grad_norm: 0.7234773929155652, clipped: 0.7234773929155652
epoch: 30, train_batch_id: 1250, avg_cost: 3.848446846008301
grad_norm: 0.48495225557462157, clipped: 0.48495225557462157
epoch: 30, train_batch_id: 1300, avg_cost: 3.847956657409668
grad_norm: 0.505804306094413, clipped: 0.505804306094413
epoch: 30, train_batch_id: 1350, avg_cost: 3.8364391326904297
grad_norm: 0.5255982043414016, clipped: 0.5255982043414016
epoch: 30, train_batch_id: 1400, avg_cost: 3.8715291023254395
grad_norm: 1.0193686998357048, clipped: 1.0
epoch: 30, train_batch_id: 1450, avg_cost: 3.8718619346618652
grad_norm: 1.482015778906473, clipped: 1.0
epoch: 30, train_batch_id: 1500, avg_cost: 3.8597137928009033
grad_norm: 0.4560592473913963, clipped: 0.4560592473913963
epoch: 30, train_batch_id: 1550, avg_cost: 3.8566131591796875
grad_norm: 0.5644111698360196, clipped: 0.5644111698360196
epoch: 30, train_batch_id: 1600, avg_cost: 3.867654800415039
grad_norm: 0.33934058437581915, clipped: 0.33934058437581915
epoch: 30, train_batch_id: 1650, avg_cost: 3.8669369220733643
grad_norm: 0.5082057499166844, clipped: 0.5082057499166844
epoch: 30, train_batch_id: 1700, avg_cost: 3.8522584438323975
grad_norm: 0.4807051513182442, clipped: 0.4807051513182442
epoch: 30, train_batch_id: 1750, avg_cost: 3.863233804702759
grad_norm: 0.48450531616799475, clipped: 0.48450531616799475
epoch: 30, train_batch_id: 1800, avg_cost: 3.865262508392334
grad_norm: 0.6025414678463595, clipped: 0.6025414678463595
epoch: 30, train_batch_id: 1850, avg_cost: 3.8376755714416504
grad_norm: 0.6213278084910294, clipped: 0.6213278084910294
epoch: 30, train_batch_id: 1900, avg_cost: 3.8337059020996094
grad_norm: 0.5550177552698087, clipped: 0.5550177552698087
epoch: 30, train_batch_id: 1950, avg_cost: 3.8584353923797607
grad_norm: 0.36217649018940284, clipped: 0.36217649018940284
epoch: 30, train_batch_id: 2000, avg_cost: 3.8593177795410156
grad_norm: 0.855221632136711, clipped: 0.855221632136711
epoch: 30, train_batch_id: 2050, avg_cost: 3.8459019660949707
grad_norm: 0.518593646663995, clipped: 0.518593646663995
epoch: 30, train_batch_id: 2100, avg_cost: 3.8547091484069824
grad_norm: 0.3978878281279886, clipped: 0.3978878281279886
epoch: 30, train_batch_id: 2150, avg_cost: 3.857978582382202
grad_norm: 0.44813545364271257, clipped: 0.44813545364271257
epoch: 30, train_batch_id: 2200, avg_cost: 3.856661796569824
grad_norm: 0.6196133014778831, clipped: 0.6196133014778831
epoch: 30, train_batch_id: 2250, avg_cost: 3.864759683609009
grad_norm: 0.48723298760281514, clipped: 0.48723298760281514
epoch: 30, train_batch_id: 2300, avg_cost: 3.865328788757324
grad_norm: 0.545482440622504, clipped: 0.545482440622504
epoch: 30, train_batch_id: 2350, avg_cost: 3.854485034942627
grad_norm: 0.41245658289736425, clipped: 0.41245658289736425
epoch: 30, train_batch_id: 2400, avg_cost: 3.8560876846313477
grad_norm: 0.5864533000754781, clipped: 0.5864533000754781
epoch: 30, train_batch_id: 2450, avg_cost: 3.864076852798462
grad_norm: 0.4496610182475794, clipped: 0.4496610182475794
Finished epoch 30, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.856013774871826 +- 0.0031350560020655394
Evaluating candidate model on evaluation dataset
Epoch 30 candidate mean 3.8487539291381836, baseline epoch 25 mean 3.8473398685455322, difference 0.0014140605926513672
Start train epoch 31, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 31, train_batch_id: 0, avg_cost: 3.841282844543457
grad_norm: 0.6218777713777147, clipped: 0.6218777713777147
epoch: 31, train_batch_id: 50, avg_cost: 3.857448101043701
grad_norm: 0.32173382160156166, clipped: 0.32173382160156166
epoch: 31, train_batch_id: 100, avg_cost: 3.8547606468200684
grad_norm: 0.3453520138622516, clipped: 0.3453520138622516
epoch: 31, train_batch_id: 150, avg_cost: 3.8636415004730225
grad_norm: 0.46908715729664957, clipped: 0.46908715729664957
epoch: 31, train_batch_id: 200, avg_cost: 3.8339614868164062
grad_norm: 0.43707334203603476, clipped: 0.43707334203603476
epoch: 31, train_batch_id: 250, avg_cost: 3.85076642036438
grad_norm: 0.5342381373577728, clipped: 0.5342381373577728
epoch: 31, train_batch_id: 300, avg_cost: 3.8303616046905518
grad_norm: 0.38536469737503454, clipped: 0.38536469737503454
epoch: 31, train_batch_id: 350, avg_cost: 3.8611631393432617
grad_norm: 0.6484171186246345, clipped: 0.6484171186246345
epoch: 31, train_batch_id: 400, avg_cost: 3.8552732467651367
grad_norm: 0.6255790356456399, clipped: 0.6255790356456399
epoch: 31, train_batch_id: 450, avg_cost: 3.845277786254883
grad_norm: 0.41380994159392304, clipped: 0.41380994159392304
epoch: 31, train_batch_id: 500, avg_cost: 3.844512939453125
grad_norm: 0.6369083777525699, clipped: 0.6369083777525699
epoch: 31, train_batch_id: 550, avg_cost: 3.8396544456481934
grad_norm: 0.6033461113054452, clipped: 0.6033461113054452
epoch: 31, train_batch_id: 600, avg_cost: 3.8568966388702393
grad_norm: 0.43697264581683515, clipped: 0.43697264581683515
epoch: 31, train_batch_id: 650, avg_cost: 3.8739047050476074
grad_norm: 0.42049028123863813, clipped: 0.42049028123863813
epoch: 31, train_batch_id: 700, avg_cost: 3.8552093505859375
grad_norm: 0.5391099605124163, clipped: 0.5391099605124163
epoch: 31, train_batch_id: 750, avg_cost: 3.8725271224975586
grad_norm: 0.4835706971238044, clipped: 0.4835706971238044
epoch: 31, train_batch_id: 800, avg_cost: 3.853607654571533
grad_norm: 0.5988355917864252, clipped: 0.5988355917864252
epoch: 31, train_batch_id: 850, avg_cost: 3.8671703338623047
grad_norm: 0.496126561272483, clipped: 0.496126561272483
epoch: 31, train_batch_id: 900, avg_cost: 3.875365734100342
grad_norm: 0.8815845441177361, clipped: 0.8815845441177361
epoch: 31, train_batch_id: 950, avg_cost: 3.8503971099853516
grad_norm: 0.5863710442515206, clipped: 0.5863710442515206
epoch: 31, train_batch_id: 1000, avg_cost: 3.8481831550598145
grad_norm: 0.36500494221495156, clipped: 0.36500494221495156
epoch: 31, train_batch_id: 1050, avg_cost: 3.8533854484558105
grad_norm: 0.33430739974537793, clipped: 0.33430739974537793
epoch: 31, train_batch_id: 1100, avg_cost: 3.8589303493499756
grad_norm: 0.48608315976060534, clipped: 0.48608315976060534
epoch: 31, train_batch_id: 1150, avg_cost: 3.8426079750061035
grad_norm: 0.4717497476397591, clipped: 0.4717497476397591
epoch: 31, train_batch_id: 1200, avg_cost: 3.867884635925293
grad_norm: 0.7824972568180356, clipped: 0.7824972568180356
epoch: 31, train_batch_id: 1250, avg_cost: 3.871056079864502
grad_norm: 0.3902709370947486, clipped: 0.3902709370947486
epoch: 31, train_batch_id: 1300, avg_cost: 3.860069751739502
grad_norm: 0.5148126000900526, clipped: 0.5148126000900526
epoch: 31, train_batch_id: 1350, avg_cost: 3.834808349609375
grad_norm: 0.5227676650208133, clipped: 0.5227676650208133
epoch: 31, train_batch_id: 1400, avg_cost: 3.8603930473327637
grad_norm: 0.5436430936104701, clipped: 0.5436430936104701
epoch: 31, train_batch_id: 1450, avg_cost: 3.8366127014160156
grad_norm: 0.4756007127599569, clipped: 0.4756007127599569
epoch: 31, train_batch_id: 1500, avg_cost: 3.8549022674560547
grad_norm: 0.42835265696329916, clipped: 0.42835265696329916
epoch: 31, train_batch_id: 1550, avg_cost: 3.857252597808838
grad_norm: 0.4269659440600421, clipped: 0.4269659440600421
epoch: 31, train_batch_id: 1600, avg_cost: 3.8367714881896973
grad_norm: 0.7734720065918921, clipped: 0.7734720065918921
epoch: 31, train_batch_id: 1650, avg_cost: 3.865544319152832
grad_norm: 0.8032151928099411, clipped: 0.8032151928099411
epoch: 31, train_batch_id: 1700, avg_cost: 3.8263278007507324
grad_norm: 0.46687569305034105, clipped: 0.46687569305034105
epoch: 31, train_batch_id: 1750, avg_cost: 3.8487789630889893
grad_norm: 0.41630133526059443, clipped: 0.41630133526059443
epoch: 31, train_batch_id: 1800, avg_cost: 3.835052251815796
grad_norm: 0.4232153396735266, clipped: 0.4232153396735266
epoch: 31, train_batch_id: 1850, avg_cost: 3.8711111545562744
grad_norm: 0.40602921515795065, clipped: 0.40602921515795065
epoch: 31, train_batch_id: 1900, avg_cost: 3.853480815887451
grad_norm: 0.41603595166280305, clipped: 0.41603595166280305
epoch: 31, train_batch_id: 1950, avg_cost: 3.8590922355651855
grad_norm: 0.46947214726390596, clipped: 0.46947214726390596
epoch: 31, train_batch_id: 2000, avg_cost: 3.831406354904175
grad_norm: 0.5093333745574212, clipped: 0.5093333745574212
epoch: 31, train_batch_id: 2050, avg_cost: 3.846615791320801
grad_norm: 0.3266832764985194, clipped: 0.3266832764985194
epoch: 31, train_batch_id: 2100, avg_cost: 3.844402313232422
grad_norm: 0.46544737659870267, clipped: 0.46544737659870267
epoch: 31, train_batch_id: 2150, avg_cost: 3.8618850708007812
grad_norm: 0.5689483852060119, clipped: 0.5689483852060119
epoch: 31, train_batch_id: 2200, avg_cost: 3.8492090702056885
grad_norm: 0.4986291334764775, clipped: 0.4986291334764775
epoch: 31, train_batch_id: 2250, avg_cost: 3.845693588256836
grad_norm: 0.4730659607962897, clipped: 0.4730659607962897
epoch: 31, train_batch_id: 2300, avg_cost: 3.8456263542175293
grad_norm: 0.5009209365680846, clipped: 0.5009209365680846
epoch: 31, train_batch_id: 2350, avg_cost: 3.8363583087921143
grad_norm: 0.5058277017191086, clipped: 0.5058277017191086
epoch: 31, train_batch_id: 2400, avg_cost: 3.8649001121520996
grad_norm: 0.5468145850368775, clipped: 0.5468145850368775
epoch: 31, train_batch_id: 2450, avg_cost: 3.8546371459960938
grad_norm: 0.42514851019258515, clipped: 0.42514851019258515
Finished epoch 31, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.853221893310547 +- 0.0031238747760653496
Evaluating candidate model on evaluation dataset
Epoch 31 candidate mean 3.8456597328186035, baseline epoch 25 mean 3.8473398685455322, difference -0.001680135726928711
p-value: 4.9946782397273075e-06
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 32, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 32, train_batch_id: 0, avg_cost: 3.847233772277832
grad_norm: 0.4774975693118261, clipped: 0.4774975693118261
epoch: 32, train_batch_id: 50, avg_cost: 3.8733973503112793
grad_norm: 0.5131063649100608, clipped: 0.5131063649100608
epoch: 32, train_batch_id: 100, avg_cost: 3.8435816764831543
grad_norm: 0.4202553478886649, clipped: 0.4202553478886649
epoch: 32, train_batch_id: 150, avg_cost: 3.8687546253204346
grad_norm: 0.42006913686526887, clipped: 0.42006913686526887
epoch: 32, train_batch_id: 200, avg_cost: 3.864933967590332
grad_norm: 0.4790662332609937, clipped: 0.4790662332609937
epoch: 32, train_batch_id: 250, avg_cost: 3.8458809852600098
grad_norm: 0.6374005054357064, clipped: 0.6374005054357064
epoch: 32, train_batch_id: 300, avg_cost: 3.8482422828674316
grad_norm: 0.37697470520984455, clipped: 0.37697470520984455
epoch: 32, train_batch_id: 350, avg_cost: 3.8560996055603027
grad_norm: 0.37665154587112687, clipped: 0.37665154587112687
epoch: 32, train_batch_id: 400, avg_cost: 3.851959228515625
grad_norm: 0.3741485438127891, clipped: 0.3741485438127891
epoch: 32, train_batch_id: 450, avg_cost: 3.8659231662750244
grad_norm: 0.3694120730607851, clipped: 0.3694120730607851
epoch: 32, train_batch_id: 500, avg_cost: 3.8393077850341797
grad_norm: 0.4855436658191713, clipped: 0.4855436658191713
epoch: 32, train_batch_id: 550, avg_cost: 3.878204345703125
grad_norm: 0.76083390852744, clipped: 0.76083390852744
epoch: 32, train_batch_id: 600, avg_cost: 3.8753836154937744
grad_norm: 0.49691107256721345, clipped: 0.49691107256721345
epoch: 32, train_batch_id: 650, avg_cost: 3.8619964122772217
grad_norm: 0.5962984837473063, clipped: 0.5962984837473063
epoch: 32, train_batch_id: 700, avg_cost: 3.852052688598633
grad_norm: 0.41604129360514247, clipped: 0.41604129360514247
epoch: 32, train_batch_id: 750, avg_cost: 3.859487533569336
grad_norm: 0.557699887552499, clipped: 0.557699887552499
epoch: 32, train_batch_id: 800, avg_cost: 3.868842124938965
grad_norm: 0.5365576317524245, clipped: 0.5365576317524245
epoch: 32, train_batch_id: 850, avg_cost: 3.8417019844055176
grad_norm: 0.6013573084804833, clipped: 0.6013573084804833
epoch: 32, train_batch_id: 900, avg_cost: 3.8373911380767822
grad_norm: 0.47077289389897325, clipped: 0.47077289389897325
epoch: 32, train_batch_id: 950, avg_cost: 3.8514389991760254
grad_norm: 0.3545566393383424, clipped: 0.3545566393383424
epoch: 32, train_batch_id: 1000, avg_cost: 3.853767156600952
grad_norm: 0.6923930130652103, clipped: 0.6923930130652103
epoch: 32, train_batch_id: 1050, avg_cost: 3.8465304374694824
grad_norm: 0.4180424324050696, clipped: 0.4180424324050696
epoch: 32, train_batch_id: 1100, avg_cost: 3.848750114440918
grad_norm: 0.4005120454297932, clipped: 0.4005120454297932
epoch: 32, train_batch_id: 1150, avg_cost: 3.8478503227233887
grad_norm: 0.5429059178682188, clipped: 0.5429059178682188
epoch: 32, train_batch_id: 1200, avg_cost: 3.858503818511963
grad_norm: 0.4138067748044847, clipped: 0.4138067748044847
epoch: 32, train_batch_id: 1250, avg_cost: 3.8562369346618652
grad_norm: 2.151320725161133, clipped: 1.0
epoch: 32, train_batch_id: 1300, avg_cost: 3.864091396331787
grad_norm: 0.4886286003595651, clipped: 0.4886286003595651
epoch: 32, train_batch_id: 1350, avg_cost: 3.8581466674804688
grad_norm: 0.4220667360018706, clipped: 0.4220667360018706
epoch: 32, train_batch_id: 1400, avg_cost: 3.862177848815918
grad_norm: 0.4017826266237675, clipped: 0.4017826266237675
epoch: 32, train_batch_id: 1450, avg_cost: 3.846681594848633
grad_norm: 0.3565973175423805, clipped: 0.3565973175423805
epoch: 32, train_batch_id: 1500, avg_cost: 3.85314679145813
grad_norm: 0.513150121123365, clipped: 0.513150121123365
epoch: 32, train_batch_id: 1550, avg_cost: 3.8501224517822266
grad_norm: 0.6009234093065619, clipped: 0.6009234093065619
epoch: 32, train_batch_id: 1600, avg_cost: 3.845149040222168
grad_norm: 0.3911444703303153, clipped: 0.3911444703303153
epoch: 32, train_batch_id: 1650, avg_cost: 3.8346107006073
grad_norm: 0.8149513306000572, clipped: 0.8149513306000572
epoch: 32, train_batch_id: 1700, avg_cost: 3.878805637359619
grad_norm: 0.4455776020804551, clipped: 0.4455776020804551
epoch: 32, train_batch_id: 1750, avg_cost: 3.840933322906494
grad_norm: 0.34060682945783655, clipped: 0.34060682945783655
epoch: 32, train_batch_id: 1800, avg_cost: 3.861812114715576
grad_norm: 0.400204382824685, clipped: 0.400204382824685
epoch: 32, train_batch_id: 1850, avg_cost: 3.8377981185913086
grad_norm: 0.4458359258585668, clipped: 0.4458359258585668
epoch: 32, train_batch_id: 1900, avg_cost: 3.886549472808838
grad_norm: 0.6497694733367751, clipped: 0.6497694733367751
epoch: 32, train_batch_id: 1950, avg_cost: 3.840519905090332
grad_norm: 0.4499353981641557, clipped: 0.4499353981641557
epoch: 32, train_batch_id: 2000, avg_cost: 3.8517744541168213
grad_norm: 0.6688216958167064, clipped: 0.6688216958167064
epoch: 32, train_batch_id: 2050, avg_cost: 3.8631882667541504
grad_norm: 0.4035562741941973, clipped: 0.4035562741941973
epoch: 32, train_batch_id: 2100, avg_cost: 3.8312864303588867
grad_norm: 0.4124767835064548, clipped: 0.4124767835064548
epoch: 32, train_batch_id: 2150, avg_cost: 3.860935688018799
grad_norm: 0.3932007110183051, clipped: 0.3932007110183051
epoch: 32, train_batch_id: 2200, avg_cost: 3.8623757362365723
grad_norm: 0.9735773685226732, clipped: 0.9735773685226732
epoch: 32, train_batch_id: 2250, avg_cost: 3.8358187675476074
grad_norm: 0.642039067070652, clipped: 0.642039067070652
epoch: 32, train_batch_id: 2300, avg_cost: 3.832988977432251
grad_norm: 0.5800426002595752, clipped: 0.5800426002595752
epoch: 32, train_batch_id: 2350, avg_cost: 3.860419988632202
grad_norm: 0.41930009641084987, clipped: 0.41930009641084987
epoch: 32, train_batch_id: 2400, avg_cost: 3.8264334201812744
grad_norm: 0.632449461823752, clipped: 0.632449461823752
epoch: 32, train_batch_id: 2450, avg_cost: 3.85428786277771
grad_norm: 0.5848329345369031, clipped: 0.5848329345369031
Finished epoch 32, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8546690940856934 +- 0.003135264152660966
Evaluating candidate model on evaluation dataset
Epoch 32 candidate mean 3.8494045734405518, baseline epoch 31 mean 3.8474273681640625, difference 0.001977205276489258
Start train epoch 33, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 33, train_batch_id: 0, avg_cost: 3.839136838912964
grad_norm: 0.6731040063306691, clipped: 0.6731040063306691
epoch: 33, train_batch_id: 50, avg_cost: 3.850090980529785
grad_norm: 0.4664073480724216, clipped: 0.4664073480724216
epoch: 33, train_batch_id: 100, avg_cost: 3.839085578918457
grad_norm: 0.41932234543991576, clipped: 0.41932234543991576
epoch: 33, train_batch_id: 150, avg_cost: 3.8462700843811035
grad_norm: 1.0520493395993962, clipped: 1.0
epoch: 33, train_batch_id: 200, avg_cost: 3.861829996109009
grad_norm: 1.6619383784526744, clipped: 1.0
epoch: 33, train_batch_id: 250, avg_cost: 3.8506741523742676
grad_norm: 0.5167535663105235, clipped: 0.5167535663105235
epoch: 33, train_batch_id: 300, avg_cost: 3.8493967056274414
grad_norm: 0.42687696993317964, clipped: 0.42687696993317964
epoch: 33, train_batch_id: 350, avg_cost: 3.857919454574585
grad_norm: 0.5844206331901659, clipped: 0.5844206331901659
epoch: 33, train_batch_id: 400, avg_cost: 3.8470027446746826
grad_norm: 0.48148475452822814, clipped: 0.48148475452822814
epoch: 33, train_batch_id: 450, avg_cost: 3.8599114418029785
grad_norm: 0.7661221438600803, clipped: 0.7661221438600803
epoch: 33, train_batch_id: 500, avg_cost: 3.8494062423706055
grad_norm: 0.4996244534769406, clipped: 0.4996244534769406
epoch: 33, train_batch_id: 550, avg_cost: 3.8570945262908936
grad_norm: 0.49281218180587044, clipped: 0.49281218180587044
epoch: 33, train_batch_id: 600, avg_cost: 3.8479602336883545
grad_norm: 0.43893125746699285, clipped: 0.43893125746699285
epoch: 33, train_batch_id: 650, avg_cost: 3.862400531768799
grad_norm: 0.4749790557255787, clipped: 0.4749790557255787
epoch: 33, train_batch_id: 700, avg_cost: 3.875584602355957
grad_norm: 0.9495726209542333, clipped: 0.9495726209542333
epoch: 33, train_batch_id: 750, avg_cost: 3.861123561859131
grad_norm: 0.6281608742883673, clipped: 0.6281608742883673
epoch: 33, train_batch_id: 800, avg_cost: 3.8522472381591797
grad_norm: 0.418598663250512, clipped: 0.418598663250512
epoch: 33, train_batch_id: 850, avg_cost: 3.854475259780884
grad_norm: 0.3845366773874094, clipped: 0.3845366773874094
epoch: 33, train_batch_id: 900, avg_cost: 3.8324875831604004
grad_norm: 0.5716973826670214, clipped: 0.5716973826670214
epoch: 33, train_batch_id: 950, avg_cost: 3.857806444168091
grad_norm: 0.420235159837093, clipped: 0.420235159837093
epoch: 33, train_batch_id: 1000, avg_cost: 3.8521170616149902
grad_norm: 0.475321108452341, clipped: 0.475321108452341
epoch: 33, train_batch_id: 1050, avg_cost: 3.85066819190979
grad_norm: 0.6565651546801239, clipped: 0.6565651546801239
epoch: 33, train_batch_id: 1100, avg_cost: 3.8242876529693604
grad_norm: 0.5425426232854654, clipped: 0.5425426232854654
epoch: 33, train_batch_id: 1150, avg_cost: 3.835921287536621
grad_norm: 0.38880890423196085, clipped: 0.38880890423196085
epoch: 33, train_batch_id: 1200, avg_cost: 3.8496837615966797
grad_norm: 0.4859484871862031, clipped: 0.4859484871862031
epoch: 33, train_batch_id: 1250, avg_cost: 3.8628392219543457
grad_norm: 0.38780510232093784, clipped: 0.38780510232093784
epoch: 33, train_batch_id: 1300, avg_cost: 3.85578989982605
grad_norm: 0.4270615151195819, clipped: 0.4270615151195819
epoch: 33, train_batch_id: 1350, avg_cost: 3.8455142974853516
grad_norm: 0.3195202205176141, clipped: 0.3195202205176141
epoch: 33, train_batch_id: 1400, avg_cost: 3.8352866172790527
grad_norm: 0.38971899486743056, clipped: 0.38971899486743056
epoch: 33, train_batch_id: 1450, avg_cost: 3.8679943084716797
grad_norm: 0.44204616124123275, clipped: 0.44204616124123275
epoch: 33, train_batch_id: 1500, avg_cost: 3.853738307952881
grad_norm: 0.5825300752093622, clipped: 0.5825300752093622
epoch: 33, train_batch_id: 1550, avg_cost: 3.8620800971984863
grad_norm: 1.2396496979294414, clipped: 1.0
epoch: 33, train_batch_id: 1600, avg_cost: 3.85329008102417
grad_norm: 0.7156224074847571, clipped: 0.7156224074847571
epoch: 33, train_batch_id: 1650, avg_cost: 3.867157220840454
grad_norm: 0.432985604856177, clipped: 0.432985604856177
epoch: 33, train_batch_id: 1700, avg_cost: 3.834916591644287
grad_norm: 0.39307429679238254, clipped: 0.39307429679238254
epoch: 33, train_batch_id: 1750, avg_cost: 3.845897674560547
grad_norm: 0.939992300305921, clipped: 0.939992300305921
epoch: 33, train_batch_id: 1800, avg_cost: 3.872079372406006
grad_norm: 1.2723911685928462, clipped: 1.0
epoch: 33, train_batch_id: 1850, avg_cost: 3.8296384811401367
grad_norm: 0.5917216360540742, clipped: 0.5917216360540742
epoch: 33, train_batch_id: 1900, avg_cost: 3.8603627681732178
grad_norm: 0.7514196279371278, clipped: 0.7514196279371278
epoch: 33, train_batch_id: 1950, avg_cost: 3.861652135848999
grad_norm: 0.4985800675167275, clipped: 0.4985800675167275
epoch: 33, train_batch_id: 2000, avg_cost: 3.852684736251831
grad_norm: 0.4493174264746015, clipped: 0.4493174264746015
epoch: 33, train_batch_id: 2050, avg_cost: 3.898181438446045
grad_norm: 0.41726269687350076, clipped: 0.41726269687350076
epoch: 33, train_batch_id: 2100, avg_cost: 3.8283166885375977
grad_norm: 0.40225122594902596, clipped: 0.40225122594902596
epoch: 33, train_batch_id: 2150, avg_cost: 3.8553450107574463
grad_norm: 0.5477443461400087, clipped: 0.5477443461400087
epoch: 33, train_batch_id: 2200, avg_cost: 3.844656229019165
grad_norm: 0.484650302327427, clipped: 0.484650302327427
epoch: 33, train_batch_id: 2250, avg_cost: 3.851832866668701
grad_norm: 0.4969605176930541, clipped: 0.4969605176930541
epoch: 33, train_batch_id: 2300, avg_cost: 3.867279529571533
grad_norm: 0.4739583190641981, clipped: 0.4739583190641981
epoch: 33, train_batch_id: 2350, avg_cost: 3.8564038276672363
grad_norm: 0.5235168103868059, clipped: 0.5235168103868059
epoch: 33, train_batch_id: 2400, avg_cost: 3.880680561065674
grad_norm: 0.43822485563725916, clipped: 0.43822485563725916
epoch: 33, train_batch_id: 2450, avg_cost: 3.8369522094726562
grad_norm: 0.3893502805616454, clipped: 0.3893502805616454
Finished epoch 33, took 00:05:35 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8533499240875244 +- 0.0031292641069740057
Evaluating candidate model on evaluation dataset
Epoch 33 candidate mean 3.848896026611328, baseline epoch 31 mean 3.8474273681640625, difference 0.001468658447265625
Start train epoch 34, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 34, train_batch_id: 0, avg_cost: 3.846485137939453
grad_norm: 0.5121632685696278, clipped: 0.5121632685696278
epoch: 34, train_batch_id: 50, avg_cost: 3.86673641204834
grad_norm: 0.39105831742552366, clipped: 0.39105831742552366
epoch: 34, train_batch_id: 100, avg_cost: 3.831512451171875
grad_norm: 0.35868379707469494, clipped: 0.35868379707469494
epoch: 34, train_batch_id: 150, avg_cost: 3.8229494094848633
grad_norm: 0.4836134215372273, clipped: 0.4836134215372273
epoch: 34, train_batch_id: 200, avg_cost: 3.8372950553894043
grad_norm: 0.3875893687688735, clipped: 0.3875893687688735
epoch: 34, train_batch_id: 250, avg_cost: 3.8500425815582275
grad_norm: 0.4175501403172158, clipped: 0.4175501403172158
epoch: 34, train_batch_id: 300, avg_cost: 3.8587779998779297
grad_norm: 0.37775944429667935, clipped: 0.37775944429667935
epoch: 34, train_batch_id: 350, avg_cost: 3.840437889099121
grad_norm: 0.6456744106159987, clipped: 0.6456744106159987
epoch: 34, train_batch_id: 400, avg_cost: 3.8400871753692627
grad_norm: 0.42505656698652916, clipped: 0.42505656698652916
epoch: 34, train_batch_id: 450, avg_cost: 3.8455252647399902
grad_norm: 0.4170347440562578, clipped: 0.4170347440562578
epoch: 34, train_batch_id: 500, avg_cost: 3.881664514541626
grad_norm: 0.4710918598698274, clipped: 0.4710918598698274
epoch: 34, train_batch_id: 550, avg_cost: 3.8556180000305176
grad_norm: 0.3857408270043252, clipped: 0.3857408270043252
epoch: 34, train_batch_id: 600, avg_cost: 3.850194215774536
grad_norm: 0.32337323272176466, clipped: 0.32337323272176466
epoch: 34, train_batch_id: 650, avg_cost: 3.839357852935791
grad_norm: 0.45920486271989547, clipped: 0.45920486271989547
epoch: 34, train_batch_id: 700, avg_cost: 3.853567123413086
grad_norm: 0.35401229928016575, clipped: 0.35401229928016575
epoch: 34, train_batch_id: 750, avg_cost: 3.8530240058898926
grad_norm: 0.5096507455135015, clipped: 0.5096507455135015
epoch: 34, train_batch_id: 800, avg_cost: 3.861351251602173
grad_norm: 0.6057279910169001, clipped: 0.6057279910169001
epoch: 34, train_batch_id: 850, avg_cost: 3.8307361602783203
grad_norm: 0.4463066150275195, clipped: 0.4463066150275195
epoch: 34, train_batch_id: 900, avg_cost: 3.845385789871216
grad_norm: 0.2891405100198823, clipped: 0.2891405100198823
epoch: 34, train_batch_id: 950, avg_cost: 3.8658289909362793
grad_norm: 0.4186912473143158, clipped: 0.4186912473143158
epoch: 34, train_batch_id: 1000, avg_cost: 3.8615283966064453
grad_norm: 0.4084167537250413, clipped: 0.4084167537250413
epoch: 34, train_batch_id: 1050, avg_cost: 3.860034704208374
grad_norm: 0.32242227976350274, clipped: 0.32242227976350274
epoch: 34, train_batch_id: 1100, avg_cost: 3.8426342010498047
grad_norm: 0.3529653544053309, clipped: 0.3529653544053309
epoch: 34, train_batch_id: 1150, avg_cost: 3.8510358333587646
grad_norm: 1.0209318172536797, clipped: 1.0
epoch: 34, train_batch_id: 1200, avg_cost: 3.84456729888916
grad_norm: 0.41425638430984685, clipped: 0.41425638430984685
epoch: 34, train_batch_id: 1250, avg_cost: 3.847825527191162
grad_norm: 0.6035431123469267, clipped: 0.6035431123469267
epoch: 34, train_batch_id: 1300, avg_cost: 3.8459291458129883
grad_norm: 0.5391687995433221, clipped: 0.5391687995433221
epoch: 34, train_batch_id: 1350, avg_cost: 3.855787754058838
grad_norm: 0.5803132044597289, clipped: 0.5803132044597289
epoch: 34, train_batch_id: 1400, avg_cost: 3.871145725250244
grad_norm: 0.4025919780059902, clipped: 0.4025919780059902
epoch: 34, train_batch_id: 1450, avg_cost: 3.8528802394866943
grad_norm: 0.38385319442575516, clipped: 0.38385319442575516
epoch: 34, train_batch_id: 1500, avg_cost: 3.818833827972412
grad_norm: 0.4030671894368835, clipped: 0.4030671894368835
epoch: 34, train_batch_id: 1550, avg_cost: 3.840488910675049
grad_norm: 0.6499734635671938, clipped: 0.6499734635671938
epoch: 34, train_batch_id: 1600, avg_cost: 3.8631763458251953
grad_norm: 0.3884982461805576, clipped: 0.3884982461805576
epoch: 34, train_batch_id: 1650, avg_cost: 3.8593082427978516
grad_norm: 0.40900691049690413, clipped: 0.40900691049690413
epoch: 34, train_batch_id: 1700, avg_cost: 3.8478169441223145
grad_norm: 0.5450141277003493, clipped: 0.5450141277003493
epoch: 34, train_batch_id: 1750, avg_cost: 3.8474628925323486
grad_norm: 0.4222134679168865, clipped: 0.4222134679168865
epoch: 34, train_batch_id: 1800, avg_cost: 3.86315655708313
grad_norm: 0.4453463558495013, clipped: 0.4453463558495013
epoch: 34, train_batch_id: 1850, avg_cost: 3.861745834350586
grad_norm: 0.48511708330285164, clipped: 0.48511708330285164
epoch: 34, train_batch_id: 1900, avg_cost: 3.8719851970672607
grad_norm: 0.5634819440743662, clipped: 0.5634819440743662
epoch: 34, train_batch_id: 1950, avg_cost: 3.867063045501709
grad_norm: 0.7664790727496821, clipped: 0.7664790727496821
epoch: 34, train_batch_id: 2000, avg_cost: 3.8308887481689453
grad_norm: 0.40432071803647984, clipped: 0.40432071803647984
epoch: 34, train_batch_id: 2050, avg_cost: 3.847784996032715
grad_norm: 0.6033468094200793, clipped: 0.6033468094200793
epoch: 34, train_batch_id: 2100, avg_cost: 3.845090866088867
grad_norm: 0.46517779215474586, clipped: 0.46517779215474586
epoch: 34, train_batch_id: 2150, avg_cost: 3.8521971702575684
grad_norm: 0.452629876892149, clipped: 0.452629876892149
epoch: 34, train_batch_id: 2200, avg_cost: 3.8524060249328613
grad_norm: 0.41205559427560196, clipped: 0.41205559427560196
epoch: 34, train_batch_id: 2250, avg_cost: 3.861959934234619
grad_norm: 0.5904531928275667, clipped: 0.5904531928275667
epoch: 34, train_batch_id: 2300, avg_cost: 3.8472471237182617
grad_norm: 0.5509062432665467, clipped: 0.5509062432665467
epoch: 34, train_batch_id: 2350, avg_cost: 3.858114719390869
grad_norm: 0.4237887778424972, clipped: 0.4237887778424972
epoch: 34, train_batch_id: 2400, avg_cost: 3.8687024116516113
grad_norm: 0.32008879547959906, clipped: 0.32008879547959906
epoch: 34, train_batch_id: 2450, avg_cost: 3.8371763229370117
grad_norm: 0.3098467805596696, clipped: 0.3098467805596696
Finished epoch 34, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.854109048843384 +- 0.0031317221000790596
Evaluating candidate model on evaluation dataset
Epoch 34 candidate mean 3.848306179046631, baseline epoch 31 mean 3.8474273681640625, difference 0.0008788108825683594
Start train epoch 35, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 35, train_batch_id: 0, avg_cost: 3.841851234436035
grad_norm: 0.40956417195646944, clipped: 0.40956417195646944
epoch: 35, train_batch_id: 50, avg_cost: 3.847470760345459
grad_norm: 0.31247679948328827, clipped: 0.31247679948328827
epoch: 35, train_batch_id: 100, avg_cost: 3.850517749786377
grad_norm: 0.49909174838919657, clipped: 0.49909174838919657
epoch: 35, train_batch_id: 150, avg_cost: 3.863157033920288
grad_norm: 0.4069927883250011, clipped: 0.4069927883250011
epoch: 35, train_batch_id: 200, avg_cost: 3.8326802253723145
grad_norm: 0.32091188483995714, clipped: 0.32091188483995714
epoch: 35, train_batch_id: 250, avg_cost: 3.839545726776123
grad_norm: 0.3472764522788932, clipped: 0.3472764522788932
epoch: 35, train_batch_id: 300, avg_cost: 3.8554089069366455
grad_norm: 0.38043053790861237, clipped: 0.38043053790861237
epoch: 35, train_batch_id: 350, avg_cost: 3.853865623474121
grad_norm: 0.46511629222360984, clipped: 0.46511629222360984
epoch: 35, train_batch_id: 400, avg_cost: 3.8694913387298584
grad_norm: 0.5743769080675907, clipped: 0.5743769080675907
epoch: 35, train_batch_id: 450, avg_cost: 3.8687477111816406
grad_norm: 0.8550635175098172, clipped: 0.8550635175098172
epoch: 35, train_batch_id: 500, avg_cost: 3.8522963523864746
grad_norm: 0.49784382311502073, clipped: 0.49784382311502073
epoch: 35, train_batch_id: 550, avg_cost: 3.8642702102661133
grad_norm: 0.454938656365653, clipped: 0.454938656365653
epoch: 35, train_batch_id: 600, avg_cost: 3.833467483520508
grad_norm: 0.440742919190762, clipped: 0.440742919190762
epoch: 35, train_batch_id: 650, avg_cost: 3.8481507301330566
grad_norm: 0.5509440579314412, clipped: 0.5509440579314412
epoch: 35, train_batch_id: 700, avg_cost: 3.837743043899536
grad_norm: 0.3466716541501875, clipped: 0.3466716541501875
epoch: 35, train_batch_id: 750, avg_cost: 3.82710337638855
grad_norm: 0.49388579192272236, clipped: 0.49388579192272236
epoch: 35, train_batch_id: 800, avg_cost: 3.8620901107788086
grad_norm: 0.4285855217223178, clipped: 0.4285855217223178
epoch: 35, train_batch_id: 850, avg_cost: 3.8584766387939453
grad_norm: 0.5607403988776839, clipped: 0.5607403988776839
epoch: 35, train_batch_id: 900, avg_cost: 3.8425345420837402
grad_norm: 0.47512268257864493, clipped: 0.47512268257864493
epoch: 35, train_batch_id: 950, avg_cost: 3.845621109008789
grad_norm: 0.313763458860491, clipped: 0.313763458860491
epoch: 35, train_batch_id: 1000, avg_cost: 3.8669381141662598
grad_norm: 0.31928006633043476, clipped: 0.31928006633043476
epoch: 35, train_batch_id: 1050, avg_cost: 3.873833656311035
grad_norm: 0.6641837090018321, clipped: 0.6641837090018321
epoch: 35, train_batch_id: 1100, avg_cost: 3.8417294025421143
grad_norm: 0.4269780122402342, clipped: 0.4269780122402342
epoch: 35, train_batch_id: 1150, avg_cost: 3.8556203842163086
grad_norm: 0.8313768025579029, clipped: 0.8313768025579029
epoch: 35, train_batch_id: 1200, avg_cost: 3.852027416229248
grad_norm: 0.41785391819743306, clipped: 0.41785391819743306
epoch: 35, train_batch_id: 1250, avg_cost: 3.841993808746338
grad_norm: 0.40032499026734103, clipped: 0.40032499026734103
epoch: 35, train_batch_id: 1300, avg_cost: 3.845900297164917
grad_norm: 0.46358005414149916, clipped: 0.46358005414149916
epoch: 35, train_batch_id: 1350, avg_cost: 3.8461079597473145
grad_norm: 0.7245480660828411, clipped: 0.7245480660828411
epoch: 35, train_batch_id: 1400, avg_cost: 3.842588424682617
grad_norm: 0.516019732118231, clipped: 0.516019732118231
epoch: 35, train_batch_id: 1450, avg_cost: 3.846801280975342
grad_norm: 0.3437682878777563, clipped: 0.3437682878777563
epoch: 35, train_batch_id: 1500, avg_cost: 3.8535759449005127
grad_norm: 0.6520860043712939, clipped: 0.6520860043712939
epoch: 35, train_batch_id: 1550, avg_cost: 3.877274751663208
grad_norm: 1.1359552308227616, clipped: 1.0
epoch: 35, train_batch_id: 1600, avg_cost: 3.8699769973754883
grad_norm: 0.597254352954188, clipped: 0.597254352954188
epoch: 35, train_batch_id: 1650, avg_cost: 3.889864921569824
grad_norm: 0.39809209556005454, clipped: 0.39809209556005454
epoch: 35, train_batch_id: 1700, avg_cost: 3.8232548236846924
grad_norm: 0.4713557001681111, clipped: 0.4713557001681111
epoch: 35, train_batch_id: 1750, avg_cost: 3.852783679962158
grad_norm: 0.4193027994113755, clipped: 0.4193027994113755
epoch: 35, train_batch_id: 1800, avg_cost: 3.849642753601074
grad_norm: 0.8255837865583118, clipped: 0.8255837865583118
epoch: 35, train_batch_id: 1850, avg_cost: 3.877087116241455
grad_norm: 0.4133189682885472, clipped: 0.4133189682885472
epoch: 35, train_batch_id: 1900, avg_cost: 3.8640589714050293
grad_norm: 1.3989075119983765, clipped: 1.0
epoch: 35, train_batch_id: 1950, avg_cost: 3.860630512237549
grad_norm: 0.46699612883865527, clipped: 0.46699612883865527
epoch: 35, train_batch_id: 2000, avg_cost: 3.8639373779296875
grad_norm: 0.34142367473663243, clipped: 0.34142367473663243
epoch: 35, train_batch_id: 2050, avg_cost: 3.857039213180542
grad_norm: 0.7758189267317457, clipped: 0.7758189267317457
epoch: 35, train_batch_id: 2100, avg_cost: 3.8395769596099854
grad_norm: 0.3804942911172725, clipped: 0.3804942911172725
epoch: 35, train_batch_id: 2150, avg_cost: 3.8591935634613037
grad_norm: 0.5726927689401379, clipped: 0.5726927689401379
epoch: 35, train_batch_id: 2200, avg_cost: 3.8793139457702637
grad_norm: 0.9741511345761381, clipped: 0.9741511345761381
epoch: 35, train_batch_id: 2250, avg_cost: 3.8425791263580322
grad_norm: 0.4007600246110763, clipped: 0.4007600246110763
epoch: 35, train_batch_id: 2300, avg_cost: 3.8679721355438232
grad_norm: 0.3958411244861893, clipped: 0.3958411244861893
epoch: 35, train_batch_id: 2350, avg_cost: 3.8498892784118652
grad_norm: 0.3110323325589999, clipped: 0.3110323325589999
epoch: 35, train_batch_id: 2400, avg_cost: 3.855438709259033
grad_norm: 1.0309004563759234, clipped: 1.0
epoch: 35, train_batch_id: 2450, avg_cost: 3.8831005096435547
grad_norm: 0.49927406274098785, clipped: 0.49927406274098785
Finished epoch 35, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8519585132598877 +- 0.0031203031539916992
Evaluating candidate model on evaluation dataset
Epoch 35 candidate mean 3.8470118045806885, baseline epoch 31 mean 3.8474273681640625, difference -0.00041556358337402344
p-value: 0.12122205875314628
Start train epoch 36, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 36, train_batch_id: 0, avg_cost: 3.8696022033691406
grad_norm: 0.30897590139900005, clipped: 0.30897590139900005
epoch: 36, train_batch_id: 50, avg_cost: 3.8579695224761963
grad_norm: 0.49772284602716155, clipped: 0.49772284602716155
epoch: 36, train_batch_id: 100, avg_cost: 3.8677706718444824
grad_norm: 0.5877590786657252, clipped: 0.5877590786657252
epoch: 36, train_batch_id: 150, avg_cost: 3.837555408477783
grad_norm: 0.5929455014506729, clipped: 0.5929455014506729
epoch: 36, train_batch_id: 200, avg_cost: 3.8567919731140137
grad_norm: 0.5901699626737293, clipped: 0.5901699626737293
epoch: 36, train_batch_id: 250, avg_cost: 3.863132953643799
grad_norm: 0.4682413329778892, clipped: 0.4682413329778892
epoch: 36, train_batch_id: 300, avg_cost: 3.8438665866851807
grad_norm: 0.4251248425705778, clipped: 0.4251248425705778
epoch: 36, train_batch_id: 350, avg_cost: 3.8388142585754395
grad_norm: 0.3712995964508244, clipped: 0.3712995964508244
epoch: 36, train_batch_id: 400, avg_cost: 3.8533406257629395
grad_norm: 0.33995055561545784, clipped: 0.33995055561545784
epoch: 36, train_batch_id: 450, avg_cost: 3.888033151626587
grad_norm: 0.44025778185739567, clipped: 0.44025778185739567
epoch: 36, train_batch_id: 500, avg_cost: 3.877279043197632
grad_norm: 0.64103958767245, clipped: 0.64103958767245
epoch: 36, train_batch_id: 550, avg_cost: 3.8634138107299805
grad_norm: 0.6804274597524476, clipped: 0.6804274597524476
epoch: 36, train_batch_id: 600, avg_cost: 3.825913429260254
grad_norm: 0.30502414589489113, clipped: 0.30502414589489113
epoch: 36, train_batch_id: 650, avg_cost: 3.837104320526123
grad_norm: 0.3661005324265191, clipped: 0.3661005324265191
epoch: 36, train_batch_id: 700, avg_cost: 3.8513267040252686
grad_norm: 0.6032311901294536, clipped: 0.6032311901294536
epoch: 36, train_batch_id: 750, avg_cost: 3.8551745414733887
grad_norm: 0.5842082529274375, clipped: 0.5842082529274375
epoch: 36, train_batch_id: 800, avg_cost: 3.8707292079925537
grad_norm: 0.7942754637134699, clipped: 0.7942754637134699
epoch: 36, train_batch_id: 850, avg_cost: 3.8539533615112305
grad_norm: 0.5398163902469045, clipped: 0.5398163902469045
epoch: 36, train_batch_id: 900, avg_cost: 3.843471050262451
grad_norm: 0.5133531931521518, clipped: 0.5133531931521518
epoch: 36, train_batch_id: 950, avg_cost: 3.8726396560668945
grad_norm: 0.905866877058927, clipped: 0.905866877058927
epoch: 36, train_batch_id: 1000, avg_cost: 3.8533096313476562
grad_norm: 0.43644463005481, clipped: 0.43644463005481
epoch: 36, train_batch_id: 1050, avg_cost: 3.860060214996338
grad_norm: 0.32269521831863446, clipped: 0.32269521831863446
epoch: 36, train_batch_id: 1100, avg_cost: 3.850858211517334
grad_norm: 0.4769896319392245, clipped: 0.4769896319392245
epoch: 36, train_batch_id: 1150, avg_cost: 3.8665313720703125
grad_norm: 0.35648430074625376, clipped: 0.35648430074625376
epoch: 36, train_batch_id: 1200, avg_cost: 3.878589630126953
grad_norm: 0.4464850888525112, clipped: 0.4464850888525112
epoch: 36, train_batch_id: 1250, avg_cost: 3.8578178882598877
grad_norm: 1.6361060793691315, clipped: 1.0
epoch: 36, train_batch_id: 1300, avg_cost: 3.874617099761963
grad_norm: 0.4555773712842267, clipped: 0.4555773712842267
epoch: 36, train_batch_id: 1350, avg_cost: 3.850050926208496
grad_norm: 0.6365064708632422, clipped: 0.6365064708632422
epoch: 36, train_batch_id: 1400, avg_cost: 3.849925994873047
grad_norm: 0.4431017679115778, clipped: 0.4431017679115778
epoch: 36, train_batch_id: 1450, avg_cost: 3.864300489425659
grad_norm: 0.51244495168707, clipped: 0.51244495168707
epoch: 36, train_batch_id: 1500, avg_cost: 3.840427875518799
grad_norm: 0.5181374512204365, clipped: 0.5181374512204365
epoch: 36, train_batch_id: 1550, avg_cost: 3.857243537902832
grad_norm: 0.3944553122030011, clipped: 0.3944553122030011
epoch: 36, train_batch_id: 1600, avg_cost: 3.859564781188965
grad_norm: 0.4749027053181408, clipped: 0.4749027053181408
epoch: 36, train_batch_id: 1650, avg_cost: 3.849012613296509
grad_norm: 0.3880062195828023, clipped: 0.3880062195828023
epoch: 36, train_batch_id: 1700, avg_cost: 3.8459181785583496
grad_norm: 0.43042158110768985, clipped: 0.43042158110768985
epoch: 36, train_batch_id: 1750, avg_cost: 3.8266165256500244
grad_norm: 0.3638047948904988, clipped: 0.3638047948904988
epoch: 36, train_batch_id: 1800, avg_cost: 3.8476507663726807
grad_norm: 0.6813565159124971, clipped: 0.6813565159124971
epoch: 36, train_batch_id: 1850, avg_cost: 3.850339412689209
grad_norm: 0.397415634198384, clipped: 0.397415634198384
epoch: 36, train_batch_id: 1900, avg_cost: 3.869399070739746
grad_norm: 0.5771089471229431, clipped: 0.5771089471229431
epoch: 36, train_batch_id: 1950, avg_cost: 3.8557240962982178
grad_norm: 0.48570635149271313, clipped: 0.48570635149271313
epoch: 36, train_batch_id: 2000, avg_cost: 3.8467578887939453
grad_norm: 0.4145423591642615, clipped: 0.4145423591642615
epoch: 36, train_batch_id: 2050, avg_cost: 3.8417129516601562
grad_norm: 0.31785375801303195, clipped: 0.31785375801303195
epoch: 36, train_batch_id: 2100, avg_cost: 3.853609561920166
grad_norm: 0.24461511049772242, clipped: 0.24461511049772242
epoch: 36, train_batch_id: 2150, avg_cost: 3.857393264770508
grad_norm: 0.5256706851426003, clipped: 0.5256706851426003
epoch: 36, train_batch_id: 2200, avg_cost: 3.842456340789795
grad_norm: 0.37470712333343653, clipped: 0.37470712333343653
epoch: 36, train_batch_id: 2250, avg_cost: 3.8388633728027344
grad_norm: 0.6187480670463579, clipped: 0.6187480670463579
epoch: 36, train_batch_id: 2300, avg_cost: 3.854823112487793
grad_norm: 0.5943066458384494, clipped: 0.5943066458384494
epoch: 36, train_batch_id: 2350, avg_cost: 3.85990571975708
grad_norm: 0.33363670527905, clipped: 0.33363670527905
epoch: 36, train_batch_id: 2400, avg_cost: 3.8530476093292236
grad_norm: 0.4623105643471203, clipped: 0.4623105643471203
epoch: 36, train_batch_id: 2450, avg_cost: 3.8613944053649902
grad_norm: 0.49249275124302366, clipped: 0.49249275124302366
Finished epoch 36, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8535749912261963 +- 0.0031342674046754837
Evaluating candidate model on evaluation dataset
Epoch 36 candidate mean 3.848665952682495, baseline epoch 31 mean 3.8474273681640625, difference 0.0012385845184326172
Start train epoch 37, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 37, train_batch_id: 0, avg_cost: 3.8452281951904297
grad_norm: 0.6047573250259675, clipped: 0.6047573250259675
epoch: 37, train_batch_id: 50, avg_cost: 3.8501667976379395
grad_norm: 0.47101831137940325, clipped: 0.47101831137940325
epoch: 37, train_batch_id: 100, avg_cost: 3.8591413497924805
grad_norm: 0.4090243578634412, clipped: 0.4090243578634412
epoch: 37, train_batch_id: 150, avg_cost: 3.8432397842407227
grad_norm: 0.494577477562157, clipped: 0.494577477562157
epoch: 37, train_batch_id: 200, avg_cost: 3.8690273761749268
grad_norm: 0.5011724442590222, clipped: 0.5011724442590222
epoch: 37, train_batch_id: 250, avg_cost: 3.850722551345825
grad_norm: 0.3180993738688383, clipped: 0.3180993738688383
epoch: 37, train_batch_id: 300, avg_cost: 3.8661506175994873
grad_norm: 0.5353404192980932, clipped: 0.5353404192980932
epoch: 37, train_batch_id: 350, avg_cost: 3.846127510070801
grad_norm: 0.43698115821236183, clipped: 0.43698115821236183
epoch: 37, train_batch_id: 400, avg_cost: 3.8356261253356934
grad_norm: 0.29767569820865514, clipped: 0.29767569820865514
epoch: 37, train_batch_id: 450, avg_cost: 3.844529151916504
grad_norm: 0.40497378784178417, clipped: 0.40497378784178417
epoch: 37, train_batch_id: 500, avg_cost: 3.850855827331543
grad_norm: 0.47818144541544527, clipped: 0.47818144541544527
epoch: 37, train_batch_id: 550, avg_cost: 3.864670753479004
grad_norm: 0.5900891260644804, clipped: 0.5900891260644804
epoch: 37, train_batch_id: 600, avg_cost: 3.8590261936187744
grad_norm: 0.4856006214538135, clipped: 0.4856006214538135
epoch: 37, train_batch_id: 650, avg_cost: 3.8481273651123047
grad_norm: 0.5129337686454601, clipped: 0.5129337686454601
epoch: 37, train_batch_id: 700, avg_cost: 3.8510236740112305
grad_norm: 0.5592278031953756, clipped: 0.5592278031953756
epoch: 37, train_batch_id: 750, avg_cost: 3.8283865451812744
grad_norm: 0.3617003641522982, clipped: 0.3617003641522982
epoch: 37, train_batch_id: 800, avg_cost: 3.844343900680542
grad_norm: 0.3884092148775679, clipped: 0.3884092148775679
epoch: 37, train_batch_id: 850, avg_cost: 3.870476007461548
grad_norm: 0.3658669569133046, clipped: 0.3658669569133046
epoch: 37, train_batch_id: 900, avg_cost: 3.8473362922668457
grad_norm: 0.5164415747295823, clipped: 0.5164415747295823
epoch: 37, train_batch_id: 950, avg_cost: 3.835757255554199
grad_norm: 0.31911074247804516, clipped: 0.31911074247804516
epoch: 37, train_batch_id: 1000, avg_cost: 3.845320701599121
grad_norm: 0.5625797925451256, clipped: 0.5625797925451256
epoch: 37, train_batch_id: 1050, avg_cost: 3.8588109016418457
grad_norm: 0.3047084988441172, clipped: 0.3047084988441172
epoch: 37, train_batch_id: 1100, avg_cost: 3.8569254875183105
grad_norm: 0.8125746724122227, clipped: 0.8125746724122227
epoch: 37, train_batch_id: 1150, avg_cost: 3.865886926651001
grad_norm: 0.41063672811271046, clipped: 0.41063672811271046
epoch: 37, train_batch_id: 1200, avg_cost: 3.8607311248779297
grad_norm: 0.5784417053970171, clipped: 0.5784417053970171
epoch: 37, train_batch_id: 1250, avg_cost: 3.8649535179138184
grad_norm: 1.076149588663218, clipped: 1.0
epoch: 37, train_batch_id: 1300, avg_cost: 3.841966390609741
grad_norm: 0.3571237336263051, clipped: 0.3571237336263051
epoch: 37, train_batch_id: 1350, avg_cost: 3.840454578399658
grad_norm: 0.5715842618242407, clipped: 0.5715842618242407
epoch: 37, train_batch_id: 1400, avg_cost: 3.831904888153076
grad_norm: 0.44904279727675545, clipped: 0.44904279727675545
epoch: 37, train_batch_id: 1450, avg_cost: 3.8682384490966797
grad_norm: 0.7535718863286053, clipped: 0.7535718863286053
epoch: 37, train_batch_id: 1500, avg_cost: 3.8744406700134277
grad_norm: 0.28477159890554343, clipped: 0.28477159890554343
epoch: 37, train_batch_id: 1550, avg_cost: 3.8696298599243164
grad_norm: 0.4470362552631641, clipped: 0.4470362552631641
epoch: 37, train_batch_id: 1600, avg_cost: 3.8411786556243896
grad_norm: 0.4583225214903749, clipped: 0.4583225214903749
epoch: 37, train_batch_id: 1650, avg_cost: 3.8512890338897705
grad_norm: 0.5367790527801192, clipped: 0.5367790527801192
epoch: 37, train_batch_id: 1700, avg_cost: 3.8683884143829346
grad_norm: 0.6692323132527589, clipped: 0.6692323132527589
epoch: 37, train_batch_id: 1750, avg_cost: 3.8298840522766113
grad_norm: 0.6528783574040802, clipped: 0.6528783574040802
epoch: 37, train_batch_id: 1800, avg_cost: 3.8326900005340576
grad_norm: 0.4744295267155891, clipped: 0.4744295267155891
epoch: 37, train_batch_id: 1850, avg_cost: 3.8393211364746094
grad_norm: 0.4296272810608046, clipped: 0.4296272810608046
epoch: 37, train_batch_id: 1900, avg_cost: 3.877331256866455
grad_norm: 0.4485693635462788, clipped: 0.4485693635462788
epoch: 37, train_batch_id: 1950, avg_cost: 3.8520803451538086
grad_norm: 0.6512873299890155, clipped: 0.6512873299890155
epoch: 37, train_batch_id: 2000, avg_cost: 3.8270602226257324
grad_norm: 0.34336933993121704, clipped: 0.34336933993121704
epoch: 37, train_batch_id: 2050, avg_cost: 3.8552002906799316
grad_norm: 0.4245326984129371, clipped: 0.4245326984129371
epoch: 37, train_batch_id: 2100, avg_cost: 3.8487932682037354
grad_norm: 0.5199942482958946, clipped: 0.5199942482958946
epoch: 37, train_batch_id: 2150, avg_cost: 3.846034526824951
grad_norm: 0.4257751834749117, clipped: 0.4257751834749117
epoch: 37, train_batch_id: 2200, avg_cost: 3.8884096145629883
grad_norm: 0.44551611975166844, clipped: 0.44551611975166844
epoch: 37, train_batch_id: 2250, avg_cost: 3.841148614883423
grad_norm: 0.46970156110371347, clipped: 0.46970156110371347
epoch: 37, train_batch_id: 2300, avg_cost: 3.860076427459717
grad_norm: 0.3887271198394869, clipped: 0.3887271198394869
epoch: 37, train_batch_id: 2350, avg_cost: 3.8595328330993652
grad_norm: 0.2924242860344929, clipped: 0.2924242860344929
epoch: 37, train_batch_id: 2400, avg_cost: 3.834649085998535
grad_norm: 0.4807447542826552, clipped: 0.4807447542826552
epoch: 37, train_batch_id: 2450, avg_cost: 3.8555140495300293
grad_norm: 0.29678414635092176, clipped: 0.29678414635092176
Finished epoch 37, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8519957065582275 +- 0.003126781899482012
Evaluating candidate model on evaluation dataset
Epoch 37 candidate mean 3.847017288208008, baseline epoch 31 mean 3.8474273681640625, difference -0.0004100799560546875
p-value: 0.11654121739796759
Start train epoch 38, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 38, train_batch_id: 0, avg_cost: 3.86814022064209
grad_norm: 0.49354795552288344, clipped: 0.49354795552288344
epoch: 38, train_batch_id: 50, avg_cost: 3.838359832763672
grad_norm: 0.3978994580151803, clipped: 0.3978994580151803
epoch: 38, train_batch_id: 100, avg_cost: 3.848207950592041
grad_norm: 0.36644149686618316, clipped: 0.36644149686618316
epoch: 38, train_batch_id: 150, avg_cost: 3.8387222290039062
grad_norm: 0.8189160100234238, clipped: 0.8189160100234238
epoch: 38, train_batch_id: 200, avg_cost: 3.860960006713867
grad_norm: 0.41433003654964357, clipped: 0.41433003654964357
epoch: 38, train_batch_id: 250, avg_cost: 3.8457624912261963
grad_norm: 0.3173383108305122, clipped: 0.3173383108305122
epoch: 38, train_batch_id: 300, avg_cost: 3.8654608726501465
grad_norm: 0.4091548232363386, clipped: 0.4091548232363386
epoch: 38, train_batch_id: 350, avg_cost: 3.838937997817993
grad_norm: 0.6345788761945417, clipped: 0.6345788761945417
epoch: 38, train_batch_id: 400, avg_cost: 3.856522798538208
grad_norm: 0.43029524174905837, clipped: 0.43029524174905837
epoch: 38, train_batch_id: 450, avg_cost: 3.871943235397339
grad_norm: 0.6399494882955773, clipped: 0.6399494882955773
epoch: 38, train_batch_id: 500, avg_cost: 3.8545188903808594
grad_norm: 0.376759277847634, clipped: 0.376759277847634
epoch: 38, train_batch_id: 550, avg_cost: 3.8486342430114746
grad_norm: 0.36022980048366254, clipped: 0.36022980048366254
epoch: 38, train_batch_id: 600, avg_cost: 3.8436458110809326
grad_norm: 0.41754327528440544, clipped: 0.41754327528440544
epoch: 38, train_batch_id: 650, avg_cost: 3.8346948623657227
grad_norm: 0.5429211235857954, clipped: 0.5429211235857954
epoch: 38, train_batch_id: 700, avg_cost: 3.83518648147583
grad_norm: 0.3653550565126452, clipped: 0.3653550565126452
epoch: 38, train_batch_id: 750, avg_cost: 3.840142250061035
grad_norm: 0.41419466885317524, clipped: 0.41419466885317524
epoch: 38, train_batch_id: 800, avg_cost: 3.8362464904785156
grad_norm: 0.45189542268869937, clipped: 0.45189542268869937
epoch: 38, train_batch_id: 850, avg_cost: 3.8543224334716797
grad_norm: 0.5256853216138092, clipped: 0.5256853216138092
epoch: 38, train_batch_id: 900, avg_cost: 3.829867362976074
grad_norm: 0.3948448669853871, clipped: 0.3948448669853871
epoch: 38, train_batch_id: 950, avg_cost: 3.8376893997192383
grad_norm: 0.3122643082248805, clipped: 0.3122643082248805
epoch: 38, train_batch_id: 1000, avg_cost: 3.858372449874878
grad_norm: 0.4552695907940376, clipped: 0.4552695907940376
epoch: 38, train_batch_id: 1050, avg_cost: 3.8460378646850586
grad_norm: 0.3894457894692481, clipped: 0.3894457894692481
epoch: 38, train_batch_id: 1100, avg_cost: 3.8464858531951904
grad_norm: 0.27643773681887523, clipped: 0.27643773681887523
epoch: 38, train_batch_id: 1150, avg_cost: 3.861696720123291
grad_norm: 0.5100861223006028, clipped: 0.5100861223006028
epoch: 38, train_batch_id: 1200, avg_cost: 3.8397064208984375
grad_norm: 0.462703585886471, clipped: 0.462703585886471
epoch: 38, train_batch_id: 1250, avg_cost: 3.8467416763305664
grad_norm: 0.4634374168881576, clipped: 0.4634374168881576
epoch: 38, train_batch_id: 1300, avg_cost: 3.85044527053833
grad_norm: 0.46429193121506024, clipped: 0.46429193121506024
epoch: 38, train_batch_id: 1350, avg_cost: 3.8734593391418457
grad_norm: 0.4406784405720062, clipped: 0.4406784405720062
epoch: 38, train_batch_id: 1400, avg_cost: 3.8392910957336426
grad_norm: 0.48994577732913813, clipped: 0.48994577732913813
epoch: 38, train_batch_id: 1450, avg_cost: 3.8637683391571045
grad_norm: 0.4365497086939413, clipped: 0.4365497086939413
epoch: 38, train_batch_id: 1500, avg_cost: 3.8590142726898193
grad_norm: 0.4799843060827466, clipped: 0.4799843060827466
epoch: 38, train_batch_id: 1550, avg_cost: 3.839480400085449
grad_norm: 0.3858884082532414, clipped: 0.3858884082532414
epoch: 38, train_batch_id: 1600, avg_cost: 3.855656147003174
grad_norm: 0.5830644905967853, clipped: 0.5830644905967853
epoch: 38, train_batch_id: 1650, avg_cost: 3.8427462577819824
grad_norm: 0.4131202201460535, clipped: 0.4131202201460535
epoch: 38, train_batch_id: 1700, avg_cost: 3.854605197906494
grad_norm: 0.35850564154877906, clipped: 0.35850564154877906
epoch: 38, train_batch_id: 1750, avg_cost: 3.8680224418640137
grad_norm: 0.38576101030963544, clipped: 0.38576101030963544
epoch: 38, train_batch_id: 1800, avg_cost: 3.8712000846862793
grad_norm: 0.35629947862117634, clipped: 0.35629947862117634
epoch: 38, train_batch_id: 1850, avg_cost: 3.855257987976074
grad_norm: 0.5560726333048771, clipped: 0.5560726333048771
epoch: 38, train_batch_id: 1900, avg_cost: 3.8635575771331787
grad_norm: 0.32386732665580975, clipped: 0.32386732665580975
epoch: 38, train_batch_id: 1950, avg_cost: 3.8669772148132324
grad_norm: 0.3920425499944784, clipped: 0.3920425499944784
epoch: 38, train_batch_id: 2000, avg_cost: 3.8372583389282227
grad_norm: 0.3551317085732142, clipped: 0.3551317085732142
epoch: 38, train_batch_id: 2050, avg_cost: 3.8315882682800293
grad_norm: 0.4807192490060419, clipped: 0.4807192490060419
epoch: 38, train_batch_id: 2100, avg_cost: 3.8629820346832275
grad_norm: 0.35318219366255954, clipped: 0.35318219366255954
epoch: 38, train_batch_id: 2150, avg_cost: 3.8496007919311523
grad_norm: 0.5865972604300101, clipped: 0.5865972604300101
epoch: 38, train_batch_id: 2200, avg_cost: 3.840477466583252
grad_norm: 0.5086511250450297, clipped: 0.5086511250450297
epoch: 38, train_batch_id: 2250, avg_cost: 3.8532752990722656
grad_norm: 0.5871302307097968, clipped: 0.5871302307097968
epoch: 38, train_batch_id: 2300, avg_cost: 3.842617988586426
grad_norm: 0.5007538201830724, clipped: 0.5007538201830724
epoch: 38, train_batch_id: 2350, avg_cost: 3.8651657104492188
grad_norm: 0.36391295773783033, clipped: 0.36391295773783033
epoch: 38, train_batch_id: 2400, avg_cost: 3.8591909408569336
grad_norm: 0.4915142367881166, clipped: 0.4915142367881166
epoch: 38, train_batch_id: 2450, avg_cost: 3.8523364067077637
grad_norm: 0.2747674839156303, clipped: 0.2747674839156303
Finished epoch 38, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.852238655090332 +- 0.0031217432115226984
Evaluating candidate model on evaluation dataset
Epoch 38 candidate mean 3.846304178237915, baseline epoch 31 mean 3.8474273681640625, difference -0.001123189926147461
p-value: 0.00033300278804015277
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 39, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 39, train_batch_id: 0, avg_cost: 3.8528966903686523
grad_norm: 0.5487068231230983, clipped: 0.5487068231230983
epoch: 39, train_batch_id: 50, avg_cost: 3.854950189590454
grad_norm: 0.401539090450965, clipped: 0.401539090450965
epoch: 39, train_batch_id: 100, avg_cost: 3.8711142539978027
grad_norm: 0.4345403692656477, clipped: 0.4345403692656477
epoch: 39, train_batch_id: 150, avg_cost: 3.857004165649414
grad_norm: 0.5338203691379939, clipped: 0.5338203691379939
epoch: 39, train_batch_id: 200, avg_cost: 3.865300178527832
grad_norm: 0.3681622607170985, clipped: 0.3681622607170985
epoch: 39, train_batch_id: 250, avg_cost: 3.851840019226074
grad_norm: 0.3293976059812323, clipped: 0.3293976059812323
epoch: 39, train_batch_id: 300, avg_cost: 3.857581615447998
grad_norm: 0.4651080140719908, clipped: 0.4651080140719908
epoch: 39, train_batch_id: 350, avg_cost: 3.8558056354522705
grad_norm: 0.3556720197942816, clipped: 0.3556720197942816
epoch: 39, train_batch_id: 400, avg_cost: 3.844363212585449
grad_norm: 0.2657460419752393, clipped: 0.2657460419752393
epoch: 39, train_batch_id: 450, avg_cost: 3.8520915508270264
grad_norm: 0.5253990230502092, clipped: 0.5253990230502092
epoch: 39, train_batch_id: 500, avg_cost: 3.865995407104492
grad_norm: 0.4588780026951592, clipped: 0.4588780026951592
epoch: 39, train_batch_id: 550, avg_cost: 3.858924150466919
grad_norm: 0.2763784841253678, clipped: 0.2763784841253678
epoch: 39, train_batch_id: 600, avg_cost: 3.8371875286102295
grad_norm: 0.40147562624770017, clipped: 0.40147562624770017
epoch: 39, train_batch_id: 650, avg_cost: 3.8519906997680664
grad_norm: 0.4294613060761701, clipped: 0.4294613060761701
epoch: 39, train_batch_id: 700, avg_cost: 3.857067823410034
grad_norm: 0.44065239615917823, clipped: 0.44065239615917823
epoch: 39, train_batch_id: 750, avg_cost: 3.846163749694824
grad_norm: 0.7808675821527344, clipped: 0.7808675821527344
epoch: 39, train_batch_id: 800, avg_cost: 3.859293222427368
grad_norm: 0.42567341645900647, clipped: 0.42567341645900647
epoch: 39, train_batch_id: 850, avg_cost: 3.829465627670288
grad_norm: 0.39921249063107495, clipped: 0.39921249063107495
epoch: 39, train_batch_id: 900, avg_cost: 3.8632936477661133
grad_norm: 0.38883300351516975, clipped: 0.38883300351516975
epoch: 39, train_batch_id: 950, avg_cost: 3.873988628387451
grad_norm: 0.4397771924834138, clipped: 0.4397771924834138
epoch: 39, train_batch_id: 1000, avg_cost: 3.85890531539917
grad_norm: 0.3520875737628116, clipped: 0.3520875737628116
epoch: 39, train_batch_id: 1050, avg_cost: 3.8272829055786133
grad_norm: 0.37859765094715186, clipped: 0.37859765094715186
epoch: 39, train_batch_id: 1100, avg_cost: 3.829103708267212
grad_norm: 0.46007404750196107, clipped: 0.46007404750196107
epoch: 39, train_batch_id: 1150, avg_cost: 3.858393669128418
grad_norm: 0.5464706159670653, clipped: 0.5464706159670653
epoch: 39, train_batch_id: 1200, avg_cost: 3.8470919132232666
grad_norm: 0.3789551986985046, clipped: 0.3789551986985046
epoch: 39, train_batch_id: 1250, avg_cost: 3.8552143573760986
grad_norm: 1.237216320611587, clipped: 1.0
epoch: 39, train_batch_id: 1300, avg_cost: 3.860593557357788
grad_norm: 0.35329546988489563, clipped: 0.35329546988489563
epoch: 39, train_batch_id: 1350, avg_cost: 3.8545446395874023
grad_norm: 0.4708807268800305, clipped: 0.4708807268800305
epoch: 39, train_batch_id: 1400, avg_cost: 3.8724417686462402
grad_norm: 0.5005363758878338, clipped: 0.5005363758878338
epoch: 39, train_batch_id: 1450, avg_cost: 3.8562798500061035
grad_norm: 0.5772716849886591, clipped: 0.5772716849886591
epoch: 39, train_batch_id: 1500, avg_cost: 3.88004732131958
grad_norm: 0.5166411352924674, clipped: 0.5166411352924674
epoch: 39, train_batch_id: 1550, avg_cost: 3.858459949493408
grad_norm: 0.4438579550001719, clipped: 0.4438579550001719
epoch: 39, train_batch_id: 1600, avg_cost: 3.853163957595825
grad_norm: 0.3742496776264544, clipped: 0.3742496776264544
epoch: 39, train_batch_id: 1650, avg_cost: 3.8359375
grad_norm: 0.48367085095718326, clipped: 0.48367085095718326
epoch: 39, train_batch_id: 1700, avg_cost: 3.849862575531006
grad_norm: 0.4136196848367842, clipped: 0.4136196848367842
epoch: 39, train_batch_id: 1750, avg_cost: 3.8440093994140625
grad_norm: 0.5162742217533152, clipped: 0.5162742217533152
epoch: 39, train_batch_id: 1800, avg_cost: 3.8477163314819336
grad_norm: 0.4381998308256589, clipped: 0.4381998308256589
epoch: 39, train_batch_id: 1850, avg_cost: 3.8863272666931152
grad_norm: 0.3269434388564264, clipped: 0.3269434388564264
epoch: 39, train_batch_id: 1900, avg_cost: 3.8528494834899902
grad_norm: 0.37475739143527576, clipped: 0.37475739143527576
epoch: 39, train_batch_id: 1950, avg_cost: 3.8523762226104736
grad_norm: 0.47311755429002594, clipped: 0.47311755429002594
epoch: 39, train_batch_id: 2000, avg_cost: 3.836526870727539
grad_norm: 0.41869341145294486, clipped: 0.41869341145294486
epoch: 39, train_batch_id: 2050, avg_cost: 3.854315996170044
grad_norm: 0.4992475358135852, clipped: 0.4992475358135852
epoch: 39, train_batch_id: 2100, avg_cost: 3.841243267059326
grad_norm: 0.43560583121177404, clipped: 0.43560583121177404
epoch: 39, train_batch_id: 2150, avg_cost: 3.8445422649383545
grad_norm: 0.3568154091652593, clipped: 0.3568154091652593
epoch: 39, train_batch_id: 2200, avg_cost: 3.8470616340637207
grad_norm: 0.3267994950636861, clipped: 0.3267994950636861
epoch: 39, train_batch_id: 2250, avg_cost: 3.863027811050415
grad_norm: 0.4630871841237155, clipped: 0.4630871841237155
epoch: 39, train_batch_id: 2300, avg_cost: 3.8606438636779785
grad_norm: 0.3378092832623493, clipped: 0.3378092832623493
epoch: 39, train_batch_id: 2350, avg_cost: 3.8280842304229736
grad_norm: 0.629097398365338, clipped: 0.629097398365338
epoch: 39, train_batch_id: 2400, avg_cost: 3.8499348163604736
grad_norm: 1.417680476530558, clipped: 1.0
epoch: 39, train_batch_id: 2450, avg_cost: 3.844766616821289
grad_norm: 0.43490453909609317, clipped: 0.43490453909609317
Finished epoch 39, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.852381706237793 +- 0.0031226465944200754
Evaluating candidate model on evaluation dataset
Epoch 39 candidate mean 3.85313081741333, baseline epoch 38 mean 3.852238655090332, difference 0.0008921623229980469
Start train epoch 40, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 40, train_batch_id: 0, avg_cost: 3.8490140438079834
grad_norm: 0.37782974703758276, clipped: 0.37782974703758276
epoch: 40, train_batch_id: 50, avg_cost: 3.8414597511291504
grad_norm: 0.32562847517808957, clipped: 0.32562847517808957
epoch: 40, train_batch_id: 100, avg_cost: 3.85388445854187
grad_norm: 0.3890708794677572, clipped: 0.3890708794677572
epoch: 40, train_batch_id: 150, avg_cost: 3.849936008453369
grad_norm: 0.2681375603079713, clipped: 0.2681375603079713
epoch: 40, train_batch_id: 200, avg_cost: 3.85653018951416
grad_norm: 0.3335240970259923, clipped: 0.3335240970259923
epoch: 40, train_batch_id: 250, avg_cost: 3.8529059886932373
grad_norm: 0.3270170729095465, clipped: 0.3270170729095465
epoch: 40, train_batch_id: 300, avg_cost: 3.8480234146118164
grad_norm: 0.2868241346865472, clipped: 0.2868241346865472
epoch: 40, train_batch_id: 350, avg_cost: 3.8493521213531494
grad_norm: 0.354659600377107, clipped: 0.354659600377107
epoch: 40, train_batch_id: 400, avg_cost: 3.8426809310913086
grad_norm: 0.28633385956342006, clipped: 0.28633385956342006
epoch: 40, train_batch_id: 450, avg_cost: 3.8550333976745605
grad_norm: 0.3554305114813669, clipped: 0.3554305114813669
epoch: 40, train_batch_id: 500, avg_cost: 3.8543624877929688
grad_norm: 0.34381170731498945, clipped: 0.34381170731498945
epoch: 40, train_batch_id: 550, avg_cost: 3.8524169921875
grad_norm: 0.4502139003013248, clipped: 0.4502139003013248
epoch: 40, train_batch_id: 600, avg_cost: 3.86014461517334
grad_norm: 0.6703858361638741, clipped: 0.6703858361638741
epoch: 40, train_batch_id: 650, avg_cost: 3.8433241844177246
grad_norm: 0.3571523087939348, clipped: 0.3571523087939348
epoch: 40, train_batch_id: 700, avg_cost: 3.842944622039795
grad_norm: 0.3476969285318817, clipped: 0.3476969285318817
epoch: 40, train_batch_id: 750, avg_cost: 3.8810067176818848
grad_norm: 0.37059014416351427, clipped: 0.37059014416351427
epoch: 40, train_batch_id: 800, avg_cost: 3.846096992492676
grad_norm: 0.4150648551446313, clipped: 0.4150648551446313
epoch: 40, train_batch_id: 850, avg_cost: 3.839632987976074
grad_norm: 0.3495287083208948, clipped: 0.3495287083208948
epoch: 40, train_batch_id: 900, avg_cost: 3.8682398796081543
grad_norm: 0.6669298721354341, clipped: 0.6669298721354341
epoch: 40, train_batch_id: 950, avg_cost: 3.8725860118865967
grad_norm: 0.4722035646849492, clipped: 0.4722035646849492
epoch: 40, train_batch_id: 1000, avg_cost: 3.8694329261779785
grad_norm: 0.41052749508971464, clipped: 0.41052749508971464
epoch: 40, train_batch_id: 1050, avg_cost: 3.817256450653076
grad_norm: 0.4537347131041172, clipped: 0.4537347131041172
epoch: 40, train_batch_id: 1100, avg_cost: 3.848212718963623
grad_norm: 0.6185318188240033, clipped: 0.6185318188240033
epoch: 40, train_batch_id: 1150, avg_cost: 3.8645660877227783
grad_norm: 0.47844555830220215, clipped: 0.47844555830220215
epoch: 40, train_batch_id: 1200, avg_cost: 3.8614935874938965
grad_norm: 0.4522571796657726, clipped: 0.4522571796657726
epoch: 40, train_batch_id: 1250, avg_cost: 3.8289883136749268
grad_norm: 0.45339335991743746, clipped: 0.45339335991743746
epoch: 40, train_batch_id: 1300, avg_cost: 3.8716788291931152
grad_norm: 0.3044282046360476, clipped: 0.3044282046360476
epoch: 40, train_batch_id: 1350, avg_cost: 3.8441386222839355
grad_norm: 0.462021707771555, clipped: 0.462021707771555
epoch: 40, train_batch_id: 1400, avg_cost: 3.8546745777130127
grad_norm: 0.5374134389290692, clipped: 0.5374134389290692
epoch: 40, train_batch_id: 1450, avg_cost: 3.844822406768799
grad_norm: 0.36337491244897585, clipped: 0.36337491244897585
epoch: 40, train_batch_id: 1500, avg_cost: 3.80924916267395
grad_norm: 0.314068736551645, clipped: 0.314068736551645
epoch: 40, train_batch_id: 1550, avg_cost: 3.882615089416504
grad_norm: 0.35625769067661645, clipped: 0.35625769067661645
epoch: 40, train_batch_id: 1600, avg_cost: 3.846606731414795
grad_norm: 0.6185133361768186, clipped: 0.6185133361768186
epoch: 40, train_batch_id: 1650, avg_cost: 3.852048635482788
grad_norm: 0.3693931662216342, clipped: 0.3693931662216342
epoch: 40, train_batch_id: 1700, avg_cost: 3.843148708343506
grad_norm: 0.4749400594712155, clipped: 0.4749400594712155
epoch: 40, train_batch_id: 1750, avg_cost: 3.8619751930236816
grad_norm: 0.48350502107270515, clipped: 0.48350502107270515
epoch: 40, train_batch_id: 1800, avg_cost: 3.841215133666992
grad_norm: 0.38377059802540514, clipped: 0.38377059802540514
epoch: 40, train_batch_id: 1850, avg_cost: 3.8606510162353516
grad_norm: 0.4877258375218, clipped: 0.4877258375218
epoch: 40, train_batch_id: 1900, avg_cost: 3.8545045852661133
grad_norm: 1.0763467499032586, clipped: 1.0
epoch: 40, train_batch_id: 1950, avg_cost: 3.870199203491211
grad_norm: 0.5341877751887771, clipped: 0.5341877751887771
epoch: 40, train_batch_id: 2000, avg_cost: 3.836167812347412
grad_norm: 0.4011346229362954, clipped: 0.4011346229362954
epoch: 40, train_batch_id: 2050, avg_cost: 3.842496633529663
grad_norm: 0.29639821322697574, clipped: 0.29639821322697574
epoch: 40, train_batch_id: 2100, avg_cost: 3.8533639907836914
grad_norm: 0.34469840558599796, clipped: 0.34469840558599796
epoch: 40, train_batch_id: 2150, avg_cost: 3.8660178184509277
grad_norm: 0.7121609543543259, clipped: 0.7121609543543259
epoch: 40, train_batch_id: 2200, avg_cost: 3.8521358966827393
grad_norm: 0.36949943805816093, clipped: 0.36949943805816093
epoch: 40, train_batch_id: 2250, avg_cost: 3.8590989112854004
grad_norm: 0.334001260903823, clipped: 0.334001260903823
epoch: 40, train_batch_id: 2300, avg_cost: 3.8551185131073
grad_norm: 0.3836056929325789, clipped: 0.3836056929325789
epoch: 40, train_batch_id: 2350, avg_cost: 3.8491859436035156
grad_norm: 0.93836989248931, clipped: 0.93836989248931
epoch: 40, train_batch_id: 2400, avg_cost: 3.85693359375
grad_norm: 5.772226958552057, clipped: 1.0
epoch: 40, train_batch_id: 2450, avg_cost: 3.8438491821289062
grad_norm: 0.5979635798414213, clipped: 0.5979635798414213
Finished epoch 40, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.850912094116211 +- 0.0031193688046187162
Evaluating candidate model on evaluation dataset
Epoch 40 candidate mean 3.851717233657837, baseline epoch 38 mean 3.852238655090332, difference -0.0005214214324951172
p-value: 0.057879350625022634
Start train epoch 41, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 41, train_batch_id: 0, avg_cost: 3.86985445022583
grad_norm: 0.49713739107424637, clipped: 0.49713739107424637
epoch: 41, train_batch_id: 50, avg_cost: 3.8311550617218018
grad_norm: 0.39730933521623724, clipped: 0.39730933521623724
epoch: 41, train_batch_id: 100, avg_cost: 3.833406448364258
grad_norm: 0.43264224046452643, clipped: 0.43264224046452643
epoch: 41, train_batch_id: 150, avg_cost: 3.8710389137268066
grad_norm: 0.4668502801602716, clipped: 0.4668502801602716
epoch: 41, train_batch_id: 200, avg_cost: 3.8356728553771973
grad_norm: 0.4539126091542259, clipped: 0.4539126091542259
epoch: 41, train_batch_id: 250, avg_cost: 3.8285531997680664
grad_norm: 0.4478906285127223, clipped: 0.4478906285127223
epoch: 41, train_batch_id: 300, avg_cost: 3.8663649559020996
grad_norm: 0.8403446487592131, clipped: 0.8403446487592131
epoch: 41, train_batch_id: 350, avg_cost: 3.843815803527832
grad_norm: 0.34831052859365347, clipped: 0.34831052859365347
epoch: 41, train_batch_id: 400, avg_cost: 3.841503143310547
grad_norm: 0.35932160200741514, clipped: 0.35932160200741514
epoch: 41, train_batch_id: 450, avg_cost: 3.8498005867004395
grad_norm: 0.49863441638206124, clipped: 0.49863441638206124
epoch: 41, train_batch_id: 500, avg_cost: 3.835355281829834
grad_norm: 0.36370079115822584, clipped: 0.36370079115822584
epoch: 41, train_batch_id: 550, avg_cost: 3.8380703926086426
grad_norm: 0.4352866692786701, clipped: 0.4352866692786701
epoch: 41, train_batch_id: 600, avg_cost: 3.8460798263549805
grad_norm: 0.4825816942706362, clipped: 0.4825816942706362
epoch: 41, train_batch_id: 650, avg_cost: 3.8516201972961426
grad_norm: 0.40676170805429446, clipped: 0.40676170805429446
epoch: 41, train_batch_id: 700, avg_cost: 3.8331236839294434
grad_norm: 0.45459588209450397, clipped: 0.45459588209450397
epoch: 41, train_batch_id: 750, avg_cost: 3.851701021194458
grad_norm: 0.5339972161434963, clipped: 0.5339972161434963
epoch: 41, train_batch_id: 800, avg_cost: 3.842033863067627
grad_norm: 0.3221130484633055, clipped: 0.3221130484633055
epoch: 41, train_batch_id: 850, avg_cost: 3.8421425819396973
grad_norm: 0.3773944739128524, clipped: 0.3773944739128524
epoch: 41, train_batch_id: 900, avg_cost: 3.833791494369507
grad_norm: 0.35021144280037475, clipped: 0.35021144280037475
epoch: 41, train_batch_id: 950, avg_cost: 3.862307071685791
grad_norm: 0.588540789992238, clipped: 0.588540789992238
epoch: 41, train_batch_id: 1000, avg_cost: 3.861466884613037
grad_norm: 0.4803095153982564, clipped: 0.4803095153982564
epoch: 41, train_batch_id: 1050, avg_cost: 3.8481645584106445
grad_norm: 0.34228275330622926, clipped: 0.34228275330622926
epoch: 41, train_batch_id: 1100, avg_cost: 3.86032772064209
grad_norm: 0.5689604526655779, clipped: 0.5689604526655779
epoch: 41, train_batch_id: 1150, avg_cost: 3.8546085357666016
grad_norm: 0.54720313593849, clipped: 0.54720313593849
epoch: 41, train_batch_id: 1200, avg_cost: 3.8495922088623047
grad_norm: 0.7553937370550825, clipped: 0.7553937370550825
epoch: 41, train_batch_id: 1250, avg_cost: 3.841167688369751
grad_norm: 0.5882620951098795, clipped: 0.5882620951098795
epoch: 41, train_batch_id: 1300, avg_cost: 3.8405323028564453
grad_norm: 0.41584638875992214, clipped: 0.41584638875992214
epoch: 41, train_batch_id: 1350, avg_cost: 3.836625576019287
grad_norm: 0.48647504698855326, clipped: 0.48647504698855326
epoch: 41, train_batch_id: 1400, avg_cost: 3.829352378845215
grad_norm: 0.548247738507528, clipped: 0.548247738507528
epoch: 41, train_batch_id: 1450, avg_cost: 3.852146625518799
grad_norm: 0.37080234626737435, clipped: 0.37080234626737435
epoch: 41, train_batch_id: 1500, avg_cost: 3.845968246459961
grad_norm: 0.2849069058880057, clipped: 0.2849069058880057
epoch: 41, train_batch_id: 1550, avg_cost: 3.8415939807891846
grad_norm: 0.5191964074962606, clipped: 0.5191964074962606
epoch: 41, train_batch_id: 1600, avg_cost: 3.8682851791381836
grad_norm: 0.3568522579696999, clipped: 0.3568522579696999
epoch: 41, train_batch_id: 1650, avg_cost: 3.8310370445251465
grad_norm: 0.4379410279809181, clipped: 0.4379410279809181
epoch: 41, train_batch_id: 1700, avg_cost: 3.861065149307251
grad_norm: 0.42821665252342916, clipped: 0.42821665252342916
epoch: 41, train_batch_id: 1750, avg_cost: 3.853698253631592
grad_norm: 0.29788418817442275, clipped: 0.29788418817442275
epoch: 41, train_batch_id: 1800, avg_cost: 3.834585189819336
grad_norm: 0.46100946096829065, clipped: 0.46100946096829065
epoch: 41, train_batch_id: 1850, avg_cost: 3.8490140438079834
grad_norm: 0.38068731864618416, clipped: 0.38068731864618416
epoch: 41, train_batch_id: 1900, avg_cost: 3.879441738128662
grad_norm: 0.43924911271786476, clipped: 0.43924911271786476
epoch: 41, train_batch_id: 1950, avg_cost: 3.843679428100586
grad_norm: 0.43382613539766385, clipped: 0.43382613539766385
epoch: 41, train_batch_id: 2000, avg_cost: 3.847839593887329
grad_norm: 0.22113810879071646, clipped: 0.22113810879071646
epoch: 41, train_batch_id: 2050, avg_cost: 3.8417582511901855
grad_norm: 0.46772305634859884, clipped: 0.46772305634859884
epoch: 41, train_batch_id: 2100, avg_cost: 3.8520898818969727
grad_norm: 0.34484544438117265, clipped: 0.34484544438117265
epoch: 41, train_batch_id: 2150, avg_cost: 3.836282730102539
grad_norm: 0.30718877533058137, clipped: 0.30718877533058137
epoch: 41, train_batch_id: 2200, avg_cost: 3.8421807289123535
grad_norm: 0.4958024054579083, clipped: 0.4958024054579083
epoch: 41, train_batch_id: 2250, avg_cost: 3.858109712600708
grad_norm: 0.4504613572396283, clipped: 0.4504613572396283
epoch: 41, train_batch_id: 2300, avg_cost: 3.863576650619507
grad_norm: 0.5031006537684339, clipped: 0.5031006537684339
epoch: 41, train_batch_id: 2350, avg_cost: 3.864189386367798
grad_norm: 0.4016868989873923, clipped: 0.4016868989873923
epoch: 41, train_batch_id: 2400, avg_cost: 3.872798442840576
grad_norm: 0.4841534789646181, clipped: 0.4841534789646181
epoch: 41, train_batch_id: 2450, avg_cost: 3.8449902534484863
grad_norm: 0.8837047423319805, clipped: 0.8837047423319805
Finished epoch 41, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8513569831848145 +- 0.0031217681244015694
Evaluating candidate model on evaluation dataset
Epoch 41 candidate mean 3.852287530899048, baseline epoch 38 mean 3.852238655090332, difference 4.887580871582031e-05
Start train epoch 42, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 42, train_batch_id: 0, avg_cost: 3.8363194465637207
grad_norm: 0.5302744502977099, clipped: 0.5302744502977099
epoch: 42, train_batch_id: 50, avg_cost: 3.8162882328033447
grad_norm: 0.36053505432095223, clipped: 0.36053505432095223
epoch: 42, train_batch_id: 100, avg_cost: 3.8269705772399902
grad_norm: 0.2737324443988618, clipped: 0.2737324443988618
epoch: 42, train_batch_id: 150, avg_cost: 3.8584461212158203
grad_norm: 0.4307956874590917, clipped: 0.4307956874590917
epoch: 42, train_batch_id: 200, avg_cost: 3.857372522354126
grad_norm: 0.551762515327379, clipped: 0.551762515327379
epoch: 42, train_batch_id: 250, avg_cost: 3.879443407058716
grad_norm: 0.48030887186256227, clipped: 0.48030887186256227
epoch: 42, train_batch_id: 300, avg_cost: 3.8496108055114746
grad_norm: 0.3047571438905022, clipped: 0.3047571438905022
epoch: 42, train_batch_id: 350, avg_cost: 3.824449300765991
grad_norm: 0.39067268812788053, clipped: 0.39067268812788053
epoch: 42, train_batch_id: 400, avg_cost: 3.8528380393981934
grad_norm: 0.3397893461313147, clipped: 0.3397893461313147
epoch: 42, train_batch_id: 450, avg_cost: 3.843700647354126
grad_norm: 0.2941886955798817, clipped: 0.2941886955798817
epoch: 42, train_batch_id: 500, avg_cost: 3.853574752807617
grad_norm: 0.3271220673414594, clipped: 0.3271220673414594
epoch: 42, train_batch_id: 550, avg_cost: 3.853309154510498
grad_norm: 0.38362941418888796, clipped: 0.38362941418888796
epoch: 42, train_batch_id: 600, avg_cost: 3.851471424102783
grad_norm: 0.41868309278700305, clipped: 0.41868309278700305
epoch: 42, train_batch_id: 650, avg_cost: 3.8498752117156982
grad_norm: 0.4462782696524059, clipped: 0.4462782696524059
epoch: 42, train_batch_id: 700, avg_cost: 3.8686017990112305
grad_norm: 0.3535952853825925, clipped: 0.3535952853825925
epoch: 42, train_batch_id: 750, avg_cost: 3.864490509033203
grad_norm: 0.5671481082990804, clipped: 0.5671481082990804
epoch: 42, train_batch_id: 800, avg_cost: 3.8522887229919434
grad_norm: 0.39900223197910845, clipped: 0.39900223197910845
epoch: 42, train_batch_id: 850, avg_cost: 3.868816375732422
grad_norm: 0.5857055098410808, clipped: 0.5857055098410808
epoch: 42, train_batch_id: 900, avg_cost: 3.862379550933838
grad_norm: 0.43837836718255685, clipped: 0.43837836718255685
epoch: 42, train_batch_id: 950, avg_cost: 3.833164691925049
grad_norm: 0.4334644036026074, clipped: 0.4334644036026074
epoch: 42, train_batch_id: 1000, avg_cost: 3.8594720363616943
grad_norm: 0.7795518069941983, clipped: 0.7795518069941983
epoch: 42, train_batch_id: 1050, avg_cost: 3.858907461166382
grad_norm: 0.38544006283147286, clipped: 0.38544006283147286
epoch: 42, train_batch_id: 1100, avg_cost: 3.835202932357788
grad_norm: 0.4170332476836251, clipped: 0.4170332476836251
epoch: 42, train_batch_id: 1150, avg_cost: 3.837315082550049
grad_norm: 0.3622815572933055, clipped: 0.3622815572933055
epoch: 42, train_batch_id: 1200, avg_cost: 3.809429407119751
grad_norm: 1.0543588518709406, clipped: 1.0
epoch: 42, train_batch_id: 1250, avg_cost: 3.851958990097046
grad_norm: 0.5385082974129807, clipped: 0.5385082974129807
epoch: 42, train_batch_id: 1300, avg_cost: 3.8566370010375977
grad_norm: 0.376712310884375, clipped: 0.376712310884375
epoch: 42, train_batch_id: 1350, avg_cost: 3.8511486053466797
grad_norm: 0.3758214347370188, clipped: 0.3758214347370188
epoch: 42, train_batch_id: 1400, avg_cost: 3.840585708618164
grad_norm: 0.462462558906124, clipped: 0.462462558906124
epoch: 42, train_batch_id: 1450, avg_cost: 3.839334011077881
grad_norm: 0.4818337046148078, clipped: 0.4818337046148078
epoch: 42, train_batch_id: 1500, avg_cost: 3.8421339988708496
grad_norm: 0.4076578607615656, clipped: 0.4076578607615656
epoch: 42, train_batch_id: 1550, avg_cost: 3.8632137775421143
grad_norm: 0.3284123423050514, clipped: 0.3284123423050514
epoch: 42, train_batch_id: 1600, avg_cost: 3.8421473503112793
grad_norm: 0.4915603050779877, clipped: 0.4915603050779877
epoch: 42, train_batch_id: 1650, avg_cost: 3.843215227127075
grad_norm: 0.46465066027402924, clipped: 0.46465066027402924
epoch: 42, train_batch_id: 1700, avg_cost: 3.80295991897583
grad_norm: 0.27077262156901094, clipped: 0.27077262156901094
epoch: 42, train_batch_id: 1750, avg_cost: 3.883103847503662
grad_norm: 0.3791983623676315, clipped: 0.3791983623676315
epoch: 42, train_batch_id: 1800, avg_cost: 3.8392138481140137
grad_norm: 0.41046510517981544, clipped: 0.41046510517981544
epoch: 42, train_batch_id: 1850, avg_cost: 3.872715950012207
grad_norm: 0.5294115006145471, clipped: 0.5294115006145471
epoch: 42, train_batch_id: 1900, avg_cost: 3.8387489318847656
grad_norm: 0.3708353091070547, clipped: 0.3708353091070547
epoch: 42, train_batch_id: 1950, avg_cost: 3.861386299133301
grad_norm: 0.2621103015104241, clipped: 0.2621103015104241
epoch: 42, train_batch_id: 2000, avg_cost: 3.8323116302490234
grad_norm: 0.43782420360418217, clipped: 0.43782420360418217
epoch: 42, train_batch_id: 2050, avg_cost: 3.851280450820923
grad_norm: 0.9151267171484077, clipped: 0.9151267171484077
epoch: 42, train_batch_id: 2100, avg_cost: 3.850630283355713
grad_norm: 0.29490953505073103, clipped: 0.29490953505073103
epoch: 42, train_batch_id: 2150, avg_cost: 3.831514835357666
grad_norm: 0.3598793654561032, clipped: 0.3598793654561032
epoch: 42, train_batch_id: 2200, avg_cost: 3.849958658218384
grad_norm: 0.3125663561807021, clipped: 0.3125663561807021
epoch: 42, train_batch_id: 2250, avg_cost: 3.849332332611084
grad_norm: 0.32481169879133, clipped: 0.32481169879133
epoch: 42, train_batch_id: 2300, avg_cost: 3.8435370922088623
grad_norm: 0.2639376363138251, clipped: 0.2639376363138251
epoch: 42, train_batch_id: 2350, avg_cost: 3.8333544731140137
grad_norm: 0.3909977916983386, clipped: 0.3909977916983386
epoch: 42, train_batch_id: 2400, avg_cost: 3.8590517044067383
grad_norm: 0.5047012172411436, clipped: 0.5047012172411436
epoch: 42, train_batch_id: 2450, avg_cost: 3.8798131942749023
grad_norm: 0.35891841176823125, clipped: 0.35891841176823125
Finished epoch 42, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.852107524871826 +- 0.0031252983026206493
Evaluating candidate model on evaluation dataset
Epoch 42 candidate mean 3.8520851135253906, baseline epoch 38 mean 3.852238655090332, difference -0.00015354156494140625
p-value: 0.3241895197883686
Start train epoch 43, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 43, train_batch_id: 0, avg_cost: 3.849177122116089
grad_norm: 0.3787573276416921, clipped: 0.3787573276416921
epoch: 43, train_batch_id: 50, avg_cost: 3.8549118041992188
grad_norm: 0.5853247606916088, clipped: 0.5853247606916088
epoch: 43, train_batch_id: 100, avg_cost: 3.811950206756592
grad_norm: 0.43647254167045224, clipped: 0.43647254167045224
epoch: 43, train_batch_id: 150, avg_cost: 3.8461194038391113
grad_norm: 0.30987960744946885, clipped: 0.30987960744946885
epoch: 43, train_batch_id: 200, avg_cost: 3.865090847015381
grad_norm: 0.7102081027446753, clipped: 0.7102081027446753
epoch: 43, train_batch_id: 250, avg_cost: 3.867961883544922
grad_norm: 0.37551893940586, clipped: 0.37551893940586
epoch: 43, train_batch_id: 300, avg_cost: 3.8631465435028076
grad_norm: 0.6200612268431692, clipped: 0.6200612268431692
epoch: 43, train_batch_id: 350, avg_cost: 3.8415420055389404
grad_norm: 0.27896617171347143, clipped: 0.27896617171347143
epoch: 43, train_batch_id: 400, avg_cost: 3.862074851989746
grad_norm: 0.3264072560546086, clipped: 0.3264072560546086
epoch: 43, train_batch_id: 450, avg_cost: 3.850916862487793
grad_norm: 0.3171437207119095, clipped: 0.3171437207119095
epoch: 43, train_batch_id: 500, avg_cost: 3.8397438526153564
grad_norm: 0.375777969245253, clipped: 0.375777969245253
epoch: 43, train_batch_id: 550, avg_cost: 3.8500161170959473
grad_norm: 0.32137433155242967, clipped: 0.32137433155242967
epoch: 43, train_batch_id: 600, avg_cost: 3.861382007598877
grad_norm: 0.33239244626735914, clipped: 0.33239244626735914
epoch: 43, train_batch_id: 650, avg_cost: 3.8571743965148926
grad_norm: 0.635353046616038, clipped: 0.635353046616038
epoch: 43, train_batch_id: 700, avg_cost: 3.8530049324035645
grad_norm: 0.5634692133945358, clipped: 0.5634692133945358
epoch: 43, train_batch_id: 750, avg_cost: 3.8542637825012207
grad_norm: 0.6930067032880691, clipped: 0.6930067032880691
epoch: 43, train_batch_id: 800, avg_cost: 3.8419747352600098
grad_norm: 0.9019238337829707, clipped: 0.9019238337829707
epoch: 43, train_batch_id: 850, avg_cost: 3.851313591003418
grad_norm: 0.5721884262708505, clipped: 0.5721884262708505
epoch: 43, train_batch_id: 900, avg_cost: 3.8686959743499756
grad_norm: 0.6955825864813003, clipped: 0.6955825864813003
epoch: 43, train_batch_id: 950, avg_cost: 3.857264518737793
grad_norm: 0.4514132024580551, clipped: 0.4514132024580551
epoch: 43, train_batch_id: 1000, avg_cost: 3.861847162246704
grad_norm: 0.3873542656752801, clipped: 0.3873542656752801
epoch: 43, train_batch_id: 1050, avg_cost: 3.839230537414551
grad_norm: 0.7890264902186609, clipped: 0.7890264902186609
epoch: 43, train_batch_id: 1100, avg_cost: 3.8692831993103027
grad_norm: 0.3903479855085564, clipped: 0.3903479855085564
epoch: 43, train_batch_id: 1150, avg_cost: 3.8390982151031494
grad_norm: 0.41154820231909744, clipped: 0.41154820231909744
epoch: 43, train_batch_id: 1200, avg_cost: 3.8383774757385254
grad_norm: 0.45952206936720824, clipped: 0.45952206936720824
epoch: 43, train_batch_id: 1250, avg_cost: 3.89170503616333
grad_norm: 0.47500167808980215, clipped: 0.47500167808980215
epoch: 43, train_batch_id: 1300, avg_cost: 3.845756769180298
grad_norm: 0.4116957889968538, clipped: 0.4116957889968538
epoch: 43, train_batch_id: 1350, avg_cost: 3.857499599456787
grad_norm: 0.2632958193647667, clipped: 0.2632958193647667
epoch: 43, train_batch_id: 1400, avg_cost: 3.8535430431365967
grad_norm: 0.5044393651698803, clipped: 0.5044393651698803
epoch: 43, train_batch_id: 1450, avg_cost: 3.8554725646972656
grad_norm: 0.36852642938451585, clipped: 0.36852642938451585
epoch: 43, train_batch_id: 1500, avg_cost: 3.8358986377716064
grad_norm: 0.5169633591680222, clipped: 0.5169633591680222
epoch: 43, train_batch_id: 1550, avg_cost: 3.8391952514648438
grad_norm: 0.35789616866667806, clipped: 0.35789616866667806
epoch: 43, train_batch_id: 1600, avg_cost: 3.8620834350585938
grad_norm: 0.35240548364138824, clipped: 0.35240548364138824
epoch: 43, train_batch_id: 1650, avg_cost: 3.8695549964904785
grad_norm: 1.382082920709544, clipped: 1.0
epoch: 43, train_batch_id: 1700, avg_cost: 3.8313024044036865
grad_norm: 0.7373586962932606, clipped: 0.7373586962932606
epoch: 43, train_batch_id: 1750, avg_cost: 3.842970848083496
grad_norm: 0.47321778488433297, clipped: 0.47321778488433297
epoch: 43, train_batch_id: 1800, avg_cost: 3.8495941162109375
grad_norm: 0.392881313163755, clipped: 0.392881313163755
epoch: 43, train_batch_id: 1850, avg_cost: 3.8609619140625
grad_norm: 0.8654746006400259, clipped: 0.8654746006400259
epoch: 43, train_batch_id: 1900, avg_cost: 3.8595504760742188
grad_norm: 0.36548062248928437, clipped: 0.36548062248928437
epoch: 43, train_batch_id: 1950, avg_cost: 3.844878673553467
grad_norm: 0.3438880774307982, clipped: 0.3438880774307982
epoch: 43, train_batch_id: 2000, avg_cost: 3.843827724456787
grad_norm: 0.24458501462892818, clipped: 0.24458501462892818
epoch: 43, train_batch_id: 2050, avg_cost: 3.83345365524292
grad_norm: 0.323318425608342, clipped: 0.323318425608342
epoch: 43, train_batch_id: 2100, avg_cost: 3.818207263946533
grad_norm: 0.339317960995767, clipped: 0.339317960995767
epoch: 43, train_batch_id: 2150, avg_cost: 3.864736318588257
grad_norm: 0.9719759226475572, clipped: 0.9719759226475572
epoch: 43, train_batch_id: 2200, avg_cost: 3.8492512702941895
grad_norm: 0.5052292403318219, clipped: 0.5052292403318219
epoch: 43, train_batch_id: 2250, avg_cost: 3.86037278175354
grad_norm: 0.2562395464000267, clipped: 0.2562395464000267
epoch: 43, train_batch_id: 2300, avg_cost: 3.8409929275512695
grad_norm: 0.531709394243819, clipped: 0.531709394243819
epoch: 43, train_batch_id: 2350, avg_cost: 3.857112407684326
grad_norm: 0.6198076412982373, clipped: 0.6198076412982373
epoch: 43, train_batch_id: 2400, avg_cost: 3.8374104499816895
grad_norm: 0.5457371805227492, clipped: 0.5457371805227492
epoch: 43, train_batch_id: 2450, avg_cost: 3.8462867736816406
grad_norm: 0.33672413127519957, clipped: 0.33672413127519957
Finished epoch 43, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8509395122528076 +- 0.0031194728799164295
Evaluating candidate model on evaluation dataset
Epoch 43 candidate mean 3.8517656326293945, baseline epoch 38 mean 3.852238655090332, difference -0.0004730224609375
p-value: 0.07260805050876944
Start train epoch 44, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 44, train_batch_id: 0, avg_cost: 3.8569412231445312
grad_norm: 0.37692193949330444, clipped: 0.37692193949330444
epoch: 44, train_batch_id: 50, avg_cost: 3.85314679145813
grad_norm: 0.5539979905236747, clipped: 0.5539979905236747
epoch: 44, train_batch_id: 100, avg_cost: 3.843554973602295
grad_norm: 0.744901363735079, clipped: 0.744901363735079
epoch: 44, train_batch_id: 150, avg_cost: 3.8418731689453125
grad_norm: 0.3480073963652924, clipped: 0.3480073963652924
epoch: 44, train_batch_id: 200, avg_cost: 3.8464229106903076
grad_norm: 0.3574271939900581, clipped: 0.3574271939900581
epoch: 44, train_batch_id: 250, avg_cost: 3.8616645336151123
grad_norm: 0.8732488457691499, clipped: 0.8732488457691499
epoch: 44, train_batch_id: 300, avg_cost: 3.8411221504211426
grad_norm: 0.32677772253302184, clipped: 0.32677772253302184
epoch: 44, train_batch_id: 350, avg_cost: 3.8304266929626465
grad_norm: 0.32332195825363036, clipped: 0.32332195825363036
epoch: 44, train_batch_id: 400, avg_cost: 3.8443222045898438
grad_norm: 0.47879704768077647, clipped: 0.47879704768077647
epoch: 44, train_batch_id: 450, avg_cost: 3.8449575901031494
grad_norm: 0.49207005059957387, clipped: 0.49207005059957387
epoch: 44, train_batch_id: 500, avg_cost: 3.8311808109283447
grad_norm: 0.28970389272732394, clipped: 0.28970389272732394
epoch: 44, train_batch_id: 550, avg_cost: 3.8509461879730225
grad_norm: 0.42376150214366254, clipped: 0.42376150214366254
epoch: 44, train_batch_id: 600, avg_cost: 3.836538314819336
grad_norm: 0.37308612388666024, clipped: 0.37308612388666024
epoch: 44, train_batch_id: 650, avg_cost: 3.848079204559326
grad_norm: 0.4848435285024777, clipped: 0.4848435285024777
epoch: 44, train_batch_id: 700, avg_cost: 3.8538684844970703
grad_norm: 0.6573934562092419, clipped: 0.6573934562092419
epoch: 44, train_batch_id: 750, avg_cost: 3.8227603435516357
grad_norm: 0.32372623949400553, clipped: 0.32372623949400553
epoch: 44, train_batch_id: 800, avg_cost: 3.856872797012329
grad_norm: 0.34634838437931664, clipped: 0.34634838437931664
epoch: 44, train_batch_id: 850, avg_cost: 3.8510146141052246
grad_norm: 0.29473612337641825, clipped: 0.29473612337641825
epoch: 44, train_batch_id: 900, avg_cost: 3.8546252250671387
grad_norm: 0.4311759777713783, clipped: 0.4311759777713783
epoch: 44, train_batch_id: 950, avg_cost: 3.8443288803100586
grad_norm: 0.5063072856724239, clipped: 0.5063072856724239
epoch: 44, train_batch_id: 1000, avg_cost: 3.8371171951293945
grad_norm: 0.33995808695702195, clipped: 0.33995808695702195
epoch: 44, train_batch_id: 1050, avg_cost: 3.866253614425659
grad_norm: 0.46243895579161665, clipped: 0.46243895579161665
epoch: 44, train_batch_id: 1100, avg_cost: 3.866983652114868
grad_norm: 0.36585920503583125, clipped: 0.36585920503583125
epoch: 44, train_batch_id: 1150, avg_cost: 3.8587374687194824
grad_norm: 0.4805338673712298, clipped: 0.4805338673712298
epoch: 44, train_batch_id: 1200, avg_cost: 3.847785472869873
grad_norm: 0.39234117440853533, clipped: 0.39234117440853533
epoch: 44, train_batch_id: 1250, avg_cost: 3.857340097427368
grad_norm: 0.46010826208112826, clipped: 0.46010826208112826
epoch: 44, train_batch_id: 1300, avg_cost: 3.847872257232666
grad_norm: 0.4375204951633982, clipped: 0.4375204951633982
epoch: 44, train_batch_id: 1350, avg_cost: 3.838404655456543
grad_norm: 0.5515637313395877, clipped: 0.5515637313395877
epoch: 44, train_batch_id: 1400, avg_cost: 3.8496692180633545
grad_norm: 0.5443842249126053, clipped: 0.5443842249126053
epoch: 44, train_batch_id: 1450, avg_cost: 3.833967447280884
grad_norm: 0.3402472359301174, clipped: 0.3402472359301174
epoch: 44, train_batch_id: 1500, avg_cost: 3.8491320610046387
grad_norm: 0.3479351336603143, clipped: 0.3479351336603143
epoch: 44, train_batch_id: 1550, avg_cost: 3.8433260917663574
grad_norm: 0.6724090948963605, clipped: 0.6724090948963605
epoch: 44, train_batch_id: 1600, avg_cost: 3.862504005432129
grad_norm: 0.39641019023506985, clipped: 0.39641019023506985
epoch: 44, train_batch_id: 1650, avg_cost: 3.828341007232666
grad_norm: 0.4998241398991033, clipped: 0.4998241398991033
epoch: 44, train_batch_id: 1700, avg_cost: 3.862572193145752
grad_norm: 1.1872736390583225, clipped: 1.0
epoch: 44, train_batch_id: 1750, avg_cost: 3.821051597595215
grad_norm: 0.2944367240138915, clipped: 0.2944367240138915
epoch: 44, train_batch_id: 1800, avg_cost: 3.8500189781188965
grad_norm: 0.41698185177813896, clipped: 0.41698185177813896
epoch: 44, train_batch_id: 1850, avg_cost: 3.8347830772399902
grad_norm: 0.28328183441811133, clipped: 0.28328183441811133
epoch: 44, train_batch_id: 1900, avg_cost: 3.8556971549987793
grad_norm: 0.33995811816317684, clipped: 0.33995811816317684
epoch: 44, train_batch_id: 1950, avg_cost: 3.829367160797119
grad_norm: 0.38604061135418366, clipped: 0.38604061135418366
epoch: 44, train_batch_id: 2000, avg_cost: 3.8304014205932617
grad_norm: 0.6444898312516412, clipped: 0.6444898312516412
epoch: 44, train_batch_id: 2050, avg_cost: 3.8759021759033203
grad_norm: 0.599873324305291, clipped: 0.599873324305291
epoch: 44, train_batch_id: 2100, avg_cost: 3.857877731323242
grad_norm: 0.5054167179573757, clipped: 0.5054167179573757
epoch: 44, train_batch_id: 2150, avg_cost: 3.8690617084503174
grad_norm: 0.8849441267651845, clipped: 0.8849441267651845
epoch: 44, train_batch_id: 2200, avg_cost: 3.847090721130371
grad_norm: 0.5372913328614455, clipped: 0.5372913328614455
epoch: 44, train_batch_id: 2250, avg_cost: 3.849500894546509
grad_norm: 0.5557580008373337, clipped: 0.5557580008373337
epoch: 44, train_batch_id: 2300, avg_cost: 3.8441288471221924
grad_norm: 0.8567468948794056, clipped: 0.8567468948794056
epoch: 44, train_batch_id: 2350, avg_cost: 3.848038673400879
grad_norm: 0.42351599494614434, clipped: 0.42351599494614434
epoch: 44, train_batch_id: 2400, avg_cost: 3.8593201637268066
grad_norm: 0.8096917261917524, clipped: 0.8096917261917524
epoch: 44, train_batch_id: 2450, avg_cost: 3.8655526638031006
grad_norm: 0.43014592412128133, clipped: 0.43014592412128133
Finished epoch 44, took 00:05:30 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8504438400268555 +- 0.003113999729976058
Evaluating candidate model on evaluation dataset
Epoch 44 candidate mean 3.8507590293884277, baseline epoch 38 mean 3.852238655090332, difference -0.0014796257019042969
p-value: 3.980947561894156e-06
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 45, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 45, train_batch_id: 0, avg_cost: 3.846405029296875
grad_norm: 0.3239632116923343, clipped: 0.3239632116923343
epoch: 45, train_batch_id: 50, avg_cost: 3.8610315322875977
grad_norm: 0.26474664403608966, clipped: 0.26474664403608966
epoch: 45, train_batch_id: 100, avg_cost: 3.8486337661743164
grad_norm: 0.6768217722484015, clipped: 0.6768217722484015
epoch: 45, train_batch_id: 150, avg_cost: 3.842664957046509
grad_norm: 0.3515398286394718, clipped: 0.3515398286394718
epoch: 45, train_batch_id: 200, avg_cost: 3.865889549255371
grad_norm: 0.5202489994741757, clipped: 0.5202489994741757
epoch: 45, train_batch_id: 250, avg_cost: 3.8454039096832275
grad_norm: 0.44480402347647074, clipped: 0.44480402347647074
epoch: 45, train_batch_id: 300, avg_cost: 3.8390870094299316
grad_norm: 0.3289478335729674, clipped: 0.3289478335729674
epoch: 45, train_batch_id: 350, avg_cost: 3.857069492340088
grad_norm: 0.9183302234453913, clipped: 0.9183302234453913
epoch: 45, train_batch_id: 400, avg_cost: 3.8573713302612305
grad_norm: 0.7503755388587862, clipped: 0.7503755388587862
epoch: 45, train_batch_id: 450, avg_cost: 3.8702192306518555
grad_norm: 0.3661266772787713, clipped: 0.3661266772787713
epoch: 45, train_batch_id: 500, avg_cost: 3.8626599311828613
grad_norm: 0.4001239029703747, clipped: 0.4001239029703747
epoch: 45, train_batch_id: 550, avg_cost: 3.8493258953094482
grad_norm: 0.30925684312975704, clipped: 0.30925684312975704
epoch: 45, train_batch_id: 600, avg_cost: 3.8512237071990967
grad_norm: 0.4610949671013964, clipped: 0.4610949671013964
epoch: 45, train_batch_id: 650, avg_cost: 3.8748650550842285
grad_norm: 0.28120493051044443, clipped: 0.28120493051044443
epoch: 45, train_batch_id: 700, avg_cost: 3.8569588661193848
grad_norm: 0.35519528618689705, clipped: 0.35519528618689705
epoch: 45, train_batch_id: 750, avg_cost: 3.839634418487549
grad_norm: 0.33896376002270723, clipped: 0.33896376002270723
epoch: 45, train_batch_id: 800, avg_cost: 3.8341012001037598
grad_norm: 0.4661844721203652, clipped: 0.4661844721203652
epoch: 45, train_batch_id: 850, avg_cost: 3.8650333881378174
grad_norm: 0.5337125082026717, clipped: 0.5337125082026717
epoch: 45, train_batch_id: 900, avg_cost: 3.8709917068481445
grad_norm: 0.4309278593528981, clipped: 0.4309278593528981
epoch: 45, train_batch_id: 950, avg_cost: 3.857076644897461
grad_norm: 0.3447622718955592, clipped: 0.3447622718955592
epoch: 45, train_batch_id: 1000, avg_cost: 3.8456850051879883
grad_norm: 0.6895367328694108, clipped: 0.6895367328694108
epoch: 45, train_batch_id: 1050, avg_cost: 3.8247194290161133
grad_norm: 0.3723115521401226, clipped: 0.3723115521401226
epoch: 45, train_batch_id: 1100, avg_cost: 3.870269298553467
grad_norm: 0.5572330492223094, clipped: 0.5572330492223094
epoch: 45, train_batch_id: 1150, avg_cost: 3.8533191680908203
grad_norm: 1.2551366165457376, clipped: 1.0
epoch: 45, train_batch_id: 1200, avg_cost: 3.845099449157715
grad_norm: 0.4027222659829799, clipped: 0.4027222659829799
epoch: 45, train_batch_id: 1250, avg_cost: 3.843263626098633
grad_norm: 0.35774573147840094, clipped: 0.35774573147840094
epoch: 45, train_batch_id: 1300, avg_cost: 3.8382115364074707
grad_norm: 0.5317412859101763, clipped: 0.5317412859101763
epoch: 45, train_batch_id: 1350, avg_cost: 3.8526501655578613
grad_norm: 0.3329498863083598, clipped: 0.3329498863083598
epoch: 45, train_batch_id: 1400, avg_cost: 3.851707935333252
grad_norm: 0.36833513151707314, clipped: 0.36833513151707314
epoch: 45, train_batch_id: 1450, avg_cost: 3.8406481742858887
grad_norm: 0.41996235862204306, clipped: 0.41996235862204306
epoch: 45, train_batch_id: 1500, avg_cost: 3.844461441040039
grad_norm: 0.2455093664544554, clipped: 0.2455093664544554
epoch: 45, train_batch_id: 1550, avg_cost: 3.834963083267212
grad_norm: 1.061359106730497, clipped: 1.0
epoch: 45, train_batch_id: 1600, avg_cost: 3.843355655670166
grad_norm: 0.34432884677255265, clipped: 0.34432884677255265
epoch: 45, train_batch_id: 1650, avg_cost: 3.8590829372406006
grad_norm: 0.36219124211405224, clipped: 0.36219124211405224
epoch: 45, train_batch_id: 1700, avg_cost: 3.8340156078338623
grad_norm: 0.38954786273992226, clipped: 0.38954786273992226
epoch: 45, train_batch_id: 1750, avg_cost: 3.8371992111206055
grad_norm: 0.4004601058212855, clipped: 0.4004601058212855
epoch: 45, train_batch_id: 1800, avg_cost: 3.8396363258361816
grad_norm: 0.516615755913189, clipped: 0.516615755913189
epoch: 45, train_batch_id: 1850, avg_cost: 3.842411518096924
grad_norm: 0.3122208679288692, clipped: 0.3122208679288692
epoch: 45, train_batch_id: 1900, avg_cost: 3.8693432807922363
grad_norm: 0.46470723885568294, clipped: 0.46470723885568294
epoch: 45, train_batch_id: 1950, avg_cost: 3.8524866104125977
grad_norm: 0.6040475963766764, clipped: 0.6040475963766764
epoch: 45, train_batch_id: 2000, avg_cost: 3.8584837913513184
grad_norm: 0.45251139103826726, clipped: 0.45251139103826726
epoch: 45, train_batch_id: 2050, avg_cost: 3.833400249481201
grad_norm: 0.2852664626109299, clipped: 0.2852664626109299
epoch: 45, train_batch_id: 2100, avg_cost: 3.812898635864258
grad_norm: 0.4763127962673769, clipped: 0.4763127962673769
epoch: 45, train_batch_id: 2150, avg_cost: 3.8351526260375977
grad_norm: 0.3608229405079068, clipped: 0.3608229405079068
epoch: 45, train_batch_id: 2200, avg_cost: 3.845818042755127
grad_norm: 0.36994410419066703, clipped: 0.36994410419066703
epoch: 45, train_batch_id: 2250, avg_cost: 3.822906970977783
grad_norm: 0.42081391594222983, clipped: 0.42081391594222983
epoch: 45, train_batch_id: 2300, avg_cost: 3.8635430335998535
grad_norm: 0.4671780156500498, clipped: 0.4671780156500498
epoch: 45, train_batch_id: 2350, avg_cost: 3.829723834991455
grad_norm: 0.6105293337648909, clipped: 0.6105293337648909
epoch: 45, train_batch_id: 2400, avg_cost: 3.8298346996307373
grad_norm: 0.35574837805121956, clipped: 0.35574837805121956
epoch: 45, train_batch_id: 2450, avg_cost: 3.814805507659912
grad_norm: 0.5777352507051615, clipped: 0.5777352507051615
Finished epoch 45, took 00:05:30 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8521952629089355 +- 0.0031248547602444887
Evaluating candidate model on evaluation dataset
Epoch 45 candidate mean 3.8493669033050537, baseline epoch 44 mean 3.846721887588501, difference 0.0026450157165527344
Start train epoch 46, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 46, train_batch_id: 0, avg_cost: 3.850860595703125
grad_norm: 0.40702564135436214, clipped: 0.40702564135436214
epoch: 46, train_batch_id: 50, avg_cost: 3.857496738433838
grad_norm: 0.43545310850043684, clipped: 0.43545310850043684
epoch: 46, train_batch_id: 100, avg_cost: 3.8674159049987793
grad_norm: 1.6621510418778929, clipped: 1.0
epoch: 46, train_batch_id: 150, avg_cost: 3.863590717315674
grad_norm: 0.3739453450284711, clipped: 0.3739453450284711
epoch: 46, train_batch_id: 200, avg_cost: 3.8562042713165283
grad_norm: 0.5156602369552777, clipped: 0.5156602369552777
epoch: 46, train_batch_id: 250, avg_cost: 3.845207452774048
grad_norm: 0.5779906363686019, clipped: 0.5779906363686019
epoch: 46, train_batch_id: 300, avg_cost: 3.878539562225342
grad_norm: 0.9303216594724419, clipped: 0.9303216594724419
epoch: 46, train_batch_id: 350, avg_cost: 3.844959259033203
grad_norm: 0.4926996739889885, clipped: 0.4926996739889885
epoch: 46, train_batch_id: 400, avg_cost: 3.854801654815674
grad_norm: 0.4422589289287509, clipped: 0.4422589289287509
epoch: 46, train_batch_id: 450, avg_cost: 3.8555994033813477
grad_norm: 0.35480817041884044, clipped: 0.35480817041884044
epoch: 46, train_batch_id: 500, avg_cost: 3.85444974899292
grad_norm: 0.48771922563971054, clipped: 0.48771922563971054
epoch: 46, train_batch_id: 550, avg_cost: 3.844416618347168
grad_norm: 0.6673211242872589, clipped: 0.6673211242872589
epoch: 46, train_batch_id: 600, avg_cost: 3.8478713035583496
grad_norm: 0.3735364007496387, clipped: 0.3735364007496387
epoch: 46, train_batch_id: 650, avg_cost: 3.845602512359619
grad_norm: 0.36978777871168805, clipped: 0.36978777871168805
epoch: 46, train_batch_id: 700, avg_cost: 3.8497142791748047
grad_norm: 0.4828368076400794, clipped: 0.4828368076400794
epoch: 46, train_batch_id: 750, avg_cost: 3.8510618209838867
grad_norm: 0.3208651388193089, clipped: 0.3208651388193089
epoch: 46, train_batch_id: 800, avg_cost: 3.8430278301239014
grad_norm: 0.48216655202161307, clipped: 0.48216655202161307
epoch: 46, train_batch_id: 850, avg_cost: 3.8469114303588867
grad_norm: 0.30302011788243355, clipped: 0.30302011788243355
epoch: 46, train_batch_id: 900, avg_cost: 3.862096071243286
grad_norm: 0.3424942743864668, clipped: 0.3424942743864668
epoch: 46, train_batch_id: 950, avg_cost: 3.873293399810791
grad_norm: 0.5315471366788084, clipped: 0.5315471366788084
epoch: 46, train_batch_id: 1000, avg_cost: 3.8403353691101074
grad_norm: 0.4428906606251292, clipped: 0.4428906606251292
epoch: 46, train_batch_id: 1050, avg_cost: 3.852349281311035
grad_norm: 1.1006221780541674, clipped: 1.0
epoch: 46, train_batch_id: 1100, avg_cost: 3.855926513671875
grad_norm: 0.41206635693615035, clipped: 0.41206635693615035
epoch: 46, train_batch_id: 1150, avg_cost: 3.8496084213256836
grad_norm: 0.3837085080567922, clipped: 0.3837085080567922
epoch: 46, train_batch_id: 1200, avg_cost: 3.8311147689819336
grad_norm: 0.3518452554728238, clipped: 0.3518452554728238
epoch: 46, train_batch_id: 1250, avg_cost: 3.8220982551574707
grad_norm: 0.39655215686567546, clipped: 0.39655215686567546
epoch: 46, train_batch_id: 1300, avg_cost: 3.8663153648376465
grad_norm: 0.4438013313287415, clipped: 0.4438013313287415
epoch: 46, train_batch_id: 1350, avg_cost: 3.8383259773254395
grad_norm: 0.4714407190753844, clipped: 0.4714407190753844
epoch: 46, train_batch_id: 1400, avg_cost: 3.8477272987365723
grad_norm: 0.2367868182969186, clipped: 0.2367868182969186
epoch: 46, train_batch_id: 1450, avg_cost: 3.8391318321228027
grad_norm: 0.42162402360563883, clipped: 0.42162402360563883
epoch: 46, train_batch_id: 1500, avg_cost: 3.8548336029052734
grad_norm: 0.41556429202996686, clipped: 0.41556429202996686
epoch: 46, train_batch_id: 1550, avg_cost: 3.857516288757324
grad_norm: 0.2832743276453392, clipped: 0.2832743276453392
epoch: 46, train_batch_id: 1600, avg_cost: 3.853147268295288
grad_norm: 0.3889513432929804, clipped: 0.3889513432929804
epoch: 46, train_batch_id: 1650, avg_cost: 3.8447818756103516
grad_norm: 0.4221719306428949, clipped: 0.4221719306428949
epoch: 46, train_batch_id: 1700, avg_cost: 3.8575518131256104
grad_norm: 0.8482858710117175, clipped: 0.8482858710117175
epoch: 46, train_batch_id: 1750, avg_cost: 3.8250441551208496
grad_norm: 0.8519787795830724, clipped: 0.8519787795830724
epoch: 46, train_batch_id: 1800, avg_cost: 3.8405139446258545
grad_norm: 0.40658643088807395, clipped: 0.40658643088807395
epoch: 46, train_batch_id: 1850, avg_cost: 3.8487138748168945
grad_norm: 0.4901066326073523, clipped: 0.4901066326073523
epoch: 46, train_batch_id: 1900, avg_cost: 3.83577299118042
grad_norm: 0.3014227772188873, clipped: 0.3014227772188873
epoch: 46, train_batch_id: 1950, avg_cost: 3.8523738384246826
grad_norm: 0.3757498011889366, clipped: 0.3757498011889366
epoch: 46, train_batch_id: 2000, avg_cost: 3.865312099456787
grad_norm: 0.6136493098674782, clipped: 0.6136493098674782
epoch: 46, train_batch_id: 2050, avg_cost: 3.8497657775878906
grad_norm: 0.48621130112521, clipped: 0.48621130112521
epoch: 46, train_batch_id: 2100, avg_cost: 3.8256404399871826
grad_norm: 0.38319730669172813, clipped: 0.38319730669172813
epoch: 46, train_batch_id: 2150, avg_cost: 3.83469557762146
grad_norm: 0.3108786866472107, clipped: 0.3108786866472107
epoch: 46, train_batch_id: 2200, avg_cost: 3.8691611289978027
grad_norm: 0.3465253134794539, clipped: 0.3465253134794539
epoch: 46, train_batch_id: 2250, avg_cost: 3.846579074859619
grad_norm: 0.2901830090397023, clipped: 0.2901830090397023
epoch: 46, train_batch_id: 2300, avg_cost: 3.840792655944824
grad_norm: 0.3676458256914152, clipped: 0.3676458256914152
epoch: 46, train_batch_id: 2350, avg_cost: 3.8446335792541504
grad_norm: 0.34034491868000877, clipped: 0.34034491868000877
epoch: 46, train_batch_id: 2400, avg_cost: 3.8525516986846924
grad_norm: 0.3702674613101122, clipped: 0.3702674613101122
epoch: 46, train_batch_id: 2450, avg_cost: 3.8517885208129883
grad_norm: 0.39888592979563087, clipped: 0.39888592979563087
Finished epoch 46, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8496994972229004 +- 0.0031171089503914118
Evaluating candidate model on evaluation dataset
Epoch 46 candidate mean 3.8460633754730225, baseline epoch 44 mean 3.846721887588501, difference -0.0006585121154785156
p-value: 0.011040935787328347
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 47, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 47, train_batch_id: 0, avg_cost: 3.8323287963867188
grad_norm: 0.37817761771412667, clipped: 0.37817761771412667
epoch: 47, train_batch_id: 50, avg_cost: 3.850536823272705
grad_norm: 0.36699899947169473, clipped: 0.36699899947169473
epoch: 47, train_batch_id: 100, avg_cost: 3.852991819381714
grad_norm: 0.23453729003921925, clipped: 0.23453729003921925
epoch: 47, train_batch_id: 150, avg_cost: 3.8435211181640625
grad_norm: 0.3710695038584033, clipped: 0.3710695038584033
epoch: 47, train_batch_id: 200, avg_cost: 3.831165075302124
grad_norm: 0.45027005183652213, clipped: 0.45027005183652213
epoch: 47, train_batch_id: 250, avg_cost: 3.8523802757263184
grad_norm: 0.372444402033218, clipped: 0.372444402033218
epoch: 47, train_batch_id: 300, avg_cost: 3.8510873317718506
grad_norm: 0.30080383453399817, clipped: 0.30080383453399817
epoch: 47, train_batch_id: 350, avg_cost: 3.858565330505371
grad_norm: 0.6041581327314779, clipped: 0.6041581327314779
epoch: 47, train_batch_id: 400, avg_cost: 3.861206531524658
grad_norm: 0.27225716459798344, clipped: 0.27225716459798344
epoch: 47, train_batch_id: 450, avg_cost: 3.86016845703125
grad_norm: 0.43730921180269894, clipped: 0.43730921180269894
epoch: 47, train_batch_id: 500, avg_cost: 3.835961103439331
grad_norm: 0.41773206957559833, clipped: 0.41773206957559833
epoch: 47, train_batch_id: 550, avg_cost: 3.871389389038086
grad_norm: 0.5908427640713182, clipped: 0.5908427640713182
epoch: 47, train_batch_id: 600, avg_cost: 3.842282772064209
grad_norm: 0.500655860499951, clipped: 0.500655860499951
epoch: 47, train_batch_id: 650, avg_cost: 3.8417763710021973
grad_norm: 0.5131478470875365, clipped: 0.5131478470875365
epoch: 47, train_batch_id: 700, avg_cost: 3.8661916255950928
grad_norm: 0.35140893300061793, clipped: 0.35140893300061793
epoch: 47, train_batch_id: 750, avg_cost: 3.8733696937561035
grad_norm: 0.47456718943398263, clipped: 0.47456718943398263
epoch: 47, train_batch_id: 800, avg_cost: 3.8637337684631348
grad_norm: 0.3456538078479455, clipped: 0.3456538078479455
epoch: 47, train_batch_id: 850, avg_cost: 3.858083724975586
grad_norm: 0.34674117340273797, clipped: 0.34674117340273797
epoch: 47, train_batch_id: 900, avg_cost: 3.843376398086548
grad_norm: 0.6684070582583733, clipped: 0.6684070582583733
epoch: 47, train_batch_id: 950, avg_cost: 3.8422040939331055
grad_norm: 0.36061050025689895, clipped: 0.36061050025689895
epoch: 47, train_batch_id: 1000, avg_cost: 3.848080635070801
grad_norm: 0.38843202297154195, clipped: 0.38843202297154195
epoch: 47, train_batch_id: 1050, avg_cost: 3.854769706726074
grad_norm: 0.4385045547349134, clipped: 0.4385045547349134
epoch: 47, train_batch_id: 1100, avg_cost: 3.827237606048584
grad_norm: 0.3916080037127204, clipped: 0.3916080037127204
epoch: 47, train_batch_id: 1150, avg_cost: 3.8510801792144775
grad_norm: 0.3817650814051412, clipped: 0.3817650814051412
epoch: 47, train_batch_id: 1200, avg_cost: 3.8472938537597656
grad_norm: 0.31079546651488915, clipped: 0.31079546651488915
epoch: 47, train_batch_id: 1250, avg_cost: 3.8396530151367188
grad_norm: 0.4727198203381313, clipped: 0.4727198203381313
epoch: 47, train_batch_id: 1300, avg_cost: 3.8598594665527344
grad_norm: 0.390103800289823, clipped: 0.390103800289823
epoch: 47, train_batch_id: 1350, avg_cost: 3.8760673999786377
grad_norm: 0.4417203020333393, clipped: 0.4417203020333393
epoch: 47, train_batch_id: 1400, avg_cost: 3.8332419395446777
grad_norm: 0.5047748900907443, clipped: 0.5047748900907443
epoch: 47, train_batch_id: 1450, avg_cost: 3.8715877532958984
grad_norm: 0.8685662516339169, clipped: 0.8685662516339169
epoch: 47, train_batch_id: 1500, avg_cost: 3.8560845851898193
grad_norm: 0.46899821267903263, clipped: 0.46899821267903263
epoch: 47, train_batch_id: 1550, avg_cost: 3.844531536102295
grad_norm: 0.3842818875569194, clipped: 0.3842818875569194
epoch: 47, train_batch_id: 1600, avg_cost: 3.860445499420166
grad_norm: 0.355415075518553, clipped: 0.355415075518553
epoch: 47, train_batch_id: 1650, avg_cost: 3.8519604206085205
grad_norm: 0.7295059329823973, clipped: 0.7295059329823973
epoch: 47, train_batch_id: 1700, avg_cost: 3.8585076332092285
grad_norm: 0.43136067781717724, clipped: 0.43136067781717724
epoch: 47, train_batch_id: 1750, avg_cost: 3.8455891609191895
grad_norm: 0.3512927948198682, clipped: 0.3512927948198682
epoch: 47, train_batch_id: 1800, avg_cost: 3.860443353652954
grad_norm: 0.37045061074245705, clipped: 0.37045061074245705
epoch: 47, train_batch_id: 1850, avg_cost: 3.8432137966156006
grad_norm: 0.27539356569779144, clipped: 0.27539356569779144
epoch: 47, train_batch_id: 1900, avg_cost: 3.8535513877868652
grad_norm: 0.3594092661705808, clipped: 0.3594092661705808
epoch: 47, train_batch_id: 1950, avg_cost: 3.8617970943450928
grad_norm: 0.3770683519264205, clipped: 0.3770683519264205
epoch: 47, train_batch_id: 2000, avg_cost: 3.8538198471069336
grad_norm: 0.3255771005950861, clipped: 0.3255771005950861
epoch: 47, train_batch_id: 2050, avg_cost: 3.843456506729126
grad_norm: 0.30544548035618907, clipped: 0.30544548035618907
epoch: 47, train_batch_id: 2100, avg_cost: 3.855060577392578
grad_norm: 0.45105693898013544, clipped: 0.45105693898013544
epoch: 47, train_batch_id: 2150, avg_cost: 3.859769821166992
grad_norm: 0.655826774241121, clipped: 0.655826774241121
epoch: 47, train_batch_id: 2200, avg_cost: 3.8750762939453125
grad_norm: 0.3927996383894661, clipped: 0.3927996383894661
epoch: 47, train_batch_id: 2250, avg_cost: 3.814488410949707
grad_norm: 0.41036185873610664, clipped: 0.41036185873610664
epoch: 47, train_batch_id: 2300, avg_cost: 3.868119716644287
grad_norm: 0.4131413063745004, clipped: 0.4131413063745004
epoch: 47, train_batch_id: 2350, avg_cost: 3.8536219596862793
grad_norm: 0.4177514653587956, clipped: 0.4177514653587956
epoch: 47, train_batch_id: 2400, avg_cost: 3.848606586456299
grad_norm: 0.283256072866691, clipped: 0.283256072866691
epoch: 47, train_batch_id: 2450, avg_cost: 3.876298189163208
grad_norm: 0.47554004417709195, clipped: 0.47554004417709195
Finished epoch 47, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.850065231323242 +- 0.0031134760938584805
Evaluating candidate model on evaluation dataset
Epoch 47 candidate mean 3.8518285751342773, baseline epoch 46 mean 3.850921869277954, difference 0.0009067058563232422
Start train epoch 48, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 48, train_batch_id: 0, avg_cost: 3.8297972679138184
grad_norm: 0.4065117816380154, clipped: 0.4065117816380154
epoch: 48, train_batch_id: 50, avg_cost: 3.847870349884033
grad_norm: 0.5570405722227894, clipped: 0.5570405722227894
epoch: 48, train_batch_id: 100, avg_cost: 3.8432457447052
grad_norm: 0.5600130313123519, clipped: 0.5600130313123519
epoch: 48, train_batch_id: 150, avg_cost: 3.869069814682007
grad_norm: 0.5471483269079642, clipped: 0.5471483269079642
epoch: 48, train_batch_id: 200, avg_cost: 3.8172459602355957
grad_norm: 0.34861622051021907, clipped: 0.34861622051021907
epoch: 48, train_batch_id: 250, avg_cost: 3.858105182647705
grad_norm: 0.40739016340408307, clipped: 0.40739016340408307
epoch: 48, train_batch_id: 300, avg_cost: 3.8664650917053223
grad_norm: 0.48169805928565046, clipped: 0.48169805928565046
epoch: 48, train_batch_id: 350, avg_cost: 3.872187376022339
grad_norm: 0.7029572403591781, clipped: 0.7029572403591781
epoch: 48, train_batch_id: 400, avg_cost: 3.857118606567383
grad_norm: 0.42027907321115804, clipped: 0.42027907321115804
epoch: 48, train_batch_id: 450, avg_cost: 3.85689640045166
grad_norm: 0.5919317177488695, clipped: 0.5919317177488695
epoch: 48, train_batch_id: 500, avg_cost: 3.840040683746338
grad_norm: 0.5871930411556853, clipped: 0.5871930411556853
epoch: 48, train_batch_id: 550, avg_cost: 3.8600707054138184
grad_norm: 0.28099392597228506, clipped: 0.28099392597228506
epoch: 48, train_batch_id: 600, avg_cost: 3.8408071994781494
grad_norm: 0.3952875803677356, clipped: 0.3952875803677356
epoch: 48, train_batch_id: 650, avg_cost: 3.8597116470336914
grad_norm: 0.28822778348621225, clipped: 0.28822778348621225
epoch: 48, train_batch_id: 700, avg_cost: 3.841935634613037
grad_norm: 0.5866262550901672, clipped: 0.5866262550901672
epoch: 48, train_batch_id: 750, avg_cost: 3.854626178741455
grad_norm: 0.4418276143269796, clipped: 0.4418276143269796
epoch: 48, train_batch_id: 800, avg_cost: 3.8415403366088867
grad_norm: 0.2779362270323021, clipped: 0.2779362270323021
epoch: 48, train_batch_id: 850, avg_cost: 3.8494105339050293
grad_norm: 0.5132080354681445, clipped: 0.5132080354681445
epoch: 48, train_batch_id: 900, avg_cost: 3.862675428390503
grad_norm: 0.3269987710809239, clipped: 0.3269987710809239
epoch: 48, train_batch_id: 950, avg_cost: 3.8757855892181396
grad_norm: 0.3462006222102527, clipped: 0.3462006222102527
epoch: 48, train_batch_id: 1000, avg_cost: 3.853541851043701
grad_norm: 0.361140081803133, clipped: 0.361140081803133
epoch: 48, train_batch_id: 1050, avg_cost: 3.8243978023529053
grad_norm: 0.3037852590436763, clipped: 0.3037852590436763
epoch: 48, train_batch_id: 1100, avg_cost: 3.8524861335754395
grad_norm: 0.3294142935627912, clipped: 0.3294142935627912
epoch: 48, train_batch_id: 1150, avg_cost: 3.851276397705078
grad_norm: 0.44121346734844213, clipped: 0.44121346734844213
epoch: 48, train_batch_id: 1200, avg_cost: 3.8437445163726807
grad_norm: 0.44114628259087746, clipped: 0.44114628259087746
epoch: 48, train_batch_id: 1250, avg_cost: 3.8597991466522217
grad_norm: 0.37303989480875455, clipped: 0.37303989480875455
epoch: 48, train_batch_id: 1300, avg_cost: 3.8525490760803223
grad_norm: 0.4378109631942832, clipped: 0.4378109631942832
epoch: 48, train_batch_id: 1350, avg_cost: 3.848731279373169
grad_norm: 0.2882933558350519, clipped: 0.2882933558350519
epoch: 48, train_batch_id: 1400, avg_cost: 3.8373911380767822
grad_norm: 0.3974987240301256, clipped: 0.3974987240301256
epoch: 48, train_batch_id: 1450, avg_cost: 3.8510982990264893
grad_norm: 0.3314477339018162, clipped: 0.3314477339018162
epoch: 48, train_batch_id: 1500, avg_cost: 3.8416337966918945
grad_norm: 0.2900734585920654, clipped: 0.2900734585920654
epoch: 48, train_batch_id: 1550, avg_cost: 3.8416638374328613
grad_norm: 0.3211358827762318, clipped: 0.3211358827762318
epoch: 48, train_batch_id: 1600, avg_cost: 3.8359458446502686
grad_norm: 0.3239183255942933, clipped: 0.3239183255942933
epoch: 48, train_batch_id: 1650, avg_cost: 3.869886875152588
grad_norm: 1.199484072823027, clipped: 1.0
epoch: 48, train_batch_id: 1700, avg_cost: 3.8563294410705566
grad_norm: 0.35897353770011786, clipped: 0.35897353770011786
epoch: 48, train_batch_id: 1750, avg_cost: 3.8337788581848145
grad_norm: 0.1977741107086801, clipped: 0.1977741107086801
epoch: 48, train_batch_id: 1800, avg_cost: 3.8361778259277344
grad_norm: 0.35438037920368115, clipped: 0.35438037920368115
epoch: 48, train_batch_id: 1850, avg_cost: 3.866316318511963
grad_norm: 0.3702474463777358, clipped: 0.3702474463777358
epoch: 48, train_batch_id: 1900, avg_cost: 3.836648464202881
grad_norm: 0.6687599763257328, clipped: 0.6687599763257328
epoch: 48, train_batch_id: 1950, avg_cost: 3.8464322090148926
grad_norm: 0.41482790467777425, clipped: 0.41482790467777425
epoch: 48, train_batch_id: 2000, avg_cost: 3.851684093475342
grad_norm: 0.2834108641040155, clipped: 0.2834108641040155
epoch: 48, train_batch_id: 2050, avg_cost: 3.870278835296631
grad_norm: 0.3402064167868371, clipped: 0.3402064167868371
epoch: 48, train_batch_id: 2100, avg_cost: 3.8516485691070557
grad_norm: 0.40429641673269445, clipped: 0.40429641673269445
epoch: 48, train_batch_id: 2150, avg_cost: 3.862370252609253
grad_norm: 0.5374802887935634, clipped: 0.5374802887935634
epoch: 48, train_batch_id: 2200, avg_cost: 3.8628358840942383
grad_norm: 0.5460205890529853, clipped: 0.5460205890529853
epoch: 48, train_batch_id: 2250, avg_cost: 3.8464550971984863
grad_norm: 0.38998612513209113, clipped: 0.38998612513209113
epoch: 48, train_batch_id: 2300, avg_cost: 3.859133243560791
grad_norm: 0.45730180513549445, clipped: 0.45730180513549445
epoch: 48, train_batch_id: 2350, avg_cost: 3.8596630096435547
grad_norm: 0.5624208512448973, clipped: 0.5624208512448973
epoch: 48, train_batch_id: 2400, avg_cost: 3.8410677909851074
grad_norm: 0.3204072821610286, clipped: 0.3204072821610286
epoch: 48, train_batch_id: 2450, avg_cost: 3.850983142852783
grad_norm: 0.4106207705497068, clipped: 0.4106207705497068
Finished epoch 48, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.849092483520508 +- 0.003114660270512104
Evaluating candidate model on evaluation dataset
Epoch 48 candidate mean 3.8501265048980713, baseline epoch 46 mean 3.850921869277954, difference -0.0007953643798828125
p-value: 0.004214530435162641
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 49, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 49, train_batch_id: 0, avg_cost: 3.8223891258239746
grad_norm: 0.4715203866518974, clipped: 0.4715203866518974
epoch: 49, train_batch_id: 50, avg_cost: 3.8535289764404297
grad_norm: 0.33272115917289297, clipped: 0.33272115917289297
epoch: 49, train_batch_id: 100, avg_cost: 3.8445234298706055
grad_norm: 0.6007621544907076, clipped: 0.6007621544907076
epoch: 49, train_batch_id: 150, avg_cost: 3.8370590209960938
grad_norm: 0.3820003945432138, clipped: 0.3820003945432138
epoch: 49, train_batch_id: 200, avg_cost: 3.8437654972076416
grad_norm: 0.32199833448169485, clipped: 0.32199833448169485
epoch: 49, train_batch_id: 250, avg_cost: 3.8562443256378174
grad_norm: 0.38994693522306695, clipped: 0.38994693522306695
epoch: 49, train_batch_id: 300, avg_cost: 3.829987049102783
grad_norm: 0.3594426959041214, clipped: 0.3594426959041214
epoch: 49, train_batch_id: 350, avg_cost: 3.8480324745178223
grad_norm: 0.3075549211131461, clipped: 0.3075549211131461
epoch: 49, train_batch_id: 400, avg_cost: 3.8546133041381836
grad_norm: 0.41045551448115936, clipped: 0.41045551448115936
epoch: 49, train_batch_id: 450, avg_cost: 3.8488576412200928
grad_norm: 0.4331038092438166, clipped: 0.4331038092438166
epoch: 49, train_batch_id: 500, avg_cost: 3.8487863540649414
grad_norm: 0.7539588496427506, clipped: 0.7539588496427506
epoch: 49, train_batch_id: 550, avg_cost: 3.8587722778320312
grad_norm: 1.8178494047248333, clipped: 1.0
epoch: 49, train_batch_id: 600, avg_cost: 3.8713924884796143
grad_norm: 0.3327711912844447, clipped: 0.3327711912844447
epoch: 49, train_batch_id: 650, avg_cost: 3.844475507736206
grad_norm: 0.3722764480927717, clipped: 0.3722764480927717
epoch: 49, train_batch_id: 700, avg_cost: 3.8545827865600586
grad_norm: 0.4006828482194213, clipped: 0.4006828482194213
epoch: 49, train_batch_id: 750, avg_cost: 3.8376851081848145
grad_norm: 0.35823668180283846, clipped: 0.35823668180283846
epoch: 49, train_batch_id: 800, avg_cost: 3.8373522758483887
grad_norm: 0.3370017907570119, clipped: 0.3370017907570119
epoch: 49, train_batch_id: 850, avg_cost: 3.8487377166748047
grad_norm: 0.3964215033320938, clipped: 0.3964215033320938
epoch: 49, train_batch_id: 900, avg_cost: 3.8883280754089355
grad_norm: 0.5158375392058273, clipped: 0.5158375392058273
epoch: 49, train_batch_id: 950, avg_cost: 3.829578161239624
grad_norm: 0.39820788280554015, clipped: 0.39820788280554015
epoch: 49, train_batch_id: 1000, avg_cost: 3.829402446746826
grad_norm: 0.32512865835226556, clipped: 0.32512865835226556
epoch: 49, train_batch_id: 1050, avg_cost: 3.8715484142303467
grad_norm: 0.4357601723263417, clipped: 0.4357601723263417
epoch: 49, train_batch_id: 1100, avg_cost: 3.8437273502349854
grad_norm: 0.4322037320244071, clipped: 0.4322037320244071
epoch: 49, train_batch_id: 1150, avg_cost: 3.863701343536377
grad_norm: 0.47144271072204125, clipped: 0.47144271072204125
epoch: 49, train_batch_id: 1200, avg_cost: 3.8523974418640137
grad_norm: 0.33956340019787634, clipped: 0.33956340019787634
epoch: 49, train_batch_id: 1250, avg_cost: 3.867203712463379
grad_norm: 0.2983255046022567, clipped: 0.2983255046022567
epoch: 49, train_batch_id: 1300, avg_cost: 3.833047389984131
grad_norm: 0.3848647353219704, clipped: 0.3848647353219704
epoch: 49, train_batch_id: 1350, avg_cost: 3.8568594455718994
grad_norm: 0.3898314188919676, clipped: 0.3898314188919676
epoch: 49, train_batch_id: 1400, avg_cost: 3.8468079566955566
grad_norm: 0.31913175444516645, clipped: 0.31913175444516645
epoch: 49, train_batch_id: 1450, avg_cost: 3.8495986461639404
grad_norm: 0.4231800916114737, clipped: 0.4231800916114737
epoch: 49, train_batch_id: 1500, avg_cost: 3.851743221282959
grad_norm: 0.5210471203957991, clipped: 0.5210471203957991
epoch: 49, train_batch_id: 1550, avg_cost: 3.823366641998291
grad_norm: 0.365326490868697, clipped: 0.365326490868697
epoch: 49, train_batch_id: 1600, avg_cost: 3.851222276687622
grad_norm: 0.3707254636381534, clipped: 0.3707254636381534
epoch: 49, train_batch_id: 1650, avg_cost: 3.8573193550109863
grad_norm: 0.3724518075310422, clipped: 0.3724518075310422
epoch: 49, train_batch_id: 1700, avg_cost: 3.8504085540771484
grad_norm: 0.2945317220333449, clipped: 0.2945317220333449
epoch: 49, train_batch_id: 1750, avg_cost: 3.8407886028289795
grad_norm: 0.5692958996804734, clipped: 0.5692958996804734
epoch: 49, train_batch_id: 1800, avg_cost: 3.844552516937256
grad_norm: 0.28851823779298763, clipped: 0.28851823779298763
epoch: 49, train_batch_id: 1850, avg_cost: 3.8629257678985596
grad_norm: 0.3619117834769844, clipped: 0.3619117834769844
epoch: 49, train_batch_id: 1900, avg_cost: 3.8391168117523193
grad_norm: 0.3614522652879117, clipped: 0.3614522652879117
epoch: 49, train_batch_id: 1950, avg_cost: 3.8571863174438477
grad_norm: 0.46339106987530226, clipped: 0.46339106987530226
epoch: 49, train_batch_id: 2000, avg_cost: 3.8582777976989746
grad_norm: 0.48436669100395174, clipped: 0.48436669100395174
epoch: 49, train_batch_id: 2050, avg_cost: 3.8286924362182617
grad_norm: 0.3654075887570115, clipped: 0.3654075887570115
epoch: 49, train_batch_id: 2100, avg_cost: 3.8483359813690186
grad_norm: 0.7785171337028337, clipped: 0.7785171337028337
epoch: 49, train_batch_id: 2150, avg_cost: 3.8450894355773926
grad_norm: 0.4459884500814275, clipped: 0.4459884500814275
epoch: 49, train_batch_id: 2200, avg_cost: 3.8515334129333496
grad_norm: 0.3780008700295927, clipped: 0.3780008700295927
epoch: 49, train_batch_id: 2250, avg_cost: 3.857856035232544
grad_norm: 0.42543472953549183, clipped: 0.42543472953549183
epoch: 49, train_batch_id: 2300, avg_cost: 3.8508214950561523
grad_norm: 0.5655788580102185, clipped: 0.5655788580102185
epoch: 49, train_batch_id: 2350, avg_cost: 3.863736152648926
grad_norm: 0.3048365461292133, clipped: 0.3048365461292133
epoch: 49, train_batch_id: 2400, avg_cost: 3.834178924560547
grad_norm: 0.1980590144919002, clipped: 0.1980590144919002
epoch: 49, train_batch_id: 2450, avg_cost: 3.8325517177581787
grad_norm: 0.3700494176921256, clipped: 0.3700494176921256
Finished epoch 49, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8489105701446533 +- 0.0031124362722039223
Evaluating candidate model on evaluation dataset
Epoch 49 candidate mean 3.8460910320281982, baseline epoch 48 mean 3.846060037612915, difference 3.0994415283203125e-05
Start train epoch 50, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 50, train_batch_id: 0, avg_cost: 3.856292247772217
grad_norm: 0.4182032062198489, clipped: 0.4182032062198489
epoch: 50, train_batch_id: 50, avg_cost: 3.8361191749572754
grad_norm: 0.31638973371537815, clipped: 0.31638973371537815
epoch: 50, train_batch_id: 100, avg_cost: 3.859523296356201
grad_norm: 0.36142285298728866, clipped: 0.36142285298728866
epoch: 50, train_batch_id: 150, avg_cost: 3.8293027877807617
grad_norm: 0.4385101600248478, clipped: 0.4385101600248478
epoch: 50, train_batch_id: 200, avg_cost: 3.8534560203552246
grad_norm: 0.3043163879792997, clipped: 0.3043163879792997
epoch: 50, train_batch_id: 250, avg_cost: 3.8234076499938965
grad_norm: 0.27616127313480643, clipped: 0.27616127313480643
epoch: 50, train_batch_id: 300, avg_cost: 3.870844841003418
grad_norm: 0.471436437259561, clipped: 0.471436437259561
epoch: 50, train_batch_id: 350, avg_cost: 3.8795557022094727
grad_norm: 0.37263917634513355, clipped: 0.37263917634513355
epoch: 50, train_batch_id: 400, avg_cost: 3.84944748878479
grad_norm: 0.3589716748812931, clipped: 0.3589716748812931
epoch: 50, train_batch_id: 450, avg_cost: 3.8495230674743652
grad_norm: 0.41329437880378167, clipped: 0.41329437880378167
epoch: 50, train_batch_id: 500, avg_cost: 3.865884304046631
grad_norm: 0.3169574470663722, clipped: 0.3169574470663722
epoch: 50, train_batch_id: 550, avg_cost: 3.8249449729919434
grad_norm: 0.3334199213403436, clipped: 0.3334199213403436
epoch: 50, train_batch_id: 600, avg_cost: 3.858886480331421
grad_norm: 0.6463204055191932, clipped: 0.6463204055191932
epoch: 50, train_batch_id: 650, avg_cost: 3.847532272338867
grad_norm: 0.3545245664803829, clipped: 0.3545245664803829
epoch: 50, train_batch_id: 700, avg_cost: 3.836637496948242
grad_norm: 0.4047631367283682, clipped: 0.4047631367283682
epoch: 50, train_batch_id: 750, avg_cost: 3.8402750492095947
grad_norm: 3.1267134791148137, clipped: 1.0
epoch: 50, train_batch_id: 800, avg_cost: 3.870149612426758
grad_norm: 0.33045384604389827, clipped: 0.33045384604389827
epoch: 50, train_batch_id: 850, avg_cost: 3.8505091667175293
grad_norm: 0.34253142509084705, clipped: 0.34253142509084705
epoch: 50, train_batch_id: 900, avg_cost: 3.861790657043457
grad_norm: 0.32383976638988377, clipped: 0.32383976638988377
epoch: 50, train_batch_id: 950, avg_cost: 3.853869915008545
grad_norm: 0.9594745056486682, clipped: 0.9594745056486682
epoch: 50, train_batch_id: 1000, avg_cost: 3.854600191116333
grad_norm: 0.3098162173128543, clipped: 0.3098162173128543
epoch: 50, train_batch_id: 1050, avg_cost: 3.8432822227478027
grad_norm: 0.314592816099348, clipped: 0.314592816099348
epoch: 50, train_batch_id: 1100, avg_cost: 3.8677544593811035
grad_norm: 0.4596603368263294, clipped: 0.4596603368263294
epoch: 50, train_batch_id: 1150, avg_cost: 3.841649293899536
grad_norm: 0.32681826990219304, clipped: 0.32681826990219304
epoch: 50, train_batch_id: 1200, avg_cost: 3.8597919940948486
grad_norm: 0.3480889217777569, clipped: 0.3480889217777569
epoch: 50, train_batch_id: 1250, avg_cost: 3.832888603210449
grad_norm: 0.443814603255986, clipped: 0.443814603255986
epoch: 50, train_batch_id: 1300, avg_cost: 3.8297207355499268
grad_norm: 0.335670687057848, clipped: 0.335670687057848
epoch: 50, train_batch_id: 1350, avg_cost: 3.8571648597717285
grad_norm: 0.32177166142890573, clipped: 0.32177166142890573
epoch: 50, train_batch_id: 1400, avg_cost: 3.8355298042297363
grad_norm: 1.2369698021696207, clipped: 1.0
epoch: 50, train_batch_id: 1450, avg_cost: 3.8510780334472656
grad_norm: 0.36213511982316976, clipped: 0.36213511982316976
epoch: 50, train_batch_id: 1500, avg_cost: 3.845637083053589
grad_norm: 0.3454158255499013, clipped: 0.3454158255499013
epoch: 50, train_batch_id: 1550, avg_cost: 3.8467113971710205
grad_norm: 0.4272057194378899, clipped: 0.4272057194378899
epoch: 50, train_batch_id: 1600, avg_cost: 3.8699140548706055
grad_norm: 0.49320724880234557, clipped: 0.49320724880234557
epoch: 50, train_batch_id: 1650, avg_cost: 3.8632097244262695
grad_norm: 0.46485856433625694, clipped: 0.46485856433625694
epoch: 50, train_batch_id: 1700, avg_cost: 3.8742892742156982
grad_norm: 0.4096484330753768, clipped: 0.4096484330753768
epoch: 50, train_batch_id: 1750, avg_cost: 3.8418662548065186
grad_norm: 0.8452199837138071, clipped: 0.8452199837138071
epoch: 50, train_batch_id: 1800, avg_cost: 3.866103410720825
grad_norm: 0.5576220989015075, clipped: 0.5576220989015075
epoch: 50, train_batch_id: 1850, avg_cost: 3.8422746658325195
grad_norm: 0.7633629201397644, clipped: 0.7633629201397644
epoch: 50, train_batch_id: 1900, avg_cost: 3.8173789978027344
grad_norm: 0.3089915615750048, clipped: 0.3089915615750048
epoch: 50, train_batch_id: 1950, avg_cost: 3.851195812225342
grad_norm: 0.5737199072081512, clipped: 0.5737199072081512
epoch: 50, train_batch_id: 2000, avg_cost: 3.8541383743286133
grad_norm: 0.4362907405060456, clipped: 0.4362907405060456
epoch: 50, train_batch_id: 2050, avg_cost: 3.842881202697754
grad_norm: 0.3692585312906552, clipped: 0.3692585312906552
epoch: 50, train_batch_id: 2100, avg_cost: 3.8595190048217773
grad_norm: 2.3850280846472884, clipped: 1.0
epoch: 50, train_batch_id: 2150, avg_cost: 3.8486738204956055
grad_norm: 0.3529201284664491, clipped: 0.3529201284664491
epoch: 50, train_batch_id: 2200, avg_cost: 3.855968475341797
grad_norm: 0.27785933669406016, clipped: 0.27785933669406016
epoch: 50, train_batch_id: 2250, avg_cost: 3.84214448928833
grad_norm: 0.4047786096953668, clipped: 0.4047786096953668
epoch: 50, train_batch_id: 2300, avg_cost: 3.8306522369384766
grad_norm: 0.3061501425426502, clipped: 0.3061501425426502
epoch: 50, train_batch_id: 2350, avg_cost: 3.840132713317871
grad_norm: 0.3742036922001133, clipped: 0.3742036922001133
epoch: 50, train_batch_id: 2400, avg_cost: 3.852330446243286
grad_norm: 0.4037499783160262, clipped: 0.4037499783160262
epoch: 50, train_batch_id: 2450, avg_cost: 3.8511569499969482
grad_norm: 0.30568145955107856, clipped: 0.30568145955107856
Finished epoch 50, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8503777980804443 +- 0.0031176158227026463
Evaluating candidate model on evaluation dataset
Epoch 50 candidate mean 3.847140312194824, baseline epoch 48 mean 3.846060037612915, difference 0.0010802745819091797
Start train epoch 51, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 51, train_batch_id: 0, avg_cost: 3.8802666664123535
grad_norm: 0.286770492328047, clipped: 0.286770492328047
epoch: 51, train_batch_id: 50, avg_cost: 3.868114471435547
grad_norm: 1.0064776292213509, clipped: 1.0
epoch: 51, train_batch_id: 100, avg_cost: 3.831833839416504
grad_norm: 0.36895826614851696, clipped: 0.36895826614851696
epoch: 51, train_batch_id: 150, avg_cost: 3.8443331718444824
grad_norm: 0.3317143491774333, clipped: 0.3317143491774333
epoch: 51, train_batch_id: 200, avg_cost: 3.8662467002868652
grad_norm: 0.36199805259703305, clipped: 0.36199805259703305
epoch: 51, train_batch_id: 250, avg_cost: 3.8397998809814453
grad_norm: 0.40363399322011934, clipped: 0.40363399322011934
epoch: 51, train_batch_id: 300, avg_cost: 3.851132869720459
grad_norm: 0.3024324000165327, clipped: 0.3024324000165327
epoch: 51, train_batch_id: 350, avg_cost: 3.8718626499176025
grad_norm: 0.39803964811159237, clipped: 0.39803964811159237
epoch: 51, train_batch_id: 400, avg_cost: 3.8575351238250732
grad_norm: 0.3619982384433512, clipped: 0.3619982384433512
epoch: 51, train_batch_id: 450, avg_cost: 3.8400135040283203
grad_norm: 0.46766951901089865, clipped: 0.46766951901089865
epoch: 51, train_batch_id: 500, avg_cost: 3.860820770263672
grad_norm: 0.39111431089442983, clipped: 0.39111431089442983
epoch: 51, train_batch_id: 550, avg_cost: 3.877375364303589
grad_norm: 0.9887355714451121, clipped: 0.9887355714451121
epoch: 51, train_batch_id: 600, avg_cost: 3.8761374950408936
grad_norm: 1.3133883166766247, clipped: 1.0
epoch: 51, train_batch_id: 650, avg_cost: 3.8461763858795166
grad_norm: 0.431241551862373, clipped: 0.431241551862373
epoch: 51, train_batch_id: 700, avg_cost: 3.856210231781006
grad_norm: 0.3138242741120226, clipped: 0.3138242741120226
epoch: 51, train_batch_id: 750, avg_cost: 3.847670555114746
grad_norm: 0.5230339814804836, clipped: 0.5230339814804836
epoch: 51, train_batch_id: 800, avg_cost: 3.838705062866211
grad_norm: 0.37093434217203536, clipped: 0.37093434217203536
epoch: 51, train_batch_id: 850, avg_cost: 3.84379243850708
grad_norm: 0.4014256227448288, clipped: 0.4014256227448288
epoch: 51, train_batch_id: 900, avg_cost: 3.8836350440979004
grad_norm: 0.9388219216908716, clipped: 0.9388219216908716
epoch: 51, train_batch_id: 950, avg_cost: 3.8538217544555664
grad_norm: 0.7204864874551541, clipped: 0.7204864874551541
epoch: 51, train_batch_id: 1000, avg_cost: 3.849531412124634
grad_norm: 0.44583045580161174, clipped: 0.44583045580161174
epoch: 51, train_batch_id: 1050, avg_cost: 3.8406362533569336
grad_norm: 0.31405658525644947, clipped: 0.31405658525644947
epoch: 51, train_batch_id: 1100, avg_cost: 3.842373847961426
grad_norm: 0.2836747827621871, clipped: 0.2836747827621871
epoch: 51, train_batch_id: 1150, avg_cost: 3.8443222045898438
grad_norm: 0.27871227223600376, clipped: 0.27871227223600376
epoch: 51, train_batch_id: 1200, avg_cost: 3.8426513671875
grad_norm: 0.4036320308195526, clipped: 0.4036320308195526
epoch: 51, train_batch_id: 1250, avg_cost: 3.8458645343780518
grad_norm: 0.39043183510348684, clipped: 0.39043183510348684
epoch: 51, train_batch_id: 1300, avg_cost: 3.836986780166626
grad_norm: 0.39053656808951986, clipped: 0.39053656808951986
epoch: 51, train_batch_id: 1350, avg_cost: 3.838991165161133
grad_norm: 0.3796112129344115, clipped: 0.3796112129344115
epoch: 51, train_batch_id: 1400, avg_cost: 3.8277812004089355
grad_norm: 0.2036498907309805, clipped: 0.2036498907309805
epoch: 51, train_batch_id: 1450, avg_cost: 3.8469789028167725
grad_norm: 0.5216583370910899, clipped: 0.5216583370910899
epoch: 51, train_batch_id: 1500, avg_cost: 3.8515090942382812
grad_norm: 0.365551623865718, clipped: 0.365551623865718
epoch: 51, train_batch_id: 1550, avg_cost: 3.8280744552612305
grad_norm: 0.6425185439568704, clipped: 0.6425185439568704
epoch: 51, train_batch_id: 1600, avg_cost: 3.845777988433838
grad_norm: 0.5953244823775032, clipped: 0.5953244823775032
epoch: 51, train_batch_id: 1650, avg_cost: 3.8510398864746094
grad_norm: 0.2591313555798176, clipped: 0.2591313555798176
epoch: 51, train_batch_id: 1700, avg_cost: 3.8501133918762207
grad_norm: 0.3435799875486023, clipped: 0.3435799875486023
epoch: 51, train_batch_id: 1750, avg_cost: 3.8455896377563477
grad_norm: 2.2978563688367366, clipped: 1.0
epoch: 51, train_batch_id: 1800, avg_cost: 3.8222219944000244
grad_norm: 0.39583790589708895, clipped: 0.39583790589708895
epoch: 51, train_batch_id: 1850, avg_cost: 3.8452281951904297
grad_norm: 0.244256018040465, clipped: 0.244256018040465
epoch: 51, train_batch_id: 1900, avg_cost: 3.8425791263580322
grad_norm: 0.31459327101013884, clipped: 0.31459327101013884
epoch: 51, train_batch_id: 1950, avg_cost: 3.8747551441192627
grad_norm: 1.2052240596864245, clipped: 1.0
epoch: 51, train_batch_id: 2000, avg_cost: 3.852787494659424
grad_norm: 0.3738018536889385, clipped: 0.3738018536889385
epoch: 51, train_batch_id: 2050, avg_cost: 3.838120222091675
grad_norm: 0.5244372715735607, clipped: 0.5244372715735607
epoch: 51, train_batch_id: 2100, avg_cost: 3.8439602851867676
grad_norm: 0.40192929749917644, clipped: 0.40192929749917644
epoch: 51, train_batch_id: 2150, avg_cost: 3.8481669425964355
grad_norm: 0.4448500457058653, clipped: 0.4448500457058653
epoch: 51, train_batch_id: 2200, avg_cost: 3.8312535285949707
grad_norm: 0.46910720265706407, clipped: 0.46910720265706407
epoch: 51, train_batch_id: 2250, avg_cost: 3.859477996826172
grad_norm: 0.35913494370284826, clipped: 0.35913494370284826
epoch: 51, train_batch_id: 2300, avg_cost: 3.8293097019195557
grad_norm: 0.3392296279641616, clipped: 0.3392296279641616
epoch: 51, train_batch_id: 2350, avg_cost: 3.842867136001587
grad_norm: 0.27815336519456096, clipped: 0.27815336519456096
epoch: 51, train_batch_id: 2400, avg_cost: 3.8373537063598633
grad_norm: 0.3013685475858611, clipped: 0.3013685475858611
epoch: 51, train_batch_id: 2450, avg_cost: 3.848024845123291
grad_norm: 0.5231369234915386, clipped: 0.5231369234915386
Finished epoch 51, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.852073907852173 +- 0.0031292473431676626
Evaluating candidate model on evaluation dataset
Epoch 51 candidate mean 3.8489866256713867, baseline epoch 48 mean 3.846060037612915, difference 0.0029265880584716797
Start train epoch 52, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 52, train_batch_id: 0, avg_cost: 3.847966194152832
grad_norm: 0.9387680799046557, clipped: 0.9387680799046557
epoch: 52, train_batch_id: 50, avg_cost: 3.843116283416748
grad_norm: 0.35752907886322055, clipped: 0.35752907886322055
epoch: 52, train_batch_id: 100, avg_cost: 3.8589208126068115
grad_norm: 0.6045640032754737, clipped: 0.6045640032754737
epoch: 52, train_batch_id: 150, avg_cost: 3.878939151763916
grad_norm: 0.32258842124705606, clipped: 0.32258842124705606
epoch: 52, train_batch_id: 200, avg_cost: 3.8492157459259033
grad_norm: 0.5583555846703109, clipped: 0.5583555846703109
epoch: 52, train_batch_id: 250, avg_cost: 3.864387035369873
grad_norm: 0.38643327220661017, clipped: 0.38643327220661017
epoch: 52, train_batch_id: 300, avg_cost: 3.8289036750793457
grad_norm: 0.3747615986200748, clipped: 0.3747615986200748
epoch: 52, train_batch_id: 350, avg_cost: 3.834688186645508
grad_norm: 0.20253131982092137, clipped: 0.20253131982092137
epoch: 52, train_batch_id: 400, avg_cost: 3.864922523498535
grad_norm: 0.34825423309696596, clipped: 0.34825423309696596
epoch: 52, train_batch_id: 450, avg_cost: 3.8603644371032715
grad_norm: 0.4072508794145803, clipped: 0.4072508794145803
epoch: 52, train_batch_id: 500, avg_cost: 3.836214780807495
grad_norm: 0.22973846382215715, clipped: 0.22973846382215715
epoch: 52, train_batch_id: 550, avg_cost: 3.8346781730651855
grad_norm: 0.37401478921025544, clipped: 0.37401478921025544
epoch: 52, train_batch_id: 600, avg_cost: 3.8665621280670166
grad_norm: 0.37877894204129386, clipped: 0.37877894204129386
epoch: 52, train_batch_id: 650, avg_cost: 3.8435425758361816
grad_norm: 0.3982546277936607, clipped: 0.3982546277936607
epoch: 52, train_batch_id: 700, avg_cost: 3.841548442840576
grad_norm: 0.4702444741854555, clipped: 0.4702444741854555
epoch: 52, train_batch_id: 750, avg_cost: 3.8590054512023926
grad_norm: 0.49234454937031, clipped: 0.49234454937031
epoch: 52, train_batch_id: 800, avg_cost: 3.856370210647583
grad_norm: 0.2856996023197695, clipped: 0.2856996023197695
epoch: 52, train_batch_id: 850, avg_cost: 3.840757369995117
grad_norm: 0.3243375292768366, clipped: 0.3243375292768366
epoch: 52, train_batch_id: 900, avg_cost: 3.8620822429656982
grad_norm: 0.9867685534168988, clipped: 0.9867685534168988
epoch: 52, train_batch_id: 950, avg_cost: 3.852269172668457
grad_norm: 0.3559658709430774, clipped: 0.3559658709430774
epoch: 52, train_batch_id: 1000, avg_cost: 3.8308093547821045
grad_norm: 0.29210622082020604, clipped: 0.29210622082020604
epoch: 52, train_batch_id: 1050, avg_cost: 3.8754258155822754
grad_norm: 0.566673960184658, clipped: 0.566673960184658
epoch: 52, train_batch_id: 1100, avg_cost: 3.8803505897521973
grad_norm: 0.38058208986699293, clipped: 0.38058208986699293
epoch: 52, train_batch_id: 1150, avg_cost: 3.8598532676696777
grad_norm: 0.29776242656969626, clipped: 0.29776242656969626
epoch: 52, train_batch_id: 1200, avg_cost: 3.850597620010376
grad_norm: 0.821109893638606, clipped: 0.821109893638606
epoch: 52, train_batch_id: 1250, avg_cost: 3.8540568351745605
grad_norm: 0.445136770058844, clipped: 0.445136770058844
epoch: 52, train_batch_id: 1300, avg_cost: 3.8550024032592773
grad_norm: 0.3151119870835381, clipped: 0.3151119870835381
epoch: 52, train_batch_id: 1350, avg_cost: 3.854109764099121
grad_norm: 0.34496671373357457, clipped: 0.34496671373357457
epoch: 52, train_batch_id: 1400, avg_cost: 3.859872341156006
grad_norm: 0.40712479952974767, clipped: 0.40712479952974767
epoch: 52, train_batch_id: 1450, avg_cost: 3.845268726348877
grad_norm: 0.56042984662818, clipped: 0.56042984662818
epoch: 52, train_batch_id: 1500, avg_cost: 3.8597042560577393
grad_norm: 0.29405486575244805, clipped: 0.29405486575244805
epoch: 52, train_batch_id: 1550, avg_cost: 3.85598087310791
grad_norm: 0.534414686175205, clipped: 0.534414686175205
epoch: 52, train_batch_id: 1600, avg_cost: 3.8321597576141357
grad_norm: 0.38852997783652576, clipped: 0.38852997783652576
epoch: 52, train_batch_id: 1650, avg_cost: 3.864424228668213
grad_norm: 0.373803209340779, clipped: 0.373803209340779
epoch: 52, train_batch_id: 1700, avg_cost: 3.8325510025024414
grad_norm: 0.4965095574034977, clipped: 0.4965095574034977
epoch: 52, train_batch_id: 1750, avg_cost: 3.8349087238311768
grad_norm: 0.4460253221703785, clipped: 0.4460253221703785
epoch: 52, train_batch_id: 1800, avg_cost: 3.860293388366699
grad_norm: 0.3118584070111461, clipped: 0.3118584070111461
epoch: 52, train_batch_id: 1850, avg_cost: 3.838038921356201
grad_norm: 0.2411621765484026, clipped: 0.2411621765484026
epoch: 52, train_batch_id: 1900, avg_cost: 3.8567209243774414
grad_norm: 0.3090785639523391, clipped: 0.3090785639523391
epoch: 52, train_batch_id: 1950, avg_cost: 3.8333864212036133
grad_norm: 0.29870708634912335, clipped: 0.29870708634912335
epoch: 52, train_batch_id: 2000, avg_cost: 3.853550910949707
grad_norm: 0.2894039442847758, clipped: 0.2894039442847758
epoch: 52, train_batch_id: 2050, avg_cost: 3.8401601314544678
grad_norm: 0.3397559352612014, clipped: 0.3397559352612014
epoch: 52, train_batch_id: 2100, avg_cost: 3.834804058074951
grad_norm: 0.6219116279295688, clipped: 0.6219116279295688
epoch: 52, train_batch_id: 2150, avg_cost: 3.8383660316467285
grad_norm: 0.6372537207339013, clipped: 0.6372537207339013
epoch: 52, train_batch_id: 2200, avg_cost: 3.842397451400757
grad_norm: 0.3005777845866574, clipped: 0.3005777845866574
epoch: 52, train_batch_id: 2250, avg_cost: 3.8569979667663574
grad_norm: 0.32367089775319735, clipped: 0.32367089775319735
epoch: 52, train_batch_id: 2300, avg_cost: 3.8226590156555176
grad_norm: 0.592793637221068, clipped: 0.592793637221068
epoch: 52, train_batch_id: 2350, avg_cost: 3.8695223331451416
grad_norm: 0.3773462346578145, clipped: 0.3773462346578145
epoch: 52, train_batch_id: 2400, avg_cost: 3.8706912994384766
grad_norm: 0.26860522123034253, clipped: 0.26860522123034253
epoch: 52, train_batch_id: 2450, avg_cost: 3.861593246459961
grad_norm: 0.633272156075746, clipped: 0.633272156075746
Finished epoch 52, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8494715690612793 +- 0.0031153992749750614
Evaluating candidate model on evaluation dataset
Epoch 52 candidate mean 3.846644878387451, baseline epoch 48 mean 3.846060037612915, difference 0.0005848407745361328
Start train epoch 53, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 53, train_batch_id: 0, avg_cost: 3.834880828857422
grad_norm: 0.36131244482350483, clipped: 0.36131244482350483
epoch: 53, train_batch_id: 50, avg_cost: 3.860262155532837
grad_norm: 0.7546449790747999, clipped: 0.7546449790747999
epoch: 53, train_batch_id: 100, avg_cost: 3.8543105125427246
grad_norm: 0.4306066053762382, clipped: 0.4306066053762382
epoch: 53, train_batch_id: 150, avg_cost: 3.848087787628174
grad_norm: 0.39382958637359716, clipped: 0.39382958637359716
epoch: 53, train_batch_id: 200, avg_cost: 3.8119049072265625
grad_norm: 0.4503217074374598, clipped: 0.4503217074374598
epoch: 53, train_batch_id: 250, avg_cost: 3.861358165740967
grad_norm: 0.3301370780832806, clipped: 0.3301370780832806
epoch: 53, train_batch_id: 300, avg_cost: 3.825888156890869
grad_norm: 0.30513923300414264, clipped: 0.30513923300414264
epoch: 53, train_batch_id: 350, avg_cost: 3.868138074874878
grad_norm: 0.43518843945434293, clipped: 0.43518843945434293
epoch: 53, train_batch_id: 400, avg_cost: 3.855376720428467
grad_norm: 2.3040964594031195, clipped: 1.0
epoch: 53, train_batch_id: 450, avg_cost: 3.8760390281677246
grad_norm: 0.33945476566960725, clipped: 0.33945476566960725
epoch: 53, train_batch_id: 500, avg_cost: 3.8512589931488037
grad_norm: 0.3206191631928012, clipped: 0.3206191631928012
epoch: 53, train_batch_id: 550, avg_cost: 3.855093479156494
grad_norm: 0.3324688653533704, clipped: 0.3324688653533704
epoch: 53, train_batch_id: 600, avg_cost: 3.8496885299682617
grad_norm: 0.28907493815321805, clipped: 0.28907493815321805
epoch: 53, train_batch_id: 650, avg_cost: 3.8357601165771484
grad_norm: 0.3688715621055842, clipped: 0.3688715621055842
epoch: 53, train_batch_id: 700, avg_cost: 3.8457164764404297
grad_norm: 0.44550093370026306, clipped: 0.44550093370026306
epoch: 53, train_batch_id: 750, avg_cost: 3.8422255516052246
grad_norm: 0.294231977490261, clipped: 0.294231977490261
epoch: 53, train_batch_id: 800, avg_cost: 3.847822666168213
grad_norm: 0.5496712545274595, clipped: 0.5496712545274595
epoch: 53, train_batch_id: 850, avg_cost: 3.87326717376709
grad_norm: 0.2955294987126432, clipped: 0.2955294987126432
epoch: 53, train_batch_id: 900, avg_cost: 3.8375163078308105
grad_norm: 0.4050685065790265, clipped: 0.4050685065790265
epoch: 53, train_batch_id: 950, avg_cost: 3.8696722984313965
grad_norm: 0.6354960677083152, clipped: 0.6354960677083152
epoch: 53, train_batch_id: 1000, avg_cost: 3.8462142944335938
grad_norm: 0.3600524274602531, clipped: 0.3600524274602531
epoch: 53, train_batch_id: 1050, avg_cost: 3.860931158065796
grad_norm: 0.6405643880266533, clipped: 0.6405643880266533
epoch: 53, train_batch_id: 1100, avg_cost: 3.8517754077911377
grad_norm: 0.309160191489702, clipped: 0.309160191489702
epoch: 53, train_batch_id: 1150, avg_cost: 3.8480067253112793
grad_norm: 0.4011768892825766, clipped: 0.4011768892825766
epoch: 53, train_batch_id: 1200, avg_cost: 3.850180149078369
grad_norm: 0.3179181518903659, clipped: 0.3179181518903659
epoch: 53, train_batch_id: 1250, avg_cost: 3.8502039909362793
grad_norm: 0.39855986179364933, clipped: 0.39855986179364933
epoch: 53, train_batch_id: 1300, avg_cost: 3.844043731689453
grad_norm: 0.2771713119151406, clipped: 0.2771713119151406
epoch: 53, train_batch_id: 1350, avg_cost: 3.85007905960083
grad_norm: 0.4386663926910568, clipped: 0.4386663926910568
epoch: 53, train_batch_id: 1400, avg_cost: 3.864760160446167
grad_norm: 0.7642432930156069, clipped: 0.7642432930156069
epoch: 53, train_batch_id: 1450, avg_cost: 3.836029052734375
grad_norm: 0.39590455864222884, clipped: 0.39590455864222884
epoch: 53, train_batch_id: 1500, avg_cost: 3.827918529510498
grad_norm: 0.2928354682365821, clipped: 0.2928354682365821
epoch: 53, train_batch_id: 1550, avg_cost: 3.8388397693634033
grad_norm: 0.4474166120073319, clipped: 0.4474166120073319
epoch: 53, train_batch_id: 1600, avg_cost: 3.86073637008667
grad_norm: 0.34370226790483105, clipped: 0.34370226790483105
epoch: 53, train_batch_id: 1650, avg_cost: 3.8289437294006348
grad_norm: 0.3657878705598345, clipped: 0.3657878705598345
epoch: 53, train_batch_id: 1700, avg_cost: 3.8407199382781982
grad_norm: 0.4576204071749001, clipped: 0.4576204071749001
epoch: 53, train_batch_id: 1750, avg_cost: 3.844599723815918
grad_norm: 0.34719539597390686, clipped: 0.34719539597390686
epoch: 53, train_batch_id: 1800, avg_cost: 3.8386144638061523
grad_norm: 0.3154239008335463, clipped: 0.3154239008335463
epoch: 53, train_batch_id: 1850, avg_cost: 3.84383487701416
grad_norm: 0.41579748004444284, clipped: 0.41579748004444284
epoch: 53, train_batch_id: 1900, avg_cost: 3.8448894023895264
grad_norm: 0.2800936518572174, clipped: 0.2800936518572174
epoch: 53, train_batch_id: 1950, avg_cost: 3.8480005264282227
grad_norm: 0.34994638153500296, clipped: 0.34994638153500296
epoch: 53, train_batch_id: 2000, avg_cost: 3.8210835456848145
grad_norm: 0.32909262445689674, clipped: 0.32909262445689674
epoch: 53, train_batch_id: 2050, avg_cost: 3.8663506507873535
grad_norm: 0.35849289391875117, clipped: 0.35849289391875117
epoch: 53, train_batch_id: 2100, avg_cost: 3.8481764793395996
grad_norm: 0.44035825227995035, clipped: 0.44035825227995035
epoch: 53, train_batch_id: 2150, avg_cost: 3.872814416885376
grad_norm: 0.5994167767698891, clipped: 0.5994167767698891
epoch: 53, train_batch_id: 2200, avg_cost: 3.848423480987549
grad_norm: 0.37747832092152905, clipped: 0.37747832092152905
epoch: 53, train_batch_id: 2250, avg_cost: 3.8527169227600098
grad_norm: 0.333318130569428, clipped: 0.333318130569428
epoch: 53, train_batch_id: 2300, avg_cost: 3.832481861114502
grad_norm: 0.26275733260721057, clipped: 0.26275733260721057
epoch: 53, train_batch_id: 2350, avg_cost: 3.8345465660095215
grad_norm: 0.35900085371713164, clipped: 0.35900085371713164
epoch: 53, train_batch_id: 2400, avg_cost: 3.8207695484161377
grad_norm: 0.44824528454343826, clipped: 0.44824528454343826
epoch: 53, train_batch_id: 2450, avg_cost: 3.881499767303467
grad_norm: 0.599727011431222, clipped: 0.599727011431222
Finished epoch 53, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.848623752593994 +- 0.0031097319442778826
Evaluating candidate model on evaluation dataset
Epoch 53 candidate mean 3.8461358547210693, baseline epoch 48 mean 3.846060037612915, difference 7.581710815429688e-05
Start train epoch 54, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 54, train_batch_id: 0, avg_cost: 3.836137294769287
grad_norm: 0.6363990349132873, clipped: 0.6363990349132873
epoch: 54, train_batch_id: 50, avg_cost: 3.8489017486572266
grad_norm: 0.46948193826644197, clipped: 0.46948193826644197
epoch: 54, train_batch_id: 100, avg_cost: 3.8496203422546387
grad_norm: 1.2713933688114232, clipped: 1.0
epoch: 54, train_batch_id: 150, avg_cost: 3.875258445739746
grad_norm: 0.4419941189861151, clipped: 0.4419941189861151
epoch: 54, train_batch_id: 200, avg_cost: 3.836883783340454
grad_norm: 0.4957484142458861, clipped: 0.4957484142458861
epoch: 54, train_batch_id: 250, avg_cost: 3.8408565521240234
grad_norm: 0.3448529661826416, clipped: 0.3448529661826416
epoch: 54, train_batch_id: 300, avg_cost: 3.8376989364624023
grad_norm: 0.4353597899917248, clipped: 0.4353597899917248
epoch: 54, train_batch_id: 350, avg_cost: 3.8472890853881836
grad_norm: 0.4106726330008338, clipped: 0.4106726330008338
epoch: 54, train_batch_id: 400, avg_cost: 3.867947578430176
grad_norm: 0.35599454887802146, clipped: 0.35599454887802146
epoch: 54, train_batch_id: 450, avg_cost: 3.8275632858276367
grad_norm: 0.3000203413213053, clipped: 0.3000203413213053
epoch: 54, train_batch_id: 500, avg_cost: 3.8168959617614746
grad_norm: 0.3552770407497963, clipped: 0.3552770407497963
epoch: 54, train_batch_id: 550, avg_cost: 3.8304831981658936
grad_norm: 0.5843007123199577, clipped: 0.5843007123199577
epoch: 54, train_batch_id: 600, avg_cost: 3.874412775039673
grad_norm: 1.0482954231774944, clipped: 1.0
epoch: 54, train_batch_id: 650, avg_cost: 3.8646655082702637
grad_norm: 0.4039205376652348, clipped: 0.4039205376652348
epoch: 54, train_batch_id: 700, avg_cost: 3.862400531768799
grad_norm: 0.27882308353401825, clipped: 0.27882308353401825
epoch: 54, train_batch_id: 750, avg_cost: 3.8598296642303467
grad_norm: 0.5789081464209708, clipped: 0.5789081464209708
epoch: 54, train_batch_id: 800, avg_cost: 3.840097188949585
grad_norm: 0.4318257492051235, clipped: 0.4318257492051235
epoch: 54, train_batch_id: 850, avg_cost: 3.8678085803985596
grad_norm: 0.6172480976703538, clipped: 0.6172480976703538
epoch: 54, train_batch_id: 900, avg_cost: 3.872494697570801
grad_norm: 0.3128536159220306, clipped: 0.3128536159220306
epoch: 54, train_batch_id: 950, avg_cost: 3.8607707023620605
grad_norm: 0.46168310119447964, clipped: 0.46168310119447964
epoch: 54, train_batch_id: 1000, avg_cost: 3.8401455879211426
grad_norm: 0.3575162792082137, clipped: 0.3575162792082137
epoch: 54, train_batch_id: 1050, avg_cost: 3.8355484008789062
grad_norm: 0.32425896529078124, clipped: 0.32425896529078124
epoch: 54, train_batch_id: 1100, avg_cost: 3.8206377029418945
grad_norm: 0.38828647041733494, clipped: 0.38828647041733494
epoch: 54, train_batch_id: 1150, avg_cost: 3.8559892177581787
grad_norm: 0.40354448575082424, clipped: 0.40354448575082424
epoch: 54, train_batch_id: 1200, avg_cost: 3.8289499282836914
grad_norm: 0.3584088608625106, clipped: 0.3584088608625106
epoch: 54, train_batch_id: 1250, avg_cost: 3.8313088417053223
grad_norm: 0.9099088504163739, clipped: 0.9099088504163739
epoch: 54, train_batch_id: 1300, avg_cost: 3.8557586669921875
grad_norm: 0.27377513726436675, clipped: 0.27377513726436675
epoch: 54, train_batch_id: 1350, avg_cost: 3.831096649169922
grad_norm: 0.28555040388738795, clipped: 0.28555040388738795
epoch: 54, train_batch_id: 1400, avg_cost: 3.84429931640625
grad_norm: 0.43227516525061377, clipped: 0.43227516525061377
epoch: 54, train_batch_id: 1450, avg_cost: 3.8636910915374756
grad_norm: 0.38523838295096346, clipped: 0.38523838295096346
epoch: 54, train_batch_id: 1500, avg_cost: 3.8385493755340576
grad_norm: 0.4234574646242279, clipped: 0.4234574646242279
epoch: 54, train_batch_id: 1550, avg_cost: 3.8151841163635254
grad_norm: 0.30500279759608523, clipped: 0.30500279759608523
epoch: 54, train_batch_id: 1600, avg_cost: 3.8617749214172363
grad_norm: 0.29067533504679494, clipped: 0.29067533504679494
epoch: 54, train_batch_id: 1650, avg_cost: 3.8598220348358154
grad_norm: 0.33340949995978336, clipped: 0.33340949995978336
epoch: 54, train_batch_id: 1700, avg_cost: 3.867459297180176
grad_norm: 0.39736073133516103, clipped: 0.39736073133516103
epoch: 54, train_batch_id: 1750, avg_cost: 3.850919008255005
grad_norm: 0.31922809245244077, clipped: 0.31922809245244077
epoch: 54, train_batch_id: 1800, avg_cost: 3.8667478561401367
grad_norm: 0.5398201045375441, clipped: 0.5398201045375441
epoch: 54, train_batch_id: 1850, avg_cost: 3.859915256500244
grad_norm: 0.536906221422269, clipped: 0.536906221422269
epoch: 54, train_batch_id: 1900, avg_cost: 3.8346452713012695
grad_norm: 0.6100154183680317, clipped: 0.6100154183680317
epoch: 54, train_batch_id: 1950, avg_cost: 3.8415703773498535
grad_norm: 0.6675227527602504, clipped: 0.6675227527602504
epoch: 54, train_batch_id: 2000, avg_cost: 3.850182056427002
grad_norm: 0.49108932184250803, clipped: 0.49108932184250803
epoch: 54, train_batch_id: 2050, avg_cost: 3.8633275032043457
grad_norm: 0.6497056034607781, clipped: 0.6497056034607781
epoch: 54, train_batch_id: 2100, avg_cost: 3.824847936630249
grad_norm: 0.3566127409510204, clipped: 0.3566127409510204
epoch: 54, train_batch_id: 2150, avg_cost: 3.865298271179199
grad_norm: 0.45257293567945456, clipped: 0.45257293567945456
epoch: 54, train_batch_id: 2200, avg_cost: 3.8540453910827637
grad_norm: 0.28619574429985456, clipped: 0.28619574429985456
epoch: 54, train_batch_id: 2250, avg_cost: 3.863666534423828
grad_norm: 0.3282233281864566, clipped: 0.3282233281864566
epoch: 54, train_batch_id: 2300, avg_cost: 3.838157892227173
grad_norm: 0.25278419760354326, clipped: 0.25278419760354326
epoch: 54, train_batch_id: 2350, avg_cost: 3.841641664505005
grad_norm: 0.3205535919200094, clipped: 0.3205535919200094
epoch: 54, train_batch_id: 2400, avg_cost: 3.8436217308044434
grad_norm: 0.4138116610397624, clipped: 0.4138116610397624
epoch: 54, train_batch_id: 2450, avg_cost: 3.8483071327209473
grad_norm: 0.47527294901771994, clipped: 0.47527294901771994
Finished epoch 54, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.849775791168213 +- 0.0031209250446408987
Evaluating candidate model on evaluation dataset
Epoch 54 candidate mean 3.8468527793884277, baseline epoch 48 mean 3.846060037612915, difference 0.0007927417755126953
Start train epoch 55, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 55, train_batch_id: 0, avg_cost: 3.849628210067749
grad_norm: 0.3547279875577122, clipped: 0.3547279875577122
epoch: 55, train_batch_id: 50, avg_cost: 3.8328874111175537
grad_norm: 0.33126289525602776, clipped: 0.33126289525602776
epoch: 55, train_batch_id: 100, avg_cost: 3.8540358543395996
grad_norm: 0.3234109649478306, clipped: 0.3234109649478306
epoch: 55, train_batch_id: 150, avg_cost: 3.844895839691162
grad_norm: 0.3859546383256608, clipped: 0.3859546383256608
epoch: 55, train_batch_id: 200, avg_cost: 3.8572094440460205
grad_norm: 0.3186793584465463, clipped: 0.3186793584465463
epoch: 55, train_batch_id: 250, avg_cost: 3.8496668338775635
grad_norm: 0.36955281422839864, clipped: 0.36955281422839864
epoch: 55, train_batch_id: 300, avg_cost: 3.8821020126342773
grad_norm: 2.8343639705637216, clipped: 1.0
epoch: 55, train_batch_id: 350, avg_cost: 3.8282618522644043
grad_norm: 0.3787439480785327, clipped: 0.3787439480785327
epoch: 55, train_batch_id: 400, avg_cost: 3.8504748344421387
grad_norm: 0.47225282005448527, clipped: 0.47225282005448527
epoch: 55, train_batch_id: 450, avg_cost: 3.8464515209198
grad_norm: 0.5732238839062039, clipped: 0.5732238839062039
epoch: 55, train_batch_id: 500, avg_cost: 3.8516159057617188
grad_norm: 0.3552220773300699, clipped: 0.3552220773300699
epoch: 55, train_batch_id: 550, avg_cost: 3.862189292907715
grad_norm: 0.38893984201614257, clipped: 0.38893984201614257
epoch: 55, train_batch_id: 600, avg_cost: 3.856330394744873
grad_norm: 0.8270956858220285, clipped: 0.8270956858220285
epoch: 55, train_batch_id: 650, avg_cost: 3.840653419494629
grad_norm: 0.34243949474376656, clipped: 0.34243949474376656
epoch: 55, train_batch_id: 700, avg_cost: 3.847104549407959
grad_norm: 0.37737373539882896, clipped: 0.37737373539882896
epoch: 55, train_batch_id: 750, avg_cost: 3.853637456893921
grad_norm: 0.3744531526432363, clipped: 0.3744531526432363
epoch: 55, train_batch_id: 800, avg_cost: 3.8572466373443604
grad_norm: 0.2951524772390555, clipped: 0.2951524772390555
epoch: 55, train_batch_id: 850, avg_cost: 3.83105731010437
grad_norm: 0.29065060064324927, clipped: 0.29065060064324927
epoch: 55, train_batch_id: 900, avg_cost: 3.8599960803985596
grad_norm: 0.34022339731695017, clipped: 0.34022339731695017
epoch: 55, train_batch_id: 950, avg_cost: 3.8416483402252197
grad_norm: 0.3340674387926, clipped: 0.3340674387926
epoch: 55, train_batch_id: 1000, avg_cost: 3.8346829414367676
grad_norm: 0.3052156421387925, clipped: 0.3052156421387925
epoch: 55, train_batch_id: 1050, avg_cost: 3.8558835983276367
grad_norm: 0.470007339451207, clipped: 0.470007339451207
epoch: 55, train_batch_id: 1100, avg_cost: 3.844500780105591
grad_norm: 0.36965366619658746, clipped: 0.36965366619658746
epoch: 55, train_batch_id: 1150, avg_cost: 3.8609020709991455
grad_norm: 0.286296692001246, clipped: 0.286296692001246
epoch: 55, train_batch_id: 1200, avg_cost: 3.8212921619415283
grad_norm: 0.3389945089920448, clipped: 0.3389945089920448
epoch: 55, train_batch_id: 1250, avg_cost: 3.8608827590942383
grad_norm: 0.3821533701286655, clipped: 0.3821533701286655
epoch: 55, train_batch_id: 1300, avg_cost: 3.841700792312622
grad_norm: 0.28962869588706747, clipped: 0.28962869588706747
epoch: 55, train_batch_id: 1350, avg_cost: 3.868842124938965
grad_norm: 0.34108675156833934, clipped: 0.34108675156833934
epoch: 55, train_batch_id: 1400, avg_cost: 3.8538460731506348
grad_norm: 0.3740819481023678, clipped: 0.3740819481023678
epoch: 55, train_batch_id: 1450, avg_cost: 3.8669815063476562
grad_norm: 0.25021264718086933, clipped: 0.25021264718086933
epoch: 55, train_batch_id: 1500, avg_cost: 3.8485541343688965
grad_norm: 0.3209439296543839, clipped: 0.3209439296543839
epoch: 55, train_batch_id: 1550, avg_cost: 3.865154981613159
grad_norm: 0.295913138649933, clipped: 0.295913138649933
epoch: 55, train_batch_id: 1600, avg_cost: 3.842961311340332
grad_norm: 0.5804097593418129, clipped: 0.5804097593418129
epoch: 55, train_batch_id: 1650, avg_cost: 3.854422092437744
grad_norm: 0.3593503649166366, clipped: 0.3593503649166366
epoch: 55, train_batch_id: 1700, avg_cost: 3.8481128215789795
grad_norm: 0.41095192033122374, clipped: 0.41095192033122374
epoch: 55, train_batch_id: 1750, avg_cost: 3.869415521621704
grad_norm: 0.4773956801188143, clipped: 0.4773956801188143
epoch: 55, train_batch_id: 1800, avg_cost: 3.858818292617798
grad_norm: 0.4137338271585497, clipped: 0.4137338271585497
epoch: 55, train_batch_id: 1850, avg_cost: 3.866551399230957
grad_norm: 0.42032852812181987, clipped: 0.42032852812181987
epoch: 55, train_batch_id: 1900, avg_cost: 3.8330607414245605
grad_norm: 0.3682326452173921, clipped: 0.3682326452173921
epoch: 55, train_batch_id: 1950, avg_cost: 3.8484249114990234
grad_norm: 0.25367672396770313, clipped: 0.25367672396770313
epoch: 55, train_batch_id: 2000, avg_cost: 3.844177484512329
grad_norm: 1.2162595751483511, clipped: 1.0
epoch: 55, train_batch_id: 2050, avg_cost: 3.836669683456421
grad_norm: 0.3750648037331955, clipped: 0.3750648037331955
epoch: 55, train_batch_id: 2100, avg_cost: 3.8441648483276367
grad_norm: 0.4261097194953117, clipped: 0.4261097194953117
epoch: 55, train_batch_id: 2150, avg_cost: 3.866089344024658
grad_norm: 0.34326882796807223, clipped: 0.34326882796807223
epoch: 55, train_batch_id: 2200, avg_cost: 3.8377344608306885
grad_norm: 0.7999245940043221, clipped: 0.7999245940043221
epoch: 55, train_batch_id: 2250, avg_cost: 3.869987964630127
grad_norm: 0.39605839954550953, clipped: 0.39605839954550953
epoch: 55, train_batch_id: 2300, avg_cost: 3.8475637435913086
grad_norm: 0.21689657291885162, clipped: 0.21689657291885162
epoch: 55, train_batch_id: 2350, avg_cost: 3.821485757827759
grad_norm: 0.260835703422662, clipped: 0.260835703422662
epoch: 55, train_batch_id: 2400, avg_cost: 3.8235437870025635
grad_norm: 0.30986301369763086, clipped: 0.30986301369763086
epoch: 55, train_batch_id: 2450, avg_cost: 3.816204786300659
grad_norm: 0.9664193838229111, clipped: 0.9664193838229111
Finished epoch 55, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8494508266448975 +- 0.003117123618721962
Evaluating candidate model on evaluation dataset
Epoch 55 candidate mean 3.846881628036499, baseline epoch 48 mean 3.846060037612915, difference 0.0008215904235839844
Start train epoch 56, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 56, train_batch_id: 0, avg_cost: 3.8140580654144287
grad_norm: 0.37054940737756803, clipped: 0.37054940737756803
epoch: 56, train_batch_id: 50, avg_cost: 3.85640549659729
grad_norm: 0.38745280331291887, clipped: 0.38745280331291887
epoch: 56, train_batch_id: 100, avg_cost: 3.8638916015625
grad_norm: 0.6243158143531368, clipped: 0.6243158143531368
epoch: 56, train_batch_id: 150, avg_cost: 3.8615598678588867
grad_norm: 0.4229125972609748, clipped: 0.4229125972609748
epoch: 56, train_batch_id: 200, avg_cost: 3.8361823558807373
grad_norm: 0.3939176286880363, clipped: 0.3939176286880363
epoch: 56, train_batch_id: 250, avg_cost: 3.8521647453308105
grad_norm: 0.24876998474998335, clipped: 0.24876998474998335
epoch: 56, train_batch_id: 300, avg_cost: 3.8402254581451416
grad_norm: 0.31645026597954296, clipped: 0.31645026597954296
epoch: 56, train_batch_id: 350, avg_cost: 3.8475263118743896
grad_norm: 0.22539909332557673, clipped: 0.22539909332557673
epoch: 56, train_batch_id: 400, avg_cost: 3.8256492614746094
grad_norm: 0.31985140703160214, clipped: 0.31985140703160214
epoch: 56, train_batch_id: 450, avg_cost: 3.851545810699463
grad_norm: 0.2968823537536176, clipped: 0.2968823537536176
epoch: 56, train_batch_id: 500, avg_cost: 3.8718156814575195
grad_norm: 0.35621489677511475, clipped: 0.35621489677511475
epoch: 56, train_batch_id: 550, avg_cost: 3.8516783714294434
grad_norm: 0.3271858558448221, clipped: 0.3271858558448221
epoch: 56, train_batch_id: 600, avg_cost: 3.8243796825408936
grad_norm: 0.34127746426693617, clipped: 0.34127746426693617
epoch: 56, train_batch_id: 650, avg_cost: 3.8739664554595947
grad_norm: 0.48015596702138647, clipped: 0.48015596702138647
epoch: 56, train_batch_id: 700, avg_cost: 3.834831714630127
grad_norm: 0.42780485232217036, clipped: 0.42780485232217036
epoch: 56, train_batch_id: 750, avg_cost: 3.8767127990722656
grad_norm: 0.3894407811171103, clipped: 0.3894407811171103
epoch: 56, train_batch_id: 800, avg_cost: 3.8335964679718018
grad_norm: 0.27001162788849986, clipped: 0.27001162788849986
epoch: 56, train_batch_id: 850, avg_cost: 3.8533363342285156
grad_norm: 0.7321498452612437, clipped: 0.7321498452612437
epoch: 56, train_batch_id: 900, avg_cost: 3.848144769668579
grad_norm: 0.22121928492273277, clipped: 0.22121928492273277
epoch: 56, train_batch_id: 950, avg_cost: 3.844222068786621
grad_norm: 0.39021938575024195, clipped: 0.39021938575024195
epoch: 56, train_batch_id: 1000, avg_cost: 3.8607044219970703
grad_norm: 0.3000538486186306, clipped: 0.3000538486186306
epoch: 56, train_batch_id: 1050, avg_cost: 3.8466668128967285
grad_norm: 0.3583594015117477, clipped: 0.3583594015117477
epoch: 56, train_batch_id: 1100, avg_cost: 3.8229424953460693
grad_norm: 0.40318233698398004, clipped: 0.40318233698398004
epoch: 56, train_batch_id: 1150, avg_cost: 3.850864887237549
grad_norm: 0.3241407637535995, clipped: 0.3241407637535995
epoch: 56, train_batch_id: 1200, avg_cost: 3.845404624938965
grad_norm: 0.4991838222685014, clipped: 0.4991838222685014
epoch: 56, train_batch_id: 1250, avg_cost: 3.8466525077819824
grad_norm: 0.34547513878425434, clipped: 0.34547513878425434
epoch: 56, train_batch_id: 1300, avg_cost: 3.843541145324707
grad_norm: 0.5863426270748462, clipped: 0.5863426270748462
epoch: 56, train_batch_id: 1350, avg_cost: 3.850907325744629
grad_norm: 0.3189907423472009, clipped: 0.3189907423472009
epoch: 56, train_batch_id: 1400, avg_cost: 3.845749855041504
grad_norm: 0.7773045842933592, clipped: 0.7773045842933592
epoch: 56, train_batch_id: 1450, avg_cost: 3.8403730392456055
grad_norm: 0.3690596770156572, clipped: 0.3690596770156572
epoch: 56, train_batch_id: 1500, avg_cost: 3.8453869819641113
grad_norm: 0.25681412699968525, clipped: 0.25681412699968525
epoch: 56, train_batch_id: 1550, avg_cost: 3.8463616371154785
grad_norm: 0.44383520162800305, clipped: 0.44383520162800305
epoch: 56, train_batch_id: 1600, avg_cost: 3.83028507232666
grad_norm: 0.258109000346943, clipped: 0.258109000346943
epoch: 56, train_batch_id: 1650, avg_cost: 3.813532590866089
grad_norm: 0.30044029057500676, clipped: 0.30044029057500676
epoch: 56, train_batch_id: 1700, avg_cost: 3.8571159839630127
grad_norm: 0.28689232129935865, clipped: 0.28689232129935865
epoch: 56, train_batch_id: 1750, avg_cost: 3.82263445854187
grad_norm: 0.40345474497615896, clipped: 0.40345474497615896
epoch: 56, train_batch_id: 1800, avg_cost: 3.83673095703125
grad_norm: 0.4812630432251482, clipped: 0.4812630432251482
epoch: 56, train_batch_id: 1850, avg_cost: 3.8651866912841797
grad_norm: 0.3191263751556495, clipped: 0.3191263751556495
epoch: 56, train_batch_id: 1900, avg_cost: 3.836759567260742
grad_norm: 0.5916386852847494, clipped: 0.5916386852847494
epoch: 56, train_batch_id: 1950, avg_cost: 3.8498876094818115
grad_norm: 0.3261054855513587, clipped: 0.3261054855513587
epoch: 56, train_batch_id: 2000, avg_cost: 3.8409171104431152
grad_norm: 0.36537436359998493, clipped: 0.36537436359998493
epoch: 56, train_batch_id: 2050, avg_cost: 3.8522884845733643
grad_norm: 0.27967498096708177, clipped: 0.27967498096708177
epoch: 56, train_batch_id: 2100, avg_cost: 3.842454433441162
grad_norm: 0.5398984359810022, clipped: 0.5398984359810022
epoch: 56, train_batch_id: 2150, avg_cost: 3.854914665222168
grad_norm: 0.5675372596047487, clipped: 0.5675372596047487
epoch: 56, train_batch_id: 2200, avg_cost: 3.8454337120056152
grad_norm: 0.3270462951634029, clipped: 0.3270462951634029
epoch: 56, train_batch_id: 2250, avg_cost: 3.850722312927246
grad_norm: 1.4233542613296049, clipped: 1.0
epoch: 56, train_batch_id: 2300, avg_cost: 3.86392879486084
grad_norm: 0.3144252420892797, clipped: 0.3144252420892797
epoch: 56, train_batch_id: 2350, avg_cost: 3.8643786907196045
grad_norm: 0.509272951260925, clipped: 0.509272951260925
epoch: 56, train_batch_id: 2400, avg_cost: 3.824463129043579
grad_norm: 0.2700599066829705, clipped: 0.2700599066829705
epoch: 56, train_batch_id: 2450, avg_cost: 3.8429954051971436
grad_norm: 0.32579199938735004, clipped: 0.32579199938735004
Finished epoch 56, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8483071327209473 +- 0.003111369675025344
Evaluating candidate model on evaluation dataset
Epoch 56 candidate mean 3.845695734024048, baseline epoch 48 mean 3.846060037612915, difference -0.0003643035888671875
p-value: 0.11890638560039196
Start train epoch 57, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 57, train_batch_id: 0, avg_cost: 3.853015422821045
grad_norm: 0.29717122653501166, clipped: 0.29717122653501166
epoch: 57, train_batch_id: 50, avg_cost: 3.843761444091797
grad_norm: 0.3640422424177949, clipped: 0.3640422424177949
epoch: 57, train_batch_id: 100, avg_cost: 3.8440160751342773
grad_norm: 0.39998763820852845, clipped: 0.39998763820852845
epoch: 57, train_batch_id: 150, avg_cost: 3.874763011932373
grad_norm: 0.31167011954725743, clipped: 0.31167011954725743
epoch: 57, train_batch_id: 200, avg_cost: 3.8524069786071777
grad_norm: 0.24205353342570055, clipped: 0.24205353342570055
epoch: 57, train_batch_id: 250, avg_cost: 3.8684072494506836
grad_norm: 0.45542832495688157, clipped: 0.45542832495688157
epoch: 57, train_batch_id: 300, avg_cost: 3.8533072471618652
grad_norm: 0.9859028533948803, clipped: 0.9859028533948803
epoch: 57, train_batch_id: 350, avg_cost: 3.862913131713867
grad_norm: 1.055426531375228, clipped: 1.0
epoch: 57, train_batch_id: 400, avg_cost: 3.858966827392578
grad_norm: 0.42140197686591857, clipped: 0.42140197686591857
epoch: 57, train_batch_id: 450, avg_cost: 3.859928607940674
grad_norm: 0.5717790273167578, clipped: 0.5717790273167578
epoch: 57, train_batch_id: 500, avg_cost: 3.8560004234313965
grad_norm: 0.537682578887872, clipped: 0.537682578887872
epoch: 57, train_batch_id: 550, avg_cost: 3.844482183456421
grad_norm: 0.4370376115207202, clipped: 0.4370376115207202
epoch: 57, train_batch_id: 600, avg_cost: 3.82674503326416
grad_norm: 0.4121711561750599, clipped: 0.4121711561750599
epoch: 57, train_batch_id: 650, avg_cost: 3.8461031913757324
grad_norm: 0.4158641291653131, clipped: 0.4158641291653131
epoch: 57, train_batch_id: 700, avg_cost: 3.8431577682495117
grad_norm: 0.28185094220199813, clipped: 0.28185094220199813
epoch: 57, train_batch_id: 750, avg_cost: 3.829557418823242
grad_norm: 0.27535469999486306, clipped: 0.27535469999486306
epoch: 57, train_batch_id: 800, avg_cost: 3.8596458435058594
grad_norm: 0.336264033188005, clipped: 0.336264033188005
epoch: 57, train_batch_id: 850, avg_cost: 3.855973720550537
grad_norm: 0.3024977496477154, clipped: 0.3024977496477154
epoch: 57, train_batch_id: 900, avg_cost: 3.8317747116088867
grad_norm: 0.32968151823305053, clipped: 0.32968151823305053
epoch: 57, train_batch_id: 950, avg_cost: 3.8444418907165527
grad_norm: 0.29400736893196755, clipped: 0.29400736893196755
epoch: 57, train_batch_id: 1000, avg_cost: 3.8547842502593994
grad_norm: 0.37509358610868465, clipped: 0.37509358610868465
epoch: 57, train_batch_id: 1050, avg_cost: 3.8477120399475098
grad_norm: 0.6673193586419386, clipped: 0.6673193586419386
epoch: 57, train_batch_id: 1100, avg_cost: 3.8301842212677
grad_norm: 0.6460156663183415, clipped: 0.6460156663183415
epoch: 57, train_batch_id: 1150, avg_cost: 3.8512039184570312
grad_norm: 0.4423372338546485, clipped: 0.4423372338546485
epoch: 57, train_batch_id: 1200, avg_cost: 3.865056037902832
grad_norm: 0.3536883870494775, clipped: 0.3536883870494775
epoch: 57, train_batch_id: 1250, avg_cost: 3.858394145965576
grad_norm: 0.3779139846827508, clipped: 0.3779139846827508
epoch: 57, train_batch_id: 1300, avg_cost: 3.827371835708618
grad_norm: 0.3904095846491603, clipped: 0.3904095846491603
epoch: 57, train_batch_id: 1350, avg_cost: 3.8356661796569824
grad_norm: 0.28090734112379867, clipped: 0.28090734112379867
epoch: 57, train_batch_id: 1400, avg_cost: 3.8639135360717773
grad_norm: 0.2540079713411589, clipped: 0.2540079713411589
epoch: 57, train_batch_id: 1450, avg_cost: 3.845176935195923
grad_norm: 0.2567976831839219, clipped: 0.2567976831839219
epoch: 57, train_batch_id: 1500, avg_cost: 3.8590028285980225
grad_norm: 0.3069871738675813, clipped: 0.3069871738675813
epoch: 57, train_batch_id: 1550, avg_cost: 3.8624892234802246
grad_norm: 0.560662310640222, clipped: 0.560662310640222
epoch: 57, train_batch_id: 1600, avg_cost: 3.8635902404785156
grad_norm: 0.6365481827003686, clipped: 0.6365481827003686
epoch: 57, train_batch_id: 1650, avg_cost: 3.8436148166656494
grad_norm: 0.555547217973598, clipped: 0.555547217973598
epoch: 57, train_batch_id: 1700, avg_cost: 3.84521484375
grad_norm: 0.3453817649343644, clipped: 0.3453817649343644
epoch: 57, train_batch_id: 1750, avg_cost: 3.8253064155578613
grad_norm: 0.25853961014542154, clipped: 0.25853961014542154
epoch: 57, train_batch_id: 1800, avg_cost: 3.8321683406829834
grad_norm: 0.283475241396632, clipped: 0.283475241396632
epoch: 57, train_batch_id: 1850, avg_cost: 3.857271194458008
grad_norm: 0.2889808153500867, clipped: 0.2889808153500867
epoch: 57, train_batch_id: 1900, avg_cost: 3.844482421875
grad_norm: 0.530093634346608, clipped: 0.530093634346608
epoch: 57, train_batch_id: 1950, avg_cost: 3.8655176162719727
grad_norm: 0.42309582364052967, clipped: 0.42309582364052967
epoch: 57, train_batch_id: 2000, avg_cost: 3.8644163608551025
grad_norm: 0.5109633167661914, clipped: 0.5109633167661914
epoch: 57, train_batch_id: 2050, avg_cost: 3.8595409393310547
grad_norm: 0.2855041588982303, clipped: 0.2855041588982303
epoch: 57, train_batch_id: 2100, avg_cost: 3.8389105796813965
grad_norm: 0.4743916856268557, clipped: 0.4743916856268557
epoch: 57, train_batch_id: 2150, avg_cost: 3.8857245445251465
grad_norm: 0.267678738028368, clipped: 0.267678738028368
epoch: 57, train_batch_id: 2200, avg_cost: 3.821293354034424
grad_norm: 0.3294117253566305, clipped: 0.3294117253566305
epoch: 57, train_batch_id: 2250, avg_cost: 3.860502243041992
grad_norm: 0.3101305623466001, clipped: 0.3101305623466001
epoch: 57, train_batch_id: 2300, avg_cost: 3.8530683517456055
grad_norm: 0.3823445347650632, clipped: 0.3823445347650632
epoch: 57, train_batch_id: 2350, avg_cost: 3.848494291305542
grad_norm: 0.3077451739639467, clipped: 0.3077451739639467
epoch: 57, train_batch_id: 2400, avg_cost: 3.8393197059631348
grad_norm: 0.24211369858489998, clipped: 0.24211369858489998
epoch: 57, train_batch_id: 2450, avg_cost: 3.876619815826416
grad_norm: 0.5190156544397004, clipped: 0.5190156544397004
Finished epoch 57, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8477907180786133 +- 0.0031072061974555254
Evaluating candidate model on evaluation dataset
Epoch 57 candidate mean 3.844909429550171, baseline epoch 48 mean 3.846060037612915, difference -0.0011506080627441406
p-value: 6.119711737675198e-05
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 58, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 58, train_batch_id: 0, avg_cost: 3.850955009460449
grad_norm: 0.3798762137426938, clipped: 0.3798762137426938
epoch: 58, train_batch_id: 50, avg_cost: 3.8336522579193115
grad_norm: 0.36616397911424564, clipped: 0.36616397911424564
epoch: 58, train_batch_id: 100, avg_cost: 3.834151029586792
grad_norm: 0.41752823325757416, clipped: 0.41752823325757416
epoch: 58, train_batch_id: 150, avg_cost: 3.831882953643799
grad_norm: 0.3269096356490833, clipped: 0.3269096356490833
epoch: 58, train_batch_id: 200, avg_cost: 3.8315954208374023
grad_norm: 0.24321525324165363, clipped: 0.24321525324165363
epoch: 58, train_batch_id: 250, avg_cost: 3.8560171127319336
grad_norm: 0.26739558821943993, clipped: 0.26739558821943993
epoch: 58, train_batch_id: 300, avg_cost: 3.83292555809021
grad_norm: 0.25674252231390005, clipped: 0.25674252231390005
epoch: 58, train_batch_id: 350, avg_cost: 3.862063407897949
grad_norm: 0.39947212046579533, clipped: 0.39947212046579533
epoch: 58, train_batch_id: 400, avg_cost: 3.8551292419433594
grad_norm: 0.2965745677073809, clipped: 0.2965745677073809
epoch: 58, train_batch_id: 450, avg_cost: 3.8362839221954346
grad_norm: 0.2590802973349641, clipped: 0.2590802973349641
epoch: 58, train_batch_id: 500, avg_cost: 3.8614978790283203
grad_norm: 0.3765706462754635, clipped: 0.3765706462754635
epoch: 58, train_batch_id: 550, avg_cost: 3.836284875869751
grad_norm: 0.342529046481381, clipped: 0.342529046481381
epoch: 58, train_batch_id: 600, avg_cost: 3.856595039367676
grad_norm: 0.2967195835016404, clipped: 0.2967195835016404
epoch: 58, train_batch_id: 650, avg_cost: 3.8620378971099854
grad_norm: 0.33792275050038384, clipped: 0.33792275050038384
epoch: 58, train_batch_id: 700, avg_cost: 3.8696980476379395
grad_norm: 0.620167504973985, clipped: 0.620167504973985
epoch: 58, train_batch_id: 750, avg_cost: 3.8972713947296143
grad_norm: 0.27558819908125937, clipped: 0.27558819908125937
epoch: 58, train_batch_id: 800, avg_cost: 3.8505983352661133
grad_norm: 0.5136928182037763, clipped: 0.5136928182037763
epoch: 58, train_batch_id: 850, avg_cost: 3.85715389251709
grad_norm: 0.3998319291122192, clipped: 0.3998319291122192
epoch: 58, train_batch_id: 900, avg_cost: 3.8666138648986816
grad_norm: 0.4123158665155248, clipped: 0.4123158665155248
epoch: 58, train_batch_id: 950, avg_cost: 3.8759326934814453
grad_norm: 0.27732170208039914, clipped: 0.27732170208039914
epoch: 58, train_batch_id: 1000, avg_cost: 3.858154773712158
grad_norm: 0.2841132081008625, clipped: 0.2841132081008625
epoch: 58, train_batch_id: 1050, avg_cost: 3.8529882431030273
grad_norm: 0.5423406327263257, clipped: 0.5423406327263257
epoch: 58, train_batch_id: 1100, avg_cost: 3.844613552093506
grad_norm: 0.3936969316367429, clipped: 0.3936969316367429
epoch: 58, train_batch_id: 1150, avg_cost: 3.842968463897705
grad_norm: 0.3205280892298556, clipped: 0.3205280892298556
epoch: 58, train_batch_id: 1200, avg_cost: 3.870889186859131
grad_norm: 0.256058803576057, clipped: 0.256058803576057
epoch: 58, train_batch_id: 1250, avg_cost: 3.8491899967193604
grad_norm: 0.3615326369740864, clipped: 0.3615326369740864
epoch: 58, train_batch_id: 1300, avg_cost: 3.8364462852478027
grad_norm: 0.34214893804939495, clipped: 0.34214893804939495
epoch: 58, train_batch_id: 1350, avg_cost: 3.8518483638763428
grad_norm: 0.3141499523165069, clipped: 0.3141499523165069
epoch: 58, train_batch_id: 1400, avg_cost: 3.870029926300049
grad_norm: 0.40993716707147015, clipped: 0.40993716707147015
epoch: 58, train_batch_id: 1450, avg_cost: 3.856745481491089
grad_norm: 0.34171728647597877, clipped: 0.34171728647597877
epoch: 58, train_batch_id: 1500, avg_cost: 3.8655776977539062
grad_norm: 0.322462433899757, clipped: 0.322462433899757
epoch: 58, train_batch_id: 1550, avg_cost: 3.8518810272216797
grad_norm: 0.40335351880325, clipped: 0.40335351880325
epoch: 58, train_batch_id: 1600, avg_cost: 3.8345224857330322
grad_norm: 0.25435936489423006, clipped: 0.25435936489423006
epoch: 58, train_batch_id: 1650, avg_cost: 3.840702772140503
grad_norm: 0.3251455199383893, clipped: 0.3251455199383893
epoch: 58, train_batch_id: 1700, avg_cost: 3.8404860496520996
grad_norm: 0.40821561700870757, clipped: 0.40821561700870757
epoch: 58, train_batch_id: 1750, avg_cost: 3.839480400085449
grad_norm: 0.6205861302016464, clipped: 0.6205861302016464
epoch: 58, train_batch_id: 1800, avg_cost: 3.836059808731079
grad_norm: 0.37912829232263373, clipped: 0.37912829232263373
epoch: 58, train_batch_id: 1850, avg_cost: 3.857388496398926
grad_norm: 0.393326436312347, clipped: 0.393326436312347
epoch: 58, train_batch_id: 1900, avg_cost: 3.8467860221862793
grad_norm: 0.25650713032181555, clipped: 0.25650713032181555
epoch: 58, train_batch_id: 1950, avg_cost: 3.8534669876098633
grad_norm: 0.3603790711051441, clipped: 0.3603790711051441
epoch: 58, train_batch_id: 2000, avg_cost: 3.8595974445343018
grad_norm: 0.3611576486449304, clipped: 0.3611576486449304
epoch: 58, train_batch_id: 2050, avg_cost: 3.875670909881592
grad_norm: 0.36101395099853767, clipped: 0.36101395099853767
epoch: 58, train_batch_id: 2100, avg_cost: 3.8715322017669678
grad_norm: 0.30779373995952963, clipped: 0.30779373995952963
epoch: 58, train_batch_id: 2150, avg_cost: 3.854062080383301
grad_norm: 0.48609819199539284, clipped: 0.48609819199539284
epoch: 58, train_batch_id: 2200, avg_cost: 3.8442301750183105
grad_norm: 0.42206951753803607, clipped: 0.42206951753803607
epoch: 58, train_batch_id: 2250, avg_cost: 3.843243360519409
grad_norm: 0.32417251258945956, clipped: 0.32417251258945956
epoch: 58, train_batch_id: 2300, avg_cost: 3.857923984527588
grad_norm: 0.28761374565247594, clipped: 0.28761374565247594
epoch: 58, train_batch_id: 2350, avg_cost: 3.866065263748169
grad_norm: 0.6420183239397946, clipped: 0.6420183239397946
epoch: 58, train_batch_id: 2400, avg_cost: 3.8434267044067383
grad_norm: 0.25730874906575263, clipped: 0.25730874906575263
epoch: 58, train_batch_id: 2450, avg_cost: 3.8736214637756348
grad_norm: 0.5557880938811781, clipped: 0.5557880938811781
Finished epoch 58, took 00:05:36 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8479485511779785 +- 0.0031094150617718697
Evaluating candidate model on evaluation dataset
Epoch 58 candidate mean 3.8516247272491455, baseline epoch 57 mean 3.8520359992980957, difference -0.0004112720489501953
p-value: 0.06776931341409766
Start train epoch 59, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 59, train_batch_id: 0, avg_cost: 3.8464300632476807
grad_norm: 0.4765563635513842, clipped: 0.4765563635513842
epoch: 59, train_batch_id: 50, avg_cost: 3.827296018600464
grad_norm: 0.2404844341960689, clipped: 0.2404844341960689
epoch: 59, train_batch_id: 100, avg_cost: 3.840627908706665
grad_norm: 0.2886360235250691, clipped: 0.2886360235250691
epoch: 59, train_batch_id: 150, avg_cost: 3.855154037475586
grad_norm: 0.4139771415920451, clipped: 0.4139771415920451
epoch: 59, train_batch_id: 200, avg_cost: 3.826784133911133
grad_norm: 0.4995881114536554, clipped: 0.4995881114536554
epoch: 59, train_batch_id: 250, avg_cost: 3.831745147705078
grad_norm: 0.31209103535843946, clipped: 0.31209103535843946
epoch: 59, train_batch_id: 300, avg_cost: 3.8455090522766113
grad_norm: 0.25111121730375124, clipped: 0.25111121730375124
epoch: 59, train_batch_id: 350, avg_cost: 3.843522787094116
grad_norm: 0.3427208907276738, clipped: 0.3427208907276738
epoch: 59, train_batch_id: 400, avg_cost: 3.8507325649261475
grad_norm: 0.2857054613898896, clipped: 0.2857054613898896
epoch: 59, train_batch_id: 450, avg_cost: 3.863112449645996
grad_norm: 0.44298288426404764, clipped: 0.44298288426404764
epoch: 59, train_batch_id: 500, avg_cost: 3.8346261978149414
grad_norm: 0.3901720608153836, clipped: 0.3901720608153836
epoch: 59, train_batch_id: 550, avg_cost: 3.8529205322265625
grad_norm: 0.30635841817442305, clipped: 0.30635841817442305
epoch: 59, train_batch_id: 600, avg_cost: 3.8275508880615234
grad_norm: 0.30054307722182966, clipped: 0.30054307722182966
epoch: 59, train_batch_id: 650, avg_cost: 3.845817804336548
grad_norm: 0.29199100650464255, clipped: 0.29199100650464255
epoch: 59, train_batch_id: 700, avg_cost: 3.8549928665161133
grad_norm: 0.5536213596303673, clipped: 0.5536213596303673
epoch: 59, train_batch_id: 750, avg_cost: 3.837161064147949
grad_norm: 0.2724936769141702, clipped: 0.2724936769141702
epoch: 59, train_batch_id: 800, avg_cost: 3.851891040802002
grad_norm: 1.4575408183034768, clipped: 1.0
epoch: 59, train_batch_id: 850, avg_cost: 3.835008144378662
grad_norm: 0.26879148195540675, clipped: 0.26879148195540675
epoch: 59, train_batch_id: 900, avg_cost: 3.8491783142089844
grad_norm: 0.29974444091262636, clipped: 0.29974444091262636
epoch: 59, train_batch_id: 950, avg_cost: 3.8654494285583496
grad_norm: 0.4194281668519845, clipped: 0.4194281668519845
epoch: 59, train_batch_id: 1000, avg_cost: 3.8528757095336914
grad_norm: 0.340814397865829, clipped: 0.340814397865829
epoch: 59, train_batch_id: 1050, avg_cost: 3.858806610107422
grad_norm: 0.3300925153296929, clipped: 0.3300925153296929
epoch: 59, train_batch_id: 1100, avg_cost: 3.858116626739502
grad_norm: 0.32824856815945047, clipped: 0.32824856815945047
epoch: 59, train_batch_id: 1150, avg_cost: 3.8489274978637695
grad_norm: 0.592788443590139, clipped: 0.592788443590139
epoch: 59, train_batch_id: 1200, avg_cost: 3.855700969696045
grad_norm: 0.6467259916353039, clipped: 0.6467259916353039
epoch: 59, train_batch_id: 1250, avg_cost: 3.8448472023010254
grad_norm: 0.5163389506774524, clipped: 0.5163389506774524
epoch: 59, train_batch_id: 1300, avg_cost: 3.8328700065612793
grad_norm: 0.4388538213487917, clipped: 0.4388538213487917
epoch: 59, train_batch_id: 1350, avg_cost: 3.8524694442749023
grad_norm: 0.3227356652263429, clipped: 0.3227356652263429
epoch: 59, train_batch_id: 1400, avg_cost: 3.8431291580200195
grad_norm: 0.45387290918643747, clipped: 0.45387290918643747
epoch: 59, train_batch_id: 1450, avg_cost: 3.8439993858337402
grad_norm: 0.21542722388340868, clipped: 0.21542722388340868
epoch: 59, train_batch_id: 1500, avg_cost: 3.857292652130127
grad_norm: 0.4198384968652471, clipped: 0.4198384968652471
epoch: 59, train_batch_id: 1550, avg_cost: 3.8308401107788086
grad_norm: 0.2831600689475842, clipped: 0.2831600689475842
epoch: 59, train_batch_id: 1600, avg_cost: 3.847468376159668
grad_norm: 0.3385007434634218, clipped: 0.3385007434634218
epoch: 59, train_batch_id: 1650, avg_cost: 3.837723731994629
grad_norm: 0.37550991739182477, clipped: 0.37550991739182477
epoch: 59, train_batch_id: 1700, avg_cost: 3.831712484359741
grad_norm: 0.3341648363575505, clipped: 0.3341648363575505
epoch: 59, train_batch_id: 1750, avg_cost: 3.8365397453308105
grad_norm: 0.24860251973314823, clipped: 0.24860251973314823
epoch: 59, train_batch_id: 1800, avg_cost: 3.8651814460754395
grad_norm: 0.30205130517733114, clipped: 0.30205130517733114
epoch: 59, train_batch_id: 1850, avg_cost: 3.863941192626953
grad_norm: 0.3594367660598548, clipped: 0.3594367660598548
epoch: 59, train_batch_id: 1900, avg_cost: 3.8420157432556152
grad_norm: 0.4629855081075277, clipped: 0.4629855081075277
epoch: 59, train_batch_id: 1950, avg_cost: 3.847900390625
grad_norm: 0.28195715667905336, clipped: 0.28195715667905336
epoch: 59, train_batch_id: 2000, avg_cost: 3.8286218643188477
grad_norm: 0.44890211141540043, clipped: 0.44890211141540043
epoch: 59, train_batch_id: 2050, avg_cost: 3.8694851398468018
grad_norm: 0.3186691966211051, clipped: 0.3186691966211051
epoch: 59, train_batch_id: 2100, avg_cost: 3.8356776237487793
grad_norm: 0.19978994690194424, clipped: 0.19978994690194424
epoch: 59, train_batch_id: 2150, avg_cost: 3.8475308418273926
grad_norm: 0.26222668687885353, clipped: 0.26222668687885353
epoch: 59, train_batch_id: 2200, avg_cost: 3.8393712043762207
grad_norm: 0.28605744245679127, clipped: 0.28605744245679127
epoch: 59, train_batch_id: 2250, avg_cost: 3.8648324012756348
grad_norm: 0.5288286566606536, clipped: 0.5288286566606536
epoch: 59, train_batch_id: 2300, avg_cost: 3.8746449947357178
grad_norm: 0.41855117246714685, clipped: 0.41855117246714685
epoch: 59, train_batch_id: 2350, avg_cost: 3.8386881351470947
grad_norm: 0.19820628594541373, clipped: 0.19820628594541373
epoch: 59, train_batch_id: 2400, avg_cost: 3.841989040374756
grad_norm: 0.7868802095666169, clipped: 0.7868802095666169
epoch: 59, train_batch_id: 2450, avg_cost: 3.850182294845581
grad_norm: 0.22943369880200756, clipped: 0.22943369880200756
Finished epoch 59, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8486335277557373 +- 0.0031098935287445784
Evaluating candidate model on evaluation dataset
Epoch 59 candidate mean 3.8524651527404785, baseline epoch 57 mean 3.8520359992980957, difference 0.0004291534423828125
Start train epoch 60, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 60, train_batch_id: 0, avg_cost: 3.8693976402282715
grad_norm: 0.37186713371650487, clipped: 0.37186713371650487
epoch: 60, train_batch_id: 50, avg_cost: 3.8656392097473145
grad_norm: 0.3089873288092607, clipped: 0.3089873288092607
epoch: 60, train_batch_id: 100, avg_cost: 3.8514318466186523
grad_norm: 0.3431966376549054, clipped: 0.3431966376549054
epoch: 60, train_batch_id: 150, avg_cost: 3.838728904724121
grad_norm: 0.28157972078041144, clipped: 0.28157972078041144
epoch: 60, train_batch_id: 200, avg_cost: 3.865811347961426
grad_norm: 0.6047662381208941, clipped: 0.6047662381208941
epoch: 60, train_batch_id: 250, avg_cost: 3.8416359424591064
grad_norm: 1.3896577205431806, clipped: 1.0
epoch: 60, train_batch_id: 300, avg_cost: 3.836160898208618
grad_norm: 0.3486760415036475, clipped: 0.3486760415036475
epoch: 60, train_batch_id: 350, avg_cost: 3.866429567337036
grad_norm: 0.29163927615904367, clipped: 0.29163927615904367
epoch: 60, train_batch_id: 400, avg_cost: 3.865875244140625
grad_norm: 0.2950534988181727, clipped: 0.2950534988181727
epoch: 60, train_batch_id: 450, avg_cost: 3.828738212585449
grad_norm: 0.4635342306455433, clipped: 0.4635342306455433
epoch: 60, train_batch_id: 500, avg_cost: 3.823817253112793
grad_norm: 0.22710018251286768, clipped: 0.22710018251286768
epoch: 60, train_batch_id: 550, avg_cost: 3.8388166427612305
grad_norm: 1.1859597330228018, clipped: 1.0
epoch: 60, train_batch_id: 600, avg_cost: 3.8599870204925537
grad_norm: 0.8762786528426996, clipped: 0.8762786528426996
epoch: 60, train_batch_id: 650, avg_cost: 3.817645311355591
grad_norm: 0.318825159076265, clipped: 0.318825159076265
epoch: 60, train_batch_id: 700, avg_cost: 3.821836233139038
grad_norm: 0.5214288739237057, clipped: 0.5214288739237057
epoch: 60, train_batch_id: 750, avg_cost: 3.864180564880371
grad_norm: 0.6142845389562184, clipped: 0.6142845389562184
epoch: 60, train_batch_id: 800, avg_cost: 3.845799684524536
grad_norm: 0.4265861367208122, clipped: 0.4265861367208122
epoch: 60, train_batch_id: 850, avg_cost: 3.852729320526123
grad_norm: 0.2498893541101626, clipped: 0.2498893541101626
epoch: 60, train_batch_id: 900, avg_cost: 3.8499276638031006
grad_norm: 0.2501536852435198, clipped: 0.2501536852435198
epoch: 60, train_batch_id: 950, avg_cost: 3.86323618888855
grad_norm: 0.31975846863255897, clipped: 0.31975846863255897
epoch: 60, train_batch_id: 1000, avg_cost: 3.8533437252044678
grad_norm: 0.2982297016648632, clipped: 0.2982297016648632
epoch: 60, train_batch_id: 1050, avg_cost: 3.850287675857544
grad_norm: 0.4092027143867, clipped: 0.4092027143867
epoch: 60, train_batch_id: 1100, avg_cost: 3.8467864990234375
grad_norm: 0.45588736364856924, clipped: 0.45588736364856924
epoch: 60, train_batch_id: 1150, avg_cost: 3.8420372009277344
grad_norm: 0.33220457431057754, clipped: 0.33220457431057754
epoch: 60, train_batch_id: 1200, avg_cost: 3.8568620681762695
grad_norm: 0.350276530962592, clipped: 0.350276530962592
epoch: 60, train_batch_id: 1250, avg_cost: 3.839114189147949
grad_norm: 0.3590224115393531, clipped: 0.3590224115393531
epoch: 60, train_batch_id: 1300, avg_cost: 3.84820556640625
grad_norm: 0.30377274513275576, clipped: 0.30377274513275576
epoch: 60, train_batch_id: 1350, avg_cost: 3.8531646728515625
grad_norm: 0.38514640927846794, clipped: 0.38514640927846794
epoch: 60, train_batch_id: 1400, avg_cost: 3.8371787071228027
grad_norm: 0.42182619425669954, clipped: 0.42182619425669954
epoch: 60, train_batch_id: 1450, avg_cost: 3.864675998687744
grad_norm: 0.6709562458615907, clipped: 0.6709562458615907
epoch: 60, train_batch_id: 1500, avg_cost: 3.8514931201934814
grad_norm: 0.44853686960931455, clipped: 0.44853686960931455
epoch: 60, train_batch_id: 1550, avg_cost: 3.8665499687194824
grad_norm: 0.9730922998102755, clipped: 0.9730922998102755
epoch: 60, train_batch_id: 1600, avg_cost: 3.8393959999084473
grad_norm: 0.4266303922770564, clipped: 0.4266303922770564
epoch: 60, train_batch_id: 1650, avg_cost: 3.8623034954071045
grad_norm: 0.3095709126647608, clipped: 0.3095709126647608
epoch: 60, train_batch_id: 1700, avg_cost: 3.848806619644165
grad_norm: 0.3310245658697445, clipped: 0.3310245658697445
epoch: 60, train_batch_id: 1750, avg_cost: 3.8491523265838623
grad_norm: 0.3290717704683068, clipped: 0.3290717704683068
epoch: 60, train_batch_id: 1800, avg_cost: 3.847115993499756
grad_norm: 1.084035780233029, clipped: 1.0
epoch: 60, train_batch_id: 1850, avg_cost: 3.839508056640625
grad_norm: 0.2860207733056046, clipped: 0.2860207733056046
epoch: 60, train_batch_id: 1900, avg_cost: 3.846156597137451
grad_norm: 0.4674346458642232, clipped: 0.4674346458642232
epoch: 60, train_batch_id: 1950, avg_cost: 3.863651752471924
grad_norm: 1.4699195033279475, clipped: 1.0
epoch: 60, train_batch_id: 2000, avg_cost: 3.83219051361084
grad_norm: 0.3328889681785546, clipped: 0.3328889681785546
epoch: 60, train_batch_id: 2050, avg_cost: 3.8698086738586426
grad_norm: 0.3209669258116746, clipped: 0.3209669258116746
epoch: 60, train_batch_id: 2100, avg_cost: 3.873382091522217
grad_norm: 0.30992346783450775, clipped: 0.30992346783450775
epoch: 60, train_batch_id: 2150, avg_cost: 3.8569812774658203
grad_norm: 0.8196592385581186, clipped: 0.8196592385581186
epoch: 60, train_batch_id: 2200, avg_cost: 3.8445019721984863
grad_norm: 0.3486170685426727, clipped: 0.3486170685426727
epoch: 60, train_batch_id: 2250, avg_cost: 3.8538360595703125
grad_norm: 0.736793078385321, clipped: 0.736793078385321
epoch: 60, train_batch_id: 2300, avg_cost: 3.8251521587371826
grad_norm: 0.28976686747996805, clipped: 0.28976686747996805
epoch: 60, train_batch_id: 2350, avg_cost: 3.8336730003356934
grad_norm: 0.30597691924467657, clipped: 0.30597691924467657
epoch: 60, train_batch_id: 2400, avg_cost: 3.8502955436706543
grad_norm: 0.28241030554049645, clipped: 0.28241030554049645
epoch: 60, train_batch_id: 2450, avg_cost: 3.8188233375549316
grad_norm: 0.3072461625908589, clipped: 0.3072461625908589
Finished epoch 60, took 00:05:25 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.847676992416382 +- 0.0031124120578169823
Evaluating candidate model on evaluation dataset
Epoch 60 candidate mean 3.8516347408294678, baseline epoch 57 mean 3.8520359992980957, difference -0.0004012584686279297
p-value: 0.0892191090483263
Start train epoch 61, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 61, train_batch_id: 0, avg_cost: 3.855682373046875
grad_norm: 0.3103054610589358, clipped: 0.3103054610589358
epoch: 61, train_batch_id: 50, avg_cost: 3.840378522872925
grad_norm: 0.5353667517204297, clipped: 0.5353667517204297
epoch: 61, train_batch_id: 100, avg_cost: 3.8295273780822754
grad_norm: 0.29061447252863476, clipped: 0.29061447252863476
epoch: 61, train_batch_id: 150, avg_cost: 3.8569984436035156
grad_norm: 0.31565656374864387, clipped: 0.31565656374864387
epoch: 61, train_batch_id: 200, avg_cost: 3.861743450164795
grad_norm: 0.3058109191844716, clipped: 0.3058109191844716
epoch: 61, train_batch_id: 250, avg_cost: 3.818906784057617
grad_norm: 0.26583842480712727, clipped: 0.26583842480712727
epoch: 61, train_batch_id: 300, avg_cost: 3.8315834999084473
grad_norm: 0.5906797804643261, clipped: 0.5906797804643261
epoch: 61, train_batch_id: 350, avg_cost: 3.8340134620666504
grad_norm: 0.24815549731610345, clipped: 0.24815549731610345
epoch: 61, train_batch_id: 400, avg_cost: 3.8422605991363525
grad_norm: 0.48987916467643516, clipped: 0.48987916467643516
epoch: 61, train_batch_id: 450, avg_cost: 3.8440189361572266
grad_norm: 0.44090123549316795, clipped: 0.44090123549316795
epoch: 61, train_batch_id: 500, avg_cost: 3.8359317779541016
grad_norm: 0.28374573781680007, clipped: 0.28374573781680007
epoch: 61, train_batch_id: 550, avg_cost: 3.861480236053467
grad_norm: 0.3494927433620016, clipped: 0.3494927433620016
epoch: 61, train_batch_id: 600, avg_cost: 3.8651583194732666
grad_norm: 0.29528996076420405, clipped: 0.29528996076420405
epoch: 61, train_batch_id: 650, avg_cost: 3.847602367401123
grad_norm: 0.2776031146776027, clipped: 0.2776031146776027
epoch: 61, train_batch_id: 700, avg_cost: 3.83538818359375
grad_norm: 0.3256813478340537, clipped: 0.3256813478340537
epoch: 61, train_batch_id: 750, avg_cost: 3.8173933029174805
grad_norm: 0.19598509540952808, clipped: 0.19598509540952808
epoch: 61, train_batch_id: 800, avg_cost: 3.8259787559509277
grad_norm: 0.4857147457549791, clipped: 0.4857147457549791
epoch: 61, train_batch_id: 850, avg_cost: 3.8433895111083984
grad_norm: 0.42803749549632586, clipped: 0.42803749549632586
epoch: 61, train_batch_id: 900, avg_cost: 3.859205722808838
grad_norm: 0.3494626071568135, clipped: 0.3494626071568135
epoch: 61, train_batch_id: 950, avg_cost: 3.849228620529175
grad_norm: 0.3396254844922561, clipped: 0.3396254844922561
epoch: 61, train_batch_id: 1000, avg_cost: 3.856081962585449
grad_norm: 0.2814319079064122, clipped: 0.2814319079064122
epoch: 61, train_batch_id: 1050, avg_cost: 3.838447093963623
grad_norm: 0.3872302614086628, clipped: 0.3872302614086628
epoch: 61, train_batch_id: 1100, avg_cost: 3.8440818786621094
grad_norm: 0.3190861705539771, clipped: 0.3190861705539771
epoch: 61, train_batch_id: 1150, avg_cost: 3.856081962585449
grad_norm: 0.5459980826325997, clipped: 0.5459980826325997
epoch: 61, train_batch_id: 1200, avg_cost: 3.8784420490264893
grad_norm: 0.3116061678856678, clipped: 0.3116061678856678
epoch: 61, train_batch_id: 1250, avg_cost: 3.837724208831787
grad_norm: 0.2783625002145654, clipped: 0.2783625002145654
epoch: 61, train_batch_id: 1300, avg_cost: 3.85843563079834
grad_norm: 0.48284662970054226, clipped: 0.48284662970054226
epoch: 61, train_batch_id: 1350, avg_cost: 3.8713526725769043
grad_norm: 0.41260092335036924, clipped: 0.41260092335036924
epoch: 61, train_batch_id: 1400, avg_cost: 3.851083755493164
grad_norm: 0.3282750005843969, clipped: 0.3282750005843969
epoch: 61, train_batch_id: 1450, avg_cost: 3.852066993713379
grad_norm: 0.4815829008914122, clipped: 0.4815829008914122
epoch: 61, train_batch_id: 1500, avg_cost: 3.848367691040039
grad_norm: 0.2554422047368665, clipped: 0.2554422047368665
epoch: 61, train_batch_id: 1550, avg_cost: 3.850374460220337
grad_norm: 0.32469437506739063, clipped: 0.32469437506739063
epoch: 61, train_batch_id: 1600, avg_cost: 3.8319168090820312
grad_norm: 0.22843205574626063, clipped: 0.22843205574626063
epoch: 61, train_batch_id: 1650, avg_cost: 3.875889778137207
grad_norm: 0.24411649245682435, clipped: 0.24411649245682435
epoch: 61, train_batch_id: 1700, avg_cost: 3.85018253326416
grad_norm: 0.25310232378997893, clipped: 0.25310232378997893
epoch: 61, train_batch_id: 1750, avg_cost: 3.8364531993865967
grad_norm: 0.26233709039556685, clipped: 0.26233709039556685
epoch: 61, train_batch_id: 1800, avg_cost: 3.8463802337646484
grad_norm: 0.49831624464421465, clipped: 0.49831624464421465
epoch: 61, train_batch_id: 1850, avg_cost: 3.8459725379943848
grad_norm: 0.39685600403634125, clipped: 0.39685600403634125
epoch: 61, train_batch_id: 1900, avg_cost: 3.862307071685791
grad_norm: 0.34149158702756643, clipped: 0.34149158702756643
epoch: 61, train_batch_id: 1950, avg_cost: 3.8482236862182617
grad_norm: 0.40039611866805225, clipped: 0.40039611866805225
epoch: 61, train_batch_id: 2000, avg_cost: 3.8263068199157715
grad_norm: 0.41764687931949895, clipped: 0.41764687931949895
epoch: 61, train_batch_id: 2050, avg_cost: 3.8546857833862305
grad_norm: 0.2088603505201591, clipped: 0.2088603505201591
epoch: 61, train_batch_id: 2100, avg_cost: 3.839550495147705
grad_norm: 0.4767017915285008, clipped: 0.4767017915285008
epoch: 61, train_batch_id: 2150, avg_cost: 3.8394415378570557
grad_norm: 0.27848010661981454, clipped: 0.27848010661981454
epoch: 61, train_batch_id: 2200, avg_cost: 3.831493377685547
grad_norm: 0.2823582157664357, clipped: 0.2823582157664357
epoch: 61, train_batch_id: 2250, avg_cost: 3.8217849731445312
grad_norm: 0.41876430506006473, clipped: 0.41876430506006473
epoch: 61, train_batch_id: 2300, avg_cost: 3.835038185119629
grad_norm: 0.3651352224107024, clipped: 0.3651352224107024
epoch: 61, train_batch_id: 2350, avg_cost: 3.839052438735962
grad_norm: 0.2635840388939376, clipped: 0.2635840388939376
epoch: 61, train_batch_id: 2400, avg_cost: 3.8475985527038574
grad_norm: 0.4620146568979605, clipped: 0.4620146568979605
epoch: 61, train_batch_id: 2450, avg_cost: 3.851132392883301
grad_norm: 0.30231377471520265, clipped: 0.30231377471520265
Finished epoch 61, took 00:05:28 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.84710693359375 +- 0.003103304887190461
Evaluating candidate model on evaluation dataset
Epoch 61 candidate mean 3.8514809608459473, baseline epoch 57 mean 3.8520359992980957, difference -0.0005550384521484375
p-value: 0.024301060226102393
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 62, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 62, train_batch_id: 0, avg_cost: 3.8406786918640137
grad_norm: 0.2559812166023036, clipped: 0.2559812166023036
epoch: 62, train_batch_id: 50, avg_cost: 3.8436241149902344
grad_norm: 0.22864719402968514, clipped: 0.22864719402968514
epoch: 62, train_batch_id: 100, avg_cost: 3.8478407859802246
grad_norm: 0.4505097850305364, clipped: 0.4505097850305364
epoch: 62, train_batch_id: 150, avg_cost: 3.845048189163208
grad_norm: 0.24332254875382295, clipped: 0.24332254875382295
epoch: 62, train_batch_id: 200, avg_cost: 3.845952272415161
grad_norm: 0.7302804589990259, clipped: 0.7302804589990259
epoch: 62, train_batch_id: 250, avg_cost: 3.862961530685425
grad_norm: 0.33797504592348837, clipped: 0.33797504592348837
epoch: 62, train_batch_id: 300, avg_cost: 3.8580820560455322
grad_norm: 0.433185969436223, clipped: 0.433185969436223
epoch: 62, train_batch_id: 350, avg_cost: 3.820916175842285
grad_norm: 0.5847535060076818, clipped: 0.5847535060076818
epoch: 62, train_batch_id: 400, avg_cost: 3.820650577545166
grad_norm: 0.33800733841368985, clipped: 0.33800733841368985
epoch: 62, train_batch_id: 450, avg_cost: 3.8420989513397217
grad_norm: 0.31481260961040314, clipped: 0.31481260961040314
epoch: 62, train_batch_id: 500, avg_cost: 3.8568451404571533
grad_norm: 0.315115209122745, clipped: 0.315115209122745
epoch: 62, train_batch_id: 550, avg_cost: 3.8587005138397217
grad_norm: 0.48210164398666105, clipped: 0.48210164398666105
epoch: 62, train_batch_id: 600, avg_cost: 3.875537872314453
grad_norm: 0.4662166242149749, clipped: 0.4662166242149749
epoch: 62, train_batch_id: 650, avg_cost: 3.83333683013916
grad_norm: 1.4529344977474297, clipped: 1.0
epoch: 62, train_batch_id: 700, avg_cost: 3.8389317989349365
grad_norm: 0.46707865480307603, clipped: 0.46707865480307603
epoch: 62, train_batch_id: 750, avg_cost: 3.841219186782837
grad_norm: 0.36941133684313915, clipped: 0.36941133684313915
epoch: 62, train_batch_id: 800, avg_cost: 3.8547728061676025
grad_norm: 0.3537703295218739, clipped: 0.3537703295218739
epoch: 62, train_batch_id: 850, avg_cost: 3.846320152282715
grad_norm: 0.250715291290451, clipped: 0.250715291290451
epoch: 62, train_batch_id: 900, avg_cost: 3.8614273071289062
grad_norm: 0.2989068520336732, clipped: 0.2989068520336732
epoch: 62, train_batch_id: 950, avg_cost: 3.8456127643585205
grad_norm: 0.3063348864329524, clipped: 0.3063348864329524
epoch: 62, train_batch_id: 1000, avg_cost: 3.831594228744507
grad_norm: 0.40534765352794416, clipped: 0.40534765352794416
epoch: 62, train_batch_id: 1050, avg_cost: 3.858689308166504
grad_norm: 0.3087203211864022, clipped: 0.3087203211864022
epoch: 62, train_batch_id: 1100, avg_cost: 3.836618423461914
grad_norm: 0.386032040562523, clipped: 0.386032040562523
epoch: 62, train_batch_id: 1150, avg_cost: 3.85076642036438
grad_norm: 0.2922436825772778, clipped: 0.2922436825772778
epoch: 62, train_batch_id: 1200, avg_cost: 3.8733386993408203
grad_norm: 0.2977310062571275, clipped: 0.2977310062571275
epoch: 62, train_batch_id: 1250, avg_cost: 3.83738112449646
grad_norm: 0.5527729357880583, clipped: 0.5527729357880583
epoch: 62, train_batch_id: 1300, avg_cost: 3.823385238647461
grad_norm: 0.3097840744241927, clipped: 0.3097840744241927
epoch: 62, train_batch_id: 1350, avg_cost: 3.848087787628174
grad_norm: 0.3512784157526077, clipped: 0.3512784157526077
epoch: 62, train_batch_id: 1400, avg_cost: 3.8567631244659424
grad_norm: 0.41138535137234483, clipped: 0.41138535137234483
epoch: 62, train_batch_id: 1450, avg_cost: 3.8617420196533203
grad_norm: 0.5287166025408953, clipped: 0.5287166025408953
epoch: 62, train_batch_id: 1500, avg_cost: 3.847202777862549
grad_norm: 0.1946299015873956, clipped: 0.1946299015873956
epoch: 62, train_batch_id: 1550, avg_cost: 3.8442044258117676
grad_norm: 0.4448617163000549, clipped: 0.4448617163000549
epoch: 62, train_batch_id: 1600, avg_cost: 3.820791721343994
grad_norm: 0.32555670809993414, clipped: 0.32555670809993414
epoch: 62, train_batch_id: 1650, avg_cost: 3.8355064392089844
grad_norm: 0.4037229744715446, clipped: 0.4037229744715446
epoch: 62, train_batch_id: 1700, avg_cost: 3.8428142070770264
grad_norm: 0.3239313858015054, clipped: 0.3239313858015054
epoch: 62, train_batch_id: 1750, avg_cost: 3.849313497543335
grad_norm: 0.35612705776337183, clipped: 0.35612705776337183
epoch: 62, train_batch_id: 1800, avg_cost: 3.85164213180542
grad_norm: 0.49748378638594914, clipped: 0.49748378638594914
epoch: 62, train_batch_id: 1850, avg_cost: 3.831864356994629
grad_norm: 0.4110052346754152, clipped: 0.4110052346754152
epoch: 62, train_batch_id: 1900, avg_cost: 3.8200502395629883
grad_norm: 0.6348844947847093, clipped: 0.6348844947847093
epoch: 62, train_batch_id: 1950, avg_cost: 3.860348701477051
grad_norm: 0.44635671070793786, clipped: 0.44635671070793786
epoch: 62, train_batch_id: 2000, avg_cost: 3.809950351715088
grad_norm: 0.24512895802282056, clipped: 0.24512895802282056
epoch: 62, train_batch_id: 2050, avg_cost: 3.8479318618774414
grad_norm: 0.4123618862301522, clipped: 0.4123618862301522
epoch: 62, train_batch_id: 2100, avg_cost: 3.8675479888916016
grad_norm: 0.4228549273013094, clipped: 0.4228549273013094
epoch: 62, train_batch_id: 2150, avg_cost: 3.8490264415740967
grad_norm: 0.3401807034603681, clipped: 0.3401807034603681
epoch: 62, train_batch_id: 2200, avg_cost: 3.819655656814575
grad_norm: 0.4154500825551124, clipped: 0.4154500825551124
epoch: 62, train_batch_id: 2250, avg_cost: 3.8650851249694824
grad_norm: 0.27406340425550996, clipped: 0.27406340425550996
epoch: 62, train_batch_id: 2300, avg_cost: 3.849397659301758
grad_norm: 0.4015169167246176, clipped: 0.4015169167246176
epoch: 62, train_batch_id: 2350, avg_cost: 3.849821090698242
grad_norm: 0.2763856026642584, clipped: 0.2763856026642584
epoch: 62, train_batch_id: 2400, avg_cost: 3.8591060638427734
grad_norm: 0.3772888435269718, clipped: 0.3772888435269718
epoch: 62, train_batch_id: 2450, avg_cost: 3.8396520614624023
grad_norm: 0.27586140542243714, clipped: 0.27586140542243714
Finished epoch 62, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8480141162872314 +- 0.0031105095986276865
Evaluating candidate model on evaluation dataset
Epoch 62 candidate mean 3.8501086235046387, baseline epoch 61 mean 3.8499972820281982, difference 0.00011134147644042969
Start train epoch 63, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 63, train_batch_id: 0, avg_cost: 3.8535242080688477
grad_norm: 1.8939954125623357, clipped: 1.0
epoch: 63, train_batch_id: 50, avg_cost: 3.8365092277526855
grad_norm: 0.38560566435390825, clipped: 0.38560566435390825
epoch: 63, train_batch_id: 100, avg_cost: 3.8467531204223633
grad_norm: 0.318252471591191, clipped: 0.318252471591191
epoch: 63, train_batch_id: 150, avg_cost: 3.8573975563049316
grad_norm: 0.33560651652048634, clipped: 0.33560651652048634
epoch: 63, train_batch_id: 200, avg_cost: 3.874563694000244
grad_norm: 0.29302559837943504, clipped: 0.29302559837943504
epoch: 63, train_batch_id: 250, avg_cost: 3.850278615951538
grad_norm: 0.41148632137615776, clipped: 0.41148632137615776
epoch: 63, train_batch_id: 300, avg_cost: 3.834592342376709
grad_norm: 0.5029571357505113, clipped: 0.5029571357505113
epoch: 63, train_batch_id: 350, avg_cost: 3.871188163757324
grad_norm: 0.3498053730593181, clipped: 0.3498053730593181
epoch: 63, train_batch_id: 400, avg_cost: 3.8558340072631836
grad_norm: 0.3614098081558242, clipped: 0.3614098081558242
epoch: 63, train_batch_id: 450, avg_cost: 3.821171760559082
grad_norm: 0.25126171815472337, clipped: 0.25126171815472337
epoch: 63, train_batch_id: 500, avg_cost: 3.8292882442474365
grad_norm: 0.2942358911051327, clipped: 0.2942358911051327
epoch: 63, train_batch_id: 550, avg_cost: 3.8284897804260254
grad_norm: 0.23720421256355717, clipped: 0.23720421256355717
epoch: 63, train_batch_id: 600, avg_cost: 3.846052646636963
grad_norm: 0.3409907658133114, clipped: 0.3409907658133114
epoch: 63, train_batch_id: 650, avg_cost: 3.8378801345825195
grad_norm: 0.44042436590230255, clipped: 0.44042436590230255
epoch: 63, train_batch_id: 700, avg_cost: 3.8424341678619385
grad_norm: 0.5285918041445418, clipped: 0.5285918041445418
epoch: 63, train_batch_id: 750, avg_cost: 3.8557095527648926
grad_norm: 0.323485651725983, clipped: 0.323485651725983
epoch: 63, train_batch_id: 800, avg_cost: 3.8550360202789307
grad_norm: 0.2776311257054489, clipped: 0.2776311257054489
epoch: 63, train_batch_id: 850, avg_cost: 3.864680767059326
grad_norm: 0.3255544842551071, clipped: 0.3255544842551071
epoch: 63, train_batch_id: 900, avg_cost: 3.852865219116211
grad_norm: 0.38593550793700754, clipped: 0.38593550793700754
epoch: 63, train_batch_id: 950, avg_cost: 3.8317112922668457
grad_norm: 0.25132466642278184, clipped: 0.25132466642278184
epoch: 63, train_batch_id: 1000, avg_cost: 3.847612142562866
grad_norm: 0.3259565644006695, clipped: 0.3259565644006695
epoch: 63, train_batch_id: 1050, avg_cost: 3.8663268089294434
grad_norm: 0.5068726806151185, clipped: 0.5068726806151185
epoch: 63, train_batch_id: 1100, avg_cost: 3.857142686843872
grad_norm: 0.2572115195788139, clipped: 0.2572115195788139
epoch: 63, train_batch_id: 1150, avg_cost: 3.845952033996582
grad_norm: 0.3196463681246989, clipped: 0.3196463681246989
epoch: 63, train_batch_id: 1200, avg_cost: 3.8470163345336914
grad_norm: 0.3918376588300488, clipped: 0.3918376588300488
epoch: 63, train_batch_id: 1250, avg_cost: 3.855861186981201
grad_norm: 0.2811533232993837, clipped: 0.2811533232993837
epoch: 63, train_batch_id: 1300, avg_cost: 3.868126153945923
grad_norm: 0.36245256342189214, clipped: 0.36245256342189214
epoch: 63, train_batch_id: 1350, avg_cost: 3.821444034576416
grad_norm: 0.9678846137823024, clipped: 0.9678846137823024
epoch: 63, train_batch_id: 1400, avg_cost: 3.8392333984375
grad_norm: 0.38663293415574534, clipped: 0.38663293415574534
epoch: 63, train_batch_id: 1450, avg_cost: 3.8691654205322266
grad_norm: 0.22523682445600082, clipped: 0.22523682445600082
epoch: 63, train_batch_id: 1500, avg_cost: 3.858834743499756
grad_norm: 0.506829924696851, clipped: 0.506829924696851
epoch: 63, train_batch_id: 1550, avg_cost: 3.8436312675476074
grad_norm: 0.5756532308172881, clipped: 0.5756532308172881
epoch: 63, train_batch_id: 1600, avg_cost: 3.85429310798645
grad_norm: 0.5683282570943435, clipped: 0.5683282570943435
epoch: 63, train_batch_id: 1650, avg_cost: 3.8289499282836914
grad_norm: 0.27998872968327065, clipped: 0.27998872968327065
epoch: 63, train_batch_id: 1700, avg_cost: 3.8158106803894043
grad_norm: 0.2938230680461306, clipped: 0.2938230680461306
epoch: 63, train_batch_id: 1750, avg_cost: 3.836543560028076
grad_norm: 0.47440399852447546, clipped: 0.47440399852447546
epoch: 63, train_batch_id: 1800, avg_cost: 3.833829641342163
grad_norm: 0.261743162202508, clipped: 0.261743162202508
epoch: 63, train_batch_id: 1850, avg_cost: 3.839637041091919
grad_norm: 0.781496549420594, clipped: 0.781496549420594
epoch: 63, train_batch_id: 1900, avg_cost: 3.836772918701172
grad_norm: 0.3257171257991042, clipped: 0.3257171257991042
epoch: 63, train_batch_id: 1950, avg_cost: 3.846950054168701
grad_norm: 0.5422091043948732, clipped: 0.5422091043948732
epoch: 63, train_batch_id: 2000, avg_cost: 3.824174642562866
grad_norm: 0.32243057092251803, clipped: 0.32243057092251803
epoch: 63, train_batch_id: 2050, avg_cost: 3.8524744510650635
grad_norm: 0.3377346382153757, clipped: 0.3377346382153757
epoch: 63, train_batch_id: 2100, avg_cost: 3.8500514030456543
grad_norm: 0.30266475961006273, clipped: 0.30266475961006273
epoch: 63, train_batch_id: 2150, avg_cost: 3.856981039047241
grad_norm: 0.30604065165462113, clipped: 0.30604065165462113
epoch: 63, train_batch_id: 2200, avg_cost: 3.8725526332855225
grad_norm: 0.3610324670192524, clipped: 0.3610324670192524
epoch: 63, train_batch_id: 2250, avg_cost: 3.855323314666748
grad_norm: 0.5969355387032667, clipped: 0.5969355387032667
epoch: 63, train_batch_id: 2300, avg_cost: 3.8604226112365723
grad_norm: 0.32424996665985106, clipped: 0.32424996665985106
epoch: 63, train_batch_id: 2350, avg_cost: 3.8383421897888184
grad_norm: 0.341398909242897, clipped: 0.341398909242897
epoch: 63, train_batch_id: 2400, avg_cost: 3.837036609649658
grad_norm: 0.3778967600385176, clipped: 0.3778967600385176
epoch: 63, train_batch_id: 2450, avg_cost: 3.8226516246795654
grad_norm: 0.28434883602505934, clipped: 0.28434883602505934
Finished epoch 63, took 00:05:35 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.848604202270508 +- 0.003106083022430539
Evaluating candidate model on evaluation dataset
Epoch 63 candidate mean 3.8509750366210938, baseline epoch 61 mean 3.8499972820281982, difference 0.0009777545928955078
Start train epoch 64, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 64, train_batch_id: 0, avg_cost: 3.8571462631225586
grad_norm: 0.3962819788141926, clipped: 0.3962819788141926
epoch: 64, train_batch_id: 50, avg_cost: 3.846665143966675
grad_norm: 0.2706963062566363, clipped: 0.2706963062566363
epoch: 64, train_batch_id: 100, avg_cost: 3.8231394290924072
grad_norm: 0.313910813528732, clipped: 0.313910813528732
epoch: 64, train_batch_id: 150, avg_cost: 3.8606839179992676
grad_norm: 0.3575268698659807, clipped: 0.3575268698659807
epoch: 64, train_batch_id: 200, avg_cost: 3.843905210494995
grad_norm: 0.944537935014896, clipped: 0.944537935014896
epoch: 64, train_batch_id: 250, avg_cost: 3.8654656410217285
grad_norm: 0.27885239814110263, clipped: 0.27885239814110263
epoch: 64, train_batch_id: 300, avg_cost: 3.8325862884521484
grad_norm: 0.36316423521420466, clipped: 0.36316423521420466
epoch: 64, train_batch_id: 350, avg_cost: 3.8656351566314697
grad_norm: 1.0812342317071078, clipped: 1.0
epoch: 64, train_batch_id: 400, avg_cost: 3.86137318611145
grad_norm: 0.446242717953023, clipped: 0.446242717953023
epoch: 64, train_batch_id: 450, avg_cost: 3.8216309547424316
grad_norm: 0.4619848353944987, clipped: 0.4619848353944987
epoch: 64, train_batch_id: 500, avg_cost: 3.839280605316162
grad_norm: 0.37354033563605493, clipped: 0.37354033563605493
epoch: 64, train_batch_id: 550, avg_cost: 3.860105037689209
grad_norm: 0.45707365875135775, clipped: 0.45707365875135775
epoch: 64, train_batch_id: 600, avg_cost: 3.859579086303711
grad_norm: 0.29554693013292305, clipped: 0.29554693013292305
epoch: 64, train_batch_id: 650, avg_cost: 3.8637707233428955
grad_norm: 0.46034869411188256, clipped: 0.46034869411188256
epoch: 64, train_batch_id: 700, avg_cost: 3.8422298431396484
grad_norm: 0.296658738871704, clipped: 0.296658738871704
epoch: 64, train_batch_id: 750, avg_cost: 3.8294241428375244
grad_norm: 0.44219899415971076, clipped: 0.44219899415971076
epoch: 64, train_batch_id: 800, avg_cost: 3.8530783653259277
grad_norm: 0.5271983027285323, clipped: 0.5271983027285323
epoch: 64, train_batch_id: 850, avg_cost: 3.861326217651367
grad_norm: 0.2761278693790566, clipped: 0.2761278693790566
epoch: 64, train_batch_id: 900, avg_cost: 3.8407158851623535
grad_norm: 0.4509703871406605, clipped: 0.4509703871406605
epoch: 64, train_batch_id: 950, avg_cost: 3.84226131439209
grad_norm: 0.37320342124923317, clipped: 0.37320342124923317
epoch: 64, train_batch_id: 1000, avg_cost: 3.8450276851654053
grad_norm: 0.28688867752334585, clipped: 0.28688867752334585
epoch: 64, train_batch_id: 1050, avg_cost: 3.8620221614837646
grad_norm: 0.4010306082971852, clipped: 0.4010306082971852
epoch: 64, train_batch_id: 1100, avg_cost: 3.8264150619506836
grad_norm: 0.32712707765210747, clipped: 0.32712707765210747
epoch: 64, train_batch_id: 1150, avg_cost: 3.8467214107513428
grad_norm: 0.40789624953038345, clipped: 0.40789624953038345
epoch: 64, train_batch_id: 1200, avg_cost: 3.8705201148986816
grad_norm: 0.3137577014321188, clipped: 0.3137577014321188
epoch: 64, train_batch_id: 1250, avg_cost: 3.8564412593841553
grad_norm: 0.5415449779309401, clipped: 0.5415449779309401
epoch: 64, train_batch_id: 1300, avg_cost: 3.8371706008911133
grad_norm: 0.27133484666822233, clipped: 0.27133484666822233
epoch: 64, train_batch_id: 1350, avg_cost: 3.8661599159240723
grad_norm: 0.3710332498771245, clipped: 0.3710332498771245
epoch: 64, train_batch_id: 1400, avg_cost: 3.8374624252319336
grad_norm: 0.43228272610935853, clipped: 0.43228272610935853
epoch: 64, train_batch_id: 1450, avg_cost: 3.85565447807312
grad_norm: 0.25681452063146526, clipped: 0.25681452063146526
epoch: 64, train_batch_id: 1500, avg_cost: 3.8489584922790527
grad_norm: 0.5727009889200293, clipped: 0.5727009889200293
epoch: 64, train_batch_id: 1550, avg_cost: 3.817397117614746
grad_norm: 0.3118330408085385, clipped: 0.3118330408085385
epoch: 64, train_batch_id: 1600, avg_cost: 3.838301658630371
grad_norm: 0.9175323021327819, clipped: 0.9175323021327819
epoch: 64, train_batch_id: 1650, avg_cost: 3.864823818206787
grad_norm: 0.5280215302137341, clipped: 0.5280215302137341
epoch: 64, train_batch_id: 1700, avg_cost: 3.844792366027832
grad_norm: 1.0535691601883255, clipped: 1.0
epoch: 64, train_batch_id: 1750, avg_cost: 3.8426406383514404
grad_norm: 0.4206005466093102, clipped: 0.4206005466093102
epoch: 64, train_batch_id: 1800, avg_cost: 3.8371009826660156
grad_norm: 0.4475734689831692, clipped: 0.4475734689831692
epoch: 64, train_batch_id: 1850, avg_cost: 3.867219924926758
grad_norm: 0.24453566979555225, clipped: 0.24453566979555225
epoch: 64, train_batch_id: 1900, avg_cost: 3.8202946186065674
grad_norm: 0.43423773504740004, clipped: 0.43423773504740004
epoch: 64, train_batch_id: 1950, avg_cost: 3.8589091300964355
grad_norm: 0.25485024696615016, clipped: 0.25485024696615016
epoch: 64, train_batch_id: 2000, avg_cost: 3.844818115234375
grad_norm: 0.32156589245391254, clipped: 0.32156589245391254
epoch: 64, train_batch_id: 2050, avg_cost: 3.8528084754943848
grad_norm: 0.3358275458894291, clipped: 0.3358275458894291
epoch: 64, train_batch_id: 2100, avg_cost: 3.8176305294036865
grad_norm: 0.41315691530695414, clipped: 0.41315691530695414
epoch: 64, train_batch_id: 2150, avg_cost: 3.8515450954437256
grad_norm: 0.3112331055413147, clipped: 0.3112331055413147
epoch: 64, train_batch_id: 2200, avg_cost: 3.8521664142608643
grad_norm: 0.34728481122700167, clipped: 0.34728481122700167
epoch: 64, train_batch_id: 2250, avg_cost: 3.8464279174804688
grad_norm: 0.4633381602196329, clipped: 0.4633381602196329
epoch: 64, train_batch_id: 2300, avg_cost: 3.824490547180176
grad_norm: 0.3717596116475758, clipped: 0.3717596116475758
epoch: 64, train_batch_id: 2350, avg_cost: 3.8649559020996094
grad_norm: 0.4571138364147342, clipped: 0.4571138364147342
epoch: 64, train_batch_id: 2400, avg_cost: 3.8588030338287354
grad_norm: 0.35999755121659244, clipped: 0.35999755121659244
epoch: 64, train_batch_id: 2450, avg_cost: 3.839038133621216
grad_norm: 0.32966554881438115, clipped: 0.32966554881438115
Finished epoch 64, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.847623109817505 +- 0.0031071866396814585
Evaluating candidate model on evaluation dataset
Epoch 64 candidate mean 3.849871873855591, baseline epoch 61 mean 3.8499972820281982, difference -0.00012540817260742188
p-value: 0.3315187153728091
Start train epoch 65, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 65, train_batch_id: 0, avg_cost: 3.8551430702209473
grad_norm: 0.21298232668679676, clipped: 0.21298232668679676
epoch: 65, train_batch_id: 50, avg_cost: 3.839773654937744
grad_norm: 0.2341744176255861, clipped: 0.2341744176255861
epoch: 65, train_batch_id: 100, avg_cost: 3.826539993286133
grad_norm: 0.29021701022033347, clipped: 0.29021701022033347
epoch: 65, train_batch_id: 150, avg_cost: 3.835864782333374
grad_norm: 0.4000123755290001, clipped: 0.4000123755290001
epoch: 65, train_batch_id: 200, avg_cost: 3.833399772644043
grad_norm: 0.4668203150823764, clipped: 0.4668203150823764
epoch: 65, train_batch_id: 250, avg_cost: 3.8301236629486084
grad_norm: 0.2642636866908437, clipped: 0.2642636866908437
epoch: 65, train_batch_id: 300, avg_cost: 3.8518455028533936
grad_norm: 0.40950664909148077, clipped: 0.40950664909148077
epoch: 65, train_batch_id: 350, avg_cost: 3.8603692054748535
grad_norm: 0.31512371969128683, clipped: 0.31512371969128683
epoch: 65, train_batch_id: 400, avg_cost: 3.843428134918213
grad_norm: 0.2580626801729444, clipped: 0.2580626801729444
epoch: 65, train_batch_id: 450, avg_cost: 3.8675498962402344
grad_norm: 0.40556206854691446, clipped: 0.40556206854691446
epoch: 65, train_batch_id: 500, avg_cost: 3.82122802734375
grad_norm: 0.3022895736000084, clipped: 0.3022895736000084
epoch: 65, train_batch_id: 550, avg_cost: 3.8369407653808594
grad_norm: 0.32183404925883574, clipped: 0.32183404925883574
epoch: 65, train_batch_id: 600, avg_cost: 3.8742499351501465
grad_norm: 0.2673388743006179, clipped: 0.2673388743006179
epoch: 65, train_batch_id: 650, avg_cost: 3.857027053833008
grad_norm: 0.3895460749901409, clipped: 0.3895460749901409
epoch: 65, train_batch_id: 700, avg_cost: 3.843400716781616
grad_norm: 0.22088289745456227, clipped: 0.22088289745456227
epoch: 65, train_batch_id: 750, avg_cost: 3.849066734313965
grad_norm: 1.3617760758584077, clipped: 1.0
epoch: 65, train_batch_id: 800, avg_cost: 3.8533525466918945
grad_norm: 0.2508449376072589, clipped: 0.2508449376072589
epoch: 65, train_batch_id: 850, avg_cost: 3.8513827323913574
grad_norm: 0.35968055429092, clipped: 0.35968055429092
epoch: 65, train_batch_id: 900, avg_cost: 3.84897518157959
grad_norm: 0.3488006733358621, clipped: 0.3488006733358621
epoch: 65, train_batch_id: 950, avg_cost: 3.846238613128662
grad_norm: 0.41055665052305323, clipped: 0.41055665052305323
epoch: 65, train_batch_id: 1000, avg_cost: 3.853651523590088
grad_norm: 0.362848149236503, clipped: 0.362848149236503
epoch: 65, train_batch_id: 1050, avg_cost: 3.848440170288086
grad_norm: 0.3047618739098548, clipped: 0.3047618739098548
epoch: 65, train_batch_id: 1100, avg_cost: 3.857302188873291
grad_norm: 0.5255590492754639, clipped: 0.5255590492754639
epoch: 65, train_batch_id: 1150, avg_cost: 3.841472625732422
grad_norm: 0.3109710801304285, clipped: 0.3109710801304285
epoch: 65, train_batch_id: 1200, avg_cost: 3.854949951171875
grad_norm: 0.36401800136927503, clipped: 0.36401800136927503
epoch: 65, train_batch_id: 1250, avg_cost: 3.8444206714630127
grad_norm: 0.29375600721602696, clipped: 0.29375600721602696
epoch: 65, train_batch_id: 1300, avg_cost: 3.82745361328125
grad_norm: 0.35647402295305375, clipped: 0.35647402295305375
epoch: 65, train_batch_id: 1350, avg_cost: 3.8423850536346436
grad_norm: 0.17545155303862647, clipped: 0.17545155303862647
epoch: 65, train_batch_id: 1400, avg_cost: 3.866264581680298
grad_norm: 0.5087605982715201, clipped: 0.5087605982715201
epoch: 65, train_batch_id: 1450, avg_cost: 3.843726396560669
grad_norm: 0.7513522030051304, clipped: 0.7513522030051304
epoch: 65, train_batch_id: 1500, avg_cost: 3.8344290256500244
grad_norm: 0.49327705827881935, clipped: 0.49327705827881935
epoch: 65, train_batch_id: 1550, avg_cost: 3.856010913848877
grad_norm: 0.30209605536775547, clipped: 0.30209605536775547
epoch: 65, train_batch_id: 1600, avg_cost: 3.8077151775360107
grad_norm: 0.4049037920771461, clipped: 0.4049037920771461
epoch: 65, train_batch_id: 1650, avg_cost: 3.8476805686950684
grad_norm: 0.8326429907810946, clipped: 0.8326429907810946
epoch: 65, train_batch_id: 1700, avg_cost: 3.850424289703369
grad_norm: 0.2872691138543938, clipped: 0.2872691138543938
epoch: 65, train_batch_id: 1750, avg_cost: 3.856559991836548
grad_norm: 0.85304334801723, clipped: 0.85304334801723
epoch: 65, train_batch_id: 1800, avg_cost: 3.8416497707366943
grad_norm: 0.22844952668448645, clipped: 0.22844952668448645
epoch: 65, train_batch_id: 1850, avg_cost: 3.8405261039733887
grad_norm: 0.28477339863613205, clipped: 0.28477339863613205
epoch: 65, train_batch_id: 1900, avg_cost: 3.842428684234619
grad_norm: 0.28380178603030765, clipped: 0.28380178603030765
epoch: 65, train_batch_id: 1950, avg_cost: 3.861262321472168
grad_norm: 0.28828828344104446, clipped: 0.28828828344104446
epoch: 65, train_batch_id: 2000, avg_cost: 3.8315253257751465
grad_norm: 0.24003693578548171, clipped: 0.24003693578548171
epoch: 65, train_batch_id: 2050, avg_cost: 3.8632726669311523
grad_norm: 0.49285330498222213, clipped: 0.49285330498222213
epoch: 65, train_batch_id: 2100, avg_cost: 3.864346742630005
grad_norm: 0.36963076277767376, clipped: 0.36963076277767376
epoch: 65, train_batch_id: 2150, avg_cost: 3.863365650177002
grad_norm: 0.7201116922049311, clipped: 0.7201116922049311
epoch: 65, train_batch_id: 2200, avg_cost: 3.8272781372070312
grad_norm: 0.5860982491496716, clipped: 0.5860982491496716
epoch: 65, train_batch_id: 2250, avg_cost: 3.847137689590454
grad_norm: 0.35485719588554065, clipped: 0.35485719588554065
epoch: 65, train_batch_id: 2300, avg_cost: 3.8247506618499756
grad_norm: 0.32022236768535184, clipped: 0.32022236768535184
epoch: 65, train_batch_id: 2350, avg_cost: 3.8316469192504883
grad_norm: 0.34349487269455486, clipped: 0.34349487269455486
epoch: 65, train_batch_id: 2400, avg_cost: 3.8419013023376465
grad_norm: 0.20883220800728272, clipped: 0.20883220800728272
epoch: 65, train_batch_id: 2450, avg_cost: 3.8458733558654785
grad_norm: 0.474700677079936, clipped: 0.474700677079936
Finished epoch 65, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.846954345703125 +- 0.003102486953139305
Evaluating candidate model on evaluation dataset
Epoch 65 candidate mean 3.8494069576263428, baseline epoch 61 mean 3.8499972820281982, difference -0.0005903244018554688
p-value: 0.017766502299512446
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 66, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 66, train_batch_id: 0, avg_cost: 3.8433070182800293
grad_norm: 0.26517987765688983, clipped: 0.26517987765688983
epoch: 66, train_batch_id: 50, avg_cost: 3.8553810119628906
grad_norm: 0.3851309563114584, clipped: 0.3851309563114584
epoch: 66, train_batch_id: 100, avg_cost: 3.844226360321045
grad_norm: 0.4198741902973081, clipped: 0.4198741902973081
epoch: 66, train_batch_id: 150, avg_cost: 3.851691722869873
grad_norm: 0.4944339510819395, clipped: 0.4944339510819395
epoch: 66, train_batch_id: 200, avg_cost: 3.843977928161621
grad_norm: 0.269950637423957, clipped: 0.269950637423957
epoch: 66, train_batch_id: 250, avg_cost: 3.8439888954162598
grad_norm: 0.3670235207066482, clipped: 0.3670235207066482
epoch: 66, train_batch_id: 300, avg_cost: 3.8531880378723145
grad_norm: 0.4146204054501344, clipped: 0.4146204054501344
epoch: 66, train_batch_id: 350, avg_cost: 3.8365683555603027
grad_norm: 0.3947444565005838, clipped: 0.3947444565005838
epoch: 66, train_batch_id: 400, avg_cost: 3.805117130279541
grad_norm: 0.28701088901517724, clipped: 0.28701088901517724
epoch: 66, train_batch_id: 450, avg_cost: 3.847917079925537
grad_norm: 0.37109394787707206, clipped: 0.37109394787707206
epoch: 66, train_batch_id: 500, avg_cost: 3.8509764671325684
grad_norm: 0.7278328027751195, clipped: 0.7278328027751195
epoch: 66, train_batch_id: 550, avg_cost: 3.858449935913086
grad_norm: 0.24547703155859657, clipped: 0.24547703155859657
epoch: 66, train_batch_id: 600, avg_cost: 3.851177215576172
grad_norm: 0.473617469343289, clipped: 0.473617469343289
epoch: 66, train_batch_id: 650, avg_cost: 3.875549077987671
grad_norm: 0.377228948463281, clipped: 0.377228948463281
epoch: 66, train_batch_id: 700, avg_cost: 3.8281054496765137
grad_norm: 0.3889487645015122, clipped: 0.3889487645015122
epoch: 66, train_batch_id: 750, avg_cost: 3.845052719116211
grad_norm: 0.39008622526756026, clipped: 0.39008622526756026
epoch: 66, train_batch_id: 800, avg_cost: 3.8479933738708496
grad_norm: 0.2515859443026562, clipped: 0.2515859443026562
epoch: 66, train_batch_id: 850, avg_cost: 3.828787088394165
grad_norm: 0.4458635965210359, clipped: 0.4458635965210359
epoch: 66, train_batch_id: 900, avg_cost: 3.860517978668213
grad_norm: 0.2635178339906001, clipped: 0.2635178339906001
epoch: 66, train_batch_id: 950, avg_cost: 3.849824905395508
grad_norm: 0.3069674692063462, clipped: 0.3069674692063462
epoch: 66, train_batch_id: 1000, avg_cost: 3.8432040214538574
grad_norm: 0.21898594966826848, clipped: 0.21898594966826848
epoch: 66, train_batch_id: 1050, avg_cost: 3.8556833267211914
grad_norm: 0.39439898923672456, clipped: 0.39439898923672456
epoch: 66, train_batch_id: 1100, avg_cost: 3.8663177490234375
grad_norm: 0.30422455688842703, clipped: 0.30422455688842703
epoch: 66, train_batch_id: 1150, avg_cost: 3.8306899070739746
grad_norm: 0.2551480776926513, clipped: 0.2551480776926513
epoch: 66, train_batch_id: 1200, avg_cost: 3.840883255004883
grad_norm: 0.41768287090366696, clipped: 0.41768287090366696
epoch: 66, train_batch_id: 1250, avg_cost: 3.855046272277832
grad_norm: 0.3012485375979178, clipped: 0.3012485375979178
epoch: 66, train_batch_id: 1300, avg_cost: 3.825570821762085
grad_norm: 0.20382003583639685, clipped: 0.20382003583639685
epoch: 66, train_batch_id: 1350, avg_cost: 3.8735647201538086
grad_norm: 0.3237399029724608, clipped: 0.3237399029724608
epoch: 66, train_batch_id: 1400, avg_cost: 3.8361892700195312
grad_norm: 0.5784055449129427, clipped: 0.5784055449129427
epoch: 66, train_batch_id: 1450, avg_cost: 3.8618180751800537
grad_norm: 0.7608802137129923, clipped: 0.7608802137129923
epoch: 66, train_batch_id: 1500, avg_cost: 3.8431622982025146
grad_norm: 0.36954234937897174, clipped: 0.36954234937897174
epoch: 66, train_batch_id: 1550, avg_cost: 3.84078049659729
grad_norm: 0.3668922151589085, clipped: 0.3668922151589085
epoch: 66, train_batch_id: 1600, avg_cost: 3.8344368934631348
grad_norm: 0.29242893682337057, clipped: 0.29242893682337057
epoch: 66, train_batch_id: 1650, avg_cost: 3.867126226425171
grad_norm: 0.36967570608745665, clipped: 0.36967570608745665
epoch: 66, train_batch_id: 1700, avg_cost: 3.8126964569091797
grad_norm: 0.29843610616288635, clipped: 0.29843610616288635
epoch: 66, train_batch_id: 1750, avg_cost: 3.8407375812530518
grad_norm: 0.3467246011293956, clipped: 0.3467246011293956
epoch: 66, train_batch_id: 1800, avg_cost: 3.855649709701538
grad_norm: 0.28059501392059766, clipped: 0.28059501392059766
epoch: 66, train_batch_id: 1850, avg_cost: 3.8465332984924316
grad_norm: 0.3211506359583907, clipped: 0.3211506359583907
epoch: 66, train_batch_id: 1900, avg_cost: 3.8403968811035156
grad_norm: 0.3629032060774243, clipped: 0.3629032060774243
epoch: 66, train_batch_id: 1950, avg_cost: 3.8388376235961914
grad_norm: 0.4762261527637176, clipped: 0.4762261527637176
epoch: 66, train_batch_id: 2000, avg_cost: 3.8483567237854004
grad_norm: 0.27727592005774243, clipped: 0.27727592005774243
epoch: 66, train_batch_id: 2050, avg_cost: 3.846383571624756
grad_norm: 0.5221920346020479, clipped: 0.5221920346020479
epoch: 66, train_batch_id: 2100, avg_cost: 3.853512763977051
grad_norm: 0.31066614425907135, clipped: 0.31066614425907135
epoch: 66, train_batch_id: 2150, avg_cost: 3.8355038166046143
grad_norm: 0.31975460274313544, clipped: 0.31975460274313544
epoch: 66, train_batch_id: 2200, avg_cost: 3.838346004486084
grad_norm: 0.5799612761852072, clipped: 0.5799612761852072
epoch: 66, train_batch_id: 2250, avg_cost: 3.8733949661254883
grad_norm: 1.0125944149059347, clipped: 1.0
epoch: 66, train_batch_id: 2300, avg_cost: 3.844463348388672
grad_norm: 0.32607570476466513, clipped: 0.32607570476466513
epoch: 66, train_batch_id: 2350, avg_cost: 3.832592010498047
grad_norm: 0.4352654600885105, clipped: 0.4352654600885105
epoch: 66, train_batch_id: 2400, avg_cost: 3.866687774658203
grad_norm: 0.22517195230964385, clipped: 0.22517195230964385
epoch: 66, train_batch_id: 2450, avg_cost: 3.849501848220825
grad_norm: 0.24944926424712127, clipped: 0.24944926424712127
Finished epoch 66, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.847811222076416 +- 0.0031081452034413815
Evaluating candidate model on evaluation dataset
Epoch 66 candidate mean 3.842679262161255, baseline epoch 65 mean 3.841723918914795, difference 0.0009553432464599609
Start train epoch 67, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 67, train_batch_id: 0, avg_cost: 3.8649587631225586
grad_norm: 0.27572013535151985, clipped: 0.27572013535151985
epoch: 67, train_batch_id: 50, avg_cost: 3.834728717803955
grad_norm: 0.3250129648892121, clipped: 0.3250129648892121
epoch: 67, train_batch_id: 100, avg_cost: 3.853931188583374
grad_norm: 0.8194908536189454, clipped: 0.8194908536189454
epoch: 67, train_batch_id: 150, avg_cost: 3.860395908355713
grad_norm: 0.3923543556905541, clipped: 0.3923543556905541
epoch: 67, train_batch_id: 200, avg_cost: 3.8228302001953125
grad_norm: 0.39690228963283214, clipped: 0.39690228963283214
epoch: 67, train_batch_id: 250, avg_cost: 3.854900360107422
grad_norm: 0.5233841154715272, clipped: 0.5233841154715272
epoch: 67, train_batch_id: 300, avg_cost: 3.8563787937164307
grad_norm: 0.40327962528289774, clipped: 0.40327962528289774
epoch: 67, train_batch_id: 350, avg_cost: 3.8593719005584717
grad_norm: 0.25688787877251834, clipped: 0.25688787877251834
epoch: 67, train_batch_id: 400, avg_cost: 3.833906650543213
grad_norm: 0.31722905920916505, clipped: 0.31722905920916505
epoch: 67, train_batch_id: 450, avg_cost: 3.8453903198242188
grad_norm: 0.3329197288296302, clipped: 0.3329197288296302
epoch: 67, train_batch_id: 500, avg_cost: 3.8588032722473145
grad_norm: 0.3967931347572057, clipped: 0.3967931347572057
epoch: 67, train_batch_id: 550, avg_cost: 3.830425977706909
grad_norm: 0.44866489187847086, clipped: 0.44866489187847086
epoch: 67, train_batch_id: 600, avg_cost: 3.8507838249206543
grad_norm: 0.3330694890248116, clipped: 0.3330694890248116
epoch: 67, train_batch_id: 650, avg_cost: 3.8459620475769043
grad_norm: 0.27302497947195037, clipped: 0.27302497947195037
epoch: 67, train_batch_id: 700, avg_cost: 3.855106830596924
grad_norm: 0.6783360079599434, clipped: 0.6783360079599434
epoch: 67, train_batch_id: 750, avg_cost: 3.8313333988189697
grad_norm: 0.3488389489364538, clipped: 0.3488389489364538
epoch: 67, train_batch_id: 800, avg_cost: 3.8268942832946777
grad_norm: 0.3747172130261418, clipped: 0.3747172130261418
epoch: 67, train_batch_id: 850, avg_cost: 3.850597381591797
grad_norm: 0.2914283519125869, clipped: 0.2914283519125869
epoch: 67, train_batch_id: 900, avg_cost: 3.8472251892089844
grad_norm: 0.3344246603359337, clipped: 0.3344246603359337
epoch: 67, train_batch_id: 950, avg_cost: 3.8312106132507324
grad_norm: 0.28144598835706974, clipped: 0.28144598835706974
epoch: 67, train_batch_id: 1000, avg_cost: 3.8615965843200684
grad_norm: 0.33888840100622836, clipped: 0.33888840100622836
epoch: 67, train_batch_id: 1050, avg_cost: 3.824331045150757
grad_norm: 0.21680672973254236, clipped: 0.21680672973254236
epoch: 67, train_batch_id: 1100, avg_cost: 3.8316426277160645
grad_norm: 0.2994072930745772, clipped: 0.2994072930745772
epoch: 67, train_batch_id: 1150, avg_cost: 3.853947162628174
grad_norm: 0.3730310238980424, clipped: 0.3730310238980424
epoch: 67, train_batch_id: 1200, avg_cost: 3.854360818862915
grad_norm: 0.4638582165848107, clipped: 0.4638582165848107
epoch: 67, train_batch_id: 1250, avg_cost: 3.8147692680358887
grad_norm: 0.32210959270442335, clipped: 0.32210959270442335
epoch: 67, train_batch_id: 1300, avg_cost: 3.8512542247772217
grad_norm: 0.31321818171554444, clipped: 0.31321818171554444
epoch: 67, train_batch_id: 1350, avg_cost: 3.8441789150238037
grad_norm: 0.3579934207284274, clipped: 0.3579934207284274
epoch: 67, train_batch_id: 1400, avg_cost: 3.843782901763916
grad_norm: 0.2370388272270834, clipped: 0.2370388272270834
epoch: 67, train_batch_id: 1450, avg_cost: 3.8392081260681152
grad_norm: 0.32479352395248406, clipped: 0.32479352395248406
epoch: 67, train_batch_id: 1500, avg_cost: 3.8398218154907227
grad_norm: 0.5075991713558854, clipped: 0.5075991713558854
epoch: 67, train_batch_id: 1550, avg_cost: 3.8437318801879883
grad_norm: 0.19689990975726152, clipped: 0.19689990975726152
epoch: 67, train_batch_id: 1600, avg_cost: 3.879244327545166
grad_norm: 0.29034682808359763, clipped: 0.29034682808359763
epoch: 67, train_batch_id: 1650, avg_cost: 3.831826686859131
grad_norm: 0.464550946725459, clipped: 0.464550946725459
epoch: 67, train_batch_id: 1700, avg_cost: 3.8548049926757812
grad_norm: 0.7035488682896543, clipped: 0.7035488682896543
epoch: 67, train_batch_id: 1750, avg_cost: 3.85152530670166
grad_norm: 0.33536803439658985, clipped: 0.33536803439658985
epoch: 67, train_batch_id: 1800, avg_cost: 3.8570432662963867
grad_norm: 0.2510736959994976, clipped: 0.2510736959994976
epoch: 67, train_batch_id: 1850, avg_cost: 3.8422586917877197
grad_norm: 0.48268658795465813, clipped: 0.48268658795465813
epoch: 67, train_batch_id: 1900, avg_cost: 3.8450253009796143
grad_norm: 0.3386455152905842, clipped: 0.3386455152905842
epoch: 67, train_batch_id: 1950, avg_cost: 3.845775842666626
grad_norm: 0.39530617921785727, clipped: 0.39530617921785727
epoch: 67, train_batch_id: 2000, avg_cost: 3.838496208190918
grad_norm: 0.44973970120133466, clipped: 0.44973970120133466
epoch: 67, train_batch_id: 2050, avg_cost: 3.8362584114074707
grad_norm: 0.3283949978911974, clipped: 0.3283949978911974
epoch: 67, train_batch_id: 2100, avg_cost: 3.809696912765503
grad_norm: 0.3372480164860683, clipped: 0.3372480164860683
epoch: 67, train_batch_id: 2150, avg_cost: 3.842923402786255
grad_norm: 0.30447323061548864, clipped: 0.30447323061548864
epoch: 67, train_batch_id: 2200, avg_cost: 3.8682756423950195
grad_norm: 0.3034951378043045, clipped: 0.3034951378043045
epoch: 67, train_batch_id: 2250, avg_cost: 3.8395469188690186
grad_norm: 0.32636676755320765, clipped: 0.32636676755320765
epoch: 67, train_batch_id: 2300, avg_cost: 3.861060619354248
grad_norm: 0.37505432202728056, clipped: 0.37505432202728056
epoch: 67, train_batch_id: 2350, avg_cost: 3.8359618186950684
grad_norm: 0.30890350477778045, clipped: 0.30890350477778045
epoch: 67, train_batch_id: 2400, avg_cost: 3.84944224357605
grad_norm: 0.2815708163456086, clipped: 0.2815708163456086
epoch: 67, train_batch_id: 2450, avg_cost: 3.854032516479492
grad_norm: 0.4585477345241264, clipped: 0.4585477345241264
Finished epoch 67, took 00:05:30 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8458971977233887 +- 0.0031015663407742977
Evaluating candidate model on evaluation dataset
Epoch 67 candidate mean 3.841202735900879, baseline epoch 65 mean 3.841723918914795, difference -0.0005211830139160156
p-value: 0.026956257459547446
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 68, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 68, train_batch_id: 0, avg_cost: 3.851591110229492
grad_norm: 0.26176797573603156, clipped: 0.26176797573603156
epoch: 68, train_batch_id: 50, avg_cost: 3.8408498764038086
grad_norm: 0.24373476844841507, clipped: 0.24373476844841507
epoch: 68, train_batch_id: 100, avg_cost: 3.83481764793396
grad_norm: 0.19723676414057387, clipped: 0.19723676414057387
epoch: 68, train_batch_id: 150, avg_cost: 3.8296101093292236
grad_norm: 0.29568218265026464, clipped: 0.29568218265026464
epoch: 68, train_batch_id: 200, avg_cost: 3.840019702911377
grad_norm: 0.3196526686981026, clipped: 0.3196526686981026
epoch: 68, train_batch_id: 250, avg_cost: 3.831141471862793
grad_norm: 0.47274894882223817, clipped: 0.47274894882223817
epoch: 68, train_batch_id: 300, avg_cost: 3.823655128479004
grad_norm: 0.21806627062557773, clipped: 0.21806627062557773
epoch: 68, train_batch_id: 350, avg_cost: 3.8272147178649902
grad_norm: 0.27181517184776144, clipped: 0.27181517184776144
epoch: 68, train_batch_id: 400, avg_cost: 3.84272837638855
grad_norm: 0.24835336359725171, clipped: 0.24835336359725171
epoch: 68, train_batch_id: 450, avg_cost: 3.862802028656006
grad_norm: 0.33102125569058627, clipped: 0.33102125569058627
epoch: 68, train_batch_id: 500, avg_cost: 3.8540701866149902
grad_norm: 0.3109637261909131, clipped: 0.3109637261909131
epoch: 68, train_batch_id: 550, avg_cost: 3.8612730503082275
grad_norm: 0.22565711655564183, clipped: 0.22565711655564183
epoch: 68, train_batch_id: 600, avg_cost: 3.8488407135009766
grad_norm: 0.2872773863048731, clipped: 0.2872773863048731
epoch: 68, train_batch_id: 650, avg_cost: 3.847064256668091
grad_norm: 0.6838755918687931, clipped: 0.6838755918687931
epoch: 68, train_batch_id: 700, avg_cost: 3.8384757041931152
grad_norm: 0.3178175105458835, clipped: 0.3178175105458835
epoch: 68, train_batch_id: 750, avg_cost: 3.8406779766082764
grad_norm: 0.4694053428408479, clipped: 0.4694053428408479
epoch: 68, train_batch_id: 800, avg_cost: 3.8277649879455566
grad_norm: 0.33704056596131865, clipped: 0.33704056596131865
epoch: 68, train_batch_id: 850, avg_cost: 3.851071357727051
grad_norm: 0.3562751821979221, clipped: 0.3562751821979221
epoch: 68, train_batch_id: 900, avg_cost: 3.8145484924316406
grad_norm: 0.3773870285557997, clipped: 0.3773870285557997
epoch: 68, train_batch_id: 950, avg_cost: 3.833674907684326
grad_norm: 0.3194415657895661, clipped: 0.3194415657895661
epoch: 68, train_batch_id: 1000, avg_cost: 3.8439571857452393
grad_norm: 0.3633562165433488, clipped: 0.3633562165433488
epoch: 68, train_batch_id: 1050, avg_cost: 3.828754186630249
grad_norm: 0.3418781305031073, clipped: 0.3418781305031073
epoch: 68, train_batch_id: 1100, avg_cost: 3.8393778800964355
grad_norm: 1.0153580086786196, clipped: 1.0
epoch: 68, train_batch_id: 1150, avg_cost: 3.8258252143859863
grad_norm: 0.5310502781885704, clipped: 0.5310502781885704
epoch: 68, train_batch_id: 1200, avg_cost: 3.8353381156921387
grad_norm: 0.34458236220377697, clipped: 0.34458236220377697
epoch: 68, train_batch_id: 1250, avg_cost: 3.835695505142212
grad_norm: 0.2477711740994358, clipped: 0.2477711740994358
epoch: 68, train_batch_id: 1300, avg_cost: 3.846529006958008
grad_norm: 0.30175972539657436, clipped: 0.30175972539657436
epoch: 68, train_batch_id: 1350, avg_cost: 3.818885326385498
grad_norm: 0.38008379507479456, clipped: 0.38008379507479456
epoch: 68, train_batch_id: 1400, avg_cost: 3.836789131164551
grad_norm: 0.4515282068650447, clipped: 0.4515282068650447
epoch: 68, train_batch_id: 1450, avg_cost: 3.835574150085449
grad_norm: 0.2817139514882524, clipped: 0.2817139514882524
epoch: 68, train_batch_id: 1500, avg_cost: 3.8473663330078125
grad_norm: 0.5416983893112518, clipped: 0.5416983893112518
epoch: 68, train_batch_id: 1550, avg_cost: 3.838430643081665
grad_norm: 1.5471281907606749, clipped: 1.0
epoch: 68, train_batch_id: 1600, avg_cost: 3.8208236694335938
grad_norm: 0.4027007725168784, clipped: 0.4027007725168784
epoch: 68, train_batch_id: 1650, avg_cost: 3.831608772277832
grad_norm: 0.2957837431329779, clipped: 0.2957837431329779
epoch: 68, train_batch_id: 1700, avg_cost: 3.852792501449585
grad_norm: 0.2836473520804758, clipped: 0.2836473520804758
epoch: 68, train_batch_id: 1750, avg_cost: 3.84285306930542
grad_norm: 0.3358223248948424, clipped: 0.3358223248948424
epoch: 68, train_batch_id: 1800, avg_cost: 3.857395648956299
grad_norm: 0.3497985043576879, clipped: 0.3497985043576879
epoch: 68, train_batch_id: 1850, avg_cost: 3.8425850868225098
grad_norm: 0.42432500528425665, clipped: 0.42432500528425665
epoch: 68, train_batch_id: 1900, avg_cost: 3.846726417541504
grad_norm: 0.36431696365580596, clipped: 0.36431696365580596
epoch: 68, train_batch_id: 1950, avg_cost: 3.848031759262085
grad_norm: 0.2882988912473245, clipped: 0.2882988912473245
epoch: 68, train_batch_id: 2000, avg_cost: 3.8549692630767822
grad_norm: 0.7269167234606254, clipped: 0.7269167234606254
epoch: 68, train_batch_id: 2050, avg_cost: 3.8323917388916016
grad_norm: 0.22084768953829345, clipped: 0.22084768953829345
epoch: 68, train_batch_id: 2100, avg_cost: 3.844791889190674
grad_norm: 0.29906237831859234, clipped: 0.29906237831859234
epoch: 68, train_batch_id: 2150, avg_cost: 3.8398585319519043
grad_norm: 0.2354135667409963, clipped: 0.2354135667409963
epoch: 68, train_batch_id: 2200, avg_cost: 3.870662212371826
grad_norm: 0.43454225560182524, clipped: 0.43454225560182524
epoch: 68, train_batch_id: 2250, avg_cost: 3.851881504058838
grad_norm: 0.41669067194758014, clipped: 0.41669067194758014
epoch: 68, train_batch_id: 2300, avg_cost: 3.829481363296509
grad_norm: 0.4178317246721088, clipped: 0.4178317246721088
epoch: 68, train_batch_id: 2350, avg_cost: 3.8378429412841797
grad_norm: 0.3131692622920389, clipped: 0.3131692622920389
epoch: 68, train_batch_id: 2400, avg_cost: 3.8373873233795166
grad_norm: 0.2599220917068418, clipped: 0.2599220917068418
epoch: 68, train_batch_id: 2450, avg_cost: 3.834292411804199
grad_norm: 0.2614292720348719, clipped: 0.2614292720348719
Finished epoch 68, took 00:05:24 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8481526374816895 +- 0.0031143531668931246
Evaluating candidate model on evaluation dataset
Epoch 68 candidate mean 3.8447303771972656, baseline epoch 67 mean 3.8424179553985596, difference 0.0023124217987060547
Start train epoch 69, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 69, train_batch_id: 0, avg_cost: 3.8506922721862793
grad_norm: 0.28498844249179406, clipped: 0.28498844249179406
epoch: 69, train_batch_id: 50, avg_cost: 3.8388357162475586
grad_norm: 0.34731958624423204, clipped: 0.34731958624423204
epoch: 69, train_batch_id: 100, avg_cost: 3.8453948497772217
grad_norm: 0.3385900413718513, clipped: 0.3385900413718513
epoch: 69, train_batch_id: 150, avg_cost: 3.863431453704834
grad_norm: 0.48378874432049596, clipped: 0.48378874432049596
epoch: 69, train_batch_id: 200, avg_cost: 3.843416690826416
grad_norm: 0.19663243930421132, clipped: 0.19663243930421132
epoch: 69, train_batch_id: 250, avg_cost: 3.8576691150665283
grad_norm: 0.3318618551281759, clipped: 0.3318618551281759
epoch: 69, train_batch_id: 300, avg_cost: 3.815309524536133
grad_norm: 0.32754119557882383, clipped: 0.32754119557882383
epoch: 69, train_batch_id: 350, avg_cost: 3.8302650451660156
grad_norm: 0.5448352404500671, clipped: 0.5448352404500671
epoch: 69, train_batch_id: 400, avg_cost: 3.81801700592041
grad_norm: 0.20567635922370078, clipped: 0.20567635922370078
epoch: 69, train_batch_id: 450, avg_cost: 3.8606958389282227
grad_norm: 0.702576970721988, clipped: 0.702576970721988
epoch: 69, train_batch_id: 500, avg_cost: 3.8285470008850098
grad_norm: 0.5076940523619231, clipped: 0.5076940523619231
epoch: 69, train_batch_id: 550, avg_cost: 3.8369319438934326
grad_norm: 0.5420526285857071, clipped: 0.5420526285857071
epoch: 69, train_batch_id: 600, avg_cost: 3.8490171432495117
grad_norm: 0.3974689850541914, clipped: 0.3974689850541914
epoch: 69, train_batch_id: 650, avg_cost: 3.8592677116394043
grad_norm: 0.30851630247194906, clipped: 0.30851630247194906
epoch: 69, train_batch_id: 700, avg_cost: 3.8446907997131348
grad_norm: 0.4012294171190707, clipped: 0.4012294171190707
epoch: 69, train_batch_id: 750, avg_cost: 3.822178602218628
grad_norm: 0.2754680091246259, clipped: 0.2754680091246259
epoch: 69, train_batch_id: 800, avg_cost: 3.8675832748413086
grad_norm: 0.30302247620572176, clipped: 0.30302247620572176
epoch: 69, train_batch_id: 850, avg_cost: 3.8434391021728516
grad_norm: 0.9187998604488838, clipped: 0.9187998604488838
epoch: 69, train_batch_id: 900, avg_cost: 3.8299779891967773
grad_norm: 0.26134291095381695, clipped: 0.26134291095381695
epoch: 69, train_batch_id: 950, avg_cost: 3.8630218505859375
grad_norm: 1.0000082574142284, clipped: 1.0
epoch: 69, train_batch_id: 1000, avg_cost: 3.8583202362060547
grad_norm: 0.46776369930743383, clipped: 0.46776369930743383
epoch: 69, train_batch_id: 1050, avg_cost: 3.8432939052581787
grad_norm: 0.2930040168258774, clipped: 0.2930040168258774
epoch: 69, train_batch_id: 1100, avg_cost: 3.841174364089966
grad_norm: 0.3414329036665742, clipped: 0.3414329036665742
epoch: 69, train_batch_id: 1150, avg_cost: 3.8492848873138428
grad_norm: 0.32945537101275196, clipped: 0.32945537101275196
epoch: 69, train_batch_id: 1200, avg_cost: 3.8640036582946777
grad_norm: 0.3733098592505456, clipped: 0.3733098592505456
epoch: 69, train_batch_id: 1250, avg_cost: 3.8368782997131348
grad_norm: 0.31522120440136264, clipped: 0.31522120440136264
epoch: 69, train_batch_id: 1300, avg_cost: 3.8590550422668457
grad_norm: 0.4173189034524122, clipped: 0.4173189034524122
epoch: 69, train_batch_id: 1350, avg_cost: 3.839144468307495
grad_norm: 0.3590227683308978, clipped: 0.3590227683308978
epoch: 69, train_batch_id: 1400, avg_cost: 3.8517086505889893
grad_norm: 0.3402709655043282, clipped: 0.3402709655043282
epoch: 69, train_batch_id: 1450, avg_cost: 3.8546295166015625
grad_norm: 0.5012099397162142, clipped: 0.5012099397162142
epoch: 69, train_batch_id: 1500, avg_cost: 3.8483147621154785
grad_norm: 0.43816421670874356, clipped: 0.43816421670874356
epoch: 69, train_batch_id: 1550, avg_cost: 3.8523926734924316
grad_norm: 0.3134500700545203, clipped: 0.3134500700545203
epoch: 69, train_batch_id: 1600, avg_cost: 3.8348007202148438
grad_norm: 0.2917995112650035, clipped: 0.2917995112650035
epoch: 69, train_batch_id: 1650, avg_cost: 3.8440043926239014
grad_norm: 0.2640142627227157, clipped: 0.2640142627227157
epoch: 69, train_batch_id: 1700, avg_cost: 3.840399742126465
grad_norm: 0.33085569877752236, clipped: 0.33085569877752236
epoch: 69, train_batch_id: 1750, avg_cost: 3.8345611095428467
grad_norm: 0.3561684599097777, clipped: 0.3561684599097777
epoch: 69, train_batch_id: 1800, avg_cost: 3.8567867279052734
grad_norm: 1.3726227174716923, clipped: 1.0
epoch: 69, train_batch_id: 1850, avg_cost: 3.833082914352417
grad_norm: 0.4417483541423383, clipped: 0.4417483541423383
epoch: 69, train_batch_id: 1900, avg_cost: 3.8378396034240723
grad_norm: 0.34212588600204613, clipped: 0.34212588600204613
epoch: 69, train_batch_id: 1950, avg_cost: 3.843257427215576
grad_norm: 0.33556307010651004, clipped: 0.33556307010651004
epoch: 69, train_batch_id: 2000, avg_cost: 3.8286242485046387
grad_norm: 0.37827238777349875, clipped: 0.37827238777349875
epoch: 69, train_batch_id: 2050, avg_cost: 3.8257999420166016
grad_norm: 0.3434317162946197, clipped: 0.3434317162946197
epoch: 69, train_batch_id: 2100, avg_cost: 3.856999397277832
grad_norm: 0.24747755119193537, clipped: 0.24747755119193537
epoch: 69, train_batch_id: 2150, avg_cost: 3.8627657890319824
grad_norm: 0.3323657681808309, clipped: 0.3323657681808309
epoch: 69, train_batch_id: 2200, avg_cost: 3.8641977310180664
grad_norm: 0.32289253415437186, clipped: 0.32289253415437186
epoch: 69, train_batch_id: 2250, avg_cost: 3.8542044162750244
grad_norm: 0.338419318579392, clipped: 0.338419318579392
epoch: 69, train_batch_id: 2300, avg_cost: 3.8601622581481934
grad_norm: 0.1883542764016169, clipped: 0.1883542764016169
epoch: 69, train_batch_id: 2350, avg_cost: 3.841362714767456
grad_norm: 0.3587384075683904, clipped: 0.3587384075683904
epoch: 69, train_batch_id: 2400, avg_cost: 3.8706605434417725
grad_norm: 0.38101065216467334, clipped: 0.38101065216467334
epoch: 69, train_batch_id: 2450, avg_cost: 3.843142509460449
grad_norm: 0.9763961687581932, clipped: 0.9763961687581932
Finished epoch 69, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8473262786865234 +- 0.003104675328359008
Evaluating candidate model on evaluation dataset
Epoch 69 candidate mean 3.84256911277771, baseline epoch 67 mean 3.8424179553985596, difference 0.00015115737915039062
Start train epoch 70, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 70, train_batch_id: 0, avg_cost: 3.8485970497131348
grad_norm: 0.40139117431143523, clipped: 0.40139117431143523
epoch: 70, train_batch_id: 50, avg_cost: 3.827627420425415
grad_norm: 0.3526861493913821, clipped: 0.3526861493913821
epoch: 70, train_batch_id: 100, avg_cost: 3.831369400024414
grad_norm: 0.26934782293688986, clipped: 0.26934782293688986
epoch: 70, train_batch_id: 150, avg_cost: 3.8239760398864746
grad_norm: 0.22990394961558522, clipped: 0.22990394961558522
epoch: 70, train_batch_id: 200, avg_cost: 3.813582181930542
grad_norm: 0.23290978414918542, clipped: 0.23290978414918542
epoch: 70, train_batch_id: 250, avg_cost: 3.8344101905822754
grad_norm: 0.31372934469664976, clipped: 0.31372934469664976
epoch: 70, train_batch_id: 300, avg_cost: 3.8459765911102295
grad_norm: 0.4942710900914836, clipped: 0.4942710900914836
epoch: 70, train_batch_id: 350, avg_cost: 3.8603098392486572
grad_norm: 0.4139160673342618, clipped: 0.4139160673342618
epoch: 70, train_batch_id: 400, avg_cost: 3.836005449295044
grad_norm: 0.34686430751257424, clipped: 0.34686430751257424
epoch: 70, train_batch_id: 450, avg_cost: 3.842193126678467
grad_norm: 0.40640816168907573, clipped: 0.40640816168907573
epoch: 70, train_batch_id: 500, avg_cost: 3.850465774536133
grad_norm: 0.2844585342790176, clipped: 0.2844585342790176
epoch: 70, train_batch_id: 550, avg_cost: 3.8848891258239746
grad_norm: 0.27076855216021134, clipped: 0.27076855216021134
epoch: 70, train_batch_id: 600, avg_cost: 3.8576407432556152
grad_norm: 0.448926022039701, clipped: 0.448926022039701
epoch: 70, train_batch_id: 650, avg_cost: 3.862107038497925
grad_norm: 0.35806886455330666, clipped: 0.35806886455330666
epoch: 70, train_batch_id: 700, avg_cost: 3.840082883834839
grad_norm: 0.40789843532775527, clipped: 0.40789843532775527
epoch: 70, train_batch_id: 750, avg_cost: 3.824537754058838
grad_norm: 0.31061468350579424, clipped: 0.31061468350579424
epoch: 70, train_batch_id: 800, avg_cost: 3.833925724029541
grad_norm: 0.3720278159100465, clipped: 0.3720278159100465
epoch: 70, train_batch_id: 850, avg_cost: 3.840989828109741
grad_norm: 0.4285275141058816, clipped: 0.4285275141058816
epoch: 70, train_batch_id: 900, avg_cost: 3.8392035961151123
grad_norm: 0.30573814084371054, clipped: 0.30573814084371054
epoch: 70, train_batch_id: 950, avg_cost: 3.8549599647521973
grad_norm: 0.30679606744529303, clipped: 0.30679606744529303
epoch: 70, train_batch_id: 1000, avg_cost: 3.8435800075531006
grad_norm: 0.25597055768054905, clipped: 0.25597055768054905
epoch: 70, train_batch_id: 1050, avg_cost: 3.8503286838531494
grad_norm: 0.5357233719887926, clipped: 0.5357233719887926
epoch: 70, train_batch_id: 1100, avg_cost: 3.848062038421631
grad_norm: 0.3575577126087253, clipped: 0.3575577126087253
epoch: 70, train_batch_id: 1150, avg_cost: 3.868861436843872
grad_norm: 0.39141022068467607, clipped: 0.39141022068467607
epoch: 70, train_batch_id: 1200, avg_cost: 3.8462748527526855
grad_norm: 0.30355527369764407, clipped: 0.30355527369764407
epoch: 70, train_batch_id: 1250, avg_cost: 3.8556313514709473
grad_norm: 0.2826150753552142, clipped: 0.2826150753552142
epoch: 70, train_batch_id: 1300, avg_cost: 3.8700504302978516
grad_norm: 0.3663084537123602, clipped: 0.3663084537123602
epoch: 70, train_batch_id: 1350, avg_cost: 3.8586673736572266
grad_norm: 0.4908146371147999, clipped: 0.4908146371147999
epoch: 70, train_batch_id: 1400, avg_cost: 3.850203037261963
grad_norm: 0.7542461724445494, clipped: 0.7542461724445494
epoch: 70, train_batch_id: 1450, avg_cost: 3.833573341369629
grad_norm: 0.3619548625100502, clipped: 0.3619548625100502
epoch: 70, train_batch_id: 1500, avg_cost: 3.8361263275146484
grad_norm: 0.32550999179746815, clipped: 0.32550999179746815
epoch: 70, train_batch_id: 1550, avg_cost: 3.848961353302002
grad_norm: 0.354560854274463, clipped: 0.354560854274463
epoch: 70, train_batch_id: 1600, avg_cost: 3.8345584869384766
grad_norm: 0.35022111986707594, clipped: 0.35022111986707594
epoch: 70, train_batch_id: 1650, avg_cost: 3.845303535461426
grad_norm: 0.2159126353172228, clipped: 0.2159126353172228
epoch: 70, train_batch_id: 1700, avg_cost: 3.860283136367798
grad_norm: 0.27740981914316915, clipped: 0.27740981914316915
epoch: 70, train_batch_id: 1750, avg_cost: 3.8577065467834473
grad_norm: 0.28393886322023015, clipped: 0.28393886322023015
epoch: 70, train_batch_id: 1800, avg_cost: 3.8569798469543457
grad_norm: 0.27772798568976087, clipped: 0.27772798568976087
epoch: 70, train_batch_id: 1850, avg_cost: 3.8274338245391846
grad_norm: 0.45430132938587797, clipped: 0.45430132938587797
epoch: 70, train_batch_id: 1900, avg_cost: 3.8520169258117676
grad_norm: 0.3491372255423476, clipped: 0.3491372255423476
epoch: 70, train_batch_id: 1950, avg_cost: 3.845460891723633
grad_norm: 0.42576819813220956, clipped: 0.42576819813220956
epoch: 70, train_batch_id: 2000, avg_cost: 3.8724474906921387
grad_norm: 0.7533485076897926, clipped: 0.7533485076897926
epoch: 70, train_batch_id: 2050, avg_cost: 3.8475184440612793
grad_norm: 0.9632660359223255, clipped: 0.9632660359223255
epoch: 70, train_batch_id: 2100, avg_cost: 3.857457160949707
grad_norm: 0.3517772840906937, clipped: 0.3517772840906937
epoch: 70, train_batch_id: 2150, avg_cost: 3.8433446884155273
grad_norm: 0.25554107380314656, clipped: 0.25554107380314656
epoch: 70, train_batch_id: 2200, avg_cost: 3.8817355632781982
grad_norm: 0.3126391845400903, clipped: 0.3126391845400903
epoch: 70, train_batch_id: 2250, avg_cost: 3.856208562850952
grad_norm: 0.34581021135760104, clipped: 0.34581021135760104
epoch: 70, train_batch_id: 2300, avg_cost: 3.84523868560791
grad_norm: 0.29911052926079257, clipped: 0.29911052926079257
epoch: 70, train_batch_id: 2350, avg_cost: 3.8348746299743652
grad_norm: 0.26921484925855604, clipped: 0.26921484925855604
epoch: 70, train_batch_id: 2400, avg_cost: 3.8378841876983643
grad_norm: 0.2582409202838445, clipped: 0.2582409202838445
epoch: 70, train_batch_id: 2450, avg_cost: 3.8522887229919434
grad_norm: 0.2933359259871695, clipped: 0.2933359259871695
Finished epoch 70, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.846406936645508 +- 0.003102328395470977
Evaluating candidate model on evaluation dataset
Epoch 70 candidate mean 3.8424394130706787, baseline epoch 67 mean 3.8424179553985596, difference 2.1457672119140625e-05
Start train epoch 71, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 71, train_batch_id: 0, avg_cost: 3.8198227882385254
grad_norm: 0.26042802375852037, clipped: 0.26042802375852037
epoch: 71, train_batch_id: 50, avg_cost: 3.8393969535827637
grad_norm: 0.4500295323830591, clipped: 0.4500295323830591
epoch: 71, train_batch_id: 100, avg_cost: 3.8670525550842285
grad_norm: 0.42192065372360127, clipped: 0.42192065372360127
epoch: 71, train_batch_id: 150, avg_cost: 3.8339266777038574
grad_norm: 0.27385869852832073, clipped: 0.27385869852832073
epoch: 71, train_batch_id: 200, avg_cost: 3.866006374359131
grad_norm: 0.3953505375083613, clipped: 0.3953505375083613
epoch: 71, train_batch_id: 250, avg_cost: 3.862389087677002
grad_norm: 0.6942453254532303, clipped: 0.6942453254532303
epoch: 71, train_batch_id: 300, avg_cost: 3.8424458503723145
grad_norm: 0.26314965501455145, clipped: 0.26314965501455145
epoch: 71, train_batch_id: 350, avg_cost: 3.849893808364868
grad_norm: 0.2802831328443242, clipped: 0.2802831328443242
epoch: 71, train_batch_id: 400, avg_cost: 3.8534181118011475
grad_norm: 0.21018576657260538, clipped: 0.21018576657260538
epoch: 71, train_batch_id: 450, avg_cost: 3.8404345512390137
grad_norm: 0.2505204104079645, clipped: 0.2505204104079645
epoch: 71, train_batch_id: 500, avg_cost: 3.835268020629883
grad_norm: 0.2887362543394722, clipped: 0.2887362543394722
epoch: 71, train_batch_id: 550, avg_cost: 3.8384106159210205
grad_norm: 0.3459600790524438, clipped: 0.3459600790524438
epoch: 71, train_batch_id: 600, avg_cost: 3.840657949447632
grad_norm: 0.46854270890683375, clipped: 0.46854270890683375
epoch: 71, train_batch_id: 650, avg_cost: 3.8416004180908203
grad_norm: 0.23259446468157902, clipped: 0.23259446468157902
epoch: 71, train_batch_id: 700, avg_cost: 3.8459033966064453
grad_norm: 0.2460688024607667, clipped: 0.2460688024607667
epoch: 71, train_batch_id: 750, avg_cost: 3.8618111610412598
grad_norm: 0.27147324676002565, clipped: 0.27147324676002565
epoch: 71, train_batch_id: 800, avg_cost: 3.885862350463867
grad_norm: 0.35929165299553195, clipped: 0.35929165299553195
epoch: 71, train_batch_id: 850, avg_cost: 3.8415181636810303
grad_norm: 0.3781164547852286, clipped: 0.3781164547852286
epoch: 71, train_batch_id: 900, avg_cost: 3.835963249206543
grad_norm: 0.33665993494913626, clipped: 0.33665993494913626
epoch: 71, train_batch_id: 950, avg_cost: 3.834073066711426
grad_norm: 0.241991059386358, clipped: 0.241991059386358
epoch: 71, train_batch_id: 1000, avg_cost: 3.845193862915039
grad_norm: 0.5352338874247853, clipped: 0.5352338874247853
epoch: 71, train_batch_id: 1050, avg_cost: 3.860128164291382
grad_norm: 0.35014068886458183, clipped: 0.35014068886458183
epoch: 71, train_batch_id: 1100, avg_cost: 3.8558108806610107
grad_norm: 0.3248024885575525, clipped: 0.3248024885575525
epoch: 71, train_batch_id: 1150, avg_cost: 3.837923526763916
grad_norm: 0.3111025775334934, clipped: 0.3111025775334934
epoch: 71, train_batch_id: 1200, avg_cost: 3.832120895385742
grad_norm: 0.22721090244669648, clipped: 0.22721090244669648
epoch: 71, train_batch_id: 1250, avg_cost: 3.8344902992248535
grad_norm: 0.24712863267412752, clipped: 0.24712863267412752
epoch: 71, train_batch_id: 1300, avg_cost: 3.841461181640625
grad_norm: 0.2461704006869106, clipped: 0.2461704006869106
epoch: 71, train_batch_id: 1350, avg_cost: 3.8396196365356445
grad_norm: 0.29688806573041293, clipped: 0.29688806573041293
epoch: 71, train_batch_id: 1400, avg_cost: 3.8341407775878906
grad_norm: 0.38620235952552445, clipped: 0.38620235952552445
epoch: 71, train_batch_id: 1450, avg_cost: 3.853039503097534
grad_norm: 0.2574083654575101, clipped: 0.2574083654575101
epoch: 71, train_batch_id: 1500, avg_cost: 3.840507984161377
grad_norm: 0.3799875547304226, clipped: 0.3799875547304226
epoch: 71, train_batch_id: 1550, avg_cost: 3.844137191772461
grad_norm: 0.2182838937578508, clipped: 0.2182838937578508
epoch: 71, train_batch_id: 1600, avg_cost: 3.8496737480163574
grad_norm: 0.22255647735359788, clipped: 0.22255647735359788
epoch: 71, train_batch_id: 1650, avg_cost: 3.805832862854004
grad_norm: 0.33606871287530454, clipped: 0.33606871287530454
epoch: 71, train_batch_id: 1700, avg_cost: 3.8566484451293945
grad_norm: 0.27368373635484183, clipped: 0.27368373635484183
epoch: 71, train_batch_id: 1750, avg_cost: 3.8361897468566895
grad_norm: 0.32196023014654535, clipped: 0.32196023014654535
epoch: 71, train_batch_id: 1800, avg_cost: 3.855619430541992
grad_norm: 0.4079791426339266, clipped: 0.4079791426339266
epoch: 71, train_batch_id: 1850, avg_cost: 3.861703395843506
grad_norm: 0.35237628788668246, clipped: 0.35237628788668246
epoch: 71, train_batch_id: 1900, avg_cost: 3.8469185829162598
grad_norm: 0.2929114498358346, clipped: 0.2929114498358346
epoch: 71, train_batch_id: 1950, avg_cost: 3.8486738204956055
grad_norm: 0.3037046853536919, clipped: 0.3037046853536919
epoch: 71, train_batch_id: 2000, avg_cost: 3.852193832397461
grad_norm: 0.41751122385135875, clipped: 0.41751122385135875
epoch: 71, train_batch_id: 2050, avg_cost: 3.8450000286102295
grad_norm: 0.3047232196934081, clipped: 0.3047232196934081
epoch: 71, train_batch_id: 2100, avg_cost: 3.8371529579162598
grad_norm: 0.28702631103871534, clipped: 0.28702631103871534
epoch: 71, train_batch_id: 2150, avg_cost: 3.8505334854125977
grad_norm: 0.33792424701376145, clipped: 0.33792424701376145
epoch: 71, train_batch_id: 2200, avg_cost: 3.853179454803467
grad_norm: 0.5629998285121705, clipped: 0.5629998285121705
epoch: 71, train_batch_id: 2250, avg_cost: 3.8333706855773926
grad_norm: 0.36427906432205603, clipped: 0.36427906432205603
epoch: 71, train_batch_id: 2300, avg_cost: 3.853992223739624
grad_norm: 0.32246699058685363, clipped: 0.32246699058685363
epoch: 71, train_batch_id: 2350, avg_cost: 3.8512609004974365
grad_norm: 0.27279809288600937, clipped: 0.27279809288600937
epoch: 71, train_batch_id: 2400, avg_cost: 3.86287784576416
grad_norm: 0.6008408673950943, clipped: 0.6008408673950943
epoch: 71, train_batch_id: 2450, avg_cost: 3.8399665355682373
grad_norm: 0.2915386532400651, clipped: 0.2915386532400651
Finished epoch 71, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.846782922744751 +- 0.00311025301925838
Evaluating candidate model on evaluation dataset
Epoch 71 candidate mean 3.842742919921875, baseline epoch 67 mean 3.8424179553985596, difference 0.0003249645233154297
Start train epoch 72, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 72, train_batch_id: 0, avg_cost: 3.846285343170166
grad_norm: 0.29876593339774316, clipped: 0.29876593339774316
epoch: 72, train_batch_id: 50, avg_cost: 3.838467597961426
grad_norm: 0.9688246683331556, clipped: 0.9688246683331556
epoch: 72, train_batch_id: 100, avg_cost: 3.8599886894226074
grad_norm: 0.27690483497636825, clipped: 0.27690483497636825
epoch: 72, train_batch_id: 150, avg_cost: 3.8362765312194824
grad_norm: 0.3508762704027839, clipped: 0.3508762704027839
epoch: 72, train_batch_id: 200, avg_cost: 3.8305740356445312
grad_norm: 0.3953150406103804, clipped: 0.3953150406103804
epoch: 72, train_batch_id: 250, avg_cost: 3.855396270751953
grad_norm: 0.4996367618017608, clipped: 0.4996367618017608
epoch: 72, train_batch_id: 300, avg_cost: 3.852651834487915
grad_norm: 0.29610769824240524, clipped: 0.29610769824240524
epoch: 72, train_batch_id: 350, avg_cost: 3.844364643096924
grad_norm: 0.2951826645056706, clipped: 0.2951826645056706
epoch: 72, train_batch_id: 400, avg_cost: 3.8527183532714844
grad_norm: 0.39755953448516923, clipped: 0.39755953448516923
epoch: 72, train_batch_id: 450, avg_cost: 3.8262076377868652
grad_norm: 0.34100332736032024, clipped: 0.34100332736032024
epoch: 72, train_batch_id: 500, avg_cost: 3.862349033355713
grad_norm: 0.354462884712688, clipped: 0.354462884712688
epoch: 72, train_batch_id: 550, avg_cost: 3.857790946960449
grad_norm: 0.3033261425060701, clipped: 0.3033261425060701
epoch: 72, train_batch_id: 600, avg_cost: 3.8561959266662598
grad_norm: 0.2559156591411566, clipped: 0.2559156591411566
epoch: 72, train_batch_id: 650, avg_cost: 3.8209612369537354
grad_norm: 0.340694852754768, clipped: 0.340694852754768
epoch: 72, train_batch_id: 700, avg_cost: 3.8443446159362793
grad_norm: 0.3219831949025533, clipped: 0.3219831949025533
epoch: 72, train_batch_id: 750, avg_cost: 3.8447651863098145
grad_norm: 0.3577836553850539, clipped: 0.3577836553850539
epoch: 72, train_batch_id: 800, avg_cost: 3.8343329429626465
grad_norm: 0.4595897393758911, clipped: 0.4595897393758911
epoch: 72, train_batch_id: 850, avg_cost: 3.8301680088043213
grad_norm: 0.33862331796894335, clipped: 0.33862331796894335
epoch: 72, train_batch_id: 900, avg_cost: 3.8482422828674316
grad_norm: 0.5152461948192233, clipped: 0.5152461948192233
epoch: 72, train_batch_id: 950, avg_cost: 3.8238306045532227
grad_norm: 0.6221487806167787, clipped: 0.6221487806167787
epoch: 72, train_batch_id: 1000, avg_cost: 3.8490376472473145
grad_norm: 0.29080344016981935, clipped: 0.29080344016981935
epoch: 72, train_batch_id: 1050, avg_cost: 3.838449478149414
grad_norm: 0.3112134387077967, clipped: 0.3112134387077967
epoch: 72, train_batch_id: 1100, avg_cost: 3.8508286476135254
grad_norm: 0.33854293252832146, clipped: 0.33854293252832146
epoch: 72, train_batch_id: 1150, avg_cost: 3.849088668823242
grad_norm: 0.2926510410482951, clipped: 0.2926510410482951
epoch: 72, train_batch_id: 1200, avg_cost: 3.832458257675171
grad_norm: 0.3953179363662281, clipped: 0.3953179363662281
epoch: 72, train_batch_id: 1250, avg_cost: 3.8491549491882324
grad_norm: 0.9799751896266853, clipped: 0.9799751896266853
epoch: 72, train_batch_id: 1300, avg_cost: 3.8219940662384033
grad_norm: 0.35466114446794766, clipped: 0.35466114446794766
epoch: 72, train_batch_id: 1350, avg_cost: 3.8362510204315186
grad_norm: 0.26310910582442576, clipped: 0.26310910582442576
epoch: 72, train_batch_id: 1400, avg_cost: 3.872946262359619
grad_norm: 0.3724698868591536, clipped: 0.3724698868591536
epoch: 72, train_batch_id: 1450, avg_cost: 3.8568437099456787
grad_norm: 0.28269756820404934, clipped: 0.28269756820404934
epoch: 72, train_batch_id: 1500, avg_cost: 3.852670669555664
grad_norm: 1.0531919602247197, clipped: 1.0
epoch: 72, train_batch_id: 1550, avg_cost: 3.8495523929595947
grad_norm: 0.2991128983041617, clipped: 0.2991128983041617
epoch: 72, train_batch_id: 1600, avg_cost: 3.8427891731262207
grad_norm: 0.18876363432305485, clipped: 0.18876363432305485
epoch: 72, train_batch_id: 1650, avg_cost: 3.8303356170654297
grad_norm: 0.3640253739281088, clipped: 0.3640253739281088
epoch: 72, train_batch_id: 1700, avg_cost: 3.8471760749816895
grad_norm: 0.628359407040509, clipped: 0.628359407040509
epoch: 72, train_batch_id: 1750, avg_cost: 3.8414063453674316
grad_norm: 0.36809856698758625, clipped: 0.36809856698758625
epoch: 72, train_batch_id: 1800, avg_cost: 3.858548164367676
grad_norm: 0.7614315422157523, clipped: 0.7614315422157523
epoch: 72, train_batch_id: 1850, avg_cost: 3.843993663787842
grad_norm: 1.2872736602853314, clipped: 1.0
epoch: 72, train_batch_id: 1900, avg_cost: 3.837547779083252
grad_norm: 0.2987944101507398, clipped: 0.2987944101507398
epoch: 72, train_batch_id: 1950, avg_cost: 3.837862253189087
grad_norm: 0.31212888893027446, clipped: 0.31212888893027446
epoch: 72, train_batch_id: 2000, avg_cost: 3.8323259353637695
grad_norm: 0.35414523660264324, clipped: 0.35414523660264324
epoch: 72, train_batch_id: 2050, avg_cost: 3.851376533508301
grad_norm: 0.3894002025550445, clipped: 0.3894002025550445
epoch: 72, train_batch_id: 2100, avg_cost: 3.860079288482666
grad_norm: 0.3436358104856573, clipped: 0.3436358104856573
epoch: 72, train_batch_id: 2150, avg_cost: 3.8417649269104004
grad_norm: 0.3364221112201344, clipped: 0.3364221112201344
epoch: 72, train_batch_id: 2200, avg_cost: 3.8459885120391846
grad_norm: 0.32541412342598475, clipped: 0.32541412342598475
epoch: 72, train_batch_id: 2250, avg_cost: 3.8488969802856445
grad_norm: 0.2403056838323565, clipped: 0.2403056838323565
epoch: 72, train_batch_id: 2300, avg_cost: 3.840973377227783
grad_norm: 0.3828218111051311, clipped: 0.3828218111051311
epoch: 72, train_batch_id: 2350, avg_cost: 3.8734869956970215
grad_norm: 0.34426841135672814, clipped: 0.34426841135672814
epoch: 72, train_batch_id: 2400, avg_cost: 3.839043617248535
grad_norm: 0.27441599448313425, clipped: 0.27441599448313425
epoch: 72, train_batch_id: 2450, avg_cost: 3.8250925540924072
grad_norm: 0.4177195319250157, clipped: 0.4177195319250157
Finished epoch 72, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8473265171051025 +- 0.0031048422679305077
Evaluating candidate model on evaluation dataset
Epoch 72 candidate mean 3.8430070877075195, baseline epoch 67 mean 3.8424179553985596, difference 0.0005891323089599609
Start train epoch 73, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 73, train_batch_id: 0, avg_cost: 3.857114315032959
grad_norm: 0.27660657705951575, clipped: 0.27660657705951575
epoch: 73, train_batch_id: 50, avg_cost: 3.852222204208374
grad_norm: 0.4158680587486615, clipped: 0.4158680587486615
epoch: 73, train_batch_id: 100, avg_cost: 3.85356068611145
grad_norm: 0.31245757138248126, clipped: 0.31245757138248126
epoch: 73, train_batch_id: 150, avg_cost: 3.866206169128418
grad_norm: 0.25408504115262204, clipped: 0.25408504115262204
epoch: 73, train_batch_id: 200, avg_cost: 3.842036008834839
grad_norm: 0.4117068326817275, clipped: 0.4117068326817275
epoch: 73, train_batch_id: 250, avg_cost: 3.884899616241455
grad_norm: 0.300560845733889, clipped: 0.300560845733889
epoch: 73, train_batch_id: 300, avg_cost: 3.8299660682678223
grad_norm: 0.6380319619131206, clipped: 0.6380319619131206
epoch: 73, train_batch_id: 350, avg_cost: 3.841416358947754
grad_norm: 0.6856383484245794, clipped: 0.6856383484245794
epoch: 73, train_batch_id: 400, avg_cost: 3.8457765579223633
grad_norm: 0.49444093666244565, clipped: 0.49444093666244565
epoch: 73, train_batch_id: 450, avg_cost: 3.8649802207946777
grad_norm: 0.22813314796349485, clipped: 0.22813314796349485
epoch: 73, train_batch_id: 500, avg_cost: 3.841848850250244
grad_norm: 0.36183211884747135, clipped: 0.36183211884747135
epoch: 73, train_batch_id: 550, avg_cost: 3.869089126586914
grad_norm: 0.393845216012283, clipped: 0.393845216012283
epoch: 73, train_batch_id: 600, avg_cost: 3.857638359069824
grad_norm: 0.329853422978383, clipped: 0.329853422978383
epoch: 73, train_batch_id: 650, avg_cost: 3.866969585418701
grad_norm: 0.44254972897511285, clipped: 0.44254972897511285
epoch: 73, train_batch_id: 700, avg_cost: 3.848478317260742
grad_norm: 1.571800059804175, clipped: 1.0
epoch: 73, train_batch_id: 750, avg_cost: 3.8388280868530273
grad_norm: 0.32186167628401524, clipped: 0.32186167628401524
epoch: 73, train_batch_id: 800, avg_cost: 3.8444299697875977
grad_norm: 0.26711373891366935, clipped: 0.26711373891366935
epoch: 73, train_batch_id: 850, avg_cost: 3.8332676887512207
grad_norm: 0.39626205131994946, clipped: 0.39626205131994946
epoch: 73, train_batch_id: 900, avg_cost: 3.8391661643981934
grad_norm: 0.3208990109973017, clipped: 0.3208990109973017
epoch: 73, train_batch_id: 950, avg_cost: 3.8223891258239746
grad_norm: 0.29117662545875456, clipped: 0.29117662545875456
epoch: 73, train_batch_id: 1000, avg_cost: 3.860372543334961
grad_norm: 0.32294621514228355, clipped: 0.32294621514228355
epoch: 73, train_batch_id: 1050, avg_cost: 3.846569061279297
grad_norm: 0.3858198648433849, clipped: 0.3858198648433849
epoch: 73, train_batch_id: 1100, avg_cost: 3.856074333190918
grad_norm: 0.8691894228768929, clipped: 0.8691894228768929
epoch: 73, train_batch_id: 1150, avg_cost: 3.8396875858306885
grad_norm: 0.2623871226440871, clipped: 0.2623871226440871
epoch: 73, train_batch_id: 1200, avg_cost: 3.82535982131958
grad_norm: 0.294825698242986, clipped: 0.294825698242986
epoch: 73, train_batch_id: 1250, avg_cost: 3.8549563884735107
grad_norm: 0.27846666079576654, clipped: 0.27846666079576654
epoch: 73, train_batch_id: 1300, avg_cost: 3.844240665435791
grad_norm: 0.4014312581344825, clipped: 0.4014312581344825
epoch: 73, train_batch_id: 1350, avg_cost: 3.8411624431610107
grad_norm: 0.31376968480493683, clipped: 0.31376968480493683
epoch: 73, train_batch_id: 1400, avg_cost: 3.8418993949890137
grad_norm: 0.3399117517039237, clipped: 0.3399117517039237
epoch: 73, train_batch_id: 1450, avg_cost: 3.8349204063415527
grad_norm: 0.28565731514156456, clipped: 0.28565731514156456
epoch: 73, train_batch_id: 1500, avg_cost: 3.8484420776367188
grad_norm: 0.28380028357025633, clipped: 0.28380028357025633
epoch: 73, train_batch_id: 1550, avg_cost: 3.839782238006592
grad_norm: 1.0980253834272167, clipped: 1.0
epoch: 73, train_batch_id: 1600, avg_cost: 3.853158950805664
grad_norm: 0.22349368042700843, clipped: 0.22349368042700843
epoch: 73, train_batch_id: 1650, avg_cost: 3.833231210708618
grad_norm: 0.37804495980076336, clipped: 0.37804495980076336
epoch: 73, train_batch_id: 1700, avg_cost: 3.831503391265869
grad_norm: 0.3685266973559033, clipped: 0.3685266973559033
epoch: 73, train_batch_id: 1750, avg_cost: 3.8659110069274902
grad_norm: 0.29549626025035447, clipped: 0.29549626025035447
epoch: 73, train_batch_id: 1800, avg_cost: 3.8406996726989746
grad_norm: 0.3026580534642048, clipped: 0.3026580534642048
epoch: 73, train_batch_id: 1850, avg_cost: 3.8549861907958984
grad_norm: 0.7336548147676605, clipped: 0.7336548147676605
epoch: 73, train_batch_id: 1900, avg_cost: 3.8535027503967285
grad_norm: 0.45427946367120275, clipped: 0.45427946367120275
epoch: 73, train_batch_id: 1950, avg_cost: 3.8646810054779053
grad_norm: 0.2633750544517682, clipped: 0.2633750544517682
epoch: 73, train_batch_id: 2000, avg_cost: 3.8435606956481934
grad_norm: 0.28757671955527764, clipped: 0.28757671955527764
epoch: 73, train_batch_id: 2050, avg_cost: 3.8349454402923584
grad_norm: 0.303707925553104, clipped: 0.303707925553104
epoch: 73, train_batch_id: 2100, avg_cost: 3.8072867393493652
grad_norm: 0.334177879248373, clipped: 0.334177879248373
epoch: 73, train_batch_id: 2150, avg_cost: 3.8491427898406982
grad_norm: 0.31782051012980256, clipped: 0.31782051012980256
epoch: 73, train_batch_id: 2200, avg_cost: 3.8356640338897705
grad_norm: 0.4903210727292519, clipped: 0.4903210727292519
epoch: 73, train_batch_id: 2250, avg_cost: 3.8292887210845947
grad_norm: 0.4212588534027286, clipped: 0.4212588534027286
epoch: 73, train_batch_id: 2300, avg_cost: 3.83864164352417
grad_norm: 0.48197049175451157, clipped: 0.48197049175451157
epoch: 73, train_batch_id: 2350, avg_cost: 3.8321890830993652
grad_norm: 0.40511471662292753, clipped: 0.40511471662292753
epoch: 73, train_batch_id: 2400, avg_cost: 3.8761978149414062
grad_norm: 0.3225348102857494, clipped: 0.3225348102857494
epoch: 73, train_batch_id: 2450, avg_cost: 3.8514981269836426
grad_norm: 0.4906592772711952, clipped: 0.4906592772711952
Finished epoch 73, took 00:05:35 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8467605113983154 +- 0.0031009302474558353
Evaluating candidate model on evaluation dataset
Epoch 73 candidate mean 3.8425848484039307, baseline epoch 67 mean 3.8424179553985596, difference 0.00016689300537109375
Start train epoch 74, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 74, train_batch_id: 0, avg_cost: 3.872462272644043
grad_norm: 0.28822506275892945, clipped: 0.28822506275892945
epoch: 74, train_batch_id: 50, avg_cost: 3.8282575607299805
grad_norm: 0.3324339080140863, clipped: 0.3324339080140863
epoch: 74, train_batch_id: 100, avg_cost: 3.8377633094787598
grad_norm: 0.26752589423956297, clipped: 0.26752589423956297
epoch: 74, train_batch_id: 150, avg_cost: 3.82228946685791
grad_norm: 0.2780087266242884, clipped: 0.2780087266242884
epoch: 74, train_batch_id: 200, avg_cost: 3.841309070587158
grad_norm: 0.27450929773411387, clipped: 0.27450929773411387
epoch: 74, train_batch_id: 250, avg_cost: 3.835003137588501
grad_norm: 0.3760515284974681, clipped: 0.3760515284974681
epoch: 74, train_batch_id: 300, avg_cost: 3.838531494140625
grad_norm: 0.22064570727736568, clipped: 0.22064570727736568
epoch: 74, train_batch_id: 350, avg_cost: 3.856482982635498
grad_norm: 0.36935017460969954, clipped: 0.36935017460969954
epoch: 74, train_batch_id: 400, avg_cost: 3.8546061515808105
grad_norm: 0.388416135243977, clipped: 0.388416135243977
epoch: 74, train_batch_id: 450, avg_cost: 3.8832387924194336
grad_norm: 0.3836968247735543, clipped: 0.3836968247735543
epoch: 74, train_batch_id: 500, avg_cost: 3.853661060333252
grad_norm: 0.24289446063739384, clipped: 0.24289446063739384
epoch: 74, train_batch_id: 550, avg_cost: 3.8504526615142822
grad_norm: 0.5452941592180082, clipped: 0.5452941592180082
epoch: 74, train_batch_id: 600, avg_cost: 3.8519365787506104
grad_norm: 0.28437470194094167, clipped: 0.28437470194094167
epoch: 74, train_batch_id: 650, avg_cost: 3.8375377655029297
grad_norm: 0.3606085080488593, clipped: 0.3606085080488593
epoch: 74, train_batch_id: 700, avg_cost: 3.8598475456237793
grad_norm: 0.2842810831663303, clipped: 0.2842810831663303
epoch: 74, train_batch_id: 750, avg_cost: 3.860628604888916
grad_norm: 0.38479028279594985, clipped: 0.38479028279594985
epoch: 74, train_batch_id: 800, avg_cost: 3.8232245445251465
grad_norm: 0.2599096148338308, clipped: 0.2599096148338308
epoch: 74, train_batch_id: 850, avg_cost: 3.8550267219543457
grad_norm: 0.25854006267759955, clipped: 0.25854006267759955
epoch: 74, train_batch_id: 900, avg_cost: 3.8627994060516357
grad_norm: 0.4311841164743755, clipped: 0.4311841164743755
epoch: 74, train_batch_id: 950, avg_cost: 3.8722429275512695
grad_norm: 0.32793716925199373, clipped: 0.32793716925199373
epoch: 74, train_batch_id: 1000, avg_cost: 3.826394557952881
grad_norm: 0.2996760846155423, clipped: 0.2996760846155423
epoch: 74, train_batch_id: 1050, avg_cost: 3.8367366790771484
grad_norm: 0.36313367835823745, clipped: 0.36313367835823745
epoch: 74, train_batch_id: 1100, avg_cost: 3.8525571823120117
grad_norm: 0.5897849615139609, clipped: 0.5897849615139609
epoch: 74, train_batch_id: 1150, avg_cost: 3.862222194671631
grad_norm: 0.38695140683833756, clipped: 0.38695140683833756
epoch: 74, train_batch_id: 1200, avg_cost: 3.851505994796753
grad_norm: 0.2646502869097682, clipped: 0.2646502869097682
epoch: 74, train_batch_id: 1250, avg_cost: 3.8466317653656006
grad_norm: 0.2686353995537943, clipped: 0.2686353995537943
epoch: 74, train_batch_id: 1300, avg_cost: 3.8149797916412354
grad_norm: 0.2654276418660995, clipped: 0.2654276418660995
epoch: 74, train_batch_id: 1350, avg_cost: 3.856856346130371
grad_norm: 0.6511738077485537, clipped: 0.6511738077485537
epoch: 74, train_batch_id: 1400, avg_cost: 3.8508663177490234
grad_norm: 0.41842701450978, clipped: 0.41842701450978
epoch: 74, train_batch_id: 1450, avg_cost: 3.847158432006836
grad_norm: 0.293657418342666, clipped: 0.293657418342666
epoch: 74, train_batch_id: 1500, avg_cost: 3.831305503845215
grad_norm: 0.3378407887644346, clipped: 0.3378407887644346
epoch: 74, train_batch_id: 1550, avg_cost: 3.826073169708252
grad_norm: 0.3029143798251271, clipped: 0.3029143798251271
epoch: 74, train_batch_id: 1600, avg_cost: 3.8560791015625
grad_norm: 0.3565917422902035, clipped: 0.3565917422902035
epoch: 74, train_batch_id: 1650, avg_cost: 3.855820417404175
grad_norm: 0.27022441732617525, clipped: 0.27022441732617525
epoch: 74, train_batch_id: 1700, avg_cost: 3.866299867630005
grad_norm: 0.36924810203942493, clipped: 0.36924810203942493
epoch: 74, train_batch_id: 1750, avg_cost: 3.831688642501831
grad_norm: 0.4256640771544098, clipped: 0.4256640771544098
epoch: 74, train_batch_id: 1800, avg_cost: 3.8587937355041504
grad_norm: 0.42501023658102316, clipped: 0.42501023658102316
epoch: 74, train_batch_id: 1850, avg_cost: 3.846433639526367
grad_norm: 0.27526336910393956, clipped: 0.27526336910393956
epoch: 74, train_batch_id: 1900, avg_cost: 3.8619308471679688
grad_norm: 0.28470461229647803, clipped: 0.28470461229647803
epoch: 74, train_batch_id: 1950, avg_cost: 3.8570332527160645
grad_norm: 0.30841894059073877, clipped: 0.30841894059073877
epoch: 74, train_batch_id: 2000, avg_cost: 3.8286848068237305
grad_norm: 0.2947177743530739, clipped: 0.2947177743530739
epoch: 74, train_batch_id: 2050, avg_cost: 3.853823184967041
grad_norm: 0.2996949556336126, clipped: 0.2996949556336126
epoch: 74, train_batch_id: 2100, avg_cost: 3.858224868774414
grad_norm: 0.3354894362083837, clipped: 0.3354894362083837
epoch: 74, train_batch_id: 2150, avg_cost: 3.849943161010742
grad_norm: 0.3856381017703059, clipped: 0.3856381017703059
epoch: 74, train_batch_id: 2200, avg_cost: 3.8511388301849365
grad_norm: 0.3130379994405295, clipped: 0.3130379994405295
epoch: 74, train_batch_id: 2250, avg_cost: 3.8387622833251953
grad_norm: 0.2582375748607612, clipped: 0.2582375748607612
epoch: 74, train_batch_id: 2300, avg_cost: 3.8575849533081055
grad_norm: 0.3237086517352317, clipped: 0.3237086517352317
epoch: 74, train_batch_id: 2350, avg_cost: 3.8407044410705566
grad_norm: 0.32235945716051095, clipped: 0.32235945716051095
epoch: 74, train_batch_id: 2400, avg_cost: 3.8376359939575195
grad_norm: 0.27235114821166617, clipped: 0.27235114821166617
epoch: 74, train_batch_id: 2450, avg_cost: 3.8510663509368896
grad_norm: 0.2734346044934116, clipped: 0.2734346044934116
Finished epoch 74, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845733642578125 +- 0.003099833382293582
Evaluating candidate model on evaluation dataset
Epoch 74 candidate mean 3.8416385650634766, baseline epoch 67 mean 3.8424179553985596, difference -0.0007793903350830078
p-value: 0.0013452163726359134
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 75, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 75, train_batch_id: 0, avg_cost: 3.8455543518066406
grad_norm: 0.23875084657626836, clipped: 0.23875084657626836
epoch: 75, train_batch_id: 50, avg_cost: 3.85329008102417
grad_norm: 0.8947614237657635, clipped: 0.8947614237657635
epoch: 75, train_batch_id: 100, avg_cost: 3.858708381652832
grad_norm: 0.30628228524526435, clipped: 0.30628228524526435
epoch: 75, train_batch_id: 150, avg_cost: 3.84348201751709
grad_norm: 0.45077740914589975, clipped: 0.45077740914589975
epoch: 75, train_batch_id: 200, avg_cost: 3.8521859645843506
grad_norm: 0.5162801484944493, clipped: 0.5162801484944493
epoch: 75, train_batch_id: 250, avg_cost: 3.8464903831481934
grad_norm: 0.3438359327864652, clipped: 0.3438359327864652
epoch: 75, train_batch_id: 300, avg_cost: 3.83270263671875
grad_norm: 0.4172105720482838, clipped: 0.4172105720482838
epoch: 75, train_batch_id: 350, avg_cost: 3.83707332611084
grad_norm: 0.2941709660201706, clipped: 0.2941709660201706
epoch: 75, train_batch_id: 400, avg_cost: 3.8363685607910156
grad_norm: 0.2597817493556242, clipped: 0.2597817493556242
epoch: 75, train_batch_id: 450, avg_cost: 3.8433003425598145
grad_norm: 0.30355089501365895, clipped: 0.30355089501365895
epoch: 75, train_batch_id: 500, avg_cost: 3.8692548274993896
grad_norm: 0.28659877805220885, clipped: 0.28659877805220885
epoch: 75, train_batch_id: 550, avg_cost: 3.848743438720703
grad_norm: 0.34037549110792004, clipped: 0.34037549110792004
epoch: 75, train_batch_id: 600, avg_cost: 3.8224074840545654
grad_norm: 0.37645712863032565, clipped: 0.37645712863032565
epoch: 75, train_batch_id: 650, avg_cost: 3.8701655864715576
grad_norm: 0.2838571193171441, clipped: 0.2838571193171441
epoch: 75, train_batch_id: 700, avg_cost: 3.8419528007507324
grad_norm: 0.2912706201971202, clipped: 0.2912706201971202
epoch: 75, train_batch_id: 750, avg_cost: 3.855792999267578
grad_norm: 0.37776497305106066, clipped: 0.37776497305106066
epoch: 75, train_batch_id: 800, avg_cost: 3.843489170074463
grad_norm: 0.2706843173329618, clipped: 0.2706843173329618
epoch: 75, train_batch_id: 850, avg_cost: 3.869919776916504
grad_norm: 0.2997900776021875, clipped: 0.2997900776021875
epoch: 75, train_batch_id: 900, avg_cost: 3.8603250980377197
grad_norm: 0.5698373982248862, clipped: 0.5698373982248862
epoch: 75, train_batch_id: 950, avg_cost: 3.832332134246826
grad_norm: 0.253990033057892, clipped: 0.253990033057892
epoch: 75, train_batch_id: 1000, avg_cost: 3.828615665435791
grad_norm: 0.5538427533732857, clipped: 0.5538427533732857
epoch: 75, train_batch_id: 1050, avg_cost: 3.8583106994628906
grad_norm: 0.31074231183164996, clipped: 0.31074231183164996
epoch: 75, train_batch_id: 1100, avg_cost: 3.8484838008880615
grad_norm: 0.37789486392800403, clipped: 0.37789486392800403
epoch: 75, train_batch_id: 1150, avg_cost: 3.8452577590942383
grad_norm: 0.41043113649487173, clipped: 0.41043113649487173
epoch: 75, train_batch_id: 1200, avg_cost: 3.8444089889526367
grad_norm: 0.39692698032997725, clipped: 0.39692698032997725
epoch: 75, train_batch_id: 1250, avg_cost: 3.8563225269317627
grad_norm: 0.29402364232257844, clipped: 0.29402364232257844
epoch: 75, train_batch_id: 1300, avg_cost: 3.849905014038086
grad_norm: 0.33821923060920145, clipped: 0.33821923060920145
epoch: 75, train_batch_id: 1350, avg_cost: 3.843658685684204
grad_norm: 0.5629509136851554, clipped: 0.5629509136851554
epoch: 75, train_batch_id: 1400, avg_cost: 3.847820520401001
grad_norm: 0.3471761178440569, clipped: 0.3471761178440569
epoch: 75, train_batch_id: 1450, avg_cost: 3.845583200454712
grad_norm: 0.24586234536131288, clipped: 0.24586234536131288
epoch: 75, train_batch_id: 1500, avg_cost: 3.849153518676758
grad_norm: 0.3711960292967927, clipped: 0.3711960292967927
epoch: 75, train_batch_id: 1550, avg_cost: 3.8209352493286133
grad_norm: 0.24992431342714, clipped: 0.24992431342714
epoch: 75, train_batch_id: 1600, avg_cost: 3.8497698307037354
grad_norm: 0.2903303496468724, clipped: 0.2903303496468724
epoch: 75, train_batch_id: 1650, avg_cost: 3.857365369796753
grad_norm: 0.6070576083050895, clipped: 0.6070576083050895
epoch: 75, train_batch_id: 1700, avg_cost: 3.8650195598602295
grad_norm: 0.2540724290884353, clipped: 0.2540724290884353
epoch: 75, train_batch_id: 1750, avg_cost: 3.8453056812286377
grad_norm: 0.4562896985487909, clipped: 0.4562896985487909
epoch: 75, train_batch_id: 1800, avg_cost: 3.8446998596191406
grad_norm: 0.24960127226604834, clipped: 0.24960127226604834
epoch: 75, train_batch_id: 1850, avg_cost: 3.8404293060302734
grad_norm: 0.3111086127038215, clipped: 0.3111086127038215
epoch: 75, train_batch_id: 1900, avg_cost: 3.8548269271850586
grad_norm: 0.42867770025910606, clipped: 0.42867770025910606
epoch: 75, train_batch_id: 1950, avg_cost: 3.8577635288238525
grad_norm: 0.27020171186642544, clipped: 0.27020171186642544
epoch: 75, train_batch_id: 2000, avg_cost: 3.8492281436920166
grad_norm: 0.418351036537581, clipped: 0.418351036537581
epoch: 75, train_batch_id: 2050, avg_cost: 3.8554959297180176
grad_norm: 0.406932302263691, clipped: 0.406932302263691
epoch: 75, train_batch_id: 2100, avg_cost: 3.852780342102051
grad_norm: 0.3365186882838129, clipped: 0.3365186882838129
epoch: 75, train_batch_id: 2150, avg_cost: 3.8468618392944336
grad_norm: 0.6664746906623088, clipped: 0.6664746906623088
epoch: 75, train_batch_id: 2200, avg_cost: 3.839554786682129
grad_norm: 0.5125907283354685, clipped: 0.5125907283354685
epoch: 75, train_batch_id: 2250, avg_cost: 3.857466220855713
grad_norm: 0.48452032854062166, clipped: 0.48452032854062166
epoch: 75, train_batch_id: 2300, avg_cost: 3.85231351852417
grad_norm: 0.377098092538034, clipped: 0.377098092538034
epoch: 75, train_batch_id: 2350, avg_cost: 3.8276491165161133
grad_norm: 0.47558148178930054, clipped: 0.47558148178930054
epoch: 75, train_batch_id: 2400, avg_cost: 3.8241395950317383
grad_norm: 0.312313570788656, clipped: 0.312313570788656
epoch: 75, train_batch_id: 2450, avg_cost: 3.8535282611846924
grad_norm: 0.26058143488731644, clipped: 0.26058143488731644
Finished epoch 75, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8465688228607178 +- 0.00310453656129539
Evaluating candidate model on evaluation dataset
Epoch 75 candidate mean 3.8449831008911133, baseline epoch 74 mean 3.8441007137298584, difference 0.0008823871612548828
Start train epoch 76, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 76, train_batch_id: 0, avg_cost: 3.8183674812316895
grad_norm: 0.20285895361207976, clipped: 0.20285895361207976
epoch: 76, train_batch_id: 50, avg_cost: 3.825242519378662
grad_norm: 0.21429013692041865, clipped: 0.21429013692041865
epoch: 76, train_batch_id: 100, avg_cost: 3.8442440032958984
grad_norm: 0.2407475150075473, clipped: 0.2407475150075473
epoch: 76, train_batch_id: 150, avg_cost: 3.8421759605407715
grad_norm: 0.2868808565093143, clipped: 0.2868808565093143
epoch: 76, train_batch_id: 200, avg_cost: 3.859266757965088
grad_norm: 0.19903849785090763, clipped: 0.19903849785090763
epoch: 76, train_batch_id: 250, avg_cost: 3.830540657043457
grad_norm: 0.39320311661574736, clipped: 0.39320311661574736
epoch: 76, train_batch_id: 300, avg_cost: 3.853954315185547
grad_norm: 0.413825248892218, clipped: 0.413825248892218
epoch: 76, train_batch_id: 350, avg_cost: 3.856353998184204
grad_norm: 0.22113432162128535, clipped: 0.22113432162128535
epoch: 76, train_batch_id: 400, avg_cost: 3.8514740467071533
grad_norm: 0.4902078544437576, clipped: 0.4902078544437576
epoch: 76, train_batch_id: 450, avg_cost: 3.854048252105713
grad_norm: 0.30115446632776566, clipped: 0.30115446632776566
epoch: 76, train_batch_id: 500, avg_cost: 3.871734142303467
grad_norm: 0.4063059697501042, clipped: 0.4063059697501042
epoch: 76, train_batch_id: 550, avg_cost: 3.8580167293548584
grad_norm: 0.30675118105528926, clipped: 0.30675118105528926
epoch: 76, train_batch_id: 600, avg_cost: 3.843515396118164
grad_norm: 0.3461307267769404, clipped: 0.3461307267769404
epoch: 76, train_batch_id: 650, avg_cost: 3.8426527976989746
grad_norm: 0.3925691537261166, clipped: 0.3925691537261166
epoch: 76, train_batch_id: 700, avg_cost: 3.8369932174682617
grad_norm: 0.22655695921022007, clipped: 0.22655695921022007
epoch: 76, train_batch_id: 750, avg_cost: 3.8318979740142822
grad_norm: 0.5829401021770949, clipped: 0.5829401021770949
epoch: 76, train_batch_id: 800, avg_cost: 3.876053810119629
grad_norm: 0.2296576407504282, clipped: 0.2296576407504282
epoch: 76, train_batch_id: 850, avg_cost: 3.8519673347473145
grad_norm: 0.4224485509543691, clipped: 0.4224485509543691
epoch: 76, train_batch_id: 900, avg_cost: 3.848923444747925
grad_norm: 0.6567112571429656, clipped: 0.6567112571429656
epoch: 76, train_batch_id: 950, avg_cost: 3.8421716690063477
grad_norm: 0.4587941670707103, clipped: 0.4587941670707103
epoch: 76, train_batch_id: 1000, avg_cost: 3.8541646003723145
grad_norm: 0.42893797674289036, clipped: 0.42893797674289036
epoch: 76, train_batch_id: 1050, avg_cost: 3.8480026721954346
grad_norm: 0.2432609612077825, clipped: 0.2432609612077825
epoch: 76, train_batch_id: 1100, avg_cost: 3.86421275138855
grad_norm: 0.33709745761895765, clipped: 0.33709745761895765
epoch: 76, train_batch_id: 1150, avg_cost: 3.841155529022217
grad_norm: 0.29834923969106875, clipped: 0.29834923969106875
epoch: 76, train_batch_id: 1200, avg_cost: 3.872565269470215
grad_norm: 0.6557714405433454, clipped: 0.6557714405433454
epoch: 76, train_batch_id: 1250, avg_cost: 3.853041887283325
grad_norm: 0.26687885772565684, clipped: 0.26687885772565684
epoch: 76, train_batch_id: 1300, avg_cost: 3.8516316413879395
grad_norm: 0.3434406651807386, clipped: 0.3434406651807386
epoch: 76, train_batch_id: 1350, avg_cost: 3.8534350395202637
grad_norm: 0.2768022214400992, clipped: 0.2768022214400992
epoch: 76, train_batch_id: 1400, avg_cost: 3.8293237686157227
grad_norm: 0.3712207801234774, clipped: 0.3712207801234774
epoch: 76, train_batch_id: 1450, avg_cost: 3.8341147899627686
grad_norm: 0.23919630256938712, clipped: 0.23919630256938712
epoch: 76, train_batch_id: 1500, avg_cost: 3.852865219116211
grad_norm: 0.21201033205394976, clipped: 0.21201033205394976
epoch: 76, train_batch_id: 1550, avg_cost: 3.8655643463134766
grad_norm: 0.42061284375248587, clipped: 0.42061284375248587
epoch: 76, train_batch_id: 1600, avg_cost: 3.861957550048828
grad_norm: 0.40187061075236646, clipped: 0.40187061075236646
epoch: 76, train_batch_id: 1650, avg_cost: 3.8378138542175293
grad_norm: 0.40898151428950763, clipped: 0.40898151428950763
epoch: 76, train_batch_id: 1700, avg_cost: 3.8482329845428467
grad_norm: 0.2792638848559123, clipped: 0.2792638848559123
epoch: 76, train_batch_id: 1750, avg_cost: 3.8554859161376953
grad_norm: 0.315586859757169, clipped: 0.315586859757169
epoch: 76, train_batch_id: 1800, avg_cost: 3.8434455394744873
grad_norm: 0.27907651301321995, clipped: 0.27907651301321995
epoch: 76, train_batch_id: 1850, avg_cost: 3.827336549758911
grad_norm: 0.6101284222764143, clipped: 0.6101284222764143
epoch: 76, train_batch_id: 1900, avg_cost: 3.8426990509033203
grad_norm: 0.5698713278623792, clipped: 0.5698713278623792
epoch: 76, train_batch_id: 1950, avg_cost: 3.865572452545166
grad_norm: 0.354185719063041, clipped: 0.354185719063041
epoch: 76, train_batch_id: 2000, avg_cost: 3.8300886154174805
grad_norm: 0.28600688125740203, clipped: 0.28600688125740203
epoch: 76, train_batch_id: 2050, avg_cost: 3.8448920249938965
grad_norm: 0.6181512256944232, clipped: 0.6181512256944232
epoch: 76, train_batch_id: 2100, avg_cost: 3.8452701568603516
grad_norm: 0.40987079554929046, clipped: 0.40987079554929046
epoch: 76, train_batch_id: 2150, avg_cost: 3.845799684524536
grad_norm: 0.43078128956356887, clipped: 0.43078128956356887
epoch: 76, train_batch_id: 2200, avg_cost: 3.824310541152954
grad_norm: 0.2965890749816903, clipped: 0.2965890749816903
epoch: 76, train_batch_id: 2250, avg_cost: 3.8329575061798096
grad_norm: 0.22487410809184388, clipped: 0.22487410809184388
epoch: 76, train_batch_id: 2300, avg_cost: 3.840522289276123
grad_norm: 1.028040127328916, clipped: 1.0
epoch: 76, train_batch_id: 2350, avg_cost: 3.8563623428344727
grad_norm: 0.3615680203339361, clipped: 0.3615680203339361
epoch: 76, train_batch_id: 2400, avg_cost: 3.862537384033203
grad_norm: 0.40392490490823946, clipped: 0.40392490490823946
epoch: 76, train_batch_id: 2450, avg_cost: 3.851170063018799
grad_norm: 0.46342508443151625, clipped: 0.46342508443151625
Finished epoch 76, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8456897735595703 +- 0.003101338166743517
Evaluating candidate model on evaluation dataset
Epoch 76 candidate mean 3.8441123962402344, baseline epoch 74 mean 3.8441007137298584, difference 1.1682510375976562e-05
Start train epoch 77, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 77, train_batch_id: 0, avg_cost: 3.8384597301483154
grad_norm: 0.25705665668516986, clipped: 0.25705665668516986
epoch: 77, train_batch_id: 50, avg_cost: 3.84860897064209
grad_norm: 0.2317750379721319, clipped: 0.2317750379721319
epoch: 77, train_batch_id: 100, avg_cost: 3.841141939163208
grad_norm: 0.33768256405783376, clipped: 0.33768256405783376
epoch: 77, train_batch_id: 150, avg_cost: 3.8221211433410645
grad_norm: 0.23582870145143184, clipped: 0.23582870145143184
epoch: 77, train_batch_id: 200, avg_cost: 3.840723991394043
grad_norm: 0.693746313936717, clipped: 0.693746313936717
epoch: 77, train_batch_id: 250, avg_cost: 3.8466637134552
grad_norm: 0.25909550177335205, clipped: 0.25909550177335205
epoch: 77, train_batch_id: 300, avg_cost: 3.857431650161743
grad_norm: 0.3096830052143844, clipped: 0.3096830052143844
epoch: 77, train_batch_id: 350, avg_cost: 3.825040340423584
grad_norm: 0.37915833066278215, clipped: 0.37915833066278215
epoch: 77, train_batch_id: 400, avg_cost: 3.83124041557312
grad_norm: 0.3116809396891603, clipped: 0.3116809396891603
epoch: 77, train_batch_id: 450, avg_cost: 3.8588781356811523
grad_norm: 0.3794264287805889, clipped: 0.3794264287805889
epoch: 77, train_batch_id: 500, avg_cost: 3.8473405838012695
grad_norm: 0.2695939094560859, clipped: 0.2695939094560859
epoch: 77, train_batch_id: 550, avg_cost: 3.8539938926696777
grad_norm: 0.3212186317165523, clipped: 0.3212186317165523
epoch: 77, train_batch_id: 600, avg_cost: 3.8295907974243164
grad_norm: 0.4621246920808772, clipped: 0.4621246920808772
epoch: 77, train_batch_id: 650, avg_cost: 3.8230247497558594
grad_norm: 0.24514874333969086, clipped: 0.24514874333969086
epoch: 77, train_batch_id: 700, avg_cost: 3.8339948654174805
grad_norm: 0.3957201999357134, clipped: 0.3957201999357134
epoch: 77, train_batch_id: 750, avg_cost: 3.863663673400879
grad_norm: 0.24088768878527708, clipped: 0.24088768878527708
epoch: 77, train_batch_id: 800, avg_cost: 3.8215227127075195
grad_norm: 0.22346855210980549, clipped: 0.22346855210980549
epoch: 77, train_batch_id: 850, avg_cost: 3.8597724437713623
grad_norm: 0.27041730164065036, clipped: 0.27041730164065036
epoch: 77, train_batch_id: 900, avg_cost: 3.8149304389953613
grad_norm: 0.21582259198247183, clipped: 0.21582259198247183
epoch: 77, train_batch_id: 950, avg_cost: 3.812887668609619
grad_norm: 0.26768633317646956, clipped: 0.26768633317646956
epoch: 77, train_batch_id: 1000, avg_cost: 3.854003667831421
grad_norm: 0.3269072053938013, clipped: 0.3269072053938013
epoch: 77, train_batch_id: 1050, avg_cost: 3.8614377975463867
grad_norm: 0.2340561114397647, clipped: 0.2340561114397647
epoch: 77, train_batch_id: 1100, avg_cost: 3.8319077491760254
grad_norm: 0.2993439921326238, clipped: 0.2993439921326238
epoch: 77, train_batch_id: 1150, avg_cost: 3.8498079776763916
grad_norm: 0.3209105479102014, clipped: 0.3209105479102014
epoch: 77, train_batch_id: 1200, avg_cost: 3.8516652584075928
grad_norm: 0.9317989770414498, clipped: 0.9317989770414498
epoch: 77, train_batch_id: 1250, avg_cost: 3.846254825592041
grad_norm: 0.26024477631724086, clipped: 0.26024477631724086
epoch: 77, train_batch_id: 1300, avg_cost: 3.8583621978759766
grad_norm: 0.2647720660766531, clipped: 0.2647720660766531
epoch: 77, train_batch_id: 1350, avg_cost: 3.836404800415039
grad_norm: 0.3583604486483949, clipped: 0.3583604486483949
epoch: 77, train_batch_id: 1400, avg_cost: 3.859470844268799
grad_norm: 0.3583909686781431, clipped: 0.3583909686781431
epoch: 77, train_batch_id: 1450, avg_cost: 3.842442512512207
grad_norm: 0.31339567160609444, clipped: 0.31339567160609444
epoch: 77, train_batch_id: 1500, avg_cost: 3.8713788986206055
grad_norm: 0.5144396507621395, clipped: 0.5144396507621395
epoch: 77, train_batch_id: 1550, avg_cost: 3.829310417175293
grad_norm: 0.32511223614652046, clipped: 0.32511223614652046
epoch: 77, train_batch_id: 1600, avg_cost: 3.8398566246032715
grad_norm: 0.2548937895949172, clipped: 0.2548937895949172
epoch: 77, train_batch_id: 1650, avg_cost: 3.8239290714263916
grad_norm: 0.27350087106254584, clipped: 0.27350087106254584
epoch: 77, train_batch_id: 1700, avg_cost: 3.825922727584839
grad_norm: 0.32713450272861366, clipped: 0.32713450272861366
epoch: 77, train_batch_id: 1750, avg_cost: 3.8163692951202393
grad_norm: 0.2780024460180005, clipped: 0.2780024460180005
epoch: 77, train_batch_id: 1800, avg_cost: 3.8470511436462402
grad_norm: 0.3689921184858215, clipped: 0.3689921184858215
epoch: 77, train_batch_id: 1850, avg_cost: 3.852837562561035
grad_norm: 0.3894936188769651, clipped: 0.3894936188769651
epoch: 77, train_batch_id: 1900, avg_cost: 3.849759340286255
grad_norm: 0.28583087657030914, clipped: 0.28583087657030914
epoch: 77, train_batch_id: 1950, avg_cost: 3.8627078533172607
grad_norm: 0.3289750691853877, clipped: 0.3289750691853877
epoch: 77, train_batch_id: 2000, avg_cost: 3.8551747798919678
grad_norm: 0.32710141894364736, clipped: 0.32710141894364736
epoch: 77, train_batch_id: 2050, avg_cost: 3.8351480960845947
grad_norm: 0.3654312843089382, clipped: 0.3654312843089382
epoch: 77, train_batch_id: 2100, avg_cost: 3.859713077545166
grad_norm: 0.3362481329574298, clipped: 0.3362481329574298
epoch: 77, train_batch_id: 2150, avg_cost: 3.845060348510742
grad_norm: 0.33956580476418224, clipped: 0.33956580476418224
epoch: 77, train_batch_id: 2200, avg_cost: 3.8545026779174805
grad_norm: 0.27405214257227284, clipped: 0.27405214257227284
epoch: 77, train_batch_id: 2250, avg_cost: 3.843590259552002
grad_norm: 0.29693897497258515, clipped: 0.29693897497258515
epoch: 77, train_batch_id: 2300, avg_cost: 3.8378114700317383
grad_norm: 0.8726366585076845, clipped: 0.8726366585076845
epoch: 77, train_batch_id: 2350, avg_cost: 3.8473093509674072
grad_norm: 0.3279994568463431, clipped: 0.3279994568463431
epoch: 77, train_batch_id: 2400, avg_cost: 3.844632863998413
grad_norm: 0.3844651833403929, clipped: 0.3844651833403929
epoch: 77, train_batch_id: 2450, avg_cost: 3.833782911300659
grad_norm: 0.39069025614872266, clipped: 0.39069025614872266
Finished epoch 77, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8462417125701904 +- 0.0030970743391662836
Evaluating candidate model on evaluation dataset
Epoch 77 candidate mean 3.8442389965057373, baseline epoch 74 mean 3.8441007137298584, difference 0.00013828277587890625
Start train epoch 78, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 78, train_batch_id: 0, avg_cost: 3.863738536834717
grad_norm: 0.2830019878583771, clipped: 0.2830019878583771
epoch: 78, train_batch_id: 50, avg_cost: 3.8378539085388184
grad_norm: 0.21187791002387268, clipped: 0.21187791002387268
epoch: 78, train_batch_id: 100, avg_cost: 3.869391679763794
grad_norm: 0.5541147087160613, clipped: 0.5541147087160613
epoch: 78, train_batch_id: 150, avg_cost: 3.8411803245544434
grad_norm: 0.40199505344720204, clipped: 0.40199505344720204
epoch: 78, train_batch_id: 200, avg_cost: 3.8699874877929688
grad_norm: 0.3574107940815169, clipped: 0.3574107940815169
epoch: 78, train_batch_id: 250, avg_cost: 3.8356189727783203
grad_norm: 1.1826363985664177, clipped: 1.0
epoch: 78, train_batch_id: 300, avg_cost: 3.855286121368408
grad_norm: 0.2820460780642188, clipped: 0.2820460780642188
epoch: 78, train_batch_id: 350, avg_cost: 3.8650169372558594
grad_norm: 0.5460396631494416, clipped: 0.5460396631494416
epoch: 78, train_batch_id: 400, avg_cost: 3.848027229309082
grad_norm: 0.4590973958281554, clipped: 0.4590973958281554
epoch: 78, train_batch_id: 450, avg_cost: 3.860079526901245
grad_norm: 0.3084405936788381, clipped: 0.3084405936788381
epoch: 78, train_batch_id: 500, avg_cost: 3.8416059017181396
grad_norm: 0.26238035841717045, clipped: 0.26238035841717045
epoch: 78, train_batch_id: 550, avg_cost: 3.872879981994629
grad_norm: 0.34191105995988286, clipped: 0.34191105995988286
epoch: 78, train_batch_id: 600, avg_cost: 3.841254234313965
grad_norm: 0.2507637886562283, clipped: 0.2507637886562283
epoch: 78, train_batch_id: 650, avg_cost: 3.8422610759735107
grad_norm: 1.3996857630033845, clipped: 1.0
epoch: 78, train_batch_id: 700, avg_cost: 3.836528778076172
grad_norm: 0.35806191349329086, clipped: 0.35806191349329086
epoch: 78, train_batch_id: 750, avg_cost: 3.830205202102661
grad_norm: 0.3357954357237015, clipped: 0.3357954357237015
epoch: 78, train_batch_id: 800, avg_cost: 3.83119535446167
grad_norm: 0.7153776392309531, clipped: 0.7153776392309531
epoch: 78, train_batch_id: 850, avg_cost: 3.8566207885742188
grad_norm: 0.3704907327598445, clipped: 0.3704907327598445
epoch: 78, train_batch_id: 900, avg_cost: 3.8258981704711914
grad_norm: 0.33425448528401386, clipped: 0.33425448528401386
epoch: 78, train_batch_id: 950, avg_cost: 3.824983596801758
grad_norm: 0.33961201330234664, clipped: 0.33961201330234664
epoch: 78, train_batch_id: 1000, avg_cost: 3.8159232139587402
grad_norm: 0.35594243335767844, clipped: 0.35594243335767844
epoch: 78, train_batch_id: 1050, avg_cost: 3.8423025608062744
grad_norm: 0.3938266934645798, clipped: 0.3938266934645798
epoch: 78, train_batch_id: 1100, avg_cost: 3.8396146297454834
grad_norm: 0.31057101392548603, clipped: 0.31057101392548603
epoch: 78, train_batch_id: 1150, avg_cost: 3.842406988143921
grad_norm: 0.32244099318978314, clipped: 0.32244099318978314
epoch: 78, train_batch_id: 1200, avg_cost: 3.8320016860961914
grad_norm: 0.34568555581716, clipped: 0.34568555581716
epoch: 78, train_batch_id: 1250, avg_cost: 3.8456034660339355
grad_norm: 0.37843412257119097, clipped: 0.37843412257119097
epoch: 78, train_batch_id: 1300, avg_cost: 3.8166375160217285
grad_norm: 0.3257374643847197, clipped: 0.3257374643847197
epoch: 78, train_batch_id: 1350, avg_cost: 3.8559470176696777
grad_norm: 0.23882319240857966, clipped: 0.23882319240857966
epoch: 78, train_batch_id: 1400, avg_cost: 3.8613057136535645
grad_norm: 0.3732054048775623, clipped: 0.3732054048775623
epoch: 78, train_batch_id: 1450, avg_cost: 3.8567686080932617
grad_norm: 0.24615193856984105, clipped: 0.24615193856984105
epoch: 78, train_batch_id: 1500, avg_cost: 3.873192071914673
grad_norm: 0.45483615455386683, clipped: 0.45483615455386683
epoch: 78, train_batch_id: 1550, avg_cost: 3.8367295265197754
grad_norm: 0.27947454167766467, clipped: 0.27947454167766467
epoch: 78, train_batch_id: 1600, avg_cost: 3.841982841491699
grad_norm: 0.2860594387876808, clipped: 0.2860594387876808
epoch: 78, train_batch_id: 1650, avg_cost: 3.839078426361084
grad_norm: 0.27657984303212857, clipped: 0.27657984303212857
epoch: 78, train_batch_id: 1700, avg_cost: 3.834489345550537
grad_norm: 0.25851297644604015, clipped: 0.25851297644604015
epoch: 78, train_batch_id: 1750, avg_cost: 3.8387093544006348
grad_norm: 0.28454602128458784, clipped: 0.28454602128458784
epoch: 78, train_batch_id: 1800, avg_cost: 3.8468809127807617
grad_norm: 0.33927449663881304, clipped: 0.33927449663881304
epoch: 78, train_batch_id: 1850, avg_cost: 3.8268840312957764
grad_norm: 0.27554779707633625, clipped: 0.27554779707633625
epoch: 78, train_batch_id: 1900, avg_cost: 3.8402762413024902
grad_norm: 0.3313518311641835, clipped: 0.3313518311641835
epoch: 78, train_batch_id: 1950, avg_cost: 3.83438777923584
grad_norm: 0.4260949089195957, clipped: 0.4260949089195957
epoch: 78, train_batch_id: 2000, avg_cost: 3.839816093444824
grad_norm: 0.20371831625261355, clipped: 0.20371831625261355
epoch: 78, train_batch_id: 2050, avg_cost: 3.848073720932007
grad_norm: 0.21633056450021404, clipped: 0.21633056450021404
epoch: 78, train_batch_id: 2100, avg_cost: 3.8365249633789062
grad_norm: 0.3035804487872057, clipped: 0.3035804487872057
epoch: 78, train_batch_id: 2150, avg_cost: 3.822756290435791
grad_norm: 0.33320537989460886, clipped: 0.33320537989460886
epoch: 78, train_batch_id: 2200, avg_cost: 3.8241453170776367
grad_norm: 0.34391041140881484, clipped: 0.34391041140881484
epoch: 78, train_batch_id: 2250, avg_cost: 3.823197364807129
grad_norm: 0.30863326026870214, clipped: 0.30863326026870214
epoch: 78, train_batch_id: 2300, avg_cost: 3.8450188636779785
grad_norm: 0.28723787816230834, clipped: 0.28723787816230834
epoch: 78, train_batch_id: 2350, avg_cost: 3.842024803161621
grad_norm: 0.2632989740045146, clipped: 0.2632989740045146
epoch: 78, train_batch_id: 2400, avg_cost: 3.8446199893951416
grad_norm: 0.2980807355810034, clipped: 0.2980807355810034
epoch: 78, train_batch_id: 2450, avg_cost: 3.8400471210479736
grad_norm: 0.36475702470963045, clipped: 0.36475702470963045
Finished epoch 78, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8465940952301025 +- 0.0031030443497002125
Evaluating candidate model on evaluation dataset
Epoch 78 candidate mean 3.844547748565674, baseline epoch 74 mean 3.8441007137298584, difference 0.0004470348358154297
Start train epoch 79, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 79, train_batch_id: 0, avg_cost: 3.8484714031219482
grad_norm: 0.2779672836911745, clipped: 0.2779672836911745
epoch: 79, train_batch_id: 50, avg_cost: 3.8602664470672607
grad_norm: 2.1345756649496237, clipped: 1.0
epoch: 79, train_batch_id: 100, avg_cost: 3.8435096740722656
grad_norm: 0.29214041182917677, clipped: 0.29214041182917677
epoch: 79, train_batch_id: 150, avg_cost: 3.8294215202331543
grad_norm: 0.6398665585298864, clipped: 0.6398665585298864
epoch: 79, train_batch_id: 200, avg_cost: 3.838090181350708
grad_norm: 0.3903662728370526, clipped: 0.3903662728370526
epoch: 79, train_batch_id: 250, avg_cost: 3.843266010284424
grad_norm: 0.3253975548400715, clipped: 0.3253975548400715
epoch: 79, train_batch_id: 300, avg_cost: 3.859743595123291
grad_norm: 0.3711992798687232, clipped: 0.3711992798687232
epoch: 79, train_batch_id: 350, avg_cost: 3.817237377166748
grad_norm: 0.26598863092865166, clipped: 0.26598863092865166
epoch: 79, train_batch_id: 400, avg_cost: 3.8503031730651855
grad_norm: 0.7997131754090694, clipped: 0.7997131754090694
epoch: 79, train_batch_id: 450, avg_cost: 3.8478281497955322
grad_norm: 0.3220145538284799, clipped: 0.3220145538284799
epoch: 79, train_batch_id: 500, avg_cost: 3.8490519523620605
grad_norm: 0.3304639938054284, clipped: 0.3304639938054284
epoch: 79, train_batch_id: 550, avg_cost: 3.8292505741119385
grad_norm: 0.29881601306603073, clipped: 0.29881601306603073
epoch: 79, train_batch_id: 600, avg_cost: 3.8462066650390625
grad_norm: 0.23602960410155838, clipped: 0.23602960410155838
epoch: 79, train_batch_id: 650, avg_cost: 3.8455402851104736
grad_norm: 0.17386562175835665, clipped: 0.17386562175835665
epoch: 79, train_batch_id: 700, avg_cost: 3.8465278148651123
grad_norm: 0.24519124668745712, clipped: 0.24519124668745712
epoch: 79, train_batch_id: 750, avg_cost: 3.8715102672576904
grad_norm: 0.6471158755992721, clipped: 0.6471158755992721
epoch: 79, train_batch_id: 800, avg_cost: 3.842273712158203
grad_norm: 0.3275857939753714, clipped: 0.3275857939753714
epoch: 79, train_batch_id: 850, avg_cost: 3.839132785797119
grad_norm: 0.3746163571366145, clipped: 0.3746163571366145
epoch: 79, train_batch_id: 900, avg_cost: 3.862210512161255
grad_norm: 0.6420778724013565, clipped: 0.6420778724013565
epoch: 79, train_batch_id: 950, avg_cost: 3.8501029014587402
grad_norm: 0.4343751338924877, clipped: 0.4343751338924877
epoch: 79, train_batch_id: 1000, avg_cost: 3.854665756225586
grad_norm: 0.40160323913313034, clipped: 0.40160323913313034
epoch: 79, train_batch_id: 1050, avg_cost: 3.8779120445251465
grad_norm: 0.31883650797870483, clipped: 0.31883650797870483
epoch: 79, train_batch_id: 1100, avg_cost: 3.834364414215088
grad_norm: 0.26380923855440913, clipped: 0.26380923855440913
epoch: 79, train_batch_id: 1150, avg_cost: 3.8410403728485107
grad_norm: 0.30497639068966154, clipped: 0.30497639068966154
epoch: 79, train_batch_id: 1200, avg_cost: 3.8424925804138184
grad_norm: 0.1929492708668704, clipped: 0.1929492708668704
epoch: 79, train_batch_id: 1250, avg_cost: 3.864922523498535
grad_norm: 0.35129702778008937, clipped: 0.35129702778008937
epoch: 79, train_batch_id: 1300, avg_cost: 3.845266819000244
grad_norm: 0.7871284915200549, clipped: 0.7871284915200549
epoch: 79, train_batch_id: 1350, avg_cost: 3.8503880500793457
grad_norm: 0.30903274847203505, clipped: 0.30903274847203505
epoch: 79, train_batch_id: 1400, avg_cost: 3.838386058807373
grad_norm: 0.4028319810273343, clipped: 0.4028319810273343
epoch: 79, train_batch_id: 1450, avg_cost: 3.8431448936462402
grad_norm: 0.32107450743650323, clipped: 0.32107450743650323
epoch: 79, train_batch_id: 1500, avg_cost: 3.8400542736053467
grad_norm: 0.23639232842330574, clipped: 0.23639232842330574
epoch: 79, train_batch_id: 1550, avg_cost: 3.850083589553833
grad_norm: 0.6177664039183128, clipped: 0.6177664039183128
epoch: 79, train_batch_id: 1600, avg_cost: 3.838094711303711
grad_norm: 0.8753008717610106, clipped: 0.8753008717610106
epoch: 79, train_batch_id: 1650, avg_cost: 3.840364456176758
grad_norm: 0.4454454512145762, clipped: 0.4454454512145762
epoch: 79, train_batch_id: 1700, avg_cost: 3.823380947113037
grad_norm: 0.25770256089431015, clipped: 0.25770256089431015
epoch: 79, train_batch_id: 1750, avg_cost: 3.8247365951538086
grad_norm: 0.22992085392148348, clipped: 0.22992085392148348
epoch: 79, train_batch_id: 1800, avg_cost: 3.8929736614227295
grad_norm: 0.7895862043531829, clipped: 0.7895862043531829
epoch: 79, train_batch_id: 1850, avg_cost: 3.846313714981079
grad_norm: 0.3526953306579704, clipped: 0.3526953306579704
epoch: 79, train_batch_id: 1900, avg_cost: 3.842963218688965
grad_norm: 0.257618309379, clipped: 0.257618309379
epoch: 79, train_batch_id: 1950, avg_cost: 3.8278651237487793
grad_norm: 0.3621890049270146, clipped: 0.3621890049270146
epoch: 79, train_batch_id: 2000, avg_cost: 3.8297574520111084
grad_norm: 0.35390171642615037, clipped: 0.35390171642615037
epoch: 79, train_batch_id: 2050, avg_cost: 3.8234610557556152
grad_norm: 0.2513156242220044, clipped: 0.2513156242220044
epoch: 79, train_batch_id: 2100, avg_cost: 3.8623032569885254
grad_norm: 0.8463600981759268, clipped: 0.8463600981759268
epoch: 79, train_batch_id: 2150, avg_cost: 3.8700015544891357
grad_norm: 0.33160400072744606, clipped: 0.33160400072744606
epoch: 79, train_batch_id: 2200, avg_cost: 3.8489630222320557
grad_norm: 0.35383988837571717, clipped: 0.35383988837571717
epoch: 79, train_batch_id: 2250, avg_cost: 3.8294076919555664
grad_norm: 0.2354446005593494, clipped: 0.2354446005593494
epoch: 79, train_batch_id: 2300, avg_cost: 3.867218494415283
grad_norm: 0.4245282434678189, clipped: 0.4245282434678189
epoch: 79, train_batch_id: 2350, avg_cost: 3.825446367263794
grad_norm: 0.46340358897175743, clipped: 0.46340358897175743
epoch: 79, train_batch_id: 2400, avg_cost: 3.8231630325317383
grad_norm: 0.27379880117840183, clipped: 0.27379880117840183
epoch: 79, train_batch_id: 2450, avg_cost: 3.8622045516967773
grad_norm: 0.8101640586644282, clipped: 0.8101640586644282
Finished epoch 79, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8460042476654053 +- 0.0031011863611638546
Evaluating candidate model on evaluation dataset
Epoch 79 candidate mean 3.844212532043457, baseline epoch 74 mean 3.8441007137298584, difference 0.00011181831359863281
Start train epoch 80, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 80, train_batch_id: 0, avg_cost: 3.868143081665039
grad_norm: 0.7693811280969193, clipped: 0.7693811280969193
epoch: 80, train_batch_id: 50, avg_cost: 3.845841884613037
grad_norm: 0.2680860572579042, clipped: 0.2680860572579042
epoch: 80, train_batch_id: 100, avg_cost: 3.852715015411377
grad_norm: 0.2641891781785536, clipped: 0.2641891781785536
epoch: 80, train_batch_id: 150, avg_cost: 3.8525118827819824
grad_norm: 0.3229617826107955, clipped: 0.3229617826107955
epoch: 80, train_batch_id: 200, avg_cost: 3.8685128688812256
grad_norm: 0.23126624632064266, clipped: 0.23126624632064266
epoch: 80, train_batch_id: 250, avg_cost: 3.8475701808929443
grad_norm: 0.5565724385049374, clipped: 0.5565724385049374
epoch: 80, train_batch_id: 300, avg_cost: 3.8653149604797363
grad_norm: 0.2569803890933304, clipped: 0.2569803890933304
epoch: 80, train_batch_id: 350, avg_cost: 3.8691086769104004
grad_norm: 0.6410348312812745, clipped: 0.6410348312812745
epoch: 80, train_batch_id: 400, avg_cost: 3.8418498039245605
grad_norm: 0.3091398576361739, clipped: 0.3091398576361739
epoch: 80, train_batch_id: 450, avg_cost: 3.853386640548706
grad_norm: 0.30919489377567244, clipped: 0.30919489377567244
epoch: 80, train_batch_id: 500, avg_cost: 3.8511273860931396
grad_norm: 0.3550970204091642, clipped: 0.3550970204091642
epoch: 80, train_batch_id: 550, avg_cost: 3.847170352935791
grad_norm: 0.28731708432093306, clipped: 0.28731708432093306
epoch: 80, train_batch_id: 600, avg_cost: 3.8340506553649902
grad_norm: 0.40946041044379466, clipped: 0.40946041044379466
epoch: 80, train_batch_id: 650, avg_cost: 3.844703197479248
grad_norm: 0.2249653696136929, clipped: 0.2249653696136929
epoch: 80, train_batch_id: 700, avg_cost: 3.831662654876709
grad_norm: 0.8757612803790374, clipped: 0.8757612803790374
epoch: 80, train_batch_id: 750, avg_cost: 3.8377442359924316
grad_norm: 0.6730052718039761, clipped: 0.6730052718039761
epoch: 80, train_batch_id: 800, avg_cost: 3.8333466053009033
grad_norm: 0.48662415162371, clipped: 0.48662415162371
epoch: 80, train_batch_id: 850, avg_cost: 3.8431320190429688
grad_norm: 0.29475118757036556, clipped: 0.29475118757036556
epoch: 80, train_batch_id: 900, avg_cost: 3.8566994667053223
grad_norm: 0.3503336523780631, clipped: 0.3503336523780631
epoch: 80, train_batch_id: 950, avg_cost: 3.8376007080078125
grad_norm: 0.21496949485872732, clipped: 0.21496949485872732
epoch: 80, train_batch_id: 1000, avg_cost: 3.844719409942627
grad_norm: 0.26443922838797984, clipped: 0.26443922838797984
epoch: 80, train_batch_id: 1050, avg_cost: 3.8608648777008057
grad_norm: 0.3605451510949984, clipped: 0.3605451510949984
epoch: 80, train_batch_id: 1100, avg_cost: 3.8422560691833496
grad_norm: 0.2712178320478243, clipped: 0.2712178320478243
epoch: 80, train_batch_id: 1150, avg_cost: 3.851581573486328
grad_norm: 0.6917909039538894, clipped: 0.6917909039538894
epoch: 80, train_batch_id: 1200, avg_cost: 3.8387832641601562
grad_norm: 0.31609587623255203, clipped: 0.31609587623255203
epoch: 80, train_batch_id: 1250, avg_cost: 3.845705509185791
grad_norm: 0.2157106268007748, clipped: 0.2157106268007748
epoch: 80, train_batch_id: 1300, avg_cost: 3.8236398696899414
grad_norm: 0.3682666686321459, clipped: 0.3682666686321459
epoch: 80, train_batch_id: 1350, avg_cost: 3.8568127155303955
grad_norm: 0.2526736356498943, clipped: 0.2526736356498943
epoch: 80, train_batch_id: 1400, avg_cost: 3.821786880493164
grad_norm: 0.2416716930611025, clipped: 0.2416716930611025
epoch: 80, train_batch_id: 1450, avg_cost: 3.851815700531006
grad_norm: 0.27135712486715646, clipped: 0.27135712486715646
epoch: 80, train_batch_id: 1500, avg_cost: 3.8505725860595703
grad_norm: 0.4260925808543465, clipped: 0.4260925808543465
epoch: 80, train_batch_id: 1550, avg_cost: 3.835270881652832
grad_norm: 0.3316929985420863, clipped: 0.3316929985420863
epoch: 80, train_batch_id: 1600, avg_cost: 3.8420310020446777
grad_norm: 0.454448865732458, clipped: 0.454448865732458
epoch: 80, train_batch_id: 1650, avg_cost: 3.8286852836608887
grad_norm: 0.3214200299070157, clipped: 0.3214200299070157
epoch: 80, train_batch_id: 1700, avg_cost: 3.8633172512054443
grad_norm: 0.2935908809966404, clipped: 0.2935908809966404
epoch: 80, train_batch_id: 1750, avg_cost: 3.8232359886169434
grad_norm: 0.32002223230102644, clipped: 0.32002223230102644
epoch: 80, train_batch_id: 1800, avg_cost: 3.8408689498901367
grad_norm: 0.7684904985391986, clipped: 0.7684904985391986
epoch: 80, train_batch_id: 1850, avg_cost: 3.8568320274353027
grad_norm: 0.27195385553262236, clipped: 0.27195385553262236
epoch: 80, train_batch_id: 1900, avg_cost: 3.85443115234375
grad_norm: 0.47201498529063707, clipped: 0.47201498529063707
epoch: 80, train_batch_id: 1950, avg_cost: 3.8306994438171387
grad_norm: 0.2641735334528043, clipped: 0.2641735334528043
epoch: 80, train_batch_id: 2000, avg_cost: 3.8605918884277344
grad_norm: 0.31079486853969424, clipped: 0.31079486853969424
epoch: 80, train_batch_id: 2050, avg_cost: 3.86264705657959
grad_norm: 0.2737115152932327, clipped: 0.2737115152932327
epoch: 80, train_batch_id: 2100, avg_cost: 3.8506579399108887
grad_norm: 0.34311775803319616, clipped: 0.34311775803319616
epoch: 80, train_batch_id: 2150, avg_cost: 3.818058729171753
grad_norm: 0.3106874510102137, clipped: 0.3106874510102137
epoch: 80, train_batch_id: 2200, avg_cost: 3.8488025665283203
grad_norm: 0.3792209638489113, clipped: 0.3792209638489113
epoch: 80, train_batch_id: 2250, avg_cost: 3.8190529346466064
grad_norm: 0.6209975894771118, clipped: 0.6209975894771118
epoch: 80, train_batch_id: 2300, avg_cost: 3.8510799407958984
grad_norm: 0.23965096099275515, clipped: 0.23965096099275515
epoch: 80, train_batch_id: 2350, avg_cost: 3.8715710639953613
grad_norm: 0.5543287722733379, clipped: 0.5543287722733379
epoch: 80, train_batch_id: 2400, avg_cost: 3.850310802459717
grad_norm: 0.4364115430162617, clipped: 0.4364115430162617
epoch: 80, train_batch_id: 2450, avg_cost: 3.828809976577759
grad_norm: 0.3178781292966928, clipped: 0.3178781292966928
Finished epoch 80, took 00:05:26 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845973014831543 +- 0.0030992073006927967
Evaluating candidate model on evaluation dataset
Epoch 80 candidate mean 3.844733476638794, baseline epoch 74 mean 3.8441007137298584, difference 0.0006327629089355469
Start train epoch 81, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 81, train_batch_id: 0, avg_cost: 3.842639923095703
grad_norm: 0.3005569123102433, clipped: 0.3005569123102433
epoch: 81, train_batch_id: 50, avg_cost: 3.851357936859131
grad_norm: 0.3103517749978823, clipped: 0.3103517749978823
epoch: 81, train_batch_id: 100, avg_cost: 3.8453879356384277
grad_norm: 1.0175084577296727, clipped: 1.0
epoch: 81, train_batch_id: 150, avg_cost: 3.851881265640259
grad_norm: 0.2903605566049022, clipped: 0.2903605566049022
epoch: 81, train_batch_id: 200, avg_cost: 3.8502960205078125
grad_norm: 0.2833456917105907, clipped: 0.2833456917105907
epoch: 81, train_batch_id: 250, avg_cost: 3.870530128479004
grad_norm: 0.28234555452741317, clipped: 0.28234555452741317
epoch: 81, train_batch_id: 300, avg_cost: 3.8618247509002686
grad_norm: 0.2492926586171232, clipped: 0.2492926586171232
epoch: 81, train_batch_id: 350, avg_cost: 3.853529214859009
grad_norm: 0.4202377454113971, clipped: 0.4202377454113971
epoch: 81, train_batch_id: 400, avg_cost: 3.860548496246338
grad_norm: 0.22539603631387894, clipped: 0.22539603631387894
epoch: 81, train_batch_id: 450, avg_cost: 3.8386175632476807
grad_norm: 0.4193879022707383, clipped: 0.4193879022707383
epoch: 81, train_batch_id: 500, avg_cost: 3.8681933879852295
grad_norm: 0.3741862591902901, clipped: 0.3741862591902901
epoch: 81, train_batch_id: 550, avg_cost: 3.8395042419433594
grad_norm: 0.33287877506834557, clipped: 0.33287877506834557
epoch: 81, train_batch_id: 600, avg_cost: 3.840857744216919
grad_norm: 0.31721388289116365, clipped: 0.31721388289116365
epoch: 81, train_batch_id: 650, avg_cost: 3.856560230255127
grad_norm: 0.2828886156644535, clipped: 0.2828886156644535
epoch: 81, train_batch_id: 700, avg_cost: 3.861835479736328
grad_norm: 0.2534658813506529, clipped: 0.2534658813506529
epoch: 81, train_batch_id: 750, avg_cost: 3.8500051498413086
grad_norm: 0.19719533894333932, clipped: 0.19719533894333932
epoch: 81, train_batch_id: 800, avg_cost: 3.857226848602295
grad_norm: 0.3635303763397417, clipped: 0.3635303763397417
epoch: 81, train_batch_id: 850, avg_cost: 3.829488754272461
grad_norm: 0.35762714079051755, clipped: 0.35762714079051755
epoch: 81, train_batch_id: 900, avg_cost: 3.847878932952881
grad_norm: 0.2898832720960222, clipped: 0.2898832720960222
epoch: 81, train_batch_id: 950, avg_cost: 3.815162420272827
grad_norm: 0.24592167358393316, clipped: 0.24592167358393316
epoch: 81, train_batch_id: 1000, avg_cost: 3.8587496280670166
grad_norm: 0.34344758547339566, clipped: 0.34344758547339566
epoch: 81, train_batch_id: 1050, avg_cost: 3.832705020904541
grad_norm: 0.39869935951689106, clipped: 0.39869935951689106
epoch: 81, train_batch_id: 1100, avg_cost: 3.829280138015747
grad_norm: 0.6981338422148317, clipped: 0.6981338422148317
epoch: 81, train_batch_id: 1150, avg_cost: 3.851712942123413
grad_norm: 0.4053086775724231, clipped: 0.4053086775724231
epoch: 81, train_batch_id: 1200, avg_cost: 3.8181753158569336
grad_norm: 0.3249231434839365, clipped: 0.3249231434839365
epoch: 81, train_batch_id: 1250, avg_cost: 3.8488006591796875
grad_norm: 0.3911691346754188, clipped: 0.3911691346754188
epoch: 81, train_batch_id: 1300, avg_cost: 3.864532947540283
grad_norm: 0.5439351444872417, clipped: 0.5439351444872417
epoch: 81, train_batch_id: 1350, avg_cost: 3.8291897773742676
grad_norm: 0.34814491921668955, clipped: 0.34814491921668955
epoch: 81, train_batch_id: 1400, avg_cost: 3.850773572921753
grad_norm: 0.30752183674217426, clipped: 0.30752183674217426
epoch: 81, train_batch_id: 1450, avg_cost: 3.8244469165802
grad_norm: 0.20017851650221102, clipped: 0.20017851650221102
epoch: 81, train_batch_id: 1500, avg_cost: 3.8387670516967773
grad_norm: 0.4631795293997404, clipped: 0.4631795293997404
epoch: 81, train_batch_id: 1550, avg_cost: 3.851329803466797
grad_norm: 0.3568614745524909, clipped: 0.3568614745524909
epoch: 81, train_batch_id: 1600, avg_cost: 3.8486194610595703
grad_norm: 0.2494407193351943, clipped: 0.2494407193351943
epoch: 81, train_batch_id: 1650, avg_cost: 3.8557798862457275
grad_norm: 0.27278216745801964, clipped: 0.27278216745801964
epoch: 81, train_batch_id: 1700, avg_cost: 3.8651108741760254
grad_norm: 0.31451087892838464, clipped: 0.31451087892838464
epoch: 81, train_batch_id: 1750, avg_cost: 3.849987030029297
grad_norm: 0.3310256395486151, clipped: 0.3310256395486151
epoch: 81, train_batch_id: 1800, avg_cost: 3.827218532562256
grad_norm: 0.45959379477796025, clipped: 0.45959379477796025
epoch: 81, train_batch_id: 1850, avg_cost: 3.839271068572998
grad_norm: 0.2918680784044092, clipped: 0.2918680784044092
epoch: 81, train_batch_id: 1900, avg_cost: 3.826334238052368
grad_norm: 0.8535296850363524, clipped: 0.8535296850363524
epoch: 81, train_batch_id: 1950, avg_cost: 3.8609557151794434
grad_norm: 0.2767337059950162, clipped: 0.2767337059950162
epoch: 81, train_batch_id: 2000, avg_cost: 3.862790584564209
grad_norm: 0.31427563559207394, clipped: 0.31427563559207394
epoch: 81, train_batch_id: 2050, avg_cost: 3.8601367473602295
grad_norm: 0.28120625043273717, clipped: 0.28120625043273717
epoch: 81, train_batch_id: 2100, avg_cost: 3.8579978942871094
grad_norm: 0.26281549288167244, clipped: 0.26281549288167244
epoch: 81, train_batch_id: 2150, avg_cost: 3.8447296619415283
grad_norm: 0.2829973772485224, clipped: 0.2829973772485224
epoch: 81, train_batch_id: 2200, avg_cost: 3.8458313941955566
grad_norm: 0.3758438911525429, clipped: 0.3758438911525429
epoch: 81, train_batch_id: 2250, avg_cost: 3.832642078399658
grad_norm: 0.2624144573081963, clipped: 0.2624144573081963
epoch: 81, train_batch_id: 2300, avg_cost: 3.832968235015869
grad_norm: 0.3049462619989895, clipped: 0.3049462619989895
epoch: 81, train_batch_id: 2350, avg_cost: 3.8346009254455566
grad_norm: 0.30677600471267563, clipped: 0.30677600471267563
epoch: 81, train_batch_id: 2400, avg_cost: 3.8471240997314453
grad_norm: 0.2106559447638192, clipped: 0.2106559447638192
epoch: 81, train_batch_id: 2450, avg_cost: 3.8447794914245605
grad_norm: 0.23985858947586194, clipped: 0.23985858947586194
Finished epoch 81, took 00:05:25 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845806360244751 +- 0.0030978750437498093
Evaluating candidate model on evaluation dataset
Epoch 81 candidate mean 3.8443074226379395, baseline epoch 74 mean 3.8441007137298584, difference 0.0002067089080810547
Start train epoch 82, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 82, train_batch_id: 0, avg_cost: 3.8251399993896484
grad_norm: 0.3103629454718886, clipped: 0.3103629454718886
epoch: 82, train_batch_id: 50, avg_cost: 3.835191249847412
grad_norm: 0.273180523499845, clipped: 0.273180523499845
epoch: 82, train_batch_id: 100, avg_cost: 3.8498926162719727
grad_norm: 0.41287697448533395, clipped: 0.41287697448533395
epoch: 82, train_batch_id: 150, avg_cost: 3.8249573707580566
grad_norm: 0.22787841383126511, clipped: 0.22787841383126511
epoch: 82, train_batch_id: 200, avg_cost: 3.8508057594299316
grad_norm: 0.27039534615832483, clipped: 0.27039534615832483
epoch: 82, train_batch_id: 250, avg_cost: 3.8263449668884277
grad_norm: 0.39878632970750777, clipped: 0.39878632970750777
epoch: 82, train_batch_id: 300, avg_cost: 3.84566068649292
grad_norm: 0.3579196328217752, clipped: 0.3579196328217752
epoch: 82, train_batch_id: 350, avg_cost: 3.8508756160736084
grad_norm: 0.336907702422753, clipped: 0.336907702422753
epoch: 82, train_batch_id: 400, avg_cost: 3.833277702331543
grad_norm: 0.29456160052530994, clipped: 0.29456160052530994
epoch: 82, train_batch_id: 450, avg_cost: 3.8390750885009766
grad_norm: 0.3008784050482087, clipped: 0.3008784050482087
epoch: 82, train_batch_id: 500, avg_cost: 3.8573930263519287
grad_norm: 0.3041098898450778, clipped: 0.3041098898450778
epoch: 82, train_batch_id: 550, avg_cost: 3.824889659881592
grad_norm: 0.5603484710461417, clipped: 0.5603484710461417
epoch: 82, train_batch_id: 600, avg_cost: 3.831012725830078
grad_norm: 0.4077384515933367, clipped: 0.4077384515933367
epoch: 82, train_batch_id: 650, avg_cost: 3.8497159481048584
grad_norm: 0.23119386523310687, clipped: 0.23119386523310687
epoch: 82, train_batch_id: 700, avg_cost: 3.8525314331054688
grad_norm: 0.23032544565274893, clipped: 0.23032544565274893
epoch: 82, train_batch_id: 750, avg_cost: 3.8323826789855957
grad_norm: 0.38206971807250273, clipped: 0.38206971807250273
epoch: 82, train_batch_id: 800, avg_cost: 3.8269662857055664
grad_norm: 0.286830737183903, clipped: 0.286830737183903
epoch: 82, train_batch_id: 850, avg_cost: 3.835749864578247
grad_norm: 0.2552541273244372, clipped: 0.2552541273244372
epoch: 82, train_batch_id: 900, avg_cost: 3.8451874256134033
grad_norm: 0.27750672576802027, clipped: 0.27750672576802027
epoch: 82, train_batch_id: 950, avg_cost: 3.8352842330932617
grad_norm: 0.5081969621756883, clipped: 0.5081969621756883
epoch: 82, train_batch_id: 1000, avg_cost: 3.85383939743042
grad_norm: 0.39115556254921957, clipped: 0.39115556254921957
epoch: 82, train_batch_id: 1050, avg_cost: 3.8507394790649414
grad_norm: 0.35763600634023623, clipped: 0.35763600634023623
epoch: 82, train_batch_id: 1100, avg_cost: 3.845036268234253
grad_norm: 0.334274205012521, clipped: 0.334274205012521
epoch: 82, train_batch_id: 1150, avg_cost: 3.8637256622314453
grad_norm: 0.47062912009393454, clipped: 0.47062912009393454
epoch: 82, train_batch_id: 1200, avg_cost: 3.832697868347168
grad_norm: 0.39048876225026036, clipped: 0.39048876225026036
epoch: 82, train_batch_id: 1250, avg_cost: 3.8573412895202637
grad_norm: 0.3088344163325219, clipped: 0.3088344163325219
epoch: 82, train_batch_id: 1300, avg_cost: 3.8394722938537598
grad_norm: 0.3352969532991526, clipped: 0.3352969532991526
epoch: 82, train_batch_id: 1350, avg_cost: 3.8375983238220215
grad_norm: 0.3273470825884829, clipped: 0.3273470825884829
epoch: 82, train_batch_id: 1400, avg_cost: 3.843494176864624
grad_norm: 0.3478821791112221, clipped: 0.3478821791112221
epoch: 82, train_batch_id: 1450, avg_cost: 3.8279948234558105
grad_norm: 0.2939846984855179, clipped: 0.2939846984855179
epoch: 82, train_batch_id: 1500, avg_cost: 3.8667831420898438
grad_norm: 0.23447189733697477, clipped: 0.23447189733697477
epoch: 82, train_batch_id: 1550, avg_cost: 3.8334498405456543
grad_norm: 0.3180322158531051, clipped: 0.3180322158531051
epoch: 82, train_batch_id: 1600, avg_cost: 3.831963300704956
grad_norm: 0.20247650500718475, clipped: 0.20247650500718475
epoch: 82, train_batch_id: 1650, avg_cost: 3.8247921466827393
grad_norm: 0.4054723868908634, clipped: 0.4054723868908634
epoch: 82, train_batch_id: 1700, avg_cost: 3.846189022064209
grad_norm: 0.3782586879305728, clipped: 0.3782586879305728
epoch: 82, train_batch_id: 1750, avg_cost: 3.857412576675415
grad_norm: 0.36328812182457193, clipped: 0.36328812182457193
epoch: 82, train_batch_id: 1800, avg_cost: 3.862332582473755
grad_norm: 0.19857389071416226, clipped: 0.19857389071416226
epoch: 82, train_batch_id: 1850, avg_cost: 3.8283729553222656
grad_norm: 0.3518330373411405, clipped: 0.3518330373411405
epoch: 82, train_batch_id: 1900, avg_cost: 3.8369126319885254
grad_norm: 0.25084339974657355, clipped: 0.25084339974657355
epoch: 82, train_batch_id: 1950, avg_cost: 3.857663631439209
grad_norm: 0.5458795611377816, clipped: 0.5458795611377816
epoch: 82, train_batch_id: 2000, avg_cost: 3.863827705383301
grad_norm: 0.36590088638429513, clipped: 0.36590088638429513
epoch: 82, train_batch_id: 2050, avg_cost: 3.8548316955566406
grad_norm: 0.309354638762794, clipped: 0.309354638762794
epoch: 82, train_batch_id: 2100, avg_cost: 3.834023952484131
grad_norm: 0.9210376903413973, clipped: 0.9210376903413973
epoch: 82, train_batch_id: 2150, avg_cost: 3.8347549438476562
grad_norm: 0.27131919995631, clipped: 0.27131919995631
epoch: 82, train_batch_id: 2200, avg_cost: 3.848659038543701
grad_norm: 0.22618523171311514, clipped: 0.22618523171311514
epoch: 82, train_batch_id: 2250, avg_cost: 3.8292882442474365
grad_norm: 0.36440781079291124, clipped: 0.36440781079291124
epoch: 82, train_batch_id: 2300, avg_cost: 3.8364901542663574
grad_norm: 0.2777132258787098, clipped: 0.2777132258787098
epoch: 82, train_batch_id: 2350, avg_cost: 3.8353219032287598
grad_norm: 0.3887263061051376, clipped: 0.3887263061051376
epoch: 82, train_batch_id: 2400, avg_cost: 3.822736978530884
grad_norm: 0.27232888071012656, clipped: 0.27232888071012656
epoch: 82, train_batch_id: 2450, avg_cost: 3.84200382232666
grad_norm: 0.33903065047468484, clipped: 0.33903065047468484
Finished epoch 82, took 00:05:25 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8450539112091064 +- 0.003098146291449666
Evaluating candidate model on evaluation dataset
Epoch 82 candidate mean 3.843754768371582, baseline epoch 74 mean 3.8441007137298584, difference -0.0003459453582763672
p-value: 0.09282997966462603
Start train epoch 83, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 83, train_batch_id: 0, avg_cost: 3.821840286254883
grad_norm: 0.2334873451814045, clipped: 0.2334873451814045
epoch: 83, train_batch_id: 50, avg_cost: 3.84768009185791
grad_norm: 0.23120296001409488, clipped: 0.23120296001409488
epoch: 83, train_batch_id: 100, avg_cost: 3.866957426071167
grad_norm: 0.32926577689706144, clipped: 0.32926577689706144
epoch: 83, train_batch_id: 150, avg_cost: 3.8432564735412598
grad_norm: 0.3224058488667696, clipped: 0.3224058488667696
epoch: 83, train_batch_id: 200, avg_cost: 3.8647806644439697
grad_norm: 0.23930646675848297, clipped: 0.23930646675848297
epoch: 83, train_batch_id: 250, avg_cost: 3.8428802490234375
grad_norm: 0.6466922523055038, clipped: 0.6466922523055038
epoch: 83, train_batch_id: 300, avg_cost: 3.850543975830078
grad_norm: 0.2503308173216752, clipped: 0.2503308173216752
epoch: 83, train_batch_id: 350, avg_cost: 3.840449094772339
grad_norm: 0.3396134359796304, clipped: 0.3396134359796304
epoch: 83, train_batch_id: 400, avg_cost: 3.8636202812194824
grad_norm: 0.22943480158717075, clipped: 0.22943480158717075
epoch: 83, train_batch_id: 450, avg_cost: 3.787874221801758
grad_norm: 0.3082269263826016, clipped: 0.3082269263826016
epoch: 83, train_batch_id: 500, avg_cost: 3.863880157470703
grad_norm: 0.32806390424928716, clipped: 0.32806390424928716
epoch: 83, train_batch_id: 550, avg_cost: 3.8445637226104736
grad_norm: 0.3386718731794603, clipped: 0.3386718731794603
epoch: 83, train_batch_id: 600, avg_cost: 3.8467023372650146
grad_norm: 0.25281944711176313, clipped: 0.25281944711176313
epoch: 83, train_batch_id: 650, avg_cost: 3.848403215408325
grad_norm: 0.45005181525400534, clipped: 0.45005181525400534
epoch: 83, train_batch_id: 700, avg_cost: 3.8496665954589844
grad_norm: 0.46241883158798186, clipped: 0.46241883158798186
epoch: 83, train_batch_id: 750, avg_cost: 3.854440689086914
grad_norm: 0.6950200476139389, clipped: 0.6950200476139389
epoch: 83, train_batch_id: 800, avg_cost: 3.8360962867736816
grad_norm: 0.45861258841555347, clipped: 0.45861258841555347
epoch: 83, train_batch_id: 850, avg_cost: 3.8316071033477783
grad_norm: 0.4305109934536287, clipped: 0.4305109934536287
epoch: 83, train_batch_id: 900, avg_cost: 3.8473949432373047
grad_norm: 0.3517719626601916, clipped: 0.3517719626601916
epoch: 83, train_batch_id: 950, avg_cost: 3.86086106300354
grad_norm: 0.3244109472531199, clipped: 0.3244109472531199
epoch: 83, train_batch_id: 1000, avg_cost: 3.8811395168304443
grad_norm: 0.35512537566847363, clipped: 0.35512537566847363
epoch: 83, train_batch_id: 1050, avg_cost: 3.8411972522735596
grad_norm: 0.5197382865299817, clipped: 0.5197382865299817
epoch: 83, train_batch_id: 1100, avg_cost: 3.846546173095703
grad_norm: 0.29999473756257633, clipped: 0.29999473756257633
epoch: 83, train_batch_id: 1150, avg_cost: 3.8617875576019287
grad_norm: 0.2967913166636721, clipped: 0.2967913166636721
epoch: 83, train_batch_id: 1200, avg_cost: 3.844757080078125
grad_norm: 0.22383011381718232, clipped: 0.22383011381718232
epoch: 83, train_batch_id: 1250, avg_cost: 3.8548264503479004
grad_norm: 0.27773541355120257, clipped: 0.27773541355120257
epoch: 83, train_batch_id: 1300, avg_cost: 3.840482711791992
grad_norm: 0.39322965891250994, clipped: 0.39322965891250994
epoch: 83, train_batch_id: 1350, avg_cost: 3.855181932449341
grad_norm: 0.39895707168359157, clipped: 0.39895707168359157
epoch: 83, train_batch_id: 1400, avg_cost: 3.8558855056762695
grad_norm: 0.2321646121896173, clipped: 0.2321646121896173
epoch: 83, train_batch_id: 1450, avg_cost: 3.8444247245788574
grad_norm: 0.30110281260704663, clipped: 0.30110281260704663
epoch: 83, train_batch_id: 1500, avg_cost: 3.8601508140563965
grad_norm: 0.3724864586169217, clipped: 0.3724864586169217
epoch: 83, train_batch_id: 1550, avg_cost: 3.842416524887085
grad_norm: 0.357573314878275, clipped: 0.357573314878275
epoch: 83, train_batch_id: 1600, avg_cost: 3.84006404876709
grad_norm: 0.465480585531158, clipped: 0.465480585531158
epoch: 83, train_batch_id: 1650, avg_cost: 3.8152709007263184
grad_norm: 0.25574539455328843, clipped: 0.25574539455328843
epoch: 83, train_batch_id: 1700, avg_cost: 3.8216452598571777
grad_norm: 0.30589489338065506, clipped: 0.30589489338065506
epoch: 83, train_batch_id: 1750, avg_cost: 3.8545894622802734
grad_norm: 0.24127011284913769, clipped: 0.24127011284913769
epoch: 83, train_batch_id: 1800, avg_cost: 3.8647751808166504
grad_norm: 0.32765821711705073, clipped: 0.32765821711705073
epoch: 83, train_batch_id: 1850, avg_cost: 3.8559682369232178
grad_norm: 0.2932514301353314, clipped: 0.2932514301353314
epoch: 83, train_batch_id: 1900, avg_cost: 3.858630657196045
grad_norm: 0.36906786232484246, clipped: 0.36906786232484246
epoch: 83, train_batch_id: 1950, avg_cost: 3.8406546115875244
grad_norm: 0.21215481792171487, clipped: 0.21215481792171487
epoch: 83, train_batch_id: 2000, avg_cost: 3.8375253677368164
grad_norm: 0.28627692482076733, clipped: 0.28627692482076733
epoch: 83, train_batch_id: 2050, avg_cost: 3.845309257507324
grad_norm: 0.2744275721624865, clipped: 0.2744275721624865
epoch: 83, train_batch_id: 2100, avg_cost: 3.832022190093994
grad_norm: 0.2865866292385415, clipped: 0.2865866292385415
epoch: 83, train_batch_id: 2150, avg_cost: 3.832970380783081
grad_norm: 0.3760229549094223, clipped: 0.3760229549094223
epoch: 83, train_batch_id: 2200, avg_cost: 3.8408291339874268
grad_norm: 0.2839017730857794, clipped: 0.2839017730857794
epoch: 83, train_batch_id: 2250, avg_cost: 3.860368251800537
grad_norm: 0.3473187505271712, clipped: 0.3473187505271712
epoch: 83, train_batch_id: 2300, avg_cost: 3.837434768676758
grad_norm: 0.309196252585742, clipped: 0.309196252585742
epoch: 83, train_batch_id: 2350, avg_cost: 3.8519368171691895
grad_norm: 0.3711394648873591, clipped: 0.3711394648873591
epoch: 83, train_batch_id: 2400, avg_cost: 3.8511147499084473
grad_norm: 0.44857296660289225, clipped: 0.44857296660289225
epoch: 83, train_batch_id: 2450, avg_cost: 3.8708386421203613
grad_norm: 0.25815974221008303, clipped: 0.25815974221008303
Finished epoch 83, took 00:05:30 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845695734024048 +- 0.0030985602643340826
Evaluating candidate model on evaluation dataset
Epoch 83 candidate mean 3.844341516494751, baseline epoch 74 mean 3.8441007137298584, difference 0.00024080276489257812
Start train epoch 84, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 84, train_batch_id: 0, avg_cost: 3.837367296218872
grad_norm: 0.17122321729364998, clipped: 0.17122321729364998
epoch: 84, train_batch_id: 50, avg_cost: 3.8452014923095703
grad_norm: 0.3654516866855872, clipped: 0.3654516866855872
epoch: 84, train_batch_id: 100, avg_cost: 3.835958480834961
grad_norm: 0.3531307806833277, clipped: 0.3531307806833277
epoch: 84, train_batch_id: 150, avg_cost: 3.8693270683288574
grad_norm: 0.39787545214586917, clipped: 0.39787545214586917
epoch: 84, train_batch_id: 200, avg_cost: 3.8396973609924316
grad_norm: 0.27142174572410654, clipped: 0.27142174572410654
epoch: 84, train_batch_id: 250, avg_cost: 3.8440463542938232
grad_norm: 0.31593820671944195, clipped: 0.31593820671944195
epoch: 84, train_batch_id: 300, avg_cost: 3.8545079231262207
grad_norm: 0.35291351365531015, clipped: 0.35291351365531015
epoch: 84, train_batch_id: 350, avg_cost: 3.8503284454345703
grad_norm: 0.2892006380925578, clipped: 0.2892006380925578
epoch: 84, train_batch_id: 400, avg_cost: 3.850905656814575
grad_norm: 0.22737240830134192, clipped: 0.22737240830134192
epoch: 84, train_batch_id: 450, avg_cost: 3.8347830772399902
grad_norm: 0.26501522615385026, clipped: 0.26501522615385026
epoch: 84, train_batch_id: 500, avg_cost: 3.844649076461792
grad_norm: 0.3726074202211407, clipped: 0.3726074202211407
epoch: 84, train_batch_id: 550, avg_cost: 3.8346288204193115
grad_norm: 0.5602860249812417, clipped: 0.5602860249812417
epoch: 84, train_batch_id: 600, avg_cost: 3.848325252532959
grad_norm: 0.2899430138679445, clipped: 0.2899430138679445
epoch: 84, train_batch_id: 650, avg_cost: 3.87345027923584
grad_norm: 0.7478701949454171, clipped: 0.7478701949454171
epoch: 84, train_batch_id: 700, avg_cost: 3.844646453857422
grad_norm: 0.9418179997538557, clipped: 0.9418179997538557
epoch: 84, train_batch_id: 750, avg_cost: 3.835573673248291
grad_norm: 0.41787971409132574, clipped: 0.41787971409132574
epoch: 84, train_batch_id: 800, avg_cost: 3.8187479972839355
grad_norm: 0.3560456550671649, clipped: 0.3560456550671649
epoch: 84, train_batch_id: 850, avg_cost: 3.8698697090148926
grad_norm: 0.3621741573457362, clipped: 0.3621741573457362
epoch: 84, train_batch_id: 900, avg_cost: 3.871880531311035
grad_norm: 0.6207531051960185, clipped: 0.6207531051960185
epoch: 84, train_batch_id: 950, avg_cost: 3.8522439002990723
grad_norm: 0.45244817491342093, clipped: 0.45244817491342093
epoch: 84, train_batch_id: 1000, avg_cost: 3.8442869186401367
grad_norm: 0.542142060874547, clipped: 0.542142060874547
epoch: 84, train_batch_id: 1050, avg_cost: 3.861579179763794
grad_norm: 0.2747679037718216, clipped: 0.2747679037718216
epoch: 84, train_batch_id: 1100, avg_cost: 3.8427064418792725
grad_norm: 0.25639446439229485, clipped: 0.25639446439229485
epoch: 84, train_batch_id: 1150, avg_cost: 3.8694872856140137
grad_norm: 0.26055807434956896, clipped: 0.26055807434956896
epoch: 84, train_batch_id: 1200, avg_cost: 3.832885265350342
grad_norm: 0.2770369692491358, clipped: 0.2770369692491358
epoch: 84, train_batch_id: 1250, avg_cost: 3.8576130867004395
grad_norm: 0.3702384095742853, clipped: 0.3702384095742853
epoch: 84, train_batch_id: 1300, avg_cost: 3.8324289321899414
grad_norm: 0.31403679392173606, clipped: 0.31403679392173606
epoch: 84, train_batch_id: 1350, avg_cost: 3.853126049041748
grad_norm: 0.250235812295973, clipped: 0.250235812295973
epoch: 84, train_batch_id: 1400, avg_cost: 3.831874370574951
grad_norm: 0.3830702509377031, clipped: 0.3830702509377031
epoch: 84, train_batch_id: 1450, avg_cost: 3.839712619781494
grad_norm: 0.32866255996415444, clipped: 0.32866255996415444
epoch: 84, train_batch_id: 1500, avg_cost: 3.832000255584717
grad_norm: 0.31019216647583614, clipped: 0.31019216647583614
epoch: 84, train_batch_id: 1550, avg_cost: 3.8455491065979004
grad_norm: 0.28277591289636356, clipped: 0.28277591289636356
epoch: 84, train_batch_id: 1600, avg_cost: 3.8532557487487793
grad_norm: 0.4057354009830728, clipped: 0.4057354009830728
epoch: 84, train_batch_id: 1650, avg_cost: 3.8365368843078613
grad_norm: 0.9741033890846886, clipped: 0.9741033890846886
epoch: 84, train_batch_id: 1700, avg_cost: 3.8373661041259766
grad_norm: 0.34894773417807046, clipped: 0.34894773417807046
epoch: 84, train_batch_id: 1750, avg_cost: 3.867595672607422
grad_norm: 0.28164358801769374, clipped: 0.28164358801769374
epoch: 84, train_batch_id: 1800, avg_cost: 3.845064163208008
grad_norm: 0.2688574858939139, clipped: 0.2688574858939139
epoch: 84, train_batch_id: 1850, avg_cost: 3.8623294830322266
grad_norm: 0.37514918453875085, clipped: 0.37514918453875085
epoch: 84, train_batch_id: 1900, avg_cost: 3.8253977298736572
grad_norm: 0.26550655712114524, clipped: 0.26550655712114524
epoch: 84, train_batch_id: 1950, avg_cost: 3.8303256034851074
grad_norm: 0.3515825253248957, clipped: 0.3515825253248957
epoch: 84, train_batch_id: 2000, avg_cost: 3.849109649658203
grad_norm: 0.354905672830724, clipped: 0.354905672830724
epoch: 84, train_batch_id: 2050, avg_cost: 3.847888946533203
grad_norm: 0.5701562873498022, clipped: 0.5701562873498022
epoch: 84, train_batch_id: 2100, avg_cost: 3.8396248817443848
grad_norm: 0.28483800971574197, clipped: 0.28483800971574197
epoch: 84, train_batch_id: 2150, avg_cost: 3.8561363220214844
grad_norm: 0.3770199011260396, clipped: 0.3770199011260396
epoch: 84, train_batch_id: 2200, avg_cost: 3.8616421222686768
grad_norm: 0.6454704194725511, clipped: 0.6454704194725511
epoch: 84, train_batch_id: 2250, avg_cost: 3.854727268218994
grad_norm: 0.2730331901660456, clipped: 0.2730331901660456
epoch: 84, train_batch_id: 2300, avg_cost: 3.8523664474487305
grad_norm: 0.5868334547698024, clipped: 0.5868334547698024
epoch: 84, train_batch_id: 2350, avg_cost: 3.859977960586548
grad_norm: 0.19711133963981547, clipped: 0.19711133963981547
epoch: 84, train_batch_id: 2400, avg_cost: 3.822753667831421
grad_norm: 0.3257023686080708, clipped: 0.3257023686080708
epoch: 84, train_batch_id: 2450, avg_cost: 3.872636318206787
grad_norm: 0.30342580120839047, clipped: 0.30342580120839047
Finished epoch 84, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845365524291992 +- 0.003094367915764451
Evaluating candidate model on evaluation dataset
Epoch 84 candidate mean 3.8443429470062256, baseline epoch 74 mean 3.8441007137298584, difference 0.0002422332763671875
Start train epoch 85, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 85, train_batch_id: 0, avg_cost: 3.839169979095459
grad_norm: 0.5695504203930138, clipped: 0.5695504203930138
epoch: 85, train_batch_id: 50, avg_cost: 3.861610174179077
grad_norm: 0.2784063217413997, clipped: 0.2784063217413997
epoch: 85, train_batch_id: 100, avg_cost: 3.8384084701538086
grad_norm: 0.25311177238313476, clipped: 0.25311177238313476
epoch: 85, train_batch_id: 150, avg_cost: 3.8482534885406494
grad_norm: 0.2762106539717871, clipped: 0.2762106539717871
epoch: 85, train_batch_id: 200, avg_cost: 3.845672130584717
grad_norm: 0.265038088659392, clipped: 0.265038088659392
epoch: 85, train_batch_id: 250, avg_cost: 3.8467469215393066
grad_norm: 0.36920810466404, clipped: 0.36920810466404
epoch: 85, train_batch_id: 300, avg_cost: 3.8550658226013184
grad_norm: 0.475577478589381, clipped: 0.475577478589381
epoch: 85, train_batch_id: 350, avg_cost: 3.8460144996643066
grad_norm: 0.26997540545024623, clipped: 0.26997540545024623
epoch: 85, train_batch_id: 400, avg_cost: 3.848654270172119
grad_norm: 0.3214769736419046, clipped: 0.3214769736419046
epoch: 85, train_batch_id: 450, avg_cost: 3.873256206512451
grad_norm: 0.49040964061719855, clipped: 0.49040964061719855
epoch: 85, train_batch_id: 500, avg_cost: 3.8401107788085938
grad_norm: 0.27584831868057336, clipped: 0.27584831868057336
epoch: 85, train_batch_id: 550, avg_cost: 3.810401439666748
grad_norm: 0.3510370791194184, clipped: 0.3510370791194184
epoch: 85, train_batch_id: 600, avg_cost: 3.8151049613952637
grad_norm: 0.28085858690072696, clipped: 0.28085858690072696
epoch: 85, train_batch_id: 650, avg_cost: 3.838942050933838
grad_norm: 0.46861825618058456, clipped: 0.46861825618058456
epoch: 85, train_batch_id: 700, avg_cost: 3.8624114990234375
grad_norm: 0.247546842028906, clipped: 0.247546842028906
epoch: 85, train_batch_id: 750, avg_cost: 3.8661561012268066
grad_norm: 0.35123485324261533, clipped: 0.35123485324261533
epoch: 85, train_batch_id: 800, avg_cost: 3.836841106414795
grad_norm: 0.3164608079143746, clipped: 0.3164608079143746
epoch: 85, train_batch_id: 850, avg_cost: 3.8573930263519287
grad_norm: 0.27757228794605093, clipped: 0.27757228794605093
epoch: 85, train_batch_id: 900, avg_cost: 3.844756603240967
grad_norm: 0.2281300617918648, clipped: 0.2281300617918648
epoch: 85, train_batch_id: 950, avg_cost: 3.846799612045288
grad_norm: 0.29587821435759404, clipped: 0.29587821435759404
epoch: 85, train_batch_id: 1000, avg_cost: 3.864942789077759
grad_norm: 0.5282138448985911, clipped: 0.5282138448985911
epoch: 85, train_batch_id: 1050, avg_cost: 3.8506851196289062
grad_norm: 0.39566116504911664, clipped: 0.39566116504911664
epoch: 85, train_batch_id: 1100, avg_cost: 3.829055070877075
grad_norm: 0.2932744941408673, clipped: 0.2932744941408673
epoch: 85, train_batch_id: 1150, avg_cost: 3.8256828784942627
grad_norm: 0.48091207011230375, clipped: 0.48091207011230375
epoch: 85, train_batch_id: 1200, avg_cost: 3.8835408687591553
grad_norm: 0.3295788513695391, clipped: 0.3295788513695391
epoch: 85, train_batch_id: 1250, avg_cost: 3.8341736793518066
grad_norm: 0.39999957223241916, clipped: 0.39999957223241916
epoch: 85, train_batch_id: 1300, avg_cost: 3.844276189804077
grad_norm: 0.30608547075972414, clipped: 0.30608547075972414
epoch: 85, train_batch_id: 1350, avg_cost: 3.8318090438842773
grad_norm: 0.1901837357835362, clipped: 0.1901837357835362
epoch: 85, train_batch_id: 1400, avg_cost: 3.850599765777588
grad_norm: 0.3000950780186988, clipped: 0.3000950780186988
epoch: 85, train_batch_id: 1450, avg_cost: 3.8371424674987793
grad_norm: 0.28327817760520685, clipped: 0.28327817760520685
epoch: 85, train_batch_id: 1500, avg_cost: 3.857010841369629
grad_norm: 0.295460108010472, clipped: 0.295460108010472
epoch: 85, train_batch_id: 1550, avg_cost: 3.8472440242767334
grad_norm: 0.42749907630587325, clipped: 0.42749907630587325
epoch: 85, train_batch_id: 1600, avg_cost: 3.858691692352295
grad_norm: 0.26678942715001325, clipped: 0.26678942715001325
epoch: 85, train_batch_id: 1650, avg_cost: 3.8268651962280273
grad_norm: 0.24850261096514498, clipped: 0.24850261096514498
epoch: 85, train_batch_id: 1700, avg_cost: 3.8353488445281982
grad_norm: 0.3802517785263957, clipped: 0.3802517785263957
epoch: 85, train_batch_id: 1750, avg_cost: 3.8522541522979736
grad_norm: 0.5371515342820892, clipped: 0.5371515342820892
epoch: 85, train_batch_id: 1800, avg_cost: 3.848968029022217
grad_norm: 0.2469244492697337, clipped: 0.2469244492697337
epoch: 85, train_batch_id: 1850, avg_cost: 3.8397529125213623
grad_norm: 0.34323167664741244, clipped: 0.34323167664741244
epoch: 85, train_batch_id: 1900, avg_cost: 3.831108570098877
grad_norm: 0.3755500571190792, clipped: 0.3755500571190792
epoch: 85, train_batch_id: 1950, avg_cost: 3.8473308086395264
grad_norm: 0.4093013646445704, clipped: 0.4093013646445704
epoch: 85, train_batch_id: 2000, avg_cost: 3.8178718090057373
grad_norm: 0.2544864155482767, clipped: 0.2544864155482767
epoch: 85, train_batch_id: 2050, avg_cost: 3.8427891731262207
grad_norm: 0.6445053248749724, clipped: 0.6445053248749724
epoch: 85, train_batch_id: 2100, avg_cost: 3.8495311737060547
grad_norm: 0.2795919381030439, clipped: 0.2795919381030439
epoch: 85, train_batch_id: 2150, avg_cost: 3.8368940353393555
grad_norm: 0.26550204238302744, clipped: 0.26550204238302744
epoch: 85, train_batch_id: 2200, avg_cost: 3.8381552696228027
grad_norm: 0.2671680313390225, clipped: 0.2671680313390225
epoch: 85, train_batch_id: 2250, avg_cost: 3.8490238189697266
grad_norm: 0.3248004684970374, clipped: 0.3248004684970374
epoch: 85, train_batch_id: 2300, avg_cost: 3.843858242034912
grad_norm: 0.21862810105248856, clipped: 0.21862810105248856
epoch: 85, train_batch_id: 2350, avg_cost: 3.8149635791778564
grad_norm: 0.2942304321247433, clipped: 0.2942304321247433
epoch: 85, train_batch_id: 2400, avg_cost: 3.8591954708099365
grad_norm: 0.2363203730811024, clipped: 0.2363203730811024
epoch: 85, train_batch_id: 2450, avg_cost: 3.8750457763671875
grad_norm: 0.6931234224203473, clipped: 0.6931234224203473
Finished epoch 85, took 00:05:29 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8464598655700684 +- 0.003106300253421068
Evaluating candidate model on evaluation dataset
Epoch 85 candidate mean 3.8447694778442383, baseline epoch 74 mean 3.8441007137298584, difference 0.0006687641143798828
Start train epoch 86, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 86, train_batch_id: 0, avg_cost: 3.861642837524414
grad_norm: 0.44301059138049204, clipped: 0.44301059138049204
epoch: 86, train_batch_id: 50, avg_cost: 3.8564929962158203
grad_norm: 0.3449699900734456, clipped: 0.3449699900734456
epoch: 86, train_batch_id: 100, avg_cost: 3.851081371307373
grad_norm: 0.2756788190760756, clipped: 0.2756788190760756
epoch: 86, train_batch_id: 150, avg_cost: 3.8382225036621094
grad_norm: 0.25915621940520206, clipped: 0.25915621940520206
epoch: 86, train_batch_id: 200, avg_cost: 3.8425943851470947
grad_norm: 0.3397637758288599, clipped: 0.3397637758288599
epoch: 86, train_batch_id: 250, avg_cost: 3.8511390686035156
grad_norm: 0.470703987446505, clipped: 0.470703987446505
epoch: 86, train_batch_id: 300, avg_cost: 3.850921154022217
grad_norm: 0.32288709941416355, clipped: 0.32288709941416355
epoch: 86, train_batch_id: 350, avg_cost: 3.8523197174072266
grad_norm: 0.25442690389221506, clipped: 0.25442690389221506
epoch: 86, train_batch_id: 400, avg_cost: 3.837270736694336
grad_norm: 0.5165240414229723, clipped: 0.5165240414229723
epoch: 86, train_batch_id: 450, avg_cost: 3.8521463871002197
grad_norm: 0.3326831069852605, clipped: 0.3326831069852605
epoch: 86, train_batch_id: 500, avg_cost: 3.8413004875183105
grad_norm: 0.27430739365571033, clipped: 0.27430739365571033
epoch: 86, train_batch_id: 550, avg_cost: 3.8367953300476074
grad_norm: 0.3130066806144459, clipped: 0.3130066806144459
epoch: 86, train_batch_id: 600, avg_cost: 3.851632595062256
grad_norm: 0.3475096771355096, clipped: 0.3475096771355096
epoch: 86, train_batch_id: 650, avg_cost: 3.8499717712402344
grad_norm: 0.43075378644395684, clipped: 0.43075378644395684
epoch: 86, train_batch_id: 700, avg_cost: 3.808460235595703
grad_norm: 0.24484206922525853, clipped: 0.24484206922525853
epoch: 86, train_batch_id: 750, avg_cost: 3.8496322631835938
grad_norm: 0.3227036664951359, clipped: 0.3227036664951359
epoch: 86, train_batch_id: 800, avg_cost: 3.839940309524536
grad_norm: 0.24770715427381612, clipped: 0.24770715427381612
epoch: 86, train_batch_id: 850, avg_cost: 3.835214853286743
grad_norm: 0.23194176748357342, clipped: 0.23194176748357342
epoch: 86, train_batch_id: 900, avg_cost: 3.8446004390716553
grad_norm: 0.29312284502868546, clipped: 0.29312284502868546
epoch: 86, train_batch_id: 950, avg_cost: 3.8530144691467285
grad_norm: 0.2158619154683458, clipped: 0.2158619154683458
epoch: 86, train_batch_id: 1000, avg_cost: 3.8377230167388916
grad_norm: 0.7511484976200593, clipped: 0.7511484976200593
epoch: 86, train_batch_id: 1050, avg_cost: 3.866919755935669
grad_norm: 0.24457033879536022, clipped: 0.24457033879536022
epoch: 86, train_batch_id: 1100, avg_cost: 3.8133034706115723
grad_norm: 0.1919576478018677, clipped: 0.1919576478018677
epoch: 86, train_batch_id: 1150, avg_cost: 3.857844829559326
grad_norm: 0.2876782035932089, clipped: 0.2876782035932089
epoch: 86, train_batch_id: 1200, avg_cost: 3.8531723022460938
grad_norm: 0.632953984456018, clipped: 0.632953984456018
epoch: 86, train_batch_id: 1250, avg_cost: 3.8342041969299316
grad_norm: 0.345646074709298, clipped: 0.345646074709298
epoch: 86, train_batch_id: 1300, avg_cost: 3.8357722759246826
grad_norm: 0.2601304555138878, clipped: 0.2601304555138878
epoch: 86, train_batch_id: 1350, avg_cost: 3.8306312561035156
grad_norm: 0.5188915478889851, clipped: 0.5188915478889851
epoch: 86, train_batch_id: 1400, avg_cost: 3.855764865875244
grad_norm: 0.3502700271945015, clipped: 0.3502700271945015
epoch: 86, train_batch_id: 1450, avg_cost: 3.830712080001831
grad_norm: 0.27592898184796505, clipped: 0.27592898184796505
epoch: 86, train_batch_id: 1500, avg_cost: 3.837944507598877
grad_norm: 0.4465077484172309, clipped: 0.4465077484172309
epoch: 86, train_batch_id: 1550, avg_cost: 3.827059268951416
grad_norm: 0.5672315367873214, clipped: 0.5672315367873214
epoch: 86, train_batch_id: 1600, avg_cost: 3.823864698410034
grad_norm: 0.3529987674321264, clipped: 0.3529987674321264
epoch: 86, train_batch_id: 1650, avg_cost: 3.849315881729126
grad_norm: 0.4295161408371418, clipped: 0.4295161408371418
epoch: 86, train_batch_id: 1700, avg_cost: 3.828428268432617
grad_norm: 0.20161708108672866, clipped: 0.20161708108672866
epoch: 86, train_batch_id: 1750, avg_cost: 3.8745784759521484
grad_norm: 0.358122332714125, clipped: 0.358122332714125
epoch: 86, train_batch_id: 1800, avg_cost: 3.8474936485290527
grad_norm: 0.2669788012736981, clipped: 0.2669788012736981
epoch: 86, train_batch_id: 1850, avg_cost: 3.8380494117736816
grad_norm: 0.38289191191884764, clipped: 0.38289191191884764
epoch: 86, train_batch_id: 1900, avg_cost: 3.8467578887939453
grad_norm: 0.36354513568083985, clipped: 0.36354513568083985
epoch: 86, train_batch_id: 1950, avg_cost: 3.8481597900390625
grad_norm: 0.6226019920406926, clipped: 0.6226019920406926
epoch: 86, train_batch_id: 2000, avg_cost: 3.825134515762329
grad_norm: 0.241710244838214, clipped: 0.241710244838214
epoch: 86, train_batch_id: 2050, avg_cost: 3.8121633529663086
grad_norm: 0.1961143896553581, clipped: 0.1961143896553581
epoch: 86, train_batch_id: 2100, avg_cost: 3.852733612060547
grad_norm: 0.2962512099422701, clipped: 0.2962512099422701
epoch: 86, train_batch_id: 2150, avg_cost: 3.8565754890441895
grad_norm: 1.2783837746612836, clipped: 1.0
epoch: 86, train_batch_id: 2200, avg_cost: 3.8664917945861816
grad_norm: 0.2973921865128885, clipped: 0.2973921865128885
epoch: 86, train_batch_id: 2250, avg_cost: 3.8236987590789795
grad_norm: 0.46793853785406403, clipped: 0.46793853785406403
epoch: 86, train_batch_id: 2300, avg_cost: 3.854243516921997
grad_norm: 0.2565570260022711, clipped: 0.2565570260022711
epoch: 86, train_batch_id: 2350, avg_cost: 3.8381757736206055
grad_norm: 0.2146380132233467, clipped: 0.2146380132233467
epoch: 86, train_batch_id: 2400, avg_cost: 3.863431930541992
grad_norm: 0.33368437666282236, clipped: 0.33368437666282236
epoch: 86, train_batch_id: 2450, avg_cost: 3.8533434867858887
grad_norm: 0.40745481683554813, clipped: 0.40745481683554813
Finished epoch 86, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8463962078094482 +- 0.0030978298746049404
Evaluating candidate model on evaluation dataset
Epoch 86 candidate mean 3.8448078632354736, baseline epoch 74 mean 3.8441007137298584, difference 0.0007071495056152344
Start train epoch 87, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 87, train_batch_id: 0, avg_cost: 3.8467183113098145
grad_norm: 0.3183210941790736, clipped: 0.3183210941790736
epoch: 87, train_batch_id: 50, avg_cost: 3.863311290740967
grad_norm: 0.3306608694499166, clipped: 0.3306608694499166
epoch: 87, train_batch_id: 100, avg_cost: 3.8419477939605713
grad_norm: 0.34771372210922347, clipped: 0.34771372210922347
epoch: 87, train_batch_id: 150, avg_cost: 3.8448843955993652
grad_norm: 0.29526484609172704, clipped: 0.29526484609172704
epoch: 87, train_batch_id: 200, avg_cost: 3.843153715133667
grad_norm: 0.2841540581340249, clipped: 0.2841540581340249
epoch: 87, train_batch_id: 250, avg_cost: 3.846384048461914
grad_norm: 1.503146851532455, clipped: 1.0
epoch: 87, train_batch_id: 300, avg_cost: 3.8342843055725098
grad_norm: 0.4187739497890697, clipped: 0.4187739497890697
epoch: 87, train_batch_id: 350, avg_cost: 3.8420214653015137
grad_norm: 0.6224054958797722, clipped: 0.6224054958797722
epoch: 87, train_batch_id: 400, avg_cost: 3.8418445587158203
grad_norm: 0.2971257277086356, clipped: 0.2971257277086356
epoch: 87, train_batch_id: 450, avg_cost: 3.8388938903808594
grad_norm: 0.35991792069485945, clipped: 0.35991792069485945
epoch: 87, train_batch_id: 500, avg_cost: 3.8340024948120117
grad_norm: 0.27054330827330836, clipped: 0.27054330827330836
epoch: 87, train_batch_id: 550, avg_cost: 3.8427469730377197
grad_norm: 0.30776510477031155, clipped: 0.30776510477031155
epoch: 87, train_batch_id: 600, avg_cost: 3.8124818801879883
grad_norm: 0.5166196858484908, clipped: 0.5166196858484908
epoch: 87, train_batch_id: 650, avg_cost: 3.8499577045440674
grad_norm: 0.7922007609651632, clipped: 0.7922007609651632
epoch: 87, train_batch_id: 700, avg_cost: 3.866834878921509
grad_norm: 0.27174794520698026, clipped: 0.27174794520698026
epoch: 87, train_batch_id: 750, avg_cost: 3.855010509490967
grad_norm: 0.347249033823878, clipped: 0.347249033823878
epoch: 87, train_batch_id: 800, avg_cost: 3.8350107669830322
grad_norm: 0.3143087888826217, clipped: 0.3143087888826217
epoch: 87, train_batch_id: 850, avg_cost: 3.8505377769470215
grad_norm: 0.3743583804540515, clipped: 0.3743583804540515
epoch: 87, train_batch_id: 900, avg_cost: 3.865091323852539
grad_norm: 0.2557472321139349, clipped: 0.2557472321139349
epoch: 87, train_batch_id: 950, avg_cost: 3.8563079833984375
grad_norm: 0.25643274828499824, clipped: 0.25643274828499824
epoch: 87, train_batch_id: 1000, avg_cost: 3.85660719871521
grad_norm: 0.24534149735549377, clipped: 0.24534149735549377
epoch: 87, train_batch_id: 1050, avg_cost: 3.854236602783203
grad_norm: 0.4408057230974263, clipped: 0.4408057230974263
epoch: 87, train_batch_id: 1100, avg_cost: 3.826246738433838
grad_norm: 0.2730123430436015, clipped: 0.2730123430436015
epoch: 87, train_batch_id: 1150, avg_cost: 3.8272109031677246
grad_norm: 0.24933558603682276, clipped: 0.24933558603682276
epoch: 87, train_batch_id: 1200, avg_cost: 3.8358564376831055
grad_norm: 0.24986830714271277, clipped: 0.24986830714271277
epoch: 87, train_batch_id: 1250, avg_cost: 3.8348655700683594
grad_norm: 0.8083574313749089, clipped: 0.8083574313749089
epoch: 87, train_batch_id: 1300, avg_cost: 3.8591361045837402
grad_norm: 0.2642376233505186, clipped: 0.2642376233505186
epoch: 87, train_batch_id: 1350, avg_cost: 3.850470542907715
grad_norm: 0.31291506828776205, clipped: 0.31291506828776205
epoch: 87, train_batch_id: 1400, avg_cost: 3.8399057388305664
grad_norm: 0.21415214318968853, clipped: 0.21415214318968853
epoch: 87, train_batch_id: 1450, avg_cost: 3.836973190307617
grad_norm: 0.2568100608744145, clipped: 0.2568100608744145
epoch: 87, train_batch_id: 1500, avg_cost: 3.8349952697753906
grad_norm: 0.32266720241794017, clipped: 0.32266720241794017
epoch: 87, train_batch_id: 1550, avg_cost: 3.8207287788391113
grad_norm: 0.4246994789567479, clipped: 0.4246994789567479
epoch: 87, train_batch_id: 1600, avg_cost: 3.8392434120178223
grad_norm: 0.2744214411468416, clipped: 0.2744214411468416
epoch: 87, train_batch_id: 1650, avg_cost: 3.8259217739105225
grad_norm: 0.313164473709951, clipped: 0.313164473709951
epoch: 87, train_batch_id: 1700, avg_cost: 3.8625476360321045
grad_norm: 0.3276212954959144, clipped: 0.3276212954959144
epoch: 87, train_batch_id: 1750, avg_cost: 3.857135057449341
grad_norm: 0.3665781474586519, clipped: 0.3665781474586519
epoch: 87, train_batch_id: 1800, avg_cost: 3.865915060043335
grad_norm: 0.329296767308184, clipped: 0.329296767308184
epoch: 87, train_batch_id: 1850, avg_cost: 3.861414909362793
grad_norm: 1.3233823765604076, clipped: 1.0
epoch: 87, train_batch_id: 1900, avg_cost: 3.8483123779296875
grad_norm: 0.28764217994741403, clipped: 0.28764217994741403
epoch: 87, train_batch_id: 1950, avg_cost: 3.8513388633728027
grad_norm: 0.28786098479354466, clipped: 0.28786098479354466
epoch: 87, train_batch_id: 2000, avg_cost: 3.822627067565918
grad_norm: 0.606656554459905, clipped: 0.606656554459905
epoch: 87, train_batch_id: 2050, avg_cost: 3.849686622619629
grad_norm: 0.4517432555735194, clipped: 0.4517432555735194
epoch: 87, train_batch_id: 2100, avg_cost: 3.8712053298950195
grad_norm: 0.3789438950447118, clipped: 0.3789438950447118
epoch: 87, train_batch_id: 2150, avg_cost: 3.853879928588867
grad_norm: 0.4599141159823238, clipped: 0.4599141159823238
epoch: 87, train_batch_id: 2200, avg_cost: 3.836230754852295
grad_norm: 0.3519559562149875, clipped: 0.3519559562149875
epoch: 87, train_batch_id: 2250, avg_cost: 3.8394715785980225
grad_norm: 0.39258016557429876, clipped: 0.39258016557429876
epoch: 87, train_batch_id: 2300, avg_cost: 3.8479700088500977
grad_norm: 0.35287650771868884, clipped: 0.35287650771868884
epoch: 87, train_batch_id: 2350, avg_cost: 3.8281898498535156
grad_norm: 0.36694412260752934, clipped: 0.36694412260752934
epoch: 87, train_batch_id: 2400, avg_cost: 3.8344779014587402
grad_norm: 0.27809771757102464, clipped: 0.27809771757102464
epoch: 87, train_batch_id: 2450, avg_cost: 3.8386895656585693
grad_norm: 1.2035133813906467, clipped: 1.0
Finished epoch 87, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8457188606262207 +- 0.0031033395789563656
Evaluating candidate model on evaluation dataset
Epoch 87 candidate mean 3.844271421432495, baseline epoch 74 mean 3.8441007137298584, difference 0.00017070770263671875
Start train epoch 88, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 88, train_batch_id: 0, avg_cost: 3.8425538539886475
grad_norm: 0.42529689296737544, clipped: 0.42529689296737544
epoch: 88, train_batch_id: 50, avg_cost: 3.832326889038086
grad_norm: 0.2041405941753154, clipped: 0.2041405941753154
epoch: 88, train_batch_id: 100, avg_cost: 3.838536262512207
grad_norm: 0.24832483990042611, clipped: 0.24832483990042611
epoch: 88, train_batch_id: 150, avg_cost: 3.8151957988739014
grad_norm: 0.35472696277954535, clipped: 0.35472696277954535
epoch: 88, train_batch_id: 200, avg_cost: 3.8466851711273193
grad_norm: 0.4236707209023676, clipped: 0.4236707209023676
epoch: 88, train_batch_id: 250, avg_cost: 3.8414435386657715
grad_norm: 0.2805576332009419, clipped: 0.2805576332009419
epoch: 88, train_batch_id: 300, avg_cost: 3.817288398742676
grad_norm: 0.3188834306815426, clipped: 0.3188834306815426
epoch: 88, train_batch_id: 350, avg_cost: 3.84731388092041
grad_norm: 0.25566295337466816, clipped: 0.25566295337466816
epoch: 88, train_batch_id: 400, avg_cost: 3.8350865840911865
grad_norm: 0.27368118755670406, clipped: 0.27368118755670406
epoch: 88, train_batch_id: 450, avg_cost: 3.856729030609131
grad_norm: 0.2972328088256842, clipped: 0.2972328088256842
epoch: 88, train_batch_id: 500, avg_cost: 3.845747947692871
grad_norm: 0.664856342086378, clipped: 0.664856342086378
epoch: 88, train_batch_id: 550, avg_cost: 3.8328559398651123
grad_norm: 0.49021846624668275, clipped: 0.49021846624668275
epoch: 88, train_batch_id: 600, avg_cost: 3.8279025554656982
grad_norm: 0.2690218807427316, clipped: 0.2690218807427316
epoch: 88, train_batch_id: 650, avg_cost: 3.8629629611968994
grad_norm: 1.0784990776458154, clipped: 1.0
epoch: 88, train_batch_id: 700, avg_cost: 3.8501315116882324
grad_norm: 0.32019998051927584, clipped: 0.32019998051927584
epoch: 88, train_batch_id: 750, avg_cost: 3.8483829498291016
grad_norm: 0.2967880566844968, clipped: 0.2967880566844968
epoch: 88, train_batch_id: 800, avg_cost: 3.8277993202209473
grad_norm: 0.28665167572888944, clipped: 0.28665167572888944
epoch: 88, train_batch_id: 850, avg_cost: 3.8453054428100586
grad_norm: 0.2808503635920594, clipped: 0.2808503635920594
epoch: 88, train_batch_id: 900, avg_cost: 3.868492364883423
grad_norm: 0.39965030169651095, clipped: 0.39965030169651095
epoch: 88, train_batch_id: 950, avg_cost: 3.8593831062316895
grad_norm: 0.3904013268163869, clipped: 0.3904013268163869
epoch: 88, train_batch_id: 1000, avg_cost: 3.8486156463623047
grad_norm: 0.2385511984590485, clipped: 0.2385511984590485
epoch: 88, train_batch_id: 1050, avg_cost: 3.8244969844818115
grad_norm: 0.211135257687694, clipped: 0.211135257687694
epoch: 88, train_batch_id: 1100, avg_cost: 3.850146770477295
grad_norm: 0.4534236295486021, clipped: 0.4534236295486021
epoch: 88, train_batch_id: 1150, avg_cost: 3.8283767700195312
grad_norm: 0.39196580146592064, clipped: 0.39196580146592064
epoch: 88, train_batch_id: 1200, avg_cost: 3.83436918258667
grad_norm: 0.4591566768569164, clipped: 0.4591566768569164
epoch: 88, train_batch_id: 1250, avg_cost: 3.826307773590088
grad_norm: 0.2721751347384986, clipped: 0.2721751347384986
epoch: 88, train_batch_id: 1300, avg_cost: 3.8326122760772705
grad_norm: 0.28647672059097623, clipped: 0.28647672059097623
epoch: 88, train_batch_id: 1350, avg_cost: 3.8455910682678223
grad_norm: 0.4267402786417253, clipped: 0.4267402786417253
epoch: 88, train_batch_id: 1400, avg_cost: 3.83901047706604
grad_norm: 0.2830195085052546, clipped: 0.2830195085052546
epoch: 88, train_batch_id: 1450, avg_cost: 3.8573718070983887
grad_norm: 0.3392442912734055, clipped: 0.3392442912734055
epoch: 88, train_batch_id: 1500, avg_cost: 3.8718249797821045
grad_norm: 0.7945860286097185, clipped: 0.7945860286097185
epoch: 88, train_batch_id: 1550, avg_cost: 3.8457112312316895
grad_norm: 0.25877574379101886, clipped: 0.25877574379101886
epoch: 88, train_batch_id: 1600, avg_cost: 3.8573694229125977
grad_norm: 0.3252560377231761, clipped: 0.3252560377231761
epoch: 88, train_batch_id: 1650, avg_cost: 3.871628761291504
grad_norm: 0.3098011544663604, clipped: 0.3098011544663604
epoch: 88, train_batch_id: 1700, avg_cost: 3.850224494934082
grad_norm: 0.4668498459986692, clipped: 0.4668498459986692
epoch: 88, train_batch_id: 1750, avg_cost: 3.8471672534942627
grad_norm: 0.35853945257783976, clipped: 0.35853945257783976
epoch: 88, train_batch_id: 1800, avg_cost: 3.8518669605255127
grad_norm: 0.22875140253835155, clipped: 0.22875140253835155
epoch: 88, train_batch_id: 1850, avg_cost: 3.860520839691162
grad_norm: 0.4040228896759254, clipped: 0.4040228896759254
epoch: 88, train_batch_id: 1900, avg_cost: 3.837440252304077
grad_norm: 0.24326632102673137, clipped: 0.24326632102673137
epoch: 88, train_batch_id: 1950, avg_cost: 3.854903221130371
grad_norm: 0.19512069965974535, clipped: 0.19512069965974535
epoch: 88, train_batch_id: 2000, avg_cost: 3.845428943634033
grad_norm: 0.34536815885853894, clipped: 0.34536815885853894
epoch: 88, train_batch_id: 2050, avg_cost: 3.835075855255127
grad_norm: 0.5037525513842632, clipped: 0.5037525513842632
epoch: 88, train_batch_id: 2100, avg_cost: 3.835265636444092
grad_norm: 0.8395094698592578, clipped: 0.8395094698592578
epoch: 88, train_batch_id: 2150, avg_cost: 3.850905418395996
grad_norm: 0.24702162990892526, clipped: 0.24702162990892526
epoch: 88, train_batch_id: 2200, avg_cost: 3.844390392303467
grad_norm: 0.4037369738381015, clipped: 0.4037369738381015
epoch: 88, train_batch_id: 2250, avg_cost: 3.8494436740875244
grad_norm: 0.40155234517878674, clipped: 0.40155234517878674
epoch: 88, train_batch_id: 2300, avg_cost: 3.8533084392547607
grad_norm: 0.41725298537640837, clipped: 0.41725298537640837
epoch: 88, train_batch_id: 2350, avg_cost: 3.8380048274993896
grad_norm: 0.24364385942211642, clipped: 0.24364385942211642
epoch: 88, train_batch_id: 2400, avg_cost: 3.8306357860565186
grad_norm: 0.31543990757056595, clipped: 0.31543990757056595
epoch: 88, train_batch_id: 2450, avg_cost: 3.842949628829956
grad_norm: 0.7740244870376695, clipped: 0.7740244870376695
Finished epoch 88, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8450403213500977 +- 0.003097627079114318
Evaluating candidate model on evaluation dataset
Epoch 88 candidate mean 3.8438425064086914, baseline epoch 74 mean 3.8441007137298584, difference -0.0002582073211669922
p-value: 0.1720523111602988
Start train epoch 89, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 89, train_batch_id: 0, avg_cost: 3.851301431655884
grad_norm: 0.3190815209384889, clipped: 0.3190815209384889
epoch: 89, train_batch_id: 50, avg_cost: 3.8589415550231934
grad_norm: 0.35746261715748423, clipped: 0.35746261715748423
epoch: 89, train_batch_id: 100, avg_cost: 3.835132598876953
grad_norm: 0.33839704503660706, clipped: 0.33839704503660706
epoch: 89, train_batch_id: 150, avg_cost: 3.859004497528076
grad_norm: 0.3821065913641111, clipped: 0.3821065913641111
epoch: 89, train_batch_id: 200, avg_cost: 3.8619766235351562
grad_norm: 0.36376883043262, clipped: 0.36376883043262
epoch: 89, train_batch_id: 250, avg_cost: 3.85364031791687
grad_norm: 0.296982637120429, clipped: 0.296982637120429
epoch: 89, train_batch_id: 300, avg_cost: 3.8423781394958496
grad_norm: 0.3908413545988746, clipped: 0.3908413545988746
epoch: 89, train_batch_id: 350, avg_cost: 3.850338935852051
grad_norm: 0.25374806817171297, clipped: 0.25374806817171297
epoch: 89, train_batch_id: 400, avg_cost: 3.8483481407165527
grad_norm: 0.236176229760196, clipped: 0.236176229760196
epoch: 89, train_batch_id: 450, avg_cost: 3.8429737091064453
grad_norm: 0.35980911658384623, clipped: 0.35980911658384623
epoch: 89, train_batch_id: 500, avg_cost: 3.8154137134552
grad_norm: 0.274918350923684, clipped: 0.274918350923684
epoch: 89, train_batch_id: 550, avg_cost: 3.8280887603759766
grad_norm: 0.27270880056235436, clipped: 0.27270880056235436
epoch: 89, train_batch_id: 600, avg_cost: 3.8455803394317627
grad_norm: 0.332490795119081, clipped: 0.332490795119081
epoch: 89, train_batch_id: 650, avg_cost: 3.8337693214416504
grad_norm: 0.2464322474750435, clipped: 0.2464322474750435
epoch: 89, train_batch_id: 700, avg_cost: 3.8486404418945312
grad_norm: 0.2696241449168547, clipped: 0.2696241449168547
epoch: 89, train_batch_id: 750, avg_cost: 3.849818706512451
grad_norm: 0.284522394085248, clipped: 0.284522394085248
epoch: 89, train_batch_id: 800, avg_cost: 3.8331055641174316
grad_norm: 0.28692670614745236, clipped: 0.28692670614745236
epoch: 89, train_batch_id: 850, avg_cost: 3.8407185077667236
grad_norm: 0.26376138579284936, clipped: 0.26376138579284936
epoch: 89, train_batch_id: 900, avg_cost: 3.8166756629943848
grad_norm: 0.23741388850402825, clipped: 0.23741388850402825
epoch: 89, train_batch_id: 950, avg_cost: 3.858053684234619
grad_norm: 0.40508198898344366, clipped: 0.40508198898344366
epoch: 89, train_batch_id: 1000, avg_cost: 3.8368170261383057
grad_norm: 0.3094728417565227, clipped: 0.3094728417565227
epoch: 89, train_batch_id: 1050, avg_cost: 3.842571258544922
grad_norm: 0.1888907840206362, clipped: 0.1888907840206362
epoch: 89, train_batch_id: 1100, avg_cost: 3.84865140914917
grad_norm: 0.39357034848195704, clipped: 0.39357034848195704
epoch: 89, train_batch_id: 1150, avg_cost: 3.8502016067504883
grad_norm: 0.30853770248201035, clipped: 0.30853770248201035
epoch: 89, train_batch_id: 1200, avg_cost: 3.8397796154022217
grad_norm: 0.24698175170930944, clipped: 0.24698175170930944
epoch: 89, train_batch_id: 1250, avg_cost: 3.8506171703338623
grad_norm: 0.26882059413577925, clipped: 0.26882059413577925
epoch: 89, train_batch_id: 1300, avg_cost: 3.8373613357543945
grad_norm: 0.2984029844127657, clipped: 0.2984029844127657
epoch: 89, train_batch_id: 1350, avg_cost: 3.858499526977539
grad_norm: 0.46865839057326786, clipped: 0.46865839057326786
epoch: 89, train_batch_id: 1400, avg_cost: 3.8622071743011475
grad_norm: 0.32908232893190326, clipped: 0.32908232893190326
epoch: 89, train_batch_id: 1450, avg_cost: 3.850083112716675
grad_norm: 0.6340229453660025, clipped: 0.6340229453660025
epoch: 89, train_batch_id: 1500, avg_cost: 3.8276124000549316
grad_norm: 0.282525409575338, clipped: 0.282525409575338
epoch: 89, train_batch_id: 1550, avg_cost: 3.8501152992248535
grad_norm: 0.288930521996278, clipped: 0.288930521996278
epoch: 89, train_batch_id: 1600, avg_cost: 3.837296485900879
grad_norm: 0.3190190860385395, clipped: 0.3190190860385395
epoch: 89, train_batch_id: 1650, avg_cost: 3.834932804107666
grad_norm: 0.271887369300004, clipped: 0.271887369300004
epoch: 89, train_batch_id: 1700, avg_cost: 3.844158172607422
grad_norm: 0.3018303673276702, clipped: 0.3018303673276702
epoch: 89, train_batch_id: 1750, avg_cost: 3.856036424636841
grad_norm: 0.3610590296591705, clipped: 0.3610590296591705
epoch: 89, train_batch_id: 1800, avg_cost: 3.860995292663574
grad_norm: 0.37830136478039567, clipped: 0.37830136478039567
epoch: 89, train_batch_id: 1850, avg_cost: 3.8492767810821533
grad_norm: 0.18528703566026608, clipped: 0.18528703566026608
epoch: 89, train_batch_id: 1900, avg_cost: 3.8349430561065674
grad_norm: 0.22083954348745005, clipped: 0.22083954348745005
epoch: 89, train_batch_id: 1950, avg_cost: 3.869863510131836
grad_norm: 0.3228487328225128, clipped: 0.3228487328225128
epoch: 89, train_batch_id: 2000, avg_cost: 3.832515239715576
grad_norm: 0.314755210407971, clipped: 0.314755210407971
epoch: 89, train_batch_id: 2050, avg_cost: 3.8340299129486084
grad_norm: 0.4197573609612598, clipped: 0.4197573609612598
epoch: 89, train_batch_id: 2100, avg_cost: 3.8533458709716797
grad_norm: 0.32754079353403864, clipped: 0.32754079353403864
epoch: 89, train_batch_id: 2150, avg_cost: 3.8278870582580566
grad_norm: 0.3644857211801298, clipped: 0.3644857211801298
epoch: 89, train_batch_id: 2200, avg_cost: 3.8477203845977783
grad_norm: 0.43245362582884816, clipped: 0.43245362582884816
epoch: 89, train_batch_id: 2250, avg_cost: 3.86497163772583
grad_norm: 0.4919635068389347, clipped: 0.4919635068389347
epoch: 89, train_batch_id: 2300, avg_cost: 3.8165135383605957
grad_norm: 0.37847548949067245, clipped: 0.37847548949067245
epoch: 89, train_batch_id: 2350, avg_cost: 3.8398001194000244
grad_norm: 0.24482673806785732, clipped: 0.24482673806785732
epoch: 89, train_batch_id: 2400, avg_cost: 3.8365256786346436
grad_norm: 0.329546912984195, clipped: 0.329546912984195
epoch: 89, train_batch_id: 2450, avg_cost: 3.831533670425415
grad_norm: 0.41641347670295914, clipped: 0.41641347670295914
Finished epoch 89, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845463752746582 +- 0.003097670618444681
Evaluating candidate model on evaluation dataset
Epoch 89 candidate mean 3.8442535400390625, baseline epoch 74 mean 3.8441007137298584, difference 0.00015282630920410156
Start train epoch 90, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 90, train_batch_id: 0, avg_cost: 3.8353772163391113
grad_norm: 0.3647438078997395, clipped: 0.3647438078997395
epoch: 90, train_batch_id: 50, avg_cost: 3.834961175918579
grad_norm: 0.236944977938251, clipped: 0.236944977938251
epoch: 90, train_batch_id: 100, avg_cost: 3.8576645851135254
grad_norm: 0.25366437310174306, clipped: 0.25366437310174306
epoch: 90, train_batch_id: 150, avg_cost: 3.8408517837524414
grad_norm: 0.3404062672556795, clipped: 0.3404062672556795
epoch: 90, train_batch_id: 200, avg_cost: 3.8583221435546875
grad_norm: 0.48143703753078454, clipped: 0.48143703753078454
epoch: 90, train_batch_id: 250, avg_cost: 3.8401923179626465
grad_norm: 0.25143937439331443, clipped: 0.25143937439331443
epoch: 90, train_batch_id: 300, avg_cost: 3.85567569732666
grad_norm: 0.3735969295133789, clipped: 0.3735969295133789
epoch: 90, train_batch_id: 350, avg_cost: 3.8229594230651855
grad_norm: 0.27576712857416513, clipped: 0.27576712857416513
epoch: 90, train_batch_id: 400, avg_cost: 3.8449621200561523
grad_norm: 0.2930000645809294, clipped: 0.2930000645809294
epoch: 90, train_batch_id: 450, avg_cost: 3.8471901416778564
grad_norm: 0.39128625595553723, clipped: 0.39128625595553723
epoch: 90, train_batch_id: 500, avg_cost: 3.8548827171325684
grad_norm: 0.22313854869040986, clipped: 0.22313854869040986
epoch: 90, train_batch_id: 550, avg_cost: 3.8395533561706543
grad_norm: 0.37792089332231027, clipped: 0.37792089332231027
epoch: 90, train_batch_id: 600, avg_cost: 3.8469185829162598
grad_norm: 0.2236421586812631, clipped: 0.2236421586812631
epoch: 90, train_batch_id: 650, avg_cost: 3.8524398803710938
grad_norm: 0.23162594533286127, clipped: 0.23162594533286127
epoch: 90, train_batch_id: 700, avg_cost: 3.8485183715820312
grad_norm: 0.2846669589679065, clipped: 0.2846669589679065
epoch: 90, train_batch_id: 750, avg_cost: 3.8443171977996826
grad_norm: 0.2598565999566723, clipped: 0.2598565999566723
epoch: 90, train_batch_id: 800, avg_cost: 3.840301990509033
grad_norm: 0.8082104996187139, clipped: 0.8082104996187139
epoch: 90, train_batch_id: 850, avg_cost: 3.843980312347412
grad_norm: 0.30962167332437096, clipped: 0.30962167332437096
epoch: 90, train_batch_id: 900, avg_cost: 3.8363537788391113
grad_norm: 0.27760867400837175, clipped: 0.27760867400837175
epoch: 90, train_batch_id: 950, avg_cost: 3.872901439666748
grad_norm: 0.3360015018489251, clipped: 0.3360015018489251
epoch: 90, train_batch_id: 1000, avg_cost: 3.8520379066467285
grad_norm: 0.1994454170299376, clipped: 0.1994454170299376
epoch: 90, train_batch_id: 1050, avg_cost: 3.8712992668151855
grad_norm: 0.27653313924464257, clipped: 0.27653313924464257
epoch: 90, train_batch_id: 1100, avg_cost: 3.84641170501709
grad_norm: 0.28558674581217536, clipped: 0.28558674581217536
epoch: 90, train_batch_id: 1150, avg_cost: 3.8475069999694824
grad_norm: 0.3599361199466413, clipped: 0.3599361199466413
epoch: 90, train_batch_id: 1200, avg_cost: 3.8318333625793457
grad_norm: 0.3367918855952284, clipped: 0.3367918855952284
epoch: 90, train_batch_id: 1250, avg_cost: 3.837639331817627
grad_norm: 0.35415433508810656, clipped: 0.35415433508810656
epoch: 90, train_batch_id: 1300, avg_cost: 3.841984748840332
grad_norm: 0.25383239302216276, clipped: 0.25383239302216276
epoch: 90, train_batch_id: 1350, avg_cost: 3.8532629013061523
grad_norm: 0.21179807111073354, clipped: 0.21179807111073354
epoch: 90, train_batch_id: 1400, avg_cost: 3.847322940826416
grad_norm: 0.6515849609290525, clipped: 0.6515849609290525
epoch: 90, train_batch_id: 1450, avg_cost: 3.833261728286743
grad_norm: 0.22998288299317135, clipped: 0.22998288299317135
epoch: 90, train_batch_id: 1500, avg_cost: 3.8688745498657227
grad_norm: 0.22636477528080462, clipped: 0.22636477528080462
epoch: 90, train_batch_id: 1550, avg_cost: 3.830679416656494
grad_norm: 0.17056794026594319, clipped: 0.17056794026594319
epoch: 90, train_batch_id: 1600, avg_cost: 3.843251943588257
grad_norm: 0.3831769483986524, clipped: 0.3831769483986524
epoch: 90, train_batch_id: 1650, avg_cost: 3.828559398651123
grad_norm: 0.41444692692918195, clipped: 0.41444692692918195
epoch: 90, train_batch_id: 1700, avg_cost: 3.817103862762451
grad_norm: 0.26622486290662795, clipped: 0.26622486290662795
epoch: 90, train_batch_id: 1750, avg_cost: 3.8550822734832764
grad_norm: 0.22876105829570112, clipped: 0.22876105829570112
epoch: 90, train_batch_id: 1800, avg_cost: 3.8478457927703857
grad_norm: 0.33562810245744745, clipped: 0.33562810245744745
epoch: 90, train_batch_id: 1850, avg_cost: 3.85699462890625
grad_norm: 0.3049614700622213, clipped: 0.3049614700622213
epoch: 90, train_batch_id: 1900, avg_cost: 3.8546786308288574
grad_norm: 0.30136073656818524, clipped: 0.30136073656818524
epoch: 90, train_batch_id: 1950, avg_cost: 3.833951950073242
grad_norm: 0.3028152455132135, clipped: 0.3028152455132135
epoch: 90, train_batch_id: 2000, avg_cost: 3.8646321296691895
grad_norm: 0.28212834530727293, clipped: 0.28212834530727293
epoch: 90, train_batch_id: 2050, avg_cost: 3.8486714363098145
grad_norm: 0.24678151105278812, clipped: 0.24678151105278812
epoch: 90, train_batch_id: 2100, avg_cost: 3.856250286102295
grad_norm: 1.0507237730599839, clipped: 1.0
epoch: 90, train_batch_id: 2150, avg_cost: 3.8347225189208984
grad_norm: 0.33850379262174396, clipped: 0.33850379262174396
epoch: 90, train_batch_id: 2200, avg_cost: 3.8420896530151367
grad_norm: 0.28522307506557604, clipped: 0.28522307506557604
epoch: 90, train_batch_id: 2250, avg_cost: 3.8403618335723877
grad_norm: 0.310544003843901, clipped: 0.310544003843901
epoch: 90, train_batch_id: 2300, avg_cost: 3.84061598777771
grad_norm: 0.5326061017188314, clipped: 0.5326061017188314
epoch: 90, train_batch_id: 2350, avg_cost: 3.840998411178589
grad_norm: 0.27291892984746563, clipped: 0.27291892984746563
epoch: 90, train_batch_id: 2400, avg_cost: 3.843902349472046
grad_norm: 0.4677069009118417, clipped: 0.4677069009118417
epoch: 90, train_batch_id: 2450, avg_cost: 3.8353958129882812
grad_norm: 0.2653813549982916, clipped: 0.2653813549982916
Finished epoch 90, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845236301422119 +- 0.003098796121776104
Evaluating candidate model on evaluation dataset
Epoch 90 candidate mean 3.843923330307007, baseline epoch 74 mean 3.8441007137298584, difference -0.0001773834228515625
p-value: 0.25874487369800586
Start train epoch 91, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 91, train_batch_id: 0, avg_cost: 3.828810691833496
grad_norm: 0.302178086522689, clipped: 0.302178086522689
epoch: 91, train_batch_id: 50, avg_cost: 3.828835964202881
grad_norm: 0.2746552431617304, clipped: 0.2746552431617304
epoch: 91, train_batch_id: 100, avg_cost: 3.867396831512451
grad_norm: 0.3298316607710772, clipped: 0.3298316607710772
epoch: 91, train_batch_id: 150, avg_cost: 3.824554681777954
grad_norm: 0.228696567893872, clipped: 0.228696567893872
epoch: 91, train_batch_id: 200, avg_cost: 3.84261417388916
grad_norm: 0.4203270078422492, clipped: 0.4203270078422492
epoch: 91, train_batch_id: 250, avg_cost: 3.8361330032348633
grad_norm: 0.29806030443011916, clipped: 0.29806030443011916
epoch: 91, train_batch_id: 300, avg_cost: 3.8486361503601074
grad_norm: 0.23902336839856816, clipped: 0.23902336839856816
epoch: 91, train_batch_id: 350, avg_cost: 3.8598439693450928
grad_norm: 0.30675893161184764, clipped: 0.30675893161184764
epoch: 91, train_batch_id: 400, avg_cost: 3.8519859313964844
grad_norm: 0.34887625727828614, clipped: 0.34887625727828614
epoch: 91, train_batch_id: 450, avg_cost: 3.842642307281494
grad_norm: 0.2652819662631246, clipped: 0.2652819662631246
epoch: 91, train_batch_id: 500, avg_cost: 3.8380632400512695
grad_norm: 0.33117468826033203, clipped: 0.33117468826033203
epoch: 91, train_batch_id: 550, avg_cost: 3.838707685470581
grad_norm: 0.3021379624596553, clipped: 0.3021379624596553
epoch: 91, train_batch_id: 600, avg_cost: 3.8442108631134033
grad_norm: 0.22434258890840084, clipped: 0.22434258890840084
epoch: 91, train_batch_id: 650, avg_cost: 3.8722658157348633
grad_norm: 0.31392123705971475, clipped: 0.31392123705971475
epoch: 91, train_batch_id: 700, avg_cost: 3.8463191986083984
grad_norm: 0.39685170450397206, clipped: 0.39685170450397206
epoch: 91, train_batch_id: 750, avg_cost: 3.845780611038208
grad_norm: 0.2722447585782594, clipped: 0.2722447585782594
epoch: 91, train_batch_id: 800, avg_cost: 3.845452308654785
grad_norm: 0.3035766653632904, clipped: 0.3035766653632904
epoch: 91, train_batch_id: 850, avg_cost: 3.8521745204925537
grad_norm: 0.4245342148793897, clipped: 0.4245342148793897
epoch: 91, train_batch_id: 900, avg_cost: 3.8360445499420166
grad_norm: 0.50286156751201, clipped: 0.50286156751201
epoch: 91, train_batch_id: 950, avg_cost: 3.834381580352783
grad_norm: 0.38994668913196195, clipped: 0.38994668913196195
epoch: 91, train_batch_id: 1000, avg_cost: 3.855461597442627
grad_norm: 0.23331820834916397, clipped: 0.23331820834916397
epoch: 91, train_batch_id: 1050, avg_cost: 3.8493499755859375
grad_norm: 0.34645168640057417, clipped: 0.34645168640057417
epoch: 91, train_batch_id: 1100, avg_cost: 3.825895309448242
grad_norm: 0.5005228268710612, clipped: 0.5005228268710612
epoch: 91, train_batch_id: 1150, avg_cost: 3.831448554992676
grad_norm: 0.2589455836654982, clipped: 0.2589455836654982
epoch: 91, train_batch_id: 1200, avg_cost: 3.831725835800171
grad_norm: 0.2380496180885766, clipped: 0.2380496180885766
epoch: 91, train_batch_id: 1250, avg_cost: 3.851783275604248
grad_norm: 0.3823661129023428, clipped: 0.3823661129023428
epoch: 91, train_batch_id: 1300, avg_cost: 3.8444418907165527
grad_norm: 0.19462829427257036, clipped: 0.19462829427257036
epoch: 91, train_batch_id: 1350, avg_cost: 3.8515970706939697
grad_norm: 0.24491801993858622, clipped: 0.24491801993858622
epoch: 91, train_batch_id: 1400, avg_cost: 3.861739158630371
grad_norm: 0.5943238352582463, clipped: 0.5943238352582463
epoch: 91, train_batch_id: 1450, avg_cost: 3.8265016078948975
grad_norm: 0.2676806551970477, clipped: 0.2676806551970477
epoch: 91, train_batch_id: 1500, avg_cost: 3.833467483520508
grad_norm: 0.22646967957335704, clipped: 0.22646967957335704
epoch: 91, train_batch_id: 1550, avg_cost: 3.869502067565918
grad_norm: 0.43327642686819806, clipped: 0.43327642686819806
epoch: 91, train_batch_id: 1600, avg_cost: 3.8456764221191406
grad_norm: 0.4001237427602969, clipped: 0.4001237427602969
epoch: 91, train_batch_id: 1650, avg_cost: 3.838003158569336
grad_norm: 0.298163482573147, clipped: 0.298163482573147
epoch: 91, train_batch_id: 1700, avg_cost: 3.8291730880737305
grad_norm: 0.25111683557831227, clipped: 0.25111683557831227
epoch: 91, train_batch_id: 1750, avg_cost: 3.8588736057281494
grad_norm: 0.29128551828778626, clipped: 0.29128551828778626
epoch: 91, train_batch_id: 1800, avg_cost: 3.8554725646972656
grad_norm: 0.2873259803517458, clipped: 0.2873259803517458
epoch: 91, train_batch_id: 1850, avg_cost: 3.860961437225342
grad_norm: 0.3879586934049241, clipped: 0.3879586934049241
epoch: 91, train_batch_id: 1900, avg_cost: 3.8492350578308105
grad_norm: 0.3554208416473906, clipped: 0.3554208416473906
epoch: 91, train_batch_id: 1950, avg_cost: 3.838611602783203
grad_norm: 0.24277987403990242, clipped: 0.24277987403990242
epoch: 91, train_batch_id: 2000, avg_cost: 3.8656206130981445
grad_norm: 0.3161244767658323, clipped: 0.3161244767658323
epoch: 91, train_batch_id: 2050, avg_cost: 3.8548085689544678
grad_norm: 0.42496372186258885, clipped: 0.42496372186258885
epoch: 91, train_batch_id: 2100, avg_cost: 3.836566686630249
grad_norm: 0.32393576307305705, clipped: 0.32393576307305705
epoch: 91, train_batch_id: 2150, avg_cost: 3.848961353302002
grad_norm: 0.3171243251517244, clipped: 0.3171243251517244
epoch: 91, train_batch_id: 2200, avg_cost: 3.8620872497558594
grad_norm: 0.6748753631080368, clipped: 0.6748753631080368
epoch: 91, train_batch_id: 2250, avg_cost: 3.824984550476074
grad_norm: 0.21059102176026487, clipped: 0.21059102176026487
epoch: 91, train_batch_id: 2300, avg_cost: 3.8289146423339844
grad_norm: 0.19061888399896648, clipped: 0.19061888399896648
epoch: 91, train_batch_id: 2350, avg_cost: 3.848050355911255
grad_norm: 0.2608177677637197, clipped: 0.2608177677637197
epoch: 91, train_batch_id: 2400, avg_cost: 3.838426113128662
grad_norm: 0.35747819188287405, clipped: 0.35747819188287405
epoch: 91, train_batch_id: 2450, avg_cost: 3.8455941677093506
grad_norm: 0.2827150702170429, clipped: 0.2827150702170429
Finished epoch 91, took 00:05:34 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.846540689468384 +- 0.0030998587608337402
Evaluating candidate model on evaluation dataset
Epoch 91 candidate mean 3.8448641300201416, baseline epoch 74 mean 3.8441007137298584, difference 0.0007634162902832031
Start train epoch 92, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 92, train_batch_id: 0, avg_cost: 3.82123064994812
grad_norm: 0.26909079184799223, clipped: 0.26909079184799223
epoch: 92, train_batch_id: 50, avg_cost: 3.841773509979248
grad_norm: 0.5549098842588029, clipped: 0.5549098842588029
epoch: 92, train_batch_id: 100, avg_cost: 3.863246202468872
grad_norm: 0.22047262897428946, clipped: 0.22047262897428946
epoch: 92, train_batch_id: 150, avg_cost: 3.8203492164611816
grad_norm: 0.24445182804835214, clipped: 0.24445182804835214
epoch: 92, train_batch_id: 200, avg_cost: 3.818333625793457
grad_norm: 0.28561330726065837, clipped: 0.28561330726065837
epoch: 92, train_batch_id: 250, avg_cost: 3.8408169746398926
grad_norm: 0.18787202811654427, clipped: 0.18787202811654427
epoch: 92, train_batch_id: 300, avg_cost: 3.8450682163238525
grad_norm: 0.27733089612574785, clipped: 0.27733089612574785
epoch: 92, train_batch_id: 350, avg_cost: 3.8476085662841797
grad_norm: 0.41581153995123266, clipped: 0.41581153995123266
epoch: 92, train_batch_id: 400, avg_cost: 3.848878860473633
grad_norm: 0.29735700942256843, clipped: 0.29735700942256843
epoch: 92, train_batch_id: 450, avg_cost: 3.8437180519104004
grad_norm: 0.29275080250041846, clipped: 0.29275080250041846
epoch: 92, train_batch_id: 500, avg_cost: 3.8548033237457275
grad_norm: 0.2586760804746784, clipped: 0.2586760804746784
epoch: 92, train_batch_id: 550, avg_cost: 3.8434858322143555
grad_norm: 0.3079843528884746, clipped: 0.3079843528884746
epoch: 92, train_batch_id: 600, avg_cost: 3.8326268196105957
grad_norm: 0.22667481214768329, clipped: 0.22667481214768329
epoch: 92, train_batch_id: 650, avg_cost: 3.845400333404541
grad_norm: 0.2398586827693767, clipped: 0.2398586827693767
epoch: 92, train_batch_id: 700, avg_cost: 3.8602938652038574
grad_norm: 0.29341810276242897, clipped: 0.29341810276242897
epoch: 92, train_batch_id: 750, avg_cost: 3.8461294174194336
grad_norm: 0.22872074811521367, clipped: 0.22872074811521367
epoch: 92, train_batch_id: 800, avg_cost: 3.8405368328094482
grad_norm: 0.3286466370795766, clipped: 0.3286466370795766
epoch: 92, train_batch_id: 850, avg_cost: 3.851682662963867
grad_norm: 0.34100966459330473, clipped: 0.34100966459330473
epoch: 92, train_batch_id: 900, avg_cost: 3.843522071838379
grad_norm: 0.3105403458529105, clipped: 0.3105403458529105
epoch: 92, train_batch_id: 950, avg_cost: 3.856008529663086
grad_norm: 0.30792305960211425, clipped: 0.30792305960211425
epoch: 92, train_batch_id: 1000, avg_cost: 3.8601818084716797
grad_norm: 0.3450670518791296, clipped: 0.3450670518791296
epoch: 92, train_batch_id: 1050, avg_cost: 3.852895736694336
grad_norm: 0.32223016912715424, clipped: 0.32223016912715424
epoch: 92, train_batch_id: 1100, avg_cost: 3.8478407859802246
grad_norm: 0.2807643761048431, clipped: 0.2807643761048431
epoch: 92, train_batch_id: 1150, avg_cost: 3.850745677947998
grad_norm: 0.26113877217180853, clipped: 0.26113877217180853
epoch: 92, train_batch_id: 1200, avg_cost: 3.8557937145233154
grad_norm: 0.2842168952968378, clipped: 0.2842168952968378
epoch: 92, train_batch_id: 1250, avg_cost: 3.8351855278015137
grad_norm: 0.4028039298171176, clipped: 0.4028039298171176
epoch: 92, train_batch_id: 1300, avg_cost: 3.8442740440368652
grad_norm: 0.41346835197560694, clipped: 0.41346835197560694
epoch: 92, train_batch_id: 1350, avg_cost: 3.8327956199645996
grad_norm: 0.3281863349874743, clipped: 0.3281863349874743
epoch: 92, train_batch_id: 1400, avg_cost: 3.854552984237671
grad_norm: 0.22509264537168033, clipped: 0.22509264537168033
epoch: 92, train_batch_id: 1450, avg_cost: 3.858808994293213
grad_norm: 0.32576604442458595, clipped: 0.32576604442458595
epoch: 92, train_batch_id: 1500, avg_cost: 3.848431348800659
grad_norm: 0.268075196961761, clipped: 0.268075196961761
epoch: 92, train_batch_id: 1550, avg_cost: 3.8692517280578613
grad_norm: 0.4007940787567567, clipped: 0.4007940787567567
epoch: 92, train_batch_id: 1600, avg_cost: 3.8453216552734375
grad_norm: 0.5118192816140678, clipped: 0.5118192816140678
epoch: 92, train_batch_id: 1650, avg_cost: 3.866476058959961
grad_norm: 0.3580378569861827, clipped: 0.3580378569861827
epoch: 92, train_batch_id: 1700, avg_cost: 3.8474411964416504
grad_norm: 0.35253598149246507, clipped: 0.35253598149246507
epoch: 92, train_batch_id: 1750, avg_cost: 3.800063371658325
grad_norm: 0.33117156104736145, clipped: 0.33117156104736145
epoch: 92, train_batch_id: 1800, avg_cost: 3.8325138092041016
grad_norm: 0.2747645268501633, clipped: 0.2747645268501633
epoch: 92, train_batch_id: 1850, avg_cost: 3.8622519969940186
grad_norm: 0.3459940508616787, clipped: 0.3459940508616787
epoch: 92, train_batch_id: 1900, avg_cost: 3.849787712097168
grad_norm: 0.2707826393808494, clipped: 0.2707826393808494
epoch: 92, train_batch_id: 1950, avg_cost: 3.8330464363098145
grad_norm: 0.3080514308265512, clipped: 0.3080514308265512
epoch: 92, train_batch_id: 2000, avg_cost: 3.85459041595459
grad_norm: 0.34276521516734754, clipped: 0.34276521516734754
epoch: 92, train_batch_id: 2050, avg_cost: 3.8663811683654785
grad_norm: 0.24418608440143574, clipped: 0.24418608440143574
epoch: 92, train_batch_id: 2100, avg_cost: 3.8293404579162598
grad_norm: 0.3431648863436803, clipped: 0.3431648863436803
epoch: 92, train_batch_id: 2150, avg_cost: 3.818924903869629
grad_norm: 0.2139189125285136, clipped: 0.2139189125285136
epoch: 92, train_batch_id: 2200, avg_cost: 3.854835033416748
grad_norm: 0.22444468168061382, clipped: 0.22444468168061382
epoch: 92, train_batch_id: 2250, avg_cost: 3.848644256591797
grad_norm: 0.24836985319413327, clipped: 0.24836985319413327
epoch: 92, train_batch_id: 2300, avg_cost: 3.8444385528564453
grad_norm: 0.28677134547219024, clipped: 0.28677134547219024
epoch: 92, train_batch_id: 2350, avg_cost: 3.8462772369384766
grad_norm: 0.3229024657011388, clipped: 0.3229024657011388
epoch: 92, train_batch_id: 2400, avg_cost: 3.8468947410583496
grad_norm: 0.23588406781874796, clipped: 0.23588406781874796
epoch: 92, train_batch_id: 2450, avg_cost: 3.8710625171661377
grad_norm: 0.2732901239728877, clipped: 0.2732901239728877
Finished epoch 92, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8449316024780273 +- 0.003098877379670739
Evaluating candidate model on evaluation dataset
Epoch 92 candidate mean 3.843456745147705, baseline epoch 74 mean 3.8441007137298584, difference -0.0006439685821533203
p-value: 0.005912230550498553
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 93, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 93, train_batch_id: 0, avg_cost: 3.841296672821045
grad_norm: 0.2822838895762966, clipped: 0.2822838895762966
epoch: 93, train_batch_id: 50, avg_cost: 3.8256895542144775
grad_norm: 0.22629139276657212, clipped: 0.22629139276657212
epoch: 93, train_batch_id: 100, avg_cost: 3.848231315612793
grad_norm: 0.2600290747804802, clipped: 0.2600290747804802
epoch: 93, train_batch_id: 150, avg_cost: 3.855191707611084
grad_norm: 0.3191048087190733, clipped: 0.3191048087190733
epoch: 93, train_batch_id: 200, avg_cost: 3.8359508514404297
grad_norm: 0.28341007215770553, clipped: 0.28341007215770553
epoch: 93, train_batch_id: 250, avg_cost: 3.841404914855957
grad_norm: 0.3500002926686993, clipped: 0.3500002926686993
epoch: 93, train_batch_id: 300, avg_cost: 3.8380913734436035
grad_norm: 0.22808545229039195, clipped: 0.22808545229039195
epoch: 93, train_batch_id: 350, avg_cost: 3.8365843296051025
grad_norm: 0.2264255134607157, clipped: 0.2264255134607157
epoch: 93, train_batch_id: 400, avg_cost: 3.8460519313812256
grad_norm: 0.20223494959981034, clipped: 0.20223494959981034
epoch: 93, train_batch_id: 450, avg_cost: 3.8496346473693848
grad_norm: 0.3290241880903084, clipped: 0.3290241880903084
epoch: 93, train_batch_id: 500, avg_cost: 3.8378734588623047
grad_norm: 0.29333830304628067, clipped: 0.29333830304628067
epoch: 93, train_batch_id: 550, avg_cost: 3.8789477348327637
grad_norm: 0.26249338143899653, clipped: 0.26249338143899653
epoch: 93, train_batch_id: 600, avg_cost: 3.8262228965759277
grad_norm: 0.3578683853961458, clipped: 0.3578683853961458
epoch: 93, train_batch_id: 650, avg_cost: 3.846785545349121
grad_norm: 0.3277035137744853, clipped: 0.3277035137744853
epoch: 93, train_batch_id: 700, avg_cost: 3.83779239654541
grad_norm: 0.3352324152161236, clipped: 0.3352324152161236
epoch: 93, train_batch_id: 750, avg_cost: 3.8503365516662598
grad_norm: 0.17648058699050626, clipped: 0.17648058699050626
epoch: 93, train_batch_id: 800, avg_cost: 3.8470144271850586
grad_norm: 0.23626191393311802, clipped: 0.23626191393311802
epoch: 93, train_batch_id: 850, avg_cost: 3.831752061843872
grad_norm: 0.31900098675951627, clipped: 0.31900098675951627
epoch: 93, train_batch_id: 900, avg_cost: 3.84633207321167
grad_norm: 0.2550486973708323, clipped: 0.2550486973708323
epoch: 93, train_batch_id: 950, avg_cost: 3.836643695831299
grad_norm: 0.17948597089619617, clipped: 0.17948597089619617
epoch: 93, train_batch_id: 1000, avg_cost: 3.861743211746216
grad_norm: 0.2409145297046398, clipped: 0.2409145297046398
epoch: 93, train_batch_id: 1050, avg_cost: 3.819197416305542
grad_norm: 0.30333829738655893, clipped: 0.30333829738655893
epoch: 93, train_batch_id: 1100, avg_cost: 3.8684260845184326
grad_norm: 0.21735900302645894, clipped: 0.21735900302645894
epoch: 93, train_batch_id: 1150, avg_cost: 3.848975419998169
grad_norm: 0.29469401935751544, clipped: 0.29469401935751544
epoch: 93, train_batch_id: 1200, avg_cost: 3.860879898071289
grad_norm: 0.24276844765493702, clipped: 0.24276844765493702
epoch: 93, train_batch_id: 1250, avg_cost: 3.8389058113098145
grad_norm: 0.2888364334066931, clipped: 0.2888364334066931
epoch: 93, train_batch_id: 1300, avg_cost: 3.8383431434631348
grad_norm: 0.23108198684391432, clipped: 0.23108198684391432
epoch: 93, train_batch_id: 1350, avg_cost: 3.8510985374450684
grad_norm: 0.29342280966464596, clipped: 0.29342280966464596
epoch: 93, train_batch_id: 1400, avg_cost: 3.8558125495910645
grad_norm: 0.25359293383680553, clipped: 0.25359293383680553
epoch: 93, train_batch_id: 1450, avg_cost: 3.8480379581451416
grad_norm: 0.36882454919171875, clipped: 0.36882454919171875
epoch: 93, train_batch_id: 1500, avg_cost: 3.86578631401062
grad_norm: 0.6456328174392781, clipped: 0.6456328174392781
epoch: 93, train_batch_id: 1550, avg_cost: 3.8253707885742188
grad_norm: 0.33789423310565114, clipped: 0.33789423310565114
epoch: 93, train_batch_id: 1600, avg_cost: 3.8361949920654297
grad_norm: 0.2617332567706419, clipped: 0.2617332567706419
epoch: 93, train_batch_id: 1650, avg_cost: 3.8484303951263428
grad_norm: 0.724666960076014, clipped: 0.724666960076014
epoch: 93, train_batch_id: 1700, avg_cost: 3.8296382427215576
grad_norm: 0.19614529936957686, clipped: 0.19614529936957686
epoch: 93, train_batch_id: 1750, avg_cost: 3.833859443664551
grad_norm: 0.42001795357186794, clipped: 0.42001795357186794
epoch: 93, train_batch_id: 1800, avg_cost: 3.8361339569091797
grad_norm: 0.36126465361620297, clipped: 0.36126465361620297
epoch: 93, train_batch_id: 1850, avg_cost: 3.8341829776763916
grad_norm: 0.33737391406225775, clipped: 0.33737391406225775
epoch: 93, train_batch_id: 1900, avg_cost: 3.886404037475586
grad_norm: 0.291320545803302, clipped: 0.291320545803302
epoch: 93, train_batch_id: 1950, avg_cost: 3.8279342651367188
grad_norm: 1.0439540406855092, clipped: 1.0
epoch: 93, train_batch_id: 2000, avg_cost: 3.8506503105163574
grad_norm: 0.4823889880354579, clipped: 0.4823889880354579
epoch: 93, train_batch_id: 2050, avg_cost: 3.8595709800720215
grad_norm: 0.37697862977716534, clipped: 0.37697862977716534
epoch: 93, train_batch_id: 2100, avg_cost: 3.836897373199463
grad_norm: 0.32268449117602527, clipped: 0.32268449117602527
epoch: 93, train_batch_id: 2150, avg_cost: 3.8453855514526367
grad_norm: 0.2664201844510846, clipped: 0.2664201844510846
epoch: 93, train_batch_id: 2200, avg_cost: 3.8291025161743164
grad_norm: 0.29242230167514355, clipped: 0.29242230167514355
epoch: 93, train_batch_id: 2250, avg_cost: 3.849602222442627
grad_norm: 0.3670250401877984, clipped: 0.3670250401877984
epoch: 93, train_batch_id: 2300, avg_cost: 3.8296194076538086
grad_norm: 0.38479692680102084, clipped: 0.38479692680102084
epoch: 93, train_batch_id: 2350, avg_cost: 3.8350300788879395
grad_norm: 0.2905260007232563, clipped: 0.2905260007232563
epoch: 93, train_batch_id: 2400, avg_cost: 3.8597822189331055
grad_norm: 0.22276764042240946, clipped: 0.22276764042240946
epoch: 93, train_batch_id: 2450, avg_cost: 3.8375613689422607
grad_norm: 0.24693556196894875, clipped: 0.24693556196894875
Finished epoch 93, took 00:05:35 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.845911741256714 +- 0.0031006119679659605
Evaluating candidate model on evaluation dataset
Epoch 93 candidate mean 3.840064764022827, baseline epoch 92 mean 3.8395330905914307, difference 0.0005316734313964844
Start train epoch 94, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 94, train_batch_id: 0, avg_cost: 3.8250603675842285
grad_norm: 0.34223013588832213, clipped: 0.34223013588832213
epoch: 94, train_batch_id: 50, avg_cost: 3.8269195556640625
grad_norm: 0.4901183099996126, clipped: 0.4901183099996126
epoch: 94, train_batch_id: 100, avg_cost: 3.8358612060546875
grad_norm: 0.18153107447588013, clipped: 0.18153107447588013
epoch: 94, train_batch_id: 150, avg_cost: 3.8379898071289062
grad_norm: 0.26652193583683703, clipped: 0.26652193583683703
epoch: 94, train_batch_id: 200, avg_cost: 3.8400087356567383
grad_norm: 0.35407520170375345, clipped: 0.35407520170375345
epoch: 94, train_batch_id: 250, avg_cost: 3.8349924087524414
grad_norm: 0.7668106294947398, clipped: 0.7668106294947398
epoch: 94, train_batch_id: 300, avg_cost: 3.8283138275146484
grad_norm: 0.31151447552888983, clipped: 0.31151447552888983
epoch: 94, train_batch_id: 350, avg_cost: 3.8509867191314697
grad_norm: 0.18013275408598747, clipped: 0.18013275408598747
epoch: 94, train_batch_id: 400, avg_cost: 3.862525224685669
grad_norm: 0.2833337805863694, clipped: 0.2833337805863694
epoch: 94, train_batch_id: 450, avg_cost: 3.859273910522461
grad_norm: 0.2305185127634906, clipped: 0.2305185127634906
epoch: 94, train_batch_id: 500, avg_cost: 3.871285915374756
grad_norm: 0.24633329586343505, clipped: 0.24633329586343505
epoch: 94, train_batch_id: 550, avg_cost: 3.8506107330322266
grad_norm: 0.2717300206615814, clipped: 0.2717300206615814
epoch: 94, train_batch_id: 600, avg_cost: 3.837332010269165
grad_norm: 0.7292619274097346, clipped: 0.7292619274097346
epoch: 94, train_batch_id: 650, avg_cost: 3.8414108753204346
grad_norm: 0.25852471785878484, clipped: 0.25852471785878484
epoch: 94, train_batch_id: 700, avg_cost: 3.85067081451416
grad_norm: 0.452927285207736, clipped: 0.452927285207736
epoch: 94, train_batch_id: 750, avg_cost: 3.8467955589294434
grad_norm: 1.0466280296350257, clipped: 1.0
epoch: 94, train_batch_id: 800, avg_cost: 3.8357362747192383
grad_norm: 0.2215326676882882, clipped: 0.2215326676882882
epoch: 94, train_batch_id: 850, avg_cost: 3.8479971885681152
grad_norm: 0.23481283001061556, clipped: 0.23481283001061556
epoch: 94, train_batch_id: 900, avg_cost: 3.855905055999756
grad_norm: 0.25542396110248966, clipped: 0.25542396110248966
epoch: 94, train_batch_id: 950, avg_cost: 3.8561220169067383
grad_norm: 1.1520355275600498, clipped: 1.0
epoch: 94, train_batch_id: 1000, avg_cost: 3.823659896850586
grad_norm: 0.33114027946616803, clipped: 0.33114027946616803
epoch: 94, train_batch_id: 1050, avg_cost: 3.833944082260132
grad_norm: 0.2392305418550921, clipped: 0.2392305418550921
epoch: 94, train_batch_id: 1100, avg_cost: 3.8351380825042725
grad_norm: 0.25559688466990493, clipped: 0.25559688466990493
epoch: 94, train_batch_id: 1150, avg_cost: 3.856358528137207
grad_norm: 0.32389972842099096, clipped: 0.32389972842099096
epoch: 94, train_batch_id: 1200, avg_cost: 3.861083507537842
grad_norm: 0.6095866766657311, clipped: 0.6095866766657311
epoch: 94, train_batch_id: 1250, avg_cost: 3.860919952392578
grad_norm: 0.3359683951457497, clipped: 0.3359683951457497
epoch: 94, train_batch_id: 1300, avg_cost: 3.8477699756622314
grad_norm: 0.43321143818425734, clipped: 0.43321143818425734
epoch: 94, train_batch_id: 1350, avg_cost: 3.831146240234375
grad_norm: 0.3269740556431989, clipped: 0.3269740556431989
epoch: 94, train_batch_id: 1400, avg_cost: 3.8438098430633545
grad_norm: 0.29380908782355736, clipped: 0.29380908782355736
epoch: 94, train_batch_id: 1450, avg_cost: 3.8510608673095703
grad_norm: 0.29636442703828864, clipped: 0.29636442703828864
epoch: 94, train_batch_id: 1500, avg_cost: 3.8306102752685547
grad_norm: 0.39947762381090535, clipped: 0.39947762381090535
epoch: 94, train_batch_id: 1550, avg_cost: 3.8347301483154297
grad_norm: 0.1860312640720614, clipped: 0.1860312640720614
epoch: 94, train_batch_id: 1600, avg_cost: 3.870610475540161
grad_norm: 0.45578960447263805, clipped: 0.45578960447263805
epoch: 94, train_batch_id: 1650, avg_cost: 3.8376059532165527
grad_norm: 0.24372226995593327, clipped: 0.24372226995593327
epoch: 94, train_batch_id: 1700, avg_cost: 3.828641653060913
grad_norm: 0.35071414948765944, clipped: 0.35071414948765944
epoch: 94, train_batch_id: 1750, avg_cost: 3.8497543334960938
grad_norm: 0.23987629150387077, clipped: 0.23987629150387077
epoch: 94, train_batch_id: 1800, avg_cost: 3.8288886547088623
grad_norm: 0.2108680162229115, clipped: 0.2108680162229115
epoch: 94, train_batch_id: 1850, avg_cost: 3.842804431915283
grad_norm: 0.2206134535783969, clipped: 0.2206134535783969
epoch: 94, train_batch_id: 1900, avg_cost: 3.842836380004883
grad_norm: 0.3017919539530838, clipped: 0.3017919539530838
epoch: 94, train_batch_id: 1950, avg_cost: 3.864795207977295
grad_norm: 0.492459049316027, clipped: 0.492459049316027
epoch: 94, train_batch_id: 2000, avg_cost: 3.8511476516723633
grad_norm: 0.2791822811793834, clipped: 0.2791822811793834
epoch: 94, train_batch_id: 2050, avg_cost: 3.843217134475708
grad_norm: 0.22841822227926895, clipped: 0.22841822227926895
epoch: 94, train_batch_id: 2100, avg_cost: 3.8527421951293945
grad_norm: 0.4024562687991019, clipped: 0.4024562687991019
epoch: 94, train_batch_id: 2150, avg_cost: 3.860399007797241
grad_norm: 0.20651335585899377, clipped: 0.20651335585899377
epoch: 94, train_batch_id: 2200, avg_cost: 3.8410916328430176
grad_norm: 0.28307155543800533, clipped: 0.28307155543800533
epoch: 94, train_batch_id: 2250, avg_cost: 3.8476808071136475
grad_norm: 0.31686921155966324, clipped: 0.31686921155966324
epoch: 94, train_batch_id: 2300, avg_cost: 3.8534092903137207
grad_norm: 0.23483148476556662, clipped: 0.23483148476556662
epoch: 94, train_batch_id: 2350, avg_cost: 3.859121322631836
grad_norm: 0.42465882282526296, clipped: 0.42465882282526296
epoch: 94, train_batch_id: 2400, avg_cost: 3.8373444080352783
grad_norm: 0.5217756671321597, clipped: 0.5217756671321597
epoch: 94, train_batch_id: 2450, avg_cost: 3.848188877105713
grad_norm: 0.2475017151543903, clipped: 0.2475017151543903
Finished epoch 94, took 00:05:44 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8456387519836426 +- 0.00310152699239552
Evaluating candidate model on evaluation dataset
Epoch 94 candidate mean 3.8399901390075684, baseline epoch 92 mean 3.8395330905914307, difference 0.0004570484161376953
Start train epoch 95, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 95, train_batch_id: 0, avg_cost: 3.826906442642212
grad_norm: 0.2369758509909447, clipped: 0.2369758509909447
epoch: 95, train_batch_id: 50, avg_cost: 3.855665683746338
grad_norm: 0.2460158008454485, clipped: 0.2460158008454485
epoch: 95, train_batch_id: 100, avg_cost: 3.8441808223724365
grad_norm: 0.3408473669234226, clipped: 0.3408473669234226
epoch: 95, train_batch_id: 150, avg_cost: 3.8325634002685547
grad_norm: 0.21893552636860167, clipped: 0.21893552636860167
epoch: 95, train_batch_id: 200, avg_cost: 3.8304619789123535
grad_norm: 0.27953609697667237, clipped: 0.27953609697667237
epoch: 95, train_batch_id: 250, avg_cost: 3.844660997390747
grad_norm: 0.31164997568268904, clipped: 0.31164997568268904
epoch: 95, train_batch_id: 300, avg_cost: 3.8501243591308594
grad_norm: 0.3019833864944628, clipped: 0.3019833864944628
epoch: 95, train_batch_id: 350, avg_cost: 3.8281311988830566
grad_norm: 0.36349561804703157, clipped: 0.36349561804703157
epoch: 95, train_batch_id: 400, avg_cost: 3.845219135284424
grad_norm: 0.5910428739710734, clipped: 0.5910428739710734
epoch: 95, train_batch_id: 450, avg_cost: 3.830240488052368
grad_norm: 0.27943236900752555, clipped: 0.27943236900752555
epoch: 95, train_batch_id: 500, avg_cost: 3.849541187286377
grad_norm: 0.7818239928001472, clipped: 0.7818239928001472
epoch: 95, train_batch_id: 550, avg_cost: 3.8598227500915527
grad_norm: 0.2495970827496349, clipped: 0.2495970827496349
epoch: 95, train_batch_id: 600, avg_cost: 3.8377466201782227
grad_norm: 0.33239749175922834, clipped: 0.33239749175922834
epoch: 95, train_batch_id: 650, avg_cost: 3.8362488746643066
grad_norm: 0.34845442182443687, clipped: 0.34845442182443687
epoch: 95, train_batch_id: 700, avg_cost: 3.848696708679199
grad_norm: 0.28437249750040516, clipped: 0.28437249750040516
epoch: 95, train_batch_id: 750, avg_cost: 3.852679491043091
grad_norm: 0.2801796892591534, clipped: 0.2801796892591534
epoch: 95, train_batch_id: 800, avg_cost: 3.823373794555664
grad_norm: 0.3172134311377496, clipped: 0.3172134311377496
epoch: 95, train_batch_id: 850, avg_cost: 3.8454818725585938
grad_norm: 0.26993520104879026, clipped: 0.26993520104879026
epoch: 95, train_batch_id: 900, avg_cost: 3.8344297409057617
grad_norm: 0.2894248278020957, clipped: 0.2894248278020957
epoch: 95, train_batch_id: 950, avg_cost: 3.849699020385742
grad_norm: 0.1897971629052273, clipped: 0.1897971629052273
epoch: 95, train_batch_id: 1000, avg_cost: 3.8360204696655273
grad_norm: 0.30186199441270667, clipped: 0.30186199441270667
epoch: 95, train_batch_id: 1050, avg_cost: 3.844521999359131
grad_norm: 0.3132459937243982, clipped: 0.3132459937243982
epoch: 95, train_batch_id: 1100, avg_cost: 3.8304591178894043
grad_norm: 0.24327636054795446, clipped: 0.24327636054795446
epoch: 95, train_batch_id: 1150, avg_cost: 3.856091022491455
grad_norm: 0.3195293193870036, clipped: 0.3195293193870036
epoch: 95, train_batch_id: 1200, avg_cost: 3.8517589569091797
grad_norm: 0.21430888584589988, clipped: 0.21430888584589988
epoch: 95, train_batch_id: 1250, avg_cost: 3.849116802215576
grad_norm: 0.3150771873059173, clipped: 0.3150771873059173
epoch: 95, train_batch_id: 1300, avg_cost: 3.85968017578125
grad_norm: 0.40805085655959294, clipped: 0.40805085655959294
epoch: 95, train_batch_id: 1350, avg_cost: 3.828092098236084
grad_norm: 0.40314473584421545, clipped: 0.40314473584421545
epoch: 95, train_batch_id: 1400, avg_cost: 3.847240686416626
grad_norm: 0.17890346133550578, clipped: 0.17890346133550578
epoch: 95, train_batch_id: 1450, avg_cost: 3.8380515575408936
grad_norm: 0.33555051947050824, clipped: 0.33555051947050824
epoch: 95, train_batch_id: 1500, avg_cost: 3.839034080505371
grad_norm: 0.6279896566040303, clipped: 0.6279896566040303
epoch: 95, train_batch_id: 1550, avg_cost: 3.849785804748535
grad_norm: 0.20280229891006407, clipped: 0.20280229891006407
epoch: 95, train_batch_id: 1600, avg_cost: 3.828493595123291
grad_norm: 0.27928132106218057, clipped: 0.27928132106218057
epoch: 95, train_batch_id: 1650, avg_cost: 3.8525078296661377
grad_norm: 0.28426968159493093, clipped: 0.28426968159493093
epoch: 95, train_batch_id: 1700, avg_cost: 3.8749513626098633
grad_norm: 0.315507528473715, clipped: 0.315507528473715
epoch: 95, train_batch_id: 1750, avg_cost: 3.8407740592956543
grad_norm: 0.23516098384705558, clipped: 0.23516098384705558
epoch: 95, train_batch_id: 1800, avg_cost: 3.860504150390625
grad_norm: 0.29887184739588796, clipped: 0.29887184739588796
epoch: 95, train_batch_id: 1850, avg_cost: 3.867177724838257
grad_norm: 0.30231644927900436, clipped: 0.30231644927900436
epoch: 95, train_batch_id: 1900, avg_cost: 3.861738443374634
grad_norm: 0.3232216361560593, clipped: 0.3232216361560593
epoch: 95, train_batch_id: 1950, avg_cost: 3.846506118774414
grad_norm: 0.24850728592866322, clipped: 0.24850728592866322
epoch: 95, train_batch_id: 2000, avg_cost: 3.8266634941101074
grad_norm: 0.5814456115117175, clipped: 0.5814456115117175
epoch: 95, train_batch_id: 2050, avg_cost: 3.804603099822998
grad_norm: 0.2935622140216903, clipped: 0.2935622140216903
epoch: 95, train_batch_id: 2100, avg_cost: 3.8380537033081055
grad_norm: 0.5958464723132786, clipped: 0.5958464723132786
epoch: 95, train_batch_id: 2150, avg_cost: 3.8719778060913086
grad_norm: 0.3438836571985372, clipped: 0.3438836571985372
epoch: 95, train_batch_id: 2200, avg_cost: 3.8390355110168457
grad_norm: 0.41070148035731696, clipped: 0.41070148035731696
epoch: 95, train_batch_id: 2250, avg_cost: 3.856015682220459
grad_norm: 0.2536689470068379, clipped: 0.2536689470068379
epoch: 95, train_batch_id: 2300, avg_cost: 3.8412179946899414
grad_norm: 0.2599844306181265, clipped: 0.2599844306181265
epoch: 95, train_batch_id: 2350, avg_cost: 3.853506088256836
grad_norm: 0.39827667653848264, clipped: 0.39827667653848264
epoch: 95, train_batch_id: 2400, avg_cost: 3.850065231323242
grad_norm: 0.24736250130227455, clipped: 0.24736250130227455
epoch: 95, train_batch_id: 2450, avg_cost: 3.8354787826538086
grad_norm: 0.5050118736343215, clipped: 0.5050118736343215
Finished epoch 95, took 00:05:31 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8449723720550537 +- 0.0030954829417169094
Evaluating candidate model on evaluation dataset
Epoch 95 candidate mean 3.8390066623687744, baseline epoch 92 mean 3.8395330905914307, difference -0.00052642822265625
p-value: 0.031010972173677577
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 96, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


157


epoch: 96, train_batch_id: 0, avg_cost: 3.8478221893310547
grad_norm: 0.2539697588933335, clipped: 0.2539697588933335
epoch: 96, train_batch_id: 50, avg_cost: 3.8393735885620117
grad_norm: 0.9200716921879626, clipped: 0.9200716921879626
epoch: 96, train_batch_id: 100, avg_cost: 3.8493692874908447
grad_norm: 0.29321191692529225, clipped: 0.29321191692529225
epoch: 96, train_batch_id: 150, avg_cost: 3.8769607543945312
grad_norm: 0.8548462866888041, clipped: 0.8548462866888041
epoch: 96, train_batch_id: 200, avg_cost: 3.8502426147460938
grad_norm: 0.26181515475425066, clipped: 0.26181515475425066
epoch: 96, train_batch_id: 250, avg_cost: 3.845609188079834
grad_norm: 0.5797516618422959, clipped: 0.5797516618422959
epoch: 96, train_batch_id: 300, avg_cost: 3.8326988220214844
grad_norm: 0.22418215567008032, clipped: 0.22418215567008032
epoch: 96, train_batch_id: 350, avg_cost: 3.851106643676758
grad_norm: 0.24212398976335373, clipped: 0.24212398976335373
epoch: 96, train_batch_id: 400, avg_cost: 3.834469795227051
grad_norm: 0.22698437596108606, clipped: 0.22698437596108606
epoch: 96, train_batch_id: 450, avg_cost: 3.8633227348327637
grad_norm: 0.2751122662819494, clipped: 0.2751122662819494
epoch: 96, train_batch_id: 500, avg_cost: 3.853886127471924
grad_norm: 0.3435135047618952, clipped: 0.3435135047618952
epoch: 96, train_batch_id: 550, avg_cost: 3.8539986610412598
grad_norm: 0.28032169994361106, clipped: 0.28032169994361106
epoch: 96, train_batch_id: 600, avg_cost: 3.845752239227295
grad_norm: 0.42180059510762546, clipped: 0.42180059510762546
epoch: 96, train_batch_id: 650, avg_cost: 3.8565785884857178
grad_norm: 0.8173483788503703, clipped: 0.8173483788503703
epoch: 96, train_batch_id: 700, avg_cost: 3.8486578464508057
grad_norm: 1.263835165924357, clipped: 1.0
epoch: 96, train_batch_id: 750, avg_cost: 3.862431049346924
grad_norm: 0.4467367080684966, clipped: 0.4467367080684966
epoch: 96, train_batch_id: 800, avg_cost: 3.84033203125
grad_norm: 0.23408696824640418, clipped: 0.23408696824640418
epoch: 96, train_batch_id: 850, avg_cost: 3.822871685028076
grad_norm: 0.32836651090433744, clipped: 0.32836651090433744
epoch: 96, train_batch_id: 900, avg_cost: 3.8376832008361816
grad_norm: 0.15818682114443267, clipped: 0.15818682114443267
epoch: 96, train_batch_id: 950, avg_cost: 3.832645893096924
grad_norm: 0.4716288778642578, clipped: 0.4716288778642578
epoch: 96, train_batch_id: 1000, avg_cost: 3.8644700050354004
grad_norm: 0.2769215518291778, clipped: 0.2769215518291778
epoch: 96, train_batch_id: 1050, avg_cost: 3.8660049438476562
grad_norm: 0.4294885213440412, clipped: 0.4294885213440412
epoch: 96, train_batch_id: 1100, avg_cost: 3.841696262359619
grad_norm: 0.18049187480608647, clipped: 0.18049187480608647
epoch: 96, train_batch_id: 1150, avg_cost: 3.836636543273926
grad_norm: 0.3167127315087783, clipped: 0.3167127315087783
epoch: 96, train_batch_id: 1200, avg_cost: 3.8223018646240234
grad_norm: 0.5401468211732845, clipped: 0.5401468211732845
epoch: 96, train_batch_id: 1250, avg_cost: 3.8465476036071777
grad_norm: 0.2512150934284609, clipped: 0.2512150934284609
epoch: 96, train_batch_id: 1300, avg_cost: 3.8432459831237793
grad_norm: 0.30825973935935624, clipped: 0.30825973935935624
epoch: 96, train_batch_id: 1350, avg_cost: 3.822373151779175
grad_norm: 0.2679278514434383, clipped: 0.2679278514434383
epoch: 96, train_batch_id: 1400, avg_cost: 3.854715347290039
grad_norm: 0.3387059622091725, clipped: 0.3387059622091725
epoch: 96, train_batch_id: 1450, avg_cost: 3.8594741821289062
grad_norm: 0.25307601332970314, clipped: 0.25307601332970314
epoch: 96, train_batch_id: 1500, avg_cost: 3.8440728187561035
grad_norm: 0.2539114068060722, clipped: 0.2539114068060722
epoch: 96, train_batch_id: 1550, avg_cost: 3.8345627784729004
grad_norm: 0.23536090066731563, clipped: 0.23536090066731563
epoch: 96, train_batch_id: 1600, avg_cost: 3.856027841567993
grad_norm: 0.4181337951475812, clipped: 0.4181337951475812
epoch: 96, train_batch_id: 1650, avg_cost: 3.8519058227539062
grad_norm: 0.2171346151194851, clipped: 0.2171346151194851
epoch: 96, train_batch_id: 1700, avg_cost: 3.8431429862976074
grad_norm: 0.21098504408242544, clipped: 0.21098504408242544
epoch: 96, train_batch_id: 1750, avg_cost: 3.8211898803710938
grad_norm: 0.4790552734307883, clipped: 0.4790552734307883
epoch: 96, train_batch_id: 1800, avg_cost: 3.844048500061035
grad_norm: 0.23830191789460567, clipped: 0.23830191789460567
epoch: 96, train_batch_id: 1850, avg_cost: 3.842545509338379
grad_norm: 0.2460246244573267, clipped: 0.2460246244573267
epoch: 96, train_batch_id: 1900, avg_cost: 3.847752571105957
grad_norm: 0.49655790259435073, clipped: 0.49655790259435073
epoch: 96, train_batch_id: 1950, avg_cost: 3.8377180099487305
grad_norm: 0.3100773862297061, clipped: 0.3100773862297061
epoch: 96, train_batch_id: 2000, avg_cost: 3.838700294494629
grad_norm: 0.21464898865631216, clipped: 0.21464898865631216
epoch: 96, train_batch_id: 2050, avg_cost: 3.8647103309631348
grad_norm: 1.267818833321116, clipped: 1.0
epoch: 96, train_batch_id: 2100, avg_cost: 3.838813304901123
grad_norm: 0.3313990636995889, clipped: 0.3313990636995889
epoch: 96, train_batch_id: 2150, avg_cost: 3.846992254257202
grad_norm: 0.40355456224839087, clipped: 0.40355456224839087
epoch: 96, train_batch_id: 2200, avg_cost: 3.8346288204193115
grad_norm: 0.31491102807039595, clipped: 0.31491102807039595
epoch: 96, train_batch_id: 2250, avg_cost: 3.8634700775146484
grad_norm: 0.3500538194757937, clipped: 0.3500538194757937
epoch: 96, train_batch_id: 2300, avg_cost: 3.847909927368164
grad_norm: 0.3714986543738302, clipped: 0.3714986543738302
epoch: 96, train_batch_id: 2350, avg_cost: 3.8521888256073
grad_norm: 0.27526021943149737, clipped: 0.27526021943149737
epoch: 96, train_batch_id: 2400, avg_cost: 3.8541529178619385
grad_norm: 0.24257887840344183, clipped: 0.24257887840344183
epoch: 96, train_batch_id: 2450, avg_cost: 3.824038505554199
grad_norm: 0.35093218633957446, clipped: 0.35093218633957446
Finished epoch 96, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.844501495361328 +- 0.003093527629971504
Evaluating candidate model on evaluation dataset
Epoch 96 candidate mean 3.845046043395996, baseline epoch 95 mean 3.8457164764404297, difference -0.0006704330444335938
p-value: 0.0029759833199092395
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 97, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


157


epoch: 97, train_batch_id: 0, avg_cost: 3.8686575889587402
grad_norm: 0.18439291540478475, clipped: 0.18439291540478475
epoch: 97, train_batch_id: 50, avg_cost: 3.860788345336914
grad_norm: 0.3523958473777206, clipped: 0.3523958473777206
epoch: 97, train_batch_id: 100, avg_cost: 3.8320205211639404
grad_norm: 0.32776842875666684, clipped: 0.32776842875666684
epoch: 97, train_batch_id: 150, avg_cost: 3.8661317825317383
grad_norm: 0.7414797285501432, clipped: 0.7414797285501432
epoch: 97, train_batch_id: 200, avg_cost: 3.8567919731140137
grad_norm: 0.6815061361932032, clipped: 0.6815061361932032
epoch: 97, train_batch_id: 250, avg_cost: 3.844696044921875
grad_norm: 0.360788584097437, clipped: 0.360788584097437
epoch: 97, train_batch_id: 300, avg_cost: 3.8338851928710938
grad_norm: 0.26713291270067563, clipped: 0.26713291270067563
epoch: 97, train_batch_id: 350, avg_cost: 3.845160961151123
grad_norm: 0.20133757915533418, clipped: 0.20133757915533418
epoch: 97, train_batch_id: 400, avg_cost: 3.846043825149536
grad_norm: 0.4723501675032151, clipped: 0.4723501675032151
epoch: 97, train_batch_id: 450, avg_cost: 3.8536312580108643
grad_norm: 0.228048281108171, clipped: 0.228048281108171
epoch: 97, train_batch_id: 500, avg_cost: 3.8620448112487793
grad_norm: 0.684719858300172, clipped: 0.684719858300172
epoch: 97, train_batch_id: 550, avg_cost: 3.8514180183410645
grad_norm: 0.23578140102861456, clipped: 0.23578140102861456
epoch: 97, train_batch_id: 600, avg_cost: 3.8529908657073975
grad_norm: 0.2957416257578206, clipped: 0.2957416257578206
epoch: 97, train_batch_id: 650, avg_cost: 3.8284881114959717
grad_norm: 0.1907899868952961, clipped: 0.1907899868952961
epoch: 97, train_batch_id: 700, avg_cost: 3.827390670776367
grad_norm: 0.3831159159122473, clipped: 0.3831159159122473
epoch: 97, train_batch_id: 750, avg_cost: 3.84834361076355
grad_norm: 0.3330857613422626, clipped: 0.3330857613422626
epoch: 97, train_batch_id: 800, avg_cost: 3.8522770404815674
grad_norm: 0.26092679006154024, clipped: 0.26092679006154024
epoch: 97, train_batch_id: 850, avg_cost: 3.838947296142578
grad_norm: 0.24734300366524584, clipped: 0.24734300366524584
epoch: 97, train_batch_id: 900, avg_cost: 3.8418853282928467
grad_norm: 0.3519978059497131, clipped: 0.3519978059497131
epoch: 97, train_batch_id: 950, avg_cost: 3.8521337509155273
grad_norm: 0.2065068616615405, clipped: 0.2065068616615405
epoch: 97, train_batch_id: 1000, avg_cost: 3.8474864959716797
grad_norm: 0.24636922709354153, clipped: 0.24636922709354153
epoch: 97, train_batch_id: 1050, avg_cost: 3.8487226963043213
grad_norm: 0.3980163076977687, clipped: 0.3980163076977687
epoch: 97, train_batch_id: 1100, avg_cost: 3.8471462726593018
grad_norm: 0.2927910708056889, clipped: 0.2927910708056889
epoch: 97, train_batch_id: 1150, avg_cost: 3.866107940673828
grad_norm: 0.3280363757823079, clipped: 0.3280363757823079
epoch: 97, train_batch_id: 1200, avg_cost: 3.8618431091308594
grad_norm: 0.20507821814590912, clipped: 0.20507821814590912
epoch: 97, train_batch_id: 1250, avg_cost: 3.8562350273132324
grad_norm: 0.23255741344709066, clipped: 0.23255741344709066
epoch: 97, train_batch_id: 1300, avg_cost: 3.821223735809326
grad_norm: 0.40870561994218746, clipped: 0.40870561994218746
epoch: 97, train_batch_id: 1350, avg_cost: 3.836247205734253
grad_norm: 0.4307491336221624, clipped: 0.4307491336221624
epoch: 97, train_batch_id: 1400, avg_cost: 3.8368005752563477
grad_norm: 0.2554983246293156, clipped: 0.2554983246293156
epoch: 97, train_batch_id: 1450, avg_cost: 3.857266664505005
grad_norm: 0.40788091025016926, clipped: 0.40788091025016926
epoch: 97, train_batch_id: 1500, avg_cost: 3.8459091186523438
grad_norm: 0.35866842797296133, clipped: 0.35866842797296133
epoch: 97, train_batch_id: 1550, avg_cost: 3.835031032562256
grad_norm: 0.3488777019211966, clipped: 0.3488777019211966
epoch: 97, train_batch_id: 1600, avg_cost: 3.8595995903015137
grad_norm: 0.23065558768298738, clipped: 0.23065558768298738
epoch: 97, train_batch_id: 1650, avg_cost: 3.85551118850708
grad_norm: 0.19489835619187518, clipped: 0.19489835619187518
epoch: 97, train_batch_id: 1700, avg_cost: 3.842641830444336
grad_norm: 0.44899788697338494, clipped: 0.44899788697338494
epoch: 97, train_batch_id: 1750, avg_cost: 3.8328540325164795
grad_norm: 0.44501217300546875, clipped: 0.44501217300546875
epoch: 97, train_batch_id: 1800, avg_cost: 3.8441359996795654
grad_norm: 0.3116335849341748, clipped: 0.3116335849341748
epoch: 97, train_batch_id: 1850, avg_cost: 3.8556768894195557
grad_norm: 0.13927055152521375, clipped: 0.13927055152521375
epoch: 97, train_batch_id: 1900, avg_cost: 3.8422584533691406
grad_norm: 0.19598881296334125, clipped: 0.19598881296334125
epoch: 97, train_batch_id: 1950, avg_cost: 3.8336410522460938
grad_norm: 0.20988921802603902, clipped: 0.20988921802603902
epoch: 97, train_batch_id: 2000, avg_cost: 3.8599491119384766
grad_norm: 0.242374555883587, clipped: 0.242374555883587
epoch: 97, train_batch_id: 2050, avg_cost: 3.849292516708374
grad_norm: 0.2759356353375556, clipped: 0.2759356353375556
epoch: 97, train_batch_id: 2100, avg_cost: 3.84649920463562
grad_norm: 0.3656274781083891, clipped: 0.3656274781083891
epoch: 97, train_batch_id: 2150, avg_cost: 3.861563205718994
grad_norm: 0.3110267386633419, clipped: 0.3110267386633419
epoch: 97, train_batch_id: 2200, avg_cost: 3.8382701873779297
grad_norm: 0.2727712307829398, clipped: 0.2727712307829398
epoch: 97, train_batch_id: 2250, avg_cost: 3.827801465988159
grad_norm: 0.30726555702134545, clipped: 0.30726555702134545
epoch: 97, train_batch_id: 2300, avg_cost: 3.845731735229492
grad_norm: 0.2758734241863695, clipped: 0.2758734241863695
epoch: 97, train_batch_id: 2350, avg_cost: 3.850447654724121
grad_norm: 0.2840461188275236, clipped: 0.2840461188275236
epoch: 97, train_batch_id: 2400, avg_cost: 3.833928108215332
grad_norm: 0.3329640550691458, clipped: 0.3329640550691458
epoch: 97, train_batch_id: 2450, avg_cost: 3.8497352600097656
grad_norm: 0.24024946253567261, clipped: 0.24024946253567261
Finished epoch 97, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.8442561626434326 +- 0.0030955160036683083
Evaluating candidate model on evaluation dataset
Epoch 97 candidate mean 3.841840982437134, baseline epoch 96 mean 3.8422772884368896, difference -0.0004363059997558594
p-value: 0.03597281746427105
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 98, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


157


epoch: 98, train_batch_id: 0, avg_cost: 3.8269729614257812
grad_norm: 0.31133952236598034, clipped: 0.31133952236598034
epoch: 98, train_batch_id: 50, avg_cost: 3.846721887588501
grad_norm: 0.2617499546051434, clipped: 0.2617499546051434
epoch: 98, train_batch_id: 100, avg_cost: 3.8370399475097656
grad_norm: 0.48664484796132185, clipped: 0.48664484796132185
epoch: 98, train_batch_id: 150, avg_cost: 3.854515314102173
grad_norm: 0.25995886528998113, clipped: 0.25995886528998113
epoch: 98, train_batch_id: 200, avg_cost: 3.8411076068878174
grad_norm: 0.2424698074873913, clipped: 0.2424698074873913
epoch: 98, train_batch_id: 250, avg_cost: 3.8540050983428955
grad_norm: 0.33813799651035725, clipped: 0.33813799651035725
epoch: 98, train_batch_id: 300, avg_cost: 3.8508381843566895
grad_norm: 0.23723422272818603, clipped: 0.23723422272818603
epoch: 98, train_batch_id: 350, avg_cost: 3.8489391803741455
grad_norm: 0.29238824127500285, clipped: 0.29238824127500285
epoch: 98, train_batch_id: 400, avg_cost: 3.8386311531066895
grad_norm: 0.2104824939601892, clipped: 0.2104824939601892
epoch: 98, train_batch_id: 450, avg_cost: 3.841986656188965
grad_norm: 0.2773372486355233, clipped: 0.2773372486355233
epoch: 98, train_batch_id: 500, avg_cost: 3.843015670776367
grad_norm: 0.62860524578637, clipped: 0.62860524578637
epoch: 98, train_batch_id: 550, avg_cost: 3.8434553146362305
grad_norm: 0.209793267412328, clipped: 0.209793267412328
epoch: 98, train_batch_id: 600, avg_cost: 3.822648286819458
grad_norm: 0.33264454300930557, clipped: 0.33264454300930557
epoch: 98, train_batch_id: 650, avg_cost: 3.8629026412963867
grad_norm: 0.2599906602126893, clipped: 0.2599906602126893
epoch: 98, train_batch_id: 700, avg_cost: 3.8557076454162598
grad_norm: 0.25414913336006334, clipped: 0.25414913336006334
epoch: 98, train_batch_id: 750, avg_cost: 3.842548370361328
grad_norm: 0.27984428647361653, clipped: 0.27984428647361653
epoch: 98, train_batch_id: 800, avg_cost: 3.838663339614868
grad_norm: 0.22336490559645103, clipped: 0.22336490559645103
epoch: 98, train_batch_id: 850, avg_cost: 3.8497238159179688
grad_norm: 0.3264401902610777, clipped: 0.3264401902610777
epoch: 98, train_batch_id: 900, avg_cost: 3.860764980316162
grad_norm: 0.6440145769098787, clipped: 0.6440145769098787
epoch: 98, train_batch_id: 950, avg_cost: 3.857215404510498
grad_norm: 0.2636782246952196, clipped: 0.2636782246952196
epoch: 98, train_batch_id: 1000, avg_cost: 3.8332486152648926
grad_norm: 0.23010643235424041, clipped: 0.23010643235424041
epoch: 98, train_batch_id: 1050, avg_cost: 3.8534395694732666
grad_norm: 1.1320464991316497, clipped: 1.0
epoch: 98, train_batch_id: 1100, avg_cost: 3.848086357116699
grad_norm: 0.17459830967590823, clipped: 0.17459830967590823
epoch: 98, train_batch_id: 1150, avg_cost: 3.8469481468200684
grad_norm: 0.5756895333416815, clipped: 0.5756895333416815
epoch: 98, train_batch_id: 1200, avg_cost: 3.857520580291748
grad_norm: 0.23520804392839637, clipped: 0.23520804392839637
epoch: 98, train_batch_id: 1250, avg_cost: 3.8392980098724365
grad_norm: 0.39581084373247316, clipped: 0.39581084373247316
epoch: 98, train_batch_id: 1300, avg_cost: 3.8421928882598877
grad_norm: 0.24649094256752618, clipped: 0.24649094256752618
epoch: 98, train_batch_id: 1350, avg_cost: 3.8478970527648926
grad_norm: 0.644409942615918, clipped: 0.644409942615918
epoch: 98, train_batch_id: 1400, avg_cost: 3.8613080978393555
grad_norm: 0.27917528128856806, clipped: 0.27917528128856806
epoch: 98, train_batch_id: 1450, avg_cost: 3.8442697525024414
grad_norm: 0.19793327005874456, clipped: 0.19793327005874456
epoch: 98, train_batch_id: 1500, avg_cost: 3.855884552001953
grad_norm: 0.24017665123487342, clipped: 0.24017665123487342
epoch: 98, train_batch_id: 1550, avg_cost: 3.8634376525878906
grad_norm: 1.0919581294089218, clipped: 1.0
epoch: 98, train_batch_id: 1600, avg_cost: 3.8496649265289307
grad_norm: 0.2750393365893214, clipped: 0.2750393365893214
epoch: 98, train_batch_id: 1650, avg_cost: 3.8262078762054443
grad_norm: 0.2566275741596213, clipped: 0.2566275741596213
epoch: 98, train_batch_id: 1700, avg_cost: 3.8584234714508057
grad_norm: 0.2376517624895962, clipped: 0.2376517624895962
epoch: 98, train_batch_id: 1750, avg_cost: 3.8404483795166016
grad_norm: 0.2806488936736882, clipped: 0.2806488936736882
epoch: 98, train_batch_id: 1800, avg_cost: 3.8351526260375977
grad_norm: 0.33220022674928423, clipped: 0.33220022674928423
epoch: 98, train_batch_id: 1850, avg_cost: 3.8434250354766846
grad_norm: 0.4516073569532335, clipped: 0.4516073569532335
epoch: 98, train_batch_id: 1900, avg_cost: 3.840519905090332
grad_norm: 0.33566673294432, clipped: 0.33566673294432
epoch: 98, train_batch_id: 1950, avg_cost: 3.8510568141937256
grad_norm: 0.27795526841655777, clipped: 0.27795526841655777
epoch: 98, train_batch_id: 2000, avg_cost: 3.845398426055908
grad_norm: 0.29335465121660226, clipped: 0.29335465121660226
epoch: 98, train_batch_id: 2050, avg_cost: 3.8547277450561523
grad_norm: 0.43758248033279934, clipped: 0.43758248033279934
epoch: 98, train_batch_id: 2100, avg_cost: 3.8219051361083984
grad_norm: 0.2835682630503857, clipped: 0.2835682630503857
epoch: 98, train_batch_id: 2150, avg_cost: 3.820096969604492
grad_norm: 0.23715893654077838, clipped: 0.23715893654077838
epoch: 98, train_batch_id: 2200, avg_cost: 3.8434677124023438
grad_norm: 0.4640811919141023, clipped: 0.4640811919141023
epoch: 98, train_batch_id: 2250, avg_cost: 3.8273544311523438
grad_norm: 0.25351150590980875, clipped: 0.25351150590980875
epoch: 98, train_batch_id: 2300, avg_cost: 3.8407819271087646
grad_norm: 0.2621361097443956, clipped: 0.2621361097443956
epoch: 98, train_batch_id: 2350, avg_cost: 3.834078550338745
grad_norm: 0.19477451663963957, clipped: 0.19477451663963957
epoch: 98, train_batch_id: 2400, avg_cost: 3.848268985748291
grad_norm: 0.49192462657338576, clipped: 0.49192462657338576
epoch: 98, train_batch_id: 2450, avg_cost: 3.8257012367248535
grad_norm: 0.24062565571164216, clipped: 0.24062565571164216
Finished epoch 98, took 00:05:33 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.844482898712158 +- 0.0030978797003626823
Evaluating candidate model on evaluation dataset
Epoch 98 candidate mean 3.838855504989624, baseline epoch 97 mean 3.839346408843994, difference -0.0004909038543701172
p-value: 0.01833544632272958
Update baseline
Evaluating baseline model on evaluation dataset
Start train epoch 99, lr=0.0001 for run tsp20_rollout_20200202T054904
Evaluating baseline on dataset...
314


314


314


314


314


epoch: 99, train_batch_id: 0, avg_cost: 3.838864803314209
grad_norm: 0.2847589679391986, clipped: 0.2847589679391986
epoch: 99, train_batch_id: 50, avg_cost: 3.8456389904022217
grad_norm: 0.2546304913279198, clipped: 0.2546304913279198
epoch: 99, train_batch_id: 100, avg_cost: 3.833850622177124
grad_norm: 0.2730905162753124, clipped: 0.2730905162753124
epoch: 99, train_batch_id: 150, avg_cost: 3.845806837081909
grad_norm: 0.42529498370971985, clipped: 0.42529498370971985
epoch: 99, train_batch_id: 200, avg_cost: 3.841973066329956
grad_norm: 0.5858103835819184, clipped: 0.5858103835819184
epoch: 99, train_batch_id: 250, avg_cost: 3.8471450805664062
grad_norm: 0.2944611196571988, clipped: 0.2944611196571988
epoch: 99, train_batch_id: 300, avg_cost: 3.8334574699401855
grad_norm: 0.24026274360826877, clipped: 0.24026274360826877
epoch: 99, train_batch_id: 350, avg_cost: 3.8465592861175537
grad_norm: 0.4480516379761234, clipped: 0.4480516379761234
epoch: 99, train_batch_id: 400, avg_cost: 3.838714838027954
grad_norm: 0.19402345776831198, clipped: 0.19402345776831198
epoch: 99, train_batch_id: 450, avg_cost: 3.8367433547973633
grad_norm: 0.23949941085186688, clipped: 0.23949941085186688
epoch: 99, train_batch_id: 500, avg_cost: 3.854365825653076
grad_norm: 0.31311785794647984, clipped: 0.31311785794647984
epoch: 99, train_batch_id: 550, avg_cost: 3.8502297401428223
grad_norm: 0.28900052660697684, clipped: 0.28900052660697684
epoch: 99, train_batch_id: 600, avg_cost: 3.8352997303009033
grad_norm: 0.6394451891055265, clipped: 0.6394451891055265
epoch: 99, train_batch_id: 650, avg_cost: 3.8523428440093994
grad_norm: 0.26667111769219415, clipped: 0.26667111769219415
epoch: 99, train_batch_id: 700, avg_cost: 3.845714569091797
grad_norm: 0.4238957125577208, clipped: 0.4238957125577208
epoch: 99, train_batch_id: 750, avg_cost: 3.853681802749634
grad_norm: 0.4045875591103225, clipped: 0.4045875591103225
epoch: 99, train_batch_id: 800, avg_cost: 3.868593215942383
grad_norm: 0.29443294121426966, clipped: 0.29443294121426966
epoch: 99, train_batch_id: 850, avg_cost: 3.846147060394287
grad_norm: 0.39124527397200154, clipped: 0.39124527397200154
epoch: 99, train_batch_id: 900, avg_cost: 3.822381019592285
grad_norm: 0.18181692812699296, clipped: 0.18181692812699296
epoch: 99, train_batch_id: 950, avg_cost: 3.870157241821289
grad_norm: 0.2128269310650254, clipped: 0.2128269310650254
epoch: 99, train_batch_id: 1000, avg_cost: 3.8405935764312744
grad_norm: 0.2517745314487253, clipped: 0.2517745314487253
epoch: 99, train_batch_id: 1050, avg_cost: 3.8492918014526367
grad_norm: 0.2845947279104716, clipped: 0.2845947279104716
epoch: 99, train_batch_id: 1100, avg_cost: 3.8704512119293213
grad_norm: 0.2701303812924789, clipped: 0.2701303812924789
epoch: 99, train_batch_id: 1150, avg_cost: 3.8156535625457764
grad_norm: 0.3510099801226851, clipped: 0.3510099801226851
epoch: 99, train_batch_id: 1200, avg_cost: 3.846597671508789
grad_norm: 0.37157959510011856, clipped: 0.37157959510011856
epoch: 99, train_batch_id: 1250, avg_cost: 3.8350958824157715
grad_norm: 0.22558012641397776, clipped: 0.22558012641397776
epoch: 99, train_batch_id: 1300, avg_cost: 3.8413665294647217
grad_norm: 0.39279156383504266, clipped: 0.39279156383504266
epoch: 99, train_batch_id: 1350, avg_cost: 3.8372559547424316
grad_norm: 0.35306829853111693, clipped: 0.35306829853111693
epoch: 99, train_batch_id: 1400, avg_cost: 3.8623056411743164
grad_norm: 0.22115525335241304, clipped: 0.22115525335241304
epoch: 99, train_batch_id: 1450, avg_cost: 3.8170177936553955
grad_norm: 0.23471255658190113, clipped: 0.23471255658190113
epoch: 99, train_batch_id: 1500, avg_cost: 3.859827995300293
grad_norm: 0.3036499423492196, clipped: 0.3036499423492196
epoch: 99, train_batch_id: 1550, avg_cost: 3.8324227333068848
grad_norm: 0.34782998387239256, clipped: 0.34782998387239256
epoch: 99, train_batch_id: 1600, avg_cost: 3.8501057624816895
grad_norm: 0.19888703270420188, clipped: 0.19888703270420188
epoch: 99, train_batch_id: 1650, avg_cost: 3.8339099884033203
grad_norm: 0.37953909918103207, clipped: 0.37953909918103207
epoch: 99, train_batch_id: 1700, avg_cost: 3.8460373878479004
grad_norm: 0.23110492519880782, clipped: 0.23110492519880782
epoch: 99, train_batch_id: 1750, avg_cost: 3.843200206756592
grad_norm: 0.2867202395270536, clipped: 0.2867202395270536
epoch: 99, train_batch_id: 1800, avg_cost: 3.80849552154541
grad_norm: 0.3223064992779578, clipped: 0.3223064992779578
epoch: 99, train_batch_id: 1850, avg_cost: 3.8529915809631348
grad_norm: 0.2346806554078719, clipped: 0.2346806554078719
epoch: 99, train_batch_id: 1900, avg_cost: 3.844686269760132
grad_norm: 0.2346035415136402, clipped: 0.2346035415136402
epoch: 99, train_batch_id: 1950, avg_cost: 3.8419156074523926
grad_norm: 0.29762322327735197, clipped: 0.29762322327735197
epoch: 99, train_batch_id: 2000, avg_cost: 3.8411409854888916
grad_norm: 0.3504658983826555, clipped: 0.3504658983826555
epoch: 99, train_batch_id: 2050, avg_cost: 3.845205068588257
grad_norm: 0.28247862381950184, clipped: 0.28247862381950184
epoch: 99, train_batch_id: 2100, avg_cost: 3.8393325805664062
grad_norm: 0.22419157252096153, clipped: 0.22419157252096153
epoch: 99, train_batch_id: 2150, avg_cost: 3.8177032470703125
grad_norm: 0.24916216629083354, clipped: 0.24916216629083354
epoch: 99, train_batch_id: 2200, avg_cost: 3.83724308013916
grad_norm: 0.26668601576375967, clipped: 0.26668601576375967
epoch: 99, train_batch_id: 2250, avg_cost: 3.84187388420105
grad_norm: 0.7072046792005822, clipped: 0.7072046792005822
epoch: 99, train_batch_id: 2300, avg_cost: 3.8535008430480957
grad_norm: 0.27907855073599624, clipped: 0.27907855073599624
epoch: 99, train_batch_id: 2350, avg_cost: 3.8680238723754883
grad_norm: 0.32787195694248905, clipped: 0.32787195694248905
epoch: 99, train_batch_id: 2400, avg_cost: 3.852468729019165
grad_norm: 0.21266957692961355, clipped: 0.21266957692961355
epoch: 99, train_batch_id: 2450, avg_cost: 3.8565521240234375
grad_norm: 0.25894036531629677, clipped: 0.25894036531629677
Finished epoch 99, took 00:05:32 s
Saving model and state...
Validating...
Validation overall avg_cost: 3.844339370727539 +- 0.0030935904942452908
Evaluating candidate model on evaluation dataset
Epoch 99 candidate mean 3.8438758850097656, baseline epoch 98 mean 3.843935966491699, difference -6.008148193359375e-05
p-value: 0.4008484227729548
0
